public class MetagunDesktop { public static void main ( String [ ] argv ) { <START_BUG> new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new Metagun ( ) , "Metagun" , 320 , 240 , false ) ; <END_BUG> } }<BUG2FIX>new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new Metagun ( ) , "Metagun" , 320 , 240 ) ;
public class BouncyDesktop { public static void main ( String [ ] argv ) { <START_BUG> new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new Bouncy ( ) , "Bouncy" , 320 , 480 ) ; <END_BUG> } }<BUG2FIX>new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new Bouncy ( ) , "Bouncy" , 320 , 480 , true ) ;
public class FilterBrowseActivity extends RoboFragmentActivity { @ Override protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; <START_BUG> setTitle ( getString ( saved_filters_title ) ) ; <END_BUG> setContentView ( issue_filter_list ) ; } }<BUG2FIX>setTitle ( saved_filters_title ) ;
public class MetaDataService extends AbstractComponent { private final ClusterService clusterService ; private final ShardsRoutingStrategy shardsRoutingStrategy ; private final IndicesService indicesService ; private final NodeIndexCreatedAction nodeIndexCreatedAction ; private final NodeIndexDeletedAction nodeIndexDeletedAction ; private final NodeMappingCreatedAction nodeMappingCreatedAction ; @ Inject public MetaDataService ( Settings settings , ClusterService clusterService , IndicesService indicesService , ShardsRoutingStrategy shardsRoutingStrategy , NodeIndexCreatedAction nodeIndexCreatedAction , NodeIndexDeletedAction nodeIndexDeletedAction , NodeMappingCreatedAction nodeMappingCreatedAction ) { } public synchronized MetaDataService . CreateIndexResult createIndex ( final String index , final Settings indexSettings , TimeValue timeout ) throws IndexAlreadyExistsException { } public synchronized MetaDataService . DeleteIndexResult deleteIndex ( final String index , TimeValue timeout ) throws IndexMissingException { } public synchronized void updateMapping ( final String index , final String type , final String mappingSource ) { } public synchronized MetaDataService . PutMappingResult putMapping ( final String [ ] indices , String mappingType , final String mappingSource , boolean ignoreConflicts , TimeValue timeout ) throws ElasticSearchException { ClusterState clusterState = clusterService . state ( ) ; for ( String index : indices ) { IndexRoutingTable indexTable = clusterState . routingTable ( ) . indicesRouting ( ) . get ( index ) ; if ( indexTable == null ) { throw new IndexMissingException ( new Index ( index ) ) ; } } Map < String , DocumentMapper > newMappers = Maps . newHashMap ( ) ; Map < String , DocumentMapper > existingMappers = Maps . newHashMap ( ) ; for ( String index : indices ) { IndexService indexService = indicesService . indexService ( index ) ; if ( indexService != null ) { DocumentMapper newMapper = indexService . mapperService ( ) . parse ( mappingType , mappingSource ) ; newMappers . put ( index , newMapper ) ; DocumentMapper existingMapper = indexService . mapperService ( ) . documentMapper ( mappingType ) ; if ( existingMapper != null ) { DocumentMapper . MergeResult mergeResult = existingMapper . merge ( newMapper , mergeFlags ( ) . simulate ( true ) ) ; if ( ( ! ignoreConflicts ) && ( mergeResult . hasConflicts ( ) ) ) { throw new org . elasticsearch . index . mapper . MergeMappingException ( mergeResult . conflicts ( ) ) ; } <START_BUG> existingMappers . put ( index , newMapper ) ; <END_BUG> } } else { throw new IndexMissingException ( new Index ( index ) ) ; } } if ( mappingType == null ) { mappingType = newMappers . values ( ) . iterator ( ) . next ( ) . type ( ) ; } else if ( ! ( mappingType . equals ( newMappers . values ( ) . iterator ( ) . next ( ) . type ( ) ) ) ) { throw new InvalidTypeNameException ( "Type<seq2seq4repair_space>name<seq2seq4repair_space>provided<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>match<seq2seq4repair_space>type<seq2seq4repair_space>name<seq2seq4repair_space>within<seq2seq4repair_space>mapping<seq2seq4repair_space>definition" ) ; } if ( ( mappingType . charAt ( 0 ) ) == '_' ) { throw new InvalidTypeNameException ( "Document<seq2seq4repair_space>mapping<seq2seq4repair_space>type<seq2seq4repair_space>name<seq2seq4repair_space>can't<seq2seq4repair_space>start<seq2seq4repair_space>with<seq2seq4repair_space>'_'" ) ; } final Map < String , Tuple < String , String > > mappings = Maps . newHashMap ( ) ; for ( Map . Entry < String , DocumentMapper > entry : newMappers . entrySet ( ) ) { Tuple < String , String > mapping ; String index = entry . getKey ( ) ; DocumentMapper newMapper = entry . getValue ( ) ; if ( existingMappers . containsKey ( entry . getKey ( ) ) ) { DocumentMapper existingMapper = existingMappers . get ( entry . getKey ( ) ) ; existingMapper . merge ( newMapper , mergeFlags ( ) . simulate ( false ) ) ; mapping = new Tuple < String , String > ( existingMapper . type ( ) , existingMapper . buildSource ( ) ) ; } else { mapping = new Tuple < String , String > ( newMapper . type ( ) , newMapper . buildSource ( ) ) ; } mappings . put ( index , mapping ) ; logger . info ( ( ( ( ( ( ( "Index<seq2seq4repair_space>[" + index ) + "]:<seq2seq4repair_space>Put<seq2seq4repair_space>mapping<seq2seq4repair_space>[" ) + ( mapping . v1 ( ) ) ) + "]<seq2seq4repair_space>with<seq2seq4repair_space>source<seq2seq4repair_space>[" ) + ( mapping . v2 ( ) ) ) + "]" ) ) ; } final CountDownLatch latch = new CountDownLatch ( ( ( clusterService . state ( ) . nodes ( ) . size ( ) ) * ( indices . length ) ) ) ; final Set < String > indicesSet = Sets . newHashSet ( indices ) ; final String fMappingType = mappingType ; NodeMappingCreatedAction . Listener listener = new NodeMappingCreatedAction . Listener ( ) { @ Override public void onNodeMappingCreated ( NodeMappingCreatedAction . NodeMappingCreatedResponse response ) { if ( ( indicesSet . contains ( response . index ( ) ) ) && ( response . type ( ) . equals ( fMappingType ) ) ) { latch . countDown ( ) ; } } } ; nodeMappingCreatedAction . add ( listener ) ; clusterService . submitStateUpdateTask ( ( ( "put-mapping<seq2seq4repair_space>[" + mappingType ) + "]" ) , new ClusterStateUpdateTask ( ) { @ Override public ClusterState execute ( ClusterState currentState ) { MetaData . MetaData . Builder builder = newMetaDataBuilder ( ) . metaData ( currentState . metaData ( ) ) ; for ( String indexName : indices ) { IndexMetaData . IndexMetaData indexMetaData = currentState . metaData ( ) . index ( indexName ) ; if ( indexMetaData == null ) { throw new IndexMissingException ( new Index ( indexName ) ) ; } Tuple < String , String > mapping = mappings . get ( indexName ) ; builder . put ( newIndexMetaDataBuilder ( indexMetaData ) . putMapping ( mapping . v1 ( ) , mapping . v2 ( ) ) ) ; } return newClusterStateBuilder ( ) . state ( currentState ) . metaData ( builder ) . build ( ) ; } } ) ; boolean acknowledged ; try { acknowledged = latch . await ( timeout . millis ( ) , TimeUnit . MILLISECONDS ) ; }<BUG2FIX>existingMappers . put ( index , existingMapper ) ;
public class MoreLikeThisFieldQueryParser extends AbstractIndexComponent implements XContentQueryParser { public static final String NAME = "mlt_field" ; public MoreLikeThisFieldQueryParser ( Index index , @ IndexSettings Settings indexSettings ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; XContentParser . Token token = parser . nextToken ( ) ; assert token == ( Token . FIELD_NAME ) ; String fieldName = parser . currentName ( ) ; token = parser . nextToken ( ) ; assert token == ( Token . START_OBJECT ) ; MoreLikeThisQuery mltQuery = new MoreLikeThisQuery ( ) ; mltQuery . setSimilarity ( parseContext . searchSimilarity ( ) ) ; String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token . isValue ( ) ) { if ( "like_text" . equals ( currentFieldName ) ) { mltQuery . setLikeText ( parser . text ( ) ) ; } else if ( ( "min_term_freq" . equals ( currentFieldName ) ) || ( "minTermFreq" . equals ( currentFieldName ) ) ) { mltQuery . setMinTermFrequency ( parser . intValue ( ) ) ; } else if ( ( "max_query_terms" . equals ( currentFieldName ) ) || ( "maxQueryTerms" . equals ( currentFieldName ) ) ) { mltQuery . setMaxQueryTerms ( parser . intValue ( ) ) ; } else if ( ( "min_doc_freq" . equals ( currentFieldName ) ) || ( "minDocFreq" . equals ( currentFieldName ) ) ) { mltQuery . setMinDocFreq ( parser . intValue ( ) ) ; } else if ( ( "max_doc_freq" . equals ( currentFieldName ) ) || ( "maxDocFreq" . equals ( currentFieldName ) ) ) { mltQuery . setMaxDocFreq ( parser . intValue ( ) ) ; } else if ( ( "min_word_len" . equals ( currentFieldName ) ) || ( "minWordLen" . equals ( currentFieldName ) ) ) { mltQuery . setMinWordLen ( parser . intValue ( ) ) ; } else if ( ( "max_word_len" . equals ( currentFieldName ) ) || ( "maxWordLen" . equals ( currentFieldName ) ) ) { mltQuery . setMaxWordLen ( parser . intValue ( ) ) ; } else if ( ( "boost_terms" . equals ( currentFieldName ) ) || ( "boostTerms" . equals ( currentFieldName ) ) ) { mltQuery . setBoostTerms ( true ) ; mltQuery . setBoostTermsFactor ( parser . floatValue ( ) ) ; } else if ( ( "percent_terms_to_match" . equals ( currentFieldName ) ) || ( "percentTermsToMatch" . equals ( currentFieldName ) ) ) { mltQuery . setPercentTermsToMatch ( parser . floatValue ( ) ) ; } } else if ( token == ( Token . START_ARRAY ) ) { if ( ( "stop_words" . equals ( currentFieldName ) ) || ( "stopWords" . equals ( currentFieldName ) ) ) { Set < String > stopWords = Sets . newHashSet ( ) ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_ARRAY ) ) { stopWords . add ( parser . text ( ) ) ; } mltQuery . setStopWords ( stopWords ) ; } } } if ( ( mltQuery . getLikeText ( ) ) == null ) { throw new QueryParsingException ( index , "more_like_this_field<seq2seq4repair_space>requires<seq2seq4repair_space>'like_text'<seq2seq4repair_space>to<seq2seq4repair_space>be<seq2seq4repair_space>specified" ) ; } token = parser . nextToken ( ) ; assert token == ( Token . END_OBJECT ) ; MapperService . SmartNameFieldMappers smartNameFieldMappers = parseContext . smartFieldMappers ( fieldName ) ; if ( smartNameFieldMappers != null ) { if ( smartNameFieldMappers . hasMapper ( ) ) { fieldName = smartNameFieldMappers . mapper ( ) . names ( ) . indexName ( ) ; mltQuery . setAnalyzer ( smartNameFieldMappers . mapper ( ) . searchAnalyzer ( ) ) ; } } if ( ( mltQuery . getAnalyzer ( ) ) == null ) { mltQuery . setAnalyzer ( parseContext . mapperService ( ) . searchAnalyzer ( ) ) ; } mltQuery . setMoreLikeFields ( new String [ ] { fieldName } ) ; <START_BUG> return wrapSmartNameQuery ( mltQuery , smartNameFieldMappers , parseContext . indexCache ( ) ) ; <END_BUG> } }<BUG2FIX>return wrapSmartNameQuery ( mltQuery , smartNameFieldMappers , parseContext ) ;
public class Fixture { private final World world ; private final Body body ; protected final long addr ; protected Shape shape ; protected Fixture ( World world , Body body , long addr ) { } public Type getType ( ) { } private native int jniGetType ( long addr ) { } public Shape getShape ( ) { if ( ( shape ) == null ) { long shapeAddr = jniGetShape ( addr ) ; <START_BUG> int type = Shape . jniGetType ( addr ) ; <END_BUG> if ( type == 0 ) shape = new CircleShape ( shapeAddr ) ; else shape = new PolygonShape ( shapeAddr ) ; } return shape ; } private native long jniGetShape ( long addr ) { } public void setSensor ( boolean sensor ) { } private native void jniSetSensor ( long addr , boolean sensor ) { } public boolean isSensor ( ) { } private native boolean jniIsSensor ( long addr ) { } public void setFilterData ( Filter filter ) { } private native void jniSetFilterData ( long addr , short categoryBits , short maskBits , short groupIndex ) { } private final short [ ] tmp = new short [ 3 ] ; private final Filter filter = new Filter ( ) ; public Filter getFilterData ( ) { } private native void jniGetFilterData ( long addr , short [ ] filter ) { } public Body getBody ( ) { } public boolean testPoint ( Vector2 p ) { } private native boolean jniTestPoint ( long addr , float x , float y ) { } public void setDensity ( float density ) { } private native void jniSetDensity ( long addr , float density ) { } public float getDensity ( ) { } private native float jniGetDensity ( long addr ) { } public float getFriction ( ) { } private native float jniGetFriction ( long addr ) { } public void setFriction ( float friction ) { } private native void jniSetFriction ( long addr , float friction ) { } public float getRestitution ( ) { } private native float jniGetRestitution ( long addr ) { } public void setRestitution ( float restitution ) { } private native void jniSetRestitution ( long addr , float restitution ) { } }<BUG2FIX>int type = Shape . jniGetType ( shapeAddr ) ;
public class TransportMultiGetAction extends TransportAction < MultiGetRequest , MultiGetResponse > { private final ClusterService clusterService ; private final TransportShardMultiGetAction shardAction ; @ Inject public TransportMultiGetAction ( Settings settings , ThreadPool threadPool , TransportService transportService , ClusterService clusterService , TransportShardMultiGetAction shardAction ) { } @ Override protected void doExecute ( final MultiGetRequest request , final ActionListener < MultiGetResponse > listener ) { } class TransportHandler extends BaseTransportRequestHandler < MultiGetRequest > { @ Override public MultiGetRequest newInstance ( ) { } @ Override public void messageReceived ( final MultiGetRequest request , final TransportChannel channel ) throws Exception { request . listenerThreaded ( false ) ; execute ( request , new ActionListener < MultiGetResponse > ( ) { @ Override public void onResponse ( MultiGetResponse response ) { try { channel . sendResponse ( response ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( e ) ; } catch ( Exception e1 ) { logger . warn ( ( ( ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>error<seq2seq4repair_space>response<seq2seq4repair_space>for<seq2seq4repair_space>action<seq2seq4repair_space>[" + ( MultiGetAction . NAME ) ) + "]<seq2seq4repair_space>and<seq2seq4repair_space>request<seq2seq4repair_space>[" ) + request ) + "]" ) , e1 ) ; } } } ) ; } @ Override public String executor ( ) { } } }<BUG2FIX>} catch ( Throwable e ) {
public class FacetsPhase implements SearchPhase { @ Override public Map < String , ? extends SearchParseElement > parseElements ( ) { } @ Override public void preProcess ( SearchContext context ) { } @ Override public void execute ( SearchContext context ) throws ElasticSearchException { if ( ( context . facets ( ) ) == null ) { return ; } if ( ( context . queryResult ( ) . facets ( ) ) != null ) { return ; } if ( ( context . searcher ( ) . globalCollectors ( ) ) != null ) { <START_BUG> Query query = new DeletionAwareConstantScoreQuery ( Queries . MATCH_ALL_FILTER ) ; <END_BUG> if ( ( context . types ( ) . length ) > 0 ) { if ( ( context . types ( ) . length ) == 1 ) { String type = context . types ( ) [ 0 ] ; DocumentMapper docMapper = context . mapperService ( ) . documentMapper ( type ) ; query = new FilteredQuery ( query , context . filterCache ( ) . cache ( docMapper . typeFilter ( ) ) ) ; } else { BooleanFilter booleanFilter = new BooleanFilter ( ) ; for ( String type : context . types ( ) ) { DocumentMapper docMapper = context . mapperService ( ) . documentMapper ( type ) ; booleanFilter . add ( new FilterClause ( context . filterCache ( ) . cache ( docMapper . typeFilter ( ) ) , Occur . SHOULD ) ) ; } query = new FilteredQuery ( query , booleanFilter ) ; } } context . searcher ( ) . useGlobalCollectors ( true ) ; try { context . searcher ( ) . search ( query , NOOP_COLLECTOR ) ; } catch ( IOException e ) { throw new org . elasticsearch . search . query . QueryPhaseExecutionException ( context , "Failed<seq2seq4repair_space>to<seq2seq4repair_space>execute<seq2seq4repair_space>global<seq2seq4repair_space>facets" , e ) ; } finally { context . searcher ( ) . useGlobalCollectors ( false ) ; } } SearchContextFacets contextFacets = context . facets ( ) ; List < Facet > facets = Lists . newArrayListWithCapacity ( 2 ) ; if ( ( contextFacets . facetCollectors ( ) ) != null ) { for ( FacetCollector facetCollector : contextFacets . facetCollectors ( ) ) { facets . add ( facetCollector . facet ( ) ) ; } } context . queryResult ( ) . facets ( new org . elasticsearch . search . facets . internal . InternalFacets ( facets ) ) ; } }<BUG2FIX>Query query = new DeletionAwareConstantScoreQuery ( Queries . MATCH_ALL_FILTER , true ) ;
public final class BytesRefOrdValComparator extends FieldComparator < BytesRef > { final IndexFieldData . WithOrdinals < ? > indexFieldData ; final int [ ] ords ; final SortMode sortMode ; final BytesRef [ ] values ; final int [ ] readerGen ; int currentReaderGen = - 1 ; WithOrdinals termsIndex ; int bottomSlot = - 1 ; int bottomOrd ; boolean bottomSameReader ; BytesRef bottomValue ; final BytesRef tempBR = new BytesRef ( ) ; public BytesRefOrdValComparator ( IndexFieldData . WithOrdinals < ? > indexFieldData , int numHits , SortMode sortMode ) { } @ Override public int compare ( int slot1 , int slot2 ) { } @ Override public int compareBottom ( int doc ) { } @ Override public void copy ( int slot , int doc ) { } @ Override public int compareDocToValue ( int doc , BytesRef value ) { } abstract class PerSegmentComparator extends FieldComparator < BytesRef > { @ Override public FieldComparator < BytesRef > setNextReader ( AtomicReaderContext context ) throws IOException { } @ Override public int compare ( int slot1 , int slot2 ) { } @ Override public void setBottom ( final int bottom ) { } @ Override public BytesRef value ( int slot ) { } @ Override public int compareValues ( BytesRef val1 , BytesRef val2 ) { } @ Override public int compareDocToValue ( int doc , BytesRef value ) { } } private final class ByteOrdComparator extends BytesRefOrdValComparator . PerSegmentComparator { private final byte [ ] readerOrds ; private final WithOrdinals termsIndex ; private final int docBase ; public ByteOrdComparator ( byte [ ] readerOrds , BytesValues . WithOrdinals termsIndex , int docBase ) { } @ Override public int compareBottom ( int doc ) { } @ Override public void copy ( int slot , int doc ) { } } private final class ShortOrdComparator extends BytesRefOrdValComparator . PerSegmentComparator { private final short [ ] readerOrds ; private final WithOrdinals termsIndex ; private final int docBase ; public ShortOrdComparator ( short [ ] readerOrds , BytesValues . WithOrdinals termsIndex , int docBase ) { } @ Override public int compareBottom ( int doc ) { } @ Override public void copy ( int slot , int doc ) { } } private final class IntOrdComparator extends BytesRefOrdValComparator . PerSegmentComparator { private final int [ ] readerOrds ; private final WithOrdinals termsIndex ; private final int docBase ; public IntOrdComparator ( int [ ] readerOrds , BytesValues . WithOrdinals termsIndex , int docBase ) { } @ Override public int compareBottom ( int doc ) { } @ Override public void copy ( int slot , int doc ) { } } final class AnyOrdComparator extends BytesRefOrdValComparator . PerSegmentComparator { private final IndexFieldData fieldData ; private final Docs readerOrds ; private final WithOrdinals termsIndex ; private final int docBase ; public AnyOrdComparator ( IndexFieldData fieldData , BytesValues . WithOrdinals termsIndex , int docBase ) { } @ Override public int compareBottom ( int doc ) { } @ Override public void copy ( int slot , int doc ) { } } @ Override public FieldComparator < BytesRef > setNextReader ( AtomicReaderContext context ) throws IOException { } @ Override public void setBottom ( final int bottom ) { } @ Override public BytesRef value ( int slot ) { } protected static final int binarySearch ( BytesValues . WithOrdinals a , BytesRef key ) { <START_BUG> return BytesRefOrdValComparator . binarySearch ( a , key , 1 , ( ( a . ordinals ( ) . getNumOrds ( ) ) - 1 ) ) ; <END_BUG> } protected static final int binarySearch ( BytesValues . WithOrdinals a , BytesRef key , int low , int high ) { } class MultiAnyOrdComparator extends BytesRefOrdValComparator . PerSegmentComparator { private final WithOrdinals termsIndex ; private final Docs readerOrds ; private MultiAnyOrdComparator ( BytesValues . WithOrdinals termsIndex ) { } @ Override public int compareBottom ( int doc ) throws IOException { } @ Override public void copy ( int slot , int doc ) throws IOException { } @ Override public int compareDocToValue ( int doc , BytesRef value ) { } } static BytesRef getRelevantValue ( BytesValues . WithOrdinals readerValues , int docId , SortMode sortMode ) { } static int getRelevantOrd ( Ordinals . Docs readerOrds , int docId , SortMode sortMode ) { } }<BUG2FIX>return BytesRefOrdValComparator . binarySearch ( a , key , 1 , a . ordinals ( ) . getNumOrds ( ) ) ;
public class TransportSearchScrollScanAction extends AbstractComponent { private final ClusterService clusterService ; private final SearchServiceTransportAction searchService ; private final SearchPhaseController searchPhaseController ; @ Inject public TransportSearchScrollScanAction ( Settings settings , ClusterService clusterService , SearchServiceTransportAction searchService , SearchPhaseController searchPhaseController ) { } public void execute ( SearchScrollRequest request , ParsedScrollId scrollId , ActionListener < SearchResponse > listener ) { } private class AsyncAction { private final SearchScrollRequest request ; private final ActionListener < SearchResponse > listener ; private final ParsedScrollId scrollId ; private final DiscoveryNodes nodes ; private volatile AtomicArray < ShardSearchFailure > shardFailures ; private final AtomicArray < QueryFetchSearchResult > queryFetchResults ; private final AtomicInteger successfulOps ; private final AtomicInteger counter ; private final long startTime = System . currentTimeMillis ( ) ; private AsyncAction ( SearchScrollRequest request , ParsedScrollId scrollId , ActionListener < SearchResponse > listener ) { } protected final ShardSearchFailure [ ] buildShardFailures ( ) { } protected final void addShardFailure ( final int shardIndex , ShardSearchFailure failure ) { } public void start ( ) { if ( ( scrollId . getContext ( ) . length ) == 0 ) { <START_BUG> final InternalSearchResponse internalResponse = new InternalSearchResponse ( new InternalSearchHits ( InternalSearchHits . EMPTY , Long . parseLong ( this . scrollId . getAttributes ( ) . get ( "total_hits" ) ) , 0.0F ) , null , null , null , false , null ) ; <END_BUG> listener . onResponse ( new SearchResponse ( internalResponse , request . scrollId ( ) , 0 , 0 , 0L , buildShardFailures ( ) ) ) ; return ; } Tuple < String , Long > [ ] context = scrollId . getContext ( ) ; for ( int i = 0 ; i < ( context . length ) ; i ++ ) { Tuple < String , Long > target = context [ i ] ; DiscoveryNode node = nodes . get ( target . v1 ( ) ) ; if ( node != null ) { executePhase ( i , node , target . v2 ( ) ) ; } else { if ( logger . isDebugEnabled ( ) ) { logger . debug ( ( ( ( ( "Node<seq2seq4repair_space>[" + ( target . v1 ( ) ) ) + "]<seq2seq4repair_space>not<seq2seq4repair_space>available<seq2seq4repair_space>for<seq2seq4repair_space>scroll<seq2seq4repair_space>request<seq2seq4repair_space>[" ) + ( scrollId . getSource ( ) ) ) + "]" ) ) ; } successfulOps . decrementAndGet ( ) ; if ( ( counter . decrementAndGet ( ) ) == 0 ) { finishHim ( ) ; } } } for ( Tuple < String , Long > target : scrollId . getContext ( ) ) { DiscoveryNode node = nodes . get ( target . v1 ( ) ) ; if ( node == null ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( ( ( ( ( "Node<seq2seq4repair_space>[" + ( target . v1 ( ) ) ) + "]<seq2seq4repair_space>not<seq2seq4repair_space>available<seq2seq4repair_space>for<seq2seq4repair_space>scroll<seq2seq4repair_space>request<seq2seq4repair_space>[" ) + ( scrollId . getSource ( ) ) ) + "]" ) ) ; } successfulOps . decrementAndGet ( ) ; if ( ( counter . decrementAndGet ( ) ) == 0 ) { finishHim ( ) ; } } else { } } } void executePhase ( final int shardIndex , DiscoveryNode node , final long searchId ) { } void onPhaseFailure ( Throwable t , long searchId , int shardIndex ) { } private void finishHim ( ) { } private void innerFinishHim ( ) throws IOException { } } }<BUG2FIX>final InternalSearchResponse internalResponse = new InternalSearchResponse ( new InternalSearchHits ( InternalSearchHits . EMPTY , Long . parseLong ( this . scrollId . getAttributes ( ) . get ( "total_hits" ) ) , 0.0F ) , null , null , false , null ) ;
public class Pools { private static final ObjectMap < Class , ReflectionPool > typePools = new ObjectMap ( ) ; public static < T > Pool < T > get ( Class < T > type ) { } public static < T > T obtain ( Class < T > type ) { } public static void free ( Object object ) { } public static void freeAll ( Array objects ) { if ( objects == null ) throw new IllegalArgumentException ( "objects<seq2seq4repair_space>cannot<seq2seq4repair_space>be<seq2seq4repair_space>null." ) ; for ( int i = 0 , n = objects . size ; i < n ; i ++ ) { Object object = objects . get ( i ) ; <START_BUG> if ( objects == null ) <END_BUG> continue ; ReflectionPool pool = Pools . typePools . get ( object . getClass ( ) ) ; if ( pool == null ) return ; pool . free ( object ) ; } } private Pools ( ) { } }<BUG2FIX>if ( object == null )
public class ProjectiveTextureTest extends GdxTest { PerspectiveCamera cam ; PerspectiveCamera projector ; Texture texture ; Mesh plane ; Matrix4 planeTrans = new Matrix4 ( ) ; Matrix4 cubeTrans = new Matrix4 ( ) ; Matrix4 modelNormal = new Matrix4 ( ) ; ShaderProgram projTexShader ; Stage ui ; Skin skin ; InputMultiplexer multiplexer = new InputMultiplexer ( ) ; PerspectiveCamController controller ; ImmediateModeRenderer20 renderer ; float angle = 0 ; private SelectBox camera ; private Label fps ; @ Override public void create ( ) { } public void setupScene ( ) { } public void setupUI ( ) { <START_BUG> ui = new Stage ( 480 , 320 , true ) ; <END_BUG> skin = new Skin ( files . internal ( "data/uiskin.json" ) ) ; TextButton reload = new TextButton ( "Reload<seq2seq4repair_space>Shaders" , skin . get ( TextButtonStyle . class ) ) ; camera = new SelectBox ( skin . get ( SelectBoxStyle . class ) ) ; camera . setItems ( "Camera" , "Light" ) ; fps = new Label ( "fps:<seq2seq4repair_space>" , skin . get ( LabelStyle . class ) ) ; Table table = new Table ( ) ; table . setFillParent ( true ) ; table . top ( ) . padTop ( 15 ) ; table . add ( reload ) . spaceRight ( 5 ) ; table . add ( camera ) . spaceRight ( 5 ) ; table . add ( fps ) ; ui . addActor ( table ) ; reload . addListener ( new ClickListener ( ) { public void clicked ( InputEvent event , float x , float y ) { ShaderProgram prog = new ShaderProgram ( files . internal ( "data/shaders/projtex-vert.glsl" ) . readString ( ) , files . internal ( "data/shaders/projtex-frag.glsl" ) . readString ( ) ) ; if ( ( prog . isCompiled ( ) ) == false ) { app . log ( "GLSL<seq2seq4repair_space>ERROR" , ( "Couldn\'t<seq2seq4repair_space>reload<seq2seq4repair_space>shaders:\n" + ( prog . getLog ( ) ) ) ) ; } else { projTexShader . dispose ( ) ; projTexShader = prog ; } } } ) ; } public void setupShaders ( ) { } @ Override public void render ( ) { } Vector3 position = new Vector3 ( ) ; private void renderMesh ( ShaderProgram shader , Matrix4 cam , Matrix4 projector , Matrix4 model , Mesh mesh , Color color ) { } @ Override public void dispose ( ) { } }<BUG2FIX>ui = new Stage ( ) ;
final class LwjglGL11 extends LwjglGL10 implements GL11 { private IntBuffer tempInt ; private FloatBuffer tempFloat ; public LwjglGL11 ( ) { } private IntBuffer toBuffer ( int n , int [ ] src , int offset ) { } private IntBuffer toBuffer ( int [ ] src , int offset ) { } private FloatBuffer toBuffer ( float [ ] src , int offset ) { } public void glBindBuffer ( int target , int buffer ) { } public void glBufferData ( int target , int size , Buffer data , int usage ) { } public void glBufferSubData ( int target , int offset , int size , Buffer data ) { } public void glClipPlanef ( int plane , float [ ] equation , int offset ) { } public void glClipPlanef ( int plane , FloatBuffer equation ) { } public void glColor4ub ( byte red , byte green , byte blue , byte alpha ) { } public void glDeleteBuffers ( int n , int [ ] buffers , int offset ) { } public void glDeleteBuffers ( int n , IntBuffer buffers ) { } public void glGenBuffers ( int n , int [ ] buffers , int offset ) { for ( int i = offset ; i < ( offset + n ) ; i ++ ) <START_BUG> buffers [ offset ] = GL15 . glGenBuffers ( ) ; <END_BUG> } public void glGenBuffers ( int n , IntBuffer buffers ) { } public void glGetBooleanv ( int pname , boolean [ ] params , int offset ) { } public void glGetBooleanv ( int pname , IntBuffer params ) { } public void glGetBufferParameteriv ( int target , int pname , int [ ] params , int offset ) { } public void glGetBufferParameteriv ( int target , int pname , IntBuffer params ) { } public void glGetClipPlanef ( int pname , float [ ] eqn , int offset ) { } public void glGetClipPlanef ( int pname , FloatBuffer eqn ) { } public void glGetFixedv ( int pname , int [ ] params , int offset ) { } public void glGetFixedv ( int pname , IntBuffer params ) { } public void glGetFloatv ( int pname , float [ ] params , int offset ) { } public void glGetFloatv ( int pname , FloatBuffer params ) { } public void glGetLightfv ( int light , int pname , float [ ] params , int offset ) { } public void glGetLightfv ( int light , int pname , FloatBuffer params ) { } public void glGetLightxv ( int light , int pname , int [ ] params , int offset ) { } public void glGetLightxv ( int light , int pname , IntBuffer params ) { } public void glGetMaterialfv ( int face , int pname , float [ ] params , int offset ) { } public void glGetMaterialfv ( int face , int pname , FloatBuffer params ) { } public void glGetMaterialxv ( int face , int pname , int [ ] params , int offset ) { } public void glGetMaterialxv ( int face , int pname , IntBuffer params ) { } public void glGetPointerv ( int pname , Buffer [ ] params ) { } public void glGetTexEnviv ( int env , int pname , int [ ] params , int offset ) { } public void glGetTexEnviv ( int env , int pname , IntBuffer params ) { } public void glGetTexEnvxv ( int env , int pname , int [ ] params , int offset ) { } public void glGetTexEnvxv ( int env , int pname , IntBuffer params ) { } public void glGetTexParameterfv ( int target , int pname , float [ ] params , int offset ) { } public void glGetTexParameterfv ( int target , int pname , FloatBuffer params ) { } public void glGetTexParameteriv ( int target , int pname , int [ ] params , int offset ) { } public void glGetTexParameteriv ( int target , int pname , IntBuffer params ) { } public void glGetTexParameterxv ( int target , int pname , int [ ] params , int offset ) { } public void glGetTexParameterxv ( int target , int pname , IntBuffer params ) { } public boolean glIsBuffer ( int buffer ) { } public boolean glIsEnabled ( int cap ) { } public boolean glIsTexture ( int texture ) { } public void glPointParameterf ( int pname , float param ) { } public void glPointParameterfv ( int pname , float [ ] params , int offset ) { } public void glPointParameterfv ( int pname , FloatBuffer params ) { } public void glPointSizePointerOES ( int type , int stride , Buffer pointer ) { } public void glTexEnvi ( int target , int pname , int param ) { } public void glTexEnviv ( int target , int pname , int [ ] params , int offset ) { } public void glTexEnviv ( int target , int pname , IntBuffer params ) { } public void glTexParameterfv ( int target , int pname , float [ ] params , int offset ) { } public void glTexParameterfv ( int target , int pname , FloatBuffer params ) { } public void glTexParameteri ( int target , int pname , int param ) { } public void glTexParameteriv ( int target , int pname , int [ ] params , int offset ) { } public void glTexParameteriv ( int target , int pname , IntBuffer params ) { } public void glColorPointer ( int size , int type , int stride , int pointer ) { } public void glNormalPointer ( int type , int stride , int pointer ) { } public void glTexCoordPointer ( int size , int type , int stride , int pointer ) { }<BUG2FIX>buffers [ i ] = GL15 . glGenBuffers ( ) ;
private final ShardIndexingService indexingService ; private final ShardSearchService searchService ; private final ShardGetService getService ; private final ShardIndexWarmerService shardWarmerService ; private final ShardFilterCache shardFilterCache ; private final ShardIdCache shardIdCache ; private final ShardFieldData shardFieldData ; private final PercolatorQueriesRegistry percolatorQueriesRegistry ; private final ShardPercolateService shardPercolateService ; private final CodecService codecService ; private final ShardTermVectorService termVectorService ; private final Object mutex = new Object ( ) ; private final String checkIndexOnStartup ; private long checkIndexTook = 0 ; private volatile IndexShardState state ; private TimeValue refreshInterval ; private final TimeValue mergeInterval ; private volatile ScheduledFuture refreshScheduledFuture ; private volatile ScheduledFuture mergeScheduleFuture ; private volatile ShardRouting shardRouting ; private RecoveryStatus peerRecoveryStatus ; private InternalIndexShard . ApplyRefreshSettings applyRefreshSettings = new InternalIndexShard . ApplyRefreshSettings ( ) ; private final MeanMetric refreshMetric = new MeanMetric ( ) ; private final MeanMetric flushMetric = new MeanMetric ( ) ; @ Inject public InternalIndexShard ( ShardId shardId , @ IndexSettings Settings indexSettings , IndexSettingsService indexSettingsService , IndicesLifecycle indicesLifecycle , Store store , Engine engine , MergeSchedulerProvider mergeScheduler , Translog translog , ThreadPool threadPool , MapperService mapperService , IndexQueryParserService queryParserService , IndexCache indexCache , IndexAliasesService indexAliasesService , ShardIndexingService indexingService , ShardGetService getService , ShardSearchService searchService , ShardIndexWarmerService shardWarmerService , ShardFilterCache shardFilterCache , ShardIdCache shardIdCache , ShardFieldData shardFieldData , PercolatorQueriesRegistry percolatorQueriesRegistry , ShardPercolateService shardPercolateService , CodecService codecService , ShardTermVectorService termVectorService ) { } public MergeSchedulerProvider mergeScheduler ( ) { } public Store store ( ) { } public Engine engine ( ) { } public Translog translog ( ) { } public ShardIndexingService indexingService ( ) { } @ Override public ShardGetService getService ( ) { } @ Override public ShardTermVectorService termVectorService ( ) { } @ Override public ShardSearchService searchService ( ) { } @ Override public ShardIndexWarmerService warmerService ( ) { } @ Override public ShardFilterCache filterCache ( ) { } @ Override public ShardIdCache idCache ( ) { } @ Override public ShardFieldData fieldData ( ) { } @ Override public ShardRouting routingEntry ( ) { } public InternalIndexShard routingEntry ( ShardRouting newRouting ) { } public IndexShardState recovering ( String reason ) throws IndexShardClosedException , IndexShardRecoveringException , IndexShardRelocatedException , IndexShardStartedException { } public InternalIndexShard relocated ( String reason ) throws IndexShardNotStartedException { } public InternalIndexShard start ( String reason ) throws IndexShardClosedException , IndexShardRelocatedException , IndexShardStartedException { } @ Override public IndexShardState state ( ) { } @ Override public Create prepareCreate ( SourceToParse source ) throws ElasticSearchException { } @ Override public ParsedDocument create ( Engine . Create create ) throws ElasticSearchException { } @ Override public Index prepareIndex ( SourceToParse source ) throws ElasticSearchException { } @ Override public ParsedDocument index ( Engine . Index index ) throws ElasticSearchException { } @ Override public Delete prepareDelete ( String type , String id , long version ) throws ElasticSearchException { } @ Override public void delete ( Engine . Delete delete ) throws ElasticSearchException { } @ Override public DeleteByQuery prepareDeleteByQuery ( BytesReference querySource , @ Nullable String [ ] filteringAliases , String ... types ) throws ElasticSearchException { } @ Override public void deleteByQuery ( Engine . DeleteByQuery deleteByQuery ) throws ElasticSearchException { } @ Override public GetResult get ( Engine . Get get ) throws ElasticSearchException { } @ Override public void refresh ( Engine . Refresh refresh ) throws ElasticSearchException { } @ Override public RefreshStats refreshStats ( ) { } @ Override public FlushStats flushStats ( ) { } @ Override public DocsStats docStats ( ) { } @ Override public IndexingStats indexingStats ( String ... types ) { } @ Override public SearchStats searchStats ( String ... groups ) { } @ Override public GetStats getStats ( ) { } @ Override public StoreStats storeStats ( ) { } @ Override public MergeStats mergeStats ( ) { } @ Override public WarmerStats warmerStats ( ) { } @ Override public FilterCacheStats filterCacheStats ( ) { } @ Override public FieldDataStats fieldDataStats ( String ... fields ) { } @ Override public PercolatorQueriesRegistry percolateRegistry ( ) { } @ Override public ShardPercolateService shardPercolateService ( ) { } @ Override public IdCacheStats idCacheStats ( ) { } @ Override public CompletionStats completionStats ( String ... fields ) { } @ Override public void flush ( Engine . Flush flush ) throws ElasticSearchException { } @ Override public void optimize ( Engine . Optimize optimize ) throws ElasticSearchException { } @ Override public < T > T snapshot ( Engine . SnapshotHandler < T > snapshotHandler ) throws EngineException { } @ Override public void recover ( Engine . RecoveryHandler recoveryHandler ) throws EngineException { } @ Override public Searcher acquireSearcher ( ) { readAllowed ( ) ; <START_BUG> return engine . searcher ( ) ; <END_BUG> } public void close ( String reason ) { } public long checkIndexTook ( ) { } public void performRecoveryPrepareForTranslog ( ) throws ElasticSearchException { } public RecoveryStatus peerRecoveryStatus ( ) { } public void performRecoveryFinalization ( boolean withFlush , RecoveryStatus peerRecoveryStatus ) throws ElasticSearchException { } public void performRecoveryFinalization ( boolean withFlush ) throws ElasticSearchException { } public void performRecoveryOperation ( Translog . Operation operation ) throws ElasticSearchException { } public boolean ignoreRecoveryAttempt ( ) { } public void readAllowed ( ) throws IllegalIndexShardStateException { } private void writeAllowed ( ) throws IllegalIndexShardStateException { } private void verifyStartedOrRecovering ( ) throws IllegalIndexShardStateException { } private void verifyNotClosed ( ) throws IllegalIndexShardStateException { } private void verifyStarted ( ) throws IllegalIndexShardStateException { } private void startScheduledTasksIfNeeded ( ) { } private Query filterQueryIfNeeded ( Query query , String [ ] types ) { } public static final String INDEX_REFRESH_INTERVAL = "index.refresh_interval" ; private class ApplyRefreshSettings implements IndexSettingsService . Listener { @ Override public void onRefreshSettings ( Settings settings ) { } } class EngineRefresher implements Runnable { @ Override public void run ( ) { } } class EngineMerger implements Runnable { @ Override public void run ( ) { } } private void checkIndex ( boolean throwException ) throws IndexShardException { } }<BUG2FIX>return engine . acquireSearcher ( ) ;
public class FetchPhase implements SearchPhase { @ Override public Map < String , ? extends SearchParseElement > parseElements ( ) { } @ Override public void preProcess ( SearchContext context ) { } public void execute ( SearchContext context ) { } private void doExplanation ( SearchContext context , int docId , InternalSearchHit searchHit ) { } private byte [ ] extractSource ( Document doc , DocumentMapper documentMapper ) { } private Uid extractUid ( SearchContext context , Document doc ) { } private Document loadDocument ( SearchContext context , FieldSelector fieldSelector , int docId ) { } private FieldSelector buildFieldSelectors ( SearchContext context ) { <START_BUG> if ( ( ( context . fieldNames ( ) ) == null ) || ( ( context . fieldNames ( ) . length ) == 0 ) ) { <END_BUG> return new UidAndSourceFieldSelector ( ) ; } FieldMappersFieldSelector fieldSelector = new FieldMappersFieldSelector ( ) ; for ( String fieldName : context . fieldNames ( ) ) { FieldMappers x = context . mapperService ( ) . smartNameFieldMappers ( fieldName ) ; if ( x == null ) { throw new FetchPhaseExecutionException ( context , ( ( "No<seq2seq4repair_space>mapping<seq2seq4repair_space>for<seq2seq4repair_space>field<seq2seq4repair_space>[" + fieldName ) + "]" ) ) ; } fieldSelector . add ( x ) ; } fieldSelector . add ( context . mapperService ( ) . uidFieldMappers ( ) ) ; return fieldSelector ; } }<BUG2FIX>if ( ( context . fieldNames ( ) ) == null ) {
for ( int j = 0 ; j < 3 ; j ++ ) { MD2Loader . VertexIndices vert = null ; boolean contains = false ; for ( int k = 0 ; k < ( vertCombos . size ( ) ) ; k ++ ) { MD2Loader . VertexIndices vIdx = vertCombos . get ( k ) ; if ( ( ( vIdx . vIdx ) == ( triangle . vertices [ j ] ) ) && ( ( vIdx . tIdx ) == ( triangle . texCoords [ j ] ) ) ) { vert = vIdx ; contains = true ; break ; } } if ( ! contains ) { vert = new MD2Loader . VertexIndices ( triangle . vertices [ j ] , triangle . texCoords [ j ] , vertIdx ) ; vertCombos . add ( vert ) ; vertIdx ++ ; } indices [ ( idx ++ ) ] = vert . nIdx ; } } idx = 0 ; float [ ] uvs = new float [ ( vertCombos . size ( ) ) * 2 ] ; for ( int i = 0 ; i < ( vertCombos . size ( ) ) ; i ++ ) { MD2Loader . VertexIndices vtI = vertCombos . get ( i ) ; uvs [ ( idx ++ ) ] = texCoords [ ( ( vtI . tIdx ) * 2 ) ] ; uvs [ ( idx ++ ) ] = texCoords [ ( ( ( vtI . tIdx ) * 2 ) + 1 ) ] ; } for ( int i = 0 ; i < ( frames . length ) ; i ++ ) { MD2Frame frame = frames [ i ] ; idx = 0 ; float [ ] newVerts = new float [ ( vertCombos . size ( ) ) * 3 ] ; for ( int j = 0 ; j < ( vertCombos . size ( ) ) ; j ++ ) { MD2Loader . VertexIndices vIdx = vertCombos . get ( j ) ; newVerts [ ( idx ++ ) ] = frame . vertices [ ( ( vIdx . vIdx ) * 3 ) ] ; newVerts [ ( idx ++ ) ] = frame . vertices [ ( ( ( vIdx . vIdx ) * 3 ) + 1 ) ] ; newVerts [ ( idx ++ ) ] = frame . vertices [ ( ( ( vIdx . vIdx ) * 3 ) + 2 ) ] ; } frame . vertices = newVerts ; } header . numVertices = vertCombos . size ( ) ; KeyframedAnimation animation = new KeyframedAnimation ( "all" , ( ( frames . length ) * 0.2F ) , new Keyframe [ frames . length ] ) ; for ( int frameNum = 0 ; frameNum < ( frames . length ) ; frameNum ++ ) { MD2Frame frame = frames [ frameNum ] ; float [ ] vertices = new float [ ( header . numVertices ) * 5 ] ; idx = 0 ; int idxV = 0 ; int idxT = 0 ; for ( int i = 0 ; i < ( header . numVertices ) ; i ++ ) { vertices [ ( idx ++ ) ] = frame . vertices [ ( idxV ++ ) ] ; vertices [ ( idx ++ ) ] = frame . vertices [ ( idxV ++ ) ] ; vertices [ ( idx ++ ) ] = frame . vertices [ ( idxV ++ ) ] ; vertices [ ( idx ++ ) ] = uvs [ ( idxT ++ ) ] ; vertices [ ( idx ++ ) ] = uvs [ ( idxT ++ ) ] ; } Keyframe keyFrame = new Keyframe ( 0 , 3 , vertices ) ; animation . keyframes [ frameNum ] = keyFrame ; } Mesh mesh = new Mesh ( false , ( ( header . numTriangles ) * 3 ) , indices . length , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . Position , 3 , "a_pos" ) , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . TextureCoordinates , 2 , "a_tex0" ) ) ; mesh . setIndices ( indices ) ; ObjectMap < String , KeyframedAnimation > animations = new ObjectMap < String , KeyframedAnimation > ( ) ; animations . put ( "all" , animation ) ; KeyframedSubMesh subMesh = new KeyframedSubMesh ( "md2-mesh" , mesh , null , animations , GL10 . GL_TRIANGLES ) ; KeyframedModel model = new KeyframedModel ( new KeyframedSubMesh [ ] { subMesh } ) ; <START_BUG> model . setAnimation ( "all" , 0 ) ; <END_BUG> return model ; } private float [ ] buildTexCoords ( MD2Header header , MD2Triangle [ ] triangles , float [ ] texCoords ) { } private short [ ] buildIndices ( MD2Triangle [ ] triangles ) { } private MD2Frame [ ] loadFrames ( MD2Header header , byte [ ] bytes ) throws IOException { } private final byte [ ] charBuffer = new byte [ 16 ] ; private MD2Frame loadFrame ( MD2Header header , LittleEndianInputStream in ) throws IOException { } private MD2Triangle [ ] loadTriangles ( MD2Header header , byte [ ] bytes ) throws IOException { } private float [ ] loadTexCoords ( MD2Header header , byte [ ] bytes ) throws IOException { } private MD2Header loadHeader ( byte [ ] bytes ) throws IOException { } private byte [ ] loadBytes ( InputStream in ) throws IOException { } public class VertexIndices { public VertexIndices ( short vIdx , short tIdx , short nIdx ) { } @ Override public int hashCode ( ) { } @ Override public boolean equals ( Object obj ) { } public short vIdx ; public short tIdx ; public short nIdx ; } }<BUG2FIX>model . setAnimation ( "all" , 0 , false ) ;
public class DateFieldMapper extends NumberFieldMapper < Long > { public static final String CONTENT_TYPE = "date" ; public static class Defaults extends NumberFieldMapper . Defaults { public static final FormatDateTimeFormatter DATE_TIME_FORMATTER = Joda . forPattern ( "dateOptionalTime" ) ; public static final FieldType FIELD_TYPE = new FieldType ( NumberFieldMapper . Defaults . FIELD_TYPE ) ; public static final String NULL_VALUE = null ; public static final TimeUnit TIME_UNIT = TimeUnit . MILLISECONDS ; public static final boolean PARSE_UPPER_INCLUSIVE = true ; } public static class Builder extends NumberFieldMapper . Builder < DateFieldMapper . Builder , DateFieldMapper > { protected TimeUnit timeUnit = DateFieldMapper . Defaults . TIME_UNIT ; protected String nullValue = DateFieldMapper . Defaults . NULL_VALUE ; protected FormatDateTimeFormatter dateTimeFormatter = DateFieldMapper . Defaults . DATE_TIME_FORMATTER ; private Locale locale ; public Builder ( String name ) { } public DateFieldMapper . Builder timeUnit ( TimeUnit timeUnit ) { } public DateFieldMapper . Builder nullValue ( String nullValue ) { } public DateFieldMapper . Builder dateTimeFormatter ( FormatDateTimeFormatter dateTimeFormatter ) { } @ Override public DateFieldMapper build ( BuilderContext context ) { } public DateFieldMapper . Builder locale ( Locale locale ) { } } public static class TypeParser implements Mapper . TypeParser { @ Override public Mapper . Builder < ? , ? > parse ( String name , Map < String , Object > node , ParserContext parserContext ) throws MapperParsingException { } } public static Locale parseLocale ( String locale ) { } protected final FormatDateTimeFormatter dateTimeFormatter ; private final boolean parseUpperInclusive ; private final DateMathParser dateMathParser ; private String nullValue ; protected final TimeUnit timeUnit ; protected DateFieldMapper ( Names names , FormatDateTimeFormatter dateTimeFormatter , int precisionStep , float boost , FieldType fieldType , String nullValue , TimeUnit timeUnit , boolean parseUpperInclusive , Explicit < Boolean > ignoreMalformed , PostingsFormatProvider provider , SimilarityProvider similarity , @ Nullable Settings fieldDataSettings ) { } @ Override public FieldType defaultFieldType ( ) { } @ Override public FieldDataType defaultFieldDataType ( ) { } @ Override protected int maxPrecisionStep ( ) { } @ Override public Long value ( Object value ) { } @ Override public Object valueForSearch ( Object value ) { } @ Override public BytesRef indexedValueForSearch ( Object value ) { } private long parseValue ( Object value ) { } private String convertToString ( Object value ) { } @ Override public Query fuzzyQuery ( String value , String minSim , int prefixLength , int maxExpansions , boolean transpositions ) { } @ Override public Query termQuery ( Object value , @ Nullable QueryParseContext context ) { } @ Override public Filter termFilter ( Object value , @ Nullable QueryParseContext context ) { } @ Override public Query rangeQuery ( Object lowerTerm , Object upperTerm , boolean includeLower , boolean includeUpper , @ Nullable QueryParseContext context ) { } @ Override public Filter rangeFilter ( Object lowerTerm , Object upperTerm , boolean includeLower , boolean includeUpper , @ Nullable QueryParseContext context ) { } @ Override public Filter rangeFilter ( IndexFieldDataService fieldData , Object lowerTerm , Object upperTerm , boolean includeLower , boolean includeUpper , @ Nullable QueryParseContext context ) { } @ Override public Filter nullValueFilter ( ) { } @ Override protected boolean customBoost ( ) { } @ Override protected Field innerParseCreateField ( ParseContext context ) throws IOException { } @ Override protected String contentType ( ) { } @ Override public void merge ( Mapper mergeWith , MergeContext mergeContext ) throws MergeMappingException { } @ Override protected void doXContentBody ( XContentBuilder builder ) throws IOException { super . doXContentBody ( builder ) ; if ( ( precisionStep ) != ( PRECISION_STEP ) ) { builder . field ( "precision_step" , precisionStep ) ; } builder . field ( "format" , dateTimeFormatter . format ( ) ) ; if ( ( nullValue ) != null ) { builder . field ( "null_value" , nullValue ) ; } if ( ( includeInAll ) != null ) { builder . field ( "include_in_all" , includeInAll ) ; } if ( ( timeUnit ) != ( DateFieldMapper . Defaults . TIME_UNIT ) ) { builder . field ( "numeric_resolution" , timeUnit . name ( ) . toLowerCase ( Locale . ROOT ) ) ; } if ( ( dateTimeFormatter . locale ( ) ) != null ) { <START_BUG> builder . field ( "locale" , dateTimeFormatter . format ( ) ) ; <END_BUG> } } private long parseStringValue ( String value ) { } }<BUG2FIX>builder . field ( "locale" , dateTimeFormatter . locale ( ) ) ;
public class TribeTests extends ElasticsearchIntegrationTest { private static InternalTestCluster cluster2 ; private Node tribeNode ; private Client tribeClient ; @ BeforeClass public static void setupSecondCluster ( ) throws Exception { ElasticsearchIntegrationTest . beforeClass ( ) ; <START_BUG> TribeTests . cluster2 = new InternalTestCluster ( randomLong ( ) , 2 , 2 , Strings . randomBase64UUID ( getRandom ( ) ) , 0 , false , CHILD_JVM_ID ) ; <END_BUG> TribeTests . cluster2 . beforeTest ( getRandom ( ) , 0.1 ) ; TribeTests . cluster2 . ensureAtLeastNumDataNodes ( 2 ) ; } @ AfterClass public static void tearDownSecondCluster ( ) { } @ After public void tearDownTribeNode ( ) throws IOException { } private void setupTribeNode ( Settings settings ) { } @ Test public void testGlobalReadWriteBlocks ( ) throws Exception { } @ Test public void testIndexWriteBlocks ( ) throws Exception { } @ Test public void testOnConflictDrop ( ) throws Exception { } @ Test public void testOnConflictPrefer ( ) throws Exception { } private void testOnConflictPrefer ( String tribe ) throws Exception { } @ Test public void testTribeOnOneCluster ( ) throws Exception { } private void awaitIndicesInClusterState ( final String ... indices ) throws Exception { } private void awaitSameNodeCounts ( ) throws Exception { } private int countDataNodesForTribe ( String tribeName , DiscoveryNodes nodes ) { } }<BUG2FIX>TribeTests . cluster2 = new InternalTestCluster ( randomLong ( ) , 2 , 2 , Strings . randomBase64UUID ( getRandom ( ) ) , 0 , false ) ;
public class ParentQuery extends Query implements ScopePhase . CollectorPhase { private final SearchContext searchContext ; private final Query parentQuery ; private final String parentType ; private final Filter childrenFilter ; private final List < String > childTypes ; private final String scope ; private TObjectFloatHashMap < HashedBytesArray > uidToScore ; public ParentQuery ( SearchContext searchContext , Query parentQuery , String parentType , List < String > childTypes , Filter childrenFilter , String scope ) { } private ParentQuery ( ParentQuery unwritten , Query rewrittenParentQuery ) { } @ Override public boolean requiresProcessing ( ) { } @ Override public Collector collector ( ) { } @ Override public void processCollector ( Collector collector ) { } @ Override public String scope ( ) { } @ Override public void clear ( ) { } @ Override public Query query ( ) { } @ Override public String toString ( String field ) { } @ Override public Query rewrite ( IndexReader reader ) throws IOException { } @ Override public void extractTerms ( Set < Term > terms ) { } @ Override public Weight createWeight ( IndexSearcher searcher ) throws IOException { } static class ParentUidCollector extends NoopCollector { final TObjectFloatHashMap < HashedBytesArray > uidToScore ; final SearchContext searchContext ; final String parentType ; Scorer scorer ; IdReaderTypeCache typeCache ; ParentUidCollector ( TObjectFloatHashMap < HashedBytesArray > uidToScore , SearchContext searchContext , String parentType ) { } @ Override public void collect ( int doc ) throws IOException { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override public void setNextReader ( AtomicReaderContext context ) throws IOException { } } class ChildWeight extends Weight { private final Weight parentWeight ; ChildWeight ( Weight parentWeight ) { } @ Override public Explanation explain ( AtomicReaderContext context , int doc ) throws IOException { } @ Override public Query getQuery ( ) { } @ Override public float getValueForNormalization ( ) throws IOException { } @ Override public void normalize ( float norm , float topLevelBoost ) { } @ Override public Scorer scorer ( AtomicReaderContext context , boolean scoreDocsInOrder , boolean topScorer , Bits acceptDocs ) throws IOException { } } static class ChildScorer extends Scorer { final TObjectFloatHashMap < HashedBytesArray > uidToScore ; final DocIdSetIterator childrenIterator ; final IdReaderTypeCache typeCache ; int currentChildDoc = - 1 ; float currentScore ; ChildScorer ( Weight weight , TObjectFloatHashMap < HashedBytesArray > uidToScore , DocIdSetIterator childrenIterator , IdReaderTypeCache typeCache ) { } @ Override public float score ( ) throws IOException { } @ Override <START_BUG> public float freq ( ) throws IOException { <END_BUG> return 1 ; } @ Override public int docID ( ) { } @ Override public int nextDoc ( ) throws IOException { } @ Override public int advance ( int target ) throws IOException { } } }<BUG2FIX>public int freq ( ) throws IOException {
public class LoginActivity extends RoboSherlockAccountAuthenticatorActivity { public static final String PARAM_AUTHTOKEN_TYPE = "authtokenType" ; private static final String PARAM_CONFIRMCREDENTIALS = "confirmCredentials" ; private static final String PARAM_USERNAME = "username" ; private static final String TAG = "LoginActivity" ; private static final long SYNC_PERIOD = ( 8L * 60L ) * 60L ; private static void configureSyncFor ( Account account ) { } private static class AccountLoader extends AuthenticatedUserTask < List < User > > { @ Inject private AccountDataManager cache ; protected AccountLoader ( Context context ) { } @ Override protected List < User > run ( ) throws Exception { } } private AccountManager accountManager ; @ InjectView ( id . et_login ) private AutoCompleteTextView loginText ; @ InjectView ( id . et_password ) private EditText passwordText ; private RoboAsyncTask < User > authenticationTask ; private String authToken ; private String authTokenType ; private MenuItem loginItem ; private Boolean confirmCredentials = false ; private String password ; protected boolean requestNewAccount = false ; private String username ; @ Override public void onCreate ( Bundle savedInstanceState ) { } @ Override protected void onResume ( ) { } private boolean loginEnabled ( ) { <START_BUG> return ( ! ( TextUtils . isEmpty ( loginText . getText ( ) ) ) ) && ( ! ( TextUtils . isDigitsOnly ( passwordText . getText ( ) ) ) ) ; <END_BUG> } private void updateEnablement ( ) { } @ Override public void startActivity ( Intent intent ) { } public void handleLogin ( ) { } protected void finishConfirmCredentials ( boolean result ) { } protected void finishLogin ( ) { } public void onAuthenticationResult ( boolean result ) { } public boolean onOptionsItemSelected ( MenuItem item ) { } @ Override public boolean onCreateOptionsMenu ( Menu optionMenu ) { } private List < String > getEmailAddresses ( ) { } }<BUG2FIX>return ( ! ( TextUtils . isEmpty ( loginText . getText ( ) ) ) ) && ( ! ( TextUtils . isEmpty ( passwordText . getText ( ) ) ) ) ;
public class SuperJumperDesktop { public static void main ( String [ ] argv ) { <START_BUG> new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new SuperJumper ( ) , "Super<seq2seq4repair_space>Jumper" , 320 , 480 , false ) ; <END_BUG> } }<BUG2FIX>new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new SuperJumper ( ) , "Super<seq2seq4repair_space>Jumper" , 320 , 480 ) ;
public class ScriptHistogramFacetExecutor extends FacetExecutor { final SearchScript keyScript ; final SearchScript valueScript ; final long interval ; private final ComparatorType comparatorType ; final Recycler . V < LongObjectOpenHashMap < InternalFullHistogramFacet . FullEntry > > entries ; public ScriptHistogramFacetExecutor ( String scriptLang , String keyScript , String valueScript , Map < String , Object > params , long interval , HistogramFacet . ComparatorType comparatorType , SearchContext context ) { } @ Override public ScriptHistogramFacetExecutor . Collector collector ( ) { } @ Override public InternalFacet buildFacet ( String facetName ) { List < InternalFullHistogramFacet . FullEntry > entries1 = new java . util . ArrayList ( entries . v ( ) . size ( ) ) ; final boolean [ ] states = entries . v ( ) . allocated ; final Object [ ] values = entries . v ( ) . values ; for ( int i = 0 ; i < ( states . length ) ; i ++ ) { if ( states [ i ] ) { InternalFullHistogramFacet . FullEntry value = ( ( InternalFullHistogramFacet . FullEntry ) ( values [ i ] ) ) ; entries1 . add ( value ) ; } } <START_BUG> entries . release ( ) ; <END_BUG> return new InternalFullHistogramFacet ( facetName , comparatorType , entries1 ) ; } public static long bucket ( double value , long interval ) { } class Collector extends FacetExecutor . Collector { final LongObjectOpenHashMap < InternalFullHistogramFacet . FullEntry > entries ; Collector ( LongObjectOpenHashMap < InternalFullHistogramFacet . FullEntry > entries ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override public void setNextReader ( AtomicReaderContext context ) throws IOException { } @ Override public void collect ( int doc ) throws IOException { } @ Override public void postCollection ( ) { } } }<BUG2FIX>entries . close ( ) ;
public class BufferUtils { static Array < ByteBuffer > unsafeBuffers = new Array < ByteBuffer > ( ) ; static int allocatedUnsafe = 0 ; public static void copy ( float [ ] src , Buffer dst , int numFloats , int offset ) { } public static void copy ( byte [ ] src , int srcOffset , Buffer dst , int numElements ) { } public static void copy ( short [ ] src , int srcOffset , Buffer dst , int numElements ) { } public static void copy ( char [ ] src , int srcOffset , Buffer dst , int numElements ) { } public static void copy ( int [ ] src , int srcOffset , Buffer dst , int numElements ) { } public static void copy ( long [ ] src , int srcOffset , Buffer dst , int numElements ) { } public static void copy ( float [ ] src , int srcOffset , Buffer dst , int numElements ) { } public static void copy ( double [ ] src , int srcOffset , Buffer dst , int numElements ) { } public static void copy ( Buffer src , Buffer dst , int numElements ) { } private static int positionInBytes ( Buffer dst ) { } private static int bytesToElements ( Buffer dst , int bytes ) { } private static int elementsToBytes ( Buffer dst , int elements ) { } public static FloatBuffer newFloatBuffer ( int numFloats ) { } public static DoubleBuffer newDoubleBuffer ( int numDoubles ) { } public static ByteBuffer newByteBuffer ( int numBytes ) { } public static ShortBuffer newShortBuffer ( int numShorts ) { } public static CharBuffer newCharBuffer ( int numChars ) { } public static IntBuffer newIntBuffer ( int numInts ) { } public static LongBuffer newLongBuffer ( int numLongs ) { } public static void disposeUnsafeByteBuffer ( ByteBuffer buffer ) { <START_BUG> int size = buffer . capacity ( ) ; <END_BUG> synchronized ( BufferUtils . unsafeBuffers ) { if ( ! ( BufferUtils . unsafeBuffers . removeValue ( buffer , true ) ) ) throw new IllegalArgumentException ( "buffer<seq2seq4repair_space>not<seq2seq4repair_space>allocated<seq2seq4repair_space>with<seq2seq4repair_space>newUnsafeByteBuffer<seq2seq4repair_space>or<seq2seq4repair_space>already<seq2seq4repair_space>disposed" ) ; } BufferUtils . allocatedUnsafe -= size ; BufferUtils . freeMemory ( buffer ) ; } public static ByteBuffer newUnsafeByteBuffer ( int numBytes ) { } public static int getAllocatedBytesUnsafe ( ) { } private static native void freeMemory ( ByteBuffer buffer ) { } private static native ByteBuffer newDisposableByteBuffer ( int numBytes ) { } public static native void clear ( ByteBuffer buffer , int numBytes ) { } private static native void copyJni ( float [ ] src , Buffer dst , int numFloats , int offset ) { } private static native void copyJni ( byte [ ] src , int srcOffset , Buffer dst , int dstOffset , int numBytes ) { } private static native void copyJni ( char [ ] src , int srcOffset , Buffer dst , int dstOffset , int numBytes ) { } private static native void copyJni ( short [ ] src , int srcOffset , Buffer dst , int dstOffset , int numBytes ) { } private static native void copyJni ( int [ ] src , int srcOffset , Buffer dst , int dstOffset , int numBytes ) { } private static native void copyJni ( long [ ] src , int srcOffset , Buffer dst , int dstOffset , int numBytes ) { } private static native void copyJni ( float [ ] src , int srcOffset , Buffer dst , int dstOffset , int numBytes ) { } private static native void copyJni ( double [ ] src , int srcOffset , Buffer dst , int dstOffset , int numBytes ) { } private static native void copyJni ( Buffer src , int srcOffset , Buffer dst , int dstOffset , int numBytes ) { } }<BUG2FIX>int size = 0 ;
public class InternalIndicesService extends AbstractLifecycleComponent < IndicesService > implements IndicesService { private final NodeEnvironment nodeEnv ; private final ThreadPool threadPool ; private final InternalIndicesLifecycle indicesLifecycle ; private final IndicesAnalysisService indicesAnalysisService ; private final IndicesStore indicesStore ; private final Injector injector ; private final PluginsService pluginsService ; private final Map < String , Injector > indicesInjectors = new HashMap < String , Injector > ( ) ; private volatile ImmutableMap < String , IndexService > indices = ImmutableMap . of ( ) ; private final InternalIndicesService . OldShardsStats oldShardsStats = new InternalIndicesService . OldShardsStats ( ) ; @ Inject public InternalIndicesService ( Settings settings , NodeEnvironment nodeEnv , ThreadPool threadPool , IndicesLifecycle indicesLifecycle , IndicesAnalysisService indicesAnalysisService , IndicesStore indicesStore , Injector injector ) { } @ Override protected void doStart ( ) throws ElasticSearchException { } @ Override protected void doStop ( ) throws ElasticSearchException { } @ Override protected void doClose ( ) throws ElasticSearchException { } @ Override public IndicesLifecycle indicesLifecycle ( ) { } @ Override public NodeIndicesStats stats ( boolean includePrevious ) { } public boolean changesAllowed ( ) { } @ Override public UnmodifiableIterator < IndexService > iterator ( ) { } public boolean hasIndex ( String index ) { } public Set < String > indices ( ) { } public IndexService indexService ( String index ) { } @ Override public IndexService indexServiceSafe ( String index ) throws IndexMissingException { } public synchronized IndexService createIndex ( String sIndexName , Settings settings , String localNodeId ) throws ElasticSearchException { if ( ! ( lifecycle . started ( ) ) ) { throw new ElasticSearchIllegalStateException ( ( ( "Can't<seq2seq4repair_space>create<seq2seq4repair_space>an<seq2seq4repair_space>index<seq2seq4repair_space>[" + sIndexName ) + "],<seq2seq4repair_space>node<seq2seq4repair_space>is<seq2seq4repair_space>closed" ) ) ; } Index index = new Index ( sIndexName ) ; if ( indicesInjectors . containsKey ( index . name ( ) ) ) { throw new IndexAlreadyExistsException ( index ) ; } indicesLifecycle . beforeIndexCreated ( index ) ; logger . debug ( "creating<seq2seq4repair_space>Index<seq2seq4repair_space>[{}],<seq2seq4repair_space>shards<seq2seq4repair_space>[{}]/[{}]" , sIndexName , settings . get ( SETTING_NUMBER_OF_SHARDS ) , settings . get ( SETTING_NUMBER_OF_REPLICAS ) ) ; Settings indexSettings = settingsBuilder ( ) . put ( "settingsType" , "index" ) . put ( this . settings ) . put ( settings ) . classLoader ( settings . getClassLoader ( ) ) . build ( ) ; ModulesBuilder modules = new ModulesBuilder ( ) ; modules . add ( new IndexNameModule ( index ) ) ; modules . add ( new LocalNodeIdModule ( localNodeId ) ) ; modules . add ( new org . elasticsearch . index . settings . IndexSettingsModule ( index , indexSettings ) ) ; modules . add ( new org . elasticsearch . plugins . IndexPluginsModule ( indexSettings , pluginsService ) ) ; modules . add ( new org . elasticsearch . index . store . IndexStoreModule ( indexSettings ) ) ; modules . add ( new org . elasticsearch . index . engine . IndexEngineModule ( indexSettings ) ) ; modules . add ( new org . elasticsearch . index . analysis . AnalysisModule ( indexSettings , indicesAnalysisService ) ) ; modules . add ( new org . elasticsearch . index . similarity . SimilarityModule ( indexSettings ) ) ; modules . add ( new org . elasticsearch . index . cache . IndexCacheModule ( indexSettings ) ) ; modules . add ( new org . elasticsearch . index . query . IndexQueryParserModule ( indexSettings ) ) ; modules . add ( new MapperServiceModule ( ) ) ; modules . add ( new IndexAliasesServiceModule ( ) ) ; modules . add ( new org . elasticsearch . index . gateway . IndexGatewayModule ( indexSettings , injector . getInstance ( Gateway . class ) ) ) ; <START_BUG> modules . add ( new IndexModule ( ) ) ; <END_BUG> modules . add ( new PercolatorModule ( ) ) ; Injector indexInjector ; try { indexInjector = modules . createChildInjector ( injector ) ; } catch ( CreationException e ) { throw new IndexCreationException ( index , Injectors . getFirstErrorFailure ( e ) ) ; } indicesInjectors . put ( index . name ( ) , indexInjector ) ; IndexService indexService = indexInjector . getInstance ( IndexService . class ) ; indicesLifecycle . afterIndexCreated ( indexService ) ; indices = newMapBuilder ( indices ) . put ( index . name ( ) , indexService ) . immutableMap ( ) ; return indexService ; } @ Override public synchronized void cleanIndex ( String index , String reason ) throws ElasticSearchException { } @ Override public synchronized void deleteIndex ( String index , String reason ) throws ElasticSearchException { } private void deleteIndex ( String index , boolean delete , String reason , @ Nullable Executor executor ) throws ElasticSearchException { } static class OldShardsStats extends IndicesLifecycle . Listener { final SearchStats searchStats = new SearchStats ( ) ; final GetStats getStats = new GetStats ( ) ; final IndexingStats indexingStats = new IndexingStats ( ) ; final MergeStats mergeStats = new MergeStats ( ) ; final RefreshStats refreshStats = new RefreshStats ( ) ; final FlushStats flushStats = new FlushStats ( ) ; @ Override public synchronized void beforeIndexShardClosed ( ShardId shardId , @ Nullable IndexShard indexShard , boolean delete ) { } } }<BUG2FIX>modules . add ( new IndexModule ( indexSettings ) ) ;
public class RangeFilterParser extends AbstractIndexComponent implements XContentFilterParser { public static final String NAME = "range" ; @ Inject public RangeFilterParser ( Index index , @ IndexSettings Settings settings ) { } @ Override public String [ ] names ( ) { } @ Override public Filter parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; XContentParser . Token token = parser . nextToken ( ) ; assert token == ( Token . FIELD_NAME ) ; String fieldName = parser . currentName ( ) ; token = parser . nextToken ( ) ; assert token == ( Token . START_OBJECT ) ; String from = null ; String to = null ; boolean includeLower = true ; boolean includeUpper = true ; String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else { if ( "from" . equals ( currentFieldName ) ) { from = parser . textOrNull ( ) ; } else if ( "to" . equals ( currentFieldName ) ) { to = parser . textOrNull ( ) ; } else if ( ( "include_lower" . equals ( currentFieldName ) ) || ( "includeLower" . equals ( currentFieldName ) ) ) { includeLower = parser . booleanValue ( ) ; } else if ( ( "include_upper" . equals ( currentFieldName ) ) || ( "includeUpper" . equals ( currentFieldName ) ) ) { includeUpper = parser . booleanValue ( ) ; } else if ( "gt" . equals ( currentFieldName ) ) { from = parser . textOrNull ( ) ; includeLower = false ; } else if ( ( "gte" . equals ( currentFieldName ) ) || ( "ge" . equals ( currentFieldName ) ) ) { from = parser . textOrNull ( ) ; includeLower = true ; } else if ( "lt" . equals ( currentFieldName ) ) { to = parser . textOrNull ( ) ; includeUpper = false ; } else if ( ( "lte" . equals ( currentFieldName ) ) || ( "le" . equals ( currentFieldName ) ) ) { to = parser . textOrNull ( ) ; includeUpper = true ; } } } token = parser . nextToken ( ) ; assert token == ( Token . END_OBJECT ) ; Filter filter = null ; MapperService . SmartNameFieldMappers smartNameFieldMappers = parseContext . smartFieldMappers ( fieldName ) ; if ( smartNameFieldMappers != null ) { if ( smartNameFieldMappers . hasMapper ( ) ) { filter = smartNameFieldMappers . mapper ( ) . rangeFilter ( from , to , includeLower , includeUpper ) ; } } if ( filter == null ) { filter = new TermRangeFilter ( fieldName , from , to , includeLower , includeUpper ) ; } <START_BUG> return wrapSmartNameFilter ( filter , smartNameFieldMappers , parseContext . indexCache ( ) ) ; <END_BUG> } }<BUG2FIX>return wrapSmartNameFilter ( filter , smartNameFieldMappers , parseContext ) ;
public abstract class CompressedIndexInput < T extends CompressorContext > extends IndexInput { private IndexInput in ; protected final T context ; private int version ; private long totalUncompressedLength ; private BigLongArray offsets ; private boolean closed ; protected byte [ ] uncompressed ; protected int uncompressedLength ; private int position = 0 ; private int valid = 0 ; private int currentOffsetIdx ; private long currentUncompressedChunkPointer ; public CompressedIndexInput ( IndexInput in , T context ) throws IOException { } public int available ( ) throws IOException { } @ Override public byte readByte ( ) throws IOException { } public int read ( byte [ ] buffer , int offset , int length , boolean fullRead ) throws IOException { } @ Override public void readBytes ( byte [ ] b , int offset , int len ) throws IOException { } @ Override public long getFilePointer ( ) { } @ Override public void seek ( long pos ) throws IOException { } @ Override public long length ( ) { } @ Override public void close ( ) throws IOException { } protected abstract void doClose ( ) throws IOException { } protected boolean readyBuffer ( ) throws IOException { } protected abstract void readHeader ( IndexInput in ) throws IOException { } protected abstract int uncompress ( IndexInput in , byte [ ] out ) throws IOException { } @ Override <START_BUG> public Object clone ( ) { <END_BUG> CompressedIndexInput cloned = ( ( CompressedIndexInput ) ( super . clone ( ) ) ) ; cloned . uncompressed = new byte [ uncompressedLength ] ; System . arraycopy ( uncompressed , 0 , cloned . uncompressed , 0 , uncompressedLength ) ; cloned . in = ( ( IndexInput ) ( cloned . in . clone ( ) ) ) ; return cloned ; } }<BUG2FIX>public IndexInput clone ( ) {
public class BitmapFontCache { private final BitmapFont font ; private float [ ] vertices = new float [ 0 ] ; private int idx ; private float x ; private float y ; private float color = WHITE . toFloatBits ( ) ; private final Color tempColor = new Color ( Color . WHITE ) ; private final TextBounds textBounds = new TextBounds ( ) ; private boolean integer = true ; public BitmapFontCache ( BitmapFont font ) { } public BitmapFontCache ( BitmapFont font , boolean integer ) { } public void setPosition ( float x , float y ) { } public void translate ( float xAmount , float yAmount ) { } public void setColor ( float color ) { } public void setColor ( Color tint ) { } public void setColor ( float r , float g , float b , float a ) { } public void setColor ( Color tint , int start , int end ) { } public void draw ( SpriteBatch spriteBatch ) { } public void draw ( SpriteBatch spriteBatch , float alphaModulation ) { } public Color getColor ( ) { } public void clear ( ) { } private void require ( int glyphCount ) { } private float addToCache ( CharSequence str , float x , float y , int start , int end ) { } private void addGlyph ( Glyph glyph , float x , float y , float width , float height ) { float x2 = x + width ; float y2 = y + height ; final float u = glyph . u ; final float u2 = glyph . u2 ; final float v = glyph . v ; final float v2 = glyph . v2 ; final float [ ] vertices = this . vertices ; if ( integer ) { x = Math . round ( x ) ; y = Math . round ( y ) ; x2 = Math . round ( x2 ) ; y2 = Math . round ( y2 ) ; } int idx = this . idx ; this . idx += 20 ; vertices [ ( idx ++ ) ] = x ; vertices [ ( idx ++ ) ] = y ; vertices [ ( idx ++ ) ] = color ; vertices [ ( idx ++ ) ] = u ; vertices [ ( idx ++ ) ] = v ; vertices [ ( idx ++ ) ] = x ; vertices [ ( idx ++ ) ] = y2 ; vertices [ ( idx ++ ) ] = color ; vertices [ ( idx ++ ) ] = u ; vertices [ ( idx ++ ) ] = v2 ; vertices [ ( idx ++ ) ] = x2 ; vertices [ ( idx ++ ) ] = y2 ; vertices [ ( idx ++ ) ] = color ; vertices [ ( idx ++ ) ] = u2 ; vertices [ ( idx ++ ) ] = v2 ; vertices [ ( idx ++ ) ] = x2 ; vertices [ ( idx ++ ) ] = y ; vertices [ ( idx ++ ) ] = color ; vertices [ ( idx ++ ) ] = u2 ; <START_BUG> vertices [ ( idx ++ ) ] = v ; <END_BUG> } public TextBounds setText ( CharSequence str , float x , float y ) { } public TextBounds setText ( CharSequence str , float x , float y , int start , int end ) { } public TextBounds addText ( CharSequence str , float x , float y ) { } public TextBounds addText ( CharSequence str , float x , float y , int start , int end ) { } public TextBounds setMultiLineText ( CharSequence str , float x , float y ) { } public TextBounds setMultiLineText ( CharSequence str , float x , float y , float alignmentWidth , HAlignment alignment ) { } public TextBounds addMultiLineText ( CharSequence str , float x , float y ) { } public TextBounds addMultiLineText ( CharSequence str , float x , float y , float alignmentWidth , HAlignment alignment ) { } public TextBounds setWrappedText ( CharSequence str , float x , float y , float wrapWidth ) { } public TextBounds setWrappedText ( CharSequence str , float x , float y , float wrapWidth , HAlignment alignment ) { } public TextBounds addWrappedText ( CharSequence str , float x , float y , float wrapWidth ) { } public TextBounds addWrappedText ( CharSequence str , float x , float y , float wrapWidth , HAlignment alignment ) { } public TextBounds getBounds ( ) { } public float getX ( ) { } public float getY ( ) { } public BitmapFont getFont ( ) { } public void setUseIntegerPositions ( boolean use ) { } public boolean usesIntegerPositions ( ) { } public float [ ] getVertices ( ) { } }<BUG2FIX>vertices [ idx ] = v ;
public class ByteBufferIndexInput extends IndexInput { private static final ByteBuffer EMPTY_BUFFER = ByteBuffer . allocate ( 0 ) . asReadOnlyBuffer ( ) ; private final ByteBufferFile file ; private final long length ; private ByteBuffer currentBuffer ; private int currentBufferIndex ; private long bufferStart ; private final int BUFFER_SIZE ; private volatile boolean closed = false ; public ByteBufferIndexInput ( String name , ByteBufferFile file ) throws IOException { } @ Override public void close ( ) { } @ Override public long length ( ) { } @ Override public short readShort ( ) throws IOException { } @ Override public int readInt ( ) throws IOException { } @ Override public long readLong ( ) throws IOException { } @ Override public byte readByte ( ) throws IOException { } @ Override public void readBytes ( byte [ ] b , int offset , int len ) throws IOException { } @ Override public long getFilePointer ( ) { } @ Override public void seek ( long pos ) throws IOException { } private void switchCurrentBuffer ( boolean enforceEOF ) throws IOException { } @ Override <START_BUG> public Object clone ( ) { <END_BUG> ByteBufferIndexInput cloned = ( ( ByteBufferIndexInput ) ( super . clone ( ) ) ) ; cloned . file . incRef ( ) ; if ( ( currentBuffer ) != ( ByteBufferIndexInput . EMPTY_BUFFER ) ) { cloned . currentBuffer = currentBuffer . asReadOnlyBuffer ( ) ; cloned . currentBuffer . position ( currentBuffer . position ( ) ) ; } return cloned ; } }<BUG2FIX>public IndexInput clone ( ) {
class RecoveryFileChunkRequest implements Streamable { private ShardId shardId ; private String name ; private long position ; private long length ; private String checksum ; private BytesReference content ; RecoveryFileChunkRequest ( ) { } RecoveryFileChunkRequest ( ShardId shardId , String name , long position , long length , String checksum , BytesArray content ) { } public ShardId shardId ( ) { } public String name ( ) { } public long position ( ) { } @ Nullable public String checksum ( ) { } public long length ( ) { } public BytesReference content ( ) { } public RecoveryFileChunkRequest readFileChunk ( StreamInput in ) throws IOException { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { shardId . writeTo ( out ) ; out . writeUTF ( name ) ; out . writeVLong ( position ) ; out . writeVLong ( length ) ; if ( ( checksum ) == null ) { out . writeBoolean ( false ) ; } else { out . writeBoolean ( true ) ; out . writeUTF ( checksum ) ; } <START_BUG> out . writeBytesReference ( content , true ) ; <END_BUG> } @ Override public String toString ( ) { } }<BUG2FIX>out . writeBytesReference ( content ) ;
public class LwjglCanvas implements Application { LwjglGraphics graphics ; OpenALAudio audio ; LwjglFiles files ; LwjglInput input ; LwjglNet net ; ApplicationListener listener ; Canvas canvas ; final Array < Runnable > runnables = new Array ( ) ; final Array < Runnable > executedRunnables = new Array ( ) ; final Array < LifecycleListener > lifecycleListeners = new Array < LifecycleListener > ( ) ; boolean running = true ; int logLevel = LOG_INFO ; Cursor cursor ; public LwjglCanvas ( ApplicationListener listener , boolean useGL2 ) { } public LwjglCanvas ( ApplicationListener listener , LwjglApplicationConfiguration config ) { } private void initialize ( ApplicationListener listener , LwjglApplicationConfiguration config ) { } protected void setDisplayMode ( int width , int height ) { } protected void setTitle ( String title ) { } @ Override public ApplicationListener getApplicationListener ( ) { } public Canvas getCanvas ( ) { } @ Override public Audio getAudio ( ) { } @ Override public Files getFiles ( ) { } @ Override public Graphics getGraphics ( ) { } @ Override public Input getInput ( ) { } @ Override public Net getNet ( ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } void create ( ) { } public boolean executeRunnables ( ) { } protected int getFrameRate ( ) { } protected void exception ( Throwable ex ) { } protected void start ( ) { } protected void resize ( int width , int height ) { } protected void stopped ( ) { } public void stop ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } Map < String , Preferences > preferences = new HashMap < String , Preferences > ( ) ; @ Override public Preferences getPreferences ( String name ) { } @ Override public Clipboard getClipboard ( ) { } @ Override public void postRunnable ( Runnable runnable ) { } @ Override public void debug ( String tag , String message ) { } @ Override public void debug ( String tag , String message , Throwable exception ) { } public void log ( String tag , String message ) { } @ Override <START_BUG> public void log ( String tag , String message , Exception exception ) { <END_BUG> if ( ( logLevel ) >= ( LOG_INFO ) ) { System . out . println ( ( ( tag + ":<seq2seq4repair_space>" ) + message ) ) ; exception . printStackTrace ( System . out ) ; } } @ Override public void error ( String tag , String message ) { } @ Override public void error ( String tag , String message , Throwable exception ) { } @ Override public void setLogLevel ( int logLevel ) { } @ Override public int getLogLevel ( ) { } @ Override public void exit ( ) { } public void setCursor ( Cursor cursor ) { } @ Override public void addLifecycleListener ( LifecycleListener listener ) { } @ Override public void removeLifecycleListener ( LifecycleListener listener ) { } }<BUG2FIX>public void log ( String tag , String message , Throwable exception ) {
public class RootObjectMapper extends ObjectMapper { public static class Defaults { public static final FormatDateTimeFormatter [ ] DYNAMIC_DATE_TIME_FORMATTERS = new FormatDateTimeFormatter [ ] { DateFieldMapper . Defaults . DATE_TIME_FORMATTER , Joda . forPattern ( "yyyy/MM/dd<seq2seq4repair_space>HH:mm:ss||yyyy/MM/dd" ) } ; public static final boolean DATE_DETECTION = true ; public static final boolean NUMERIC_DETECTION = false ; } public static class Builder extends ObjectMapper . Builder < RootObjectMapper . Builder , RootObjectMapper > { protected final List < DynamicTemplate > dynamicTemplates = newArrayList ( ) ; protected Set < String > seenDateFormats = Sets . newHashSet ( ) ; protected List < FormatDateTimeFormatter > dynamicDateTimeFormatters = newArrayList ( ) ; protected boolean dateDetection = RootObjectMapper . Defaults . DATE_DETECTION ; protected boolean numericDetection = RootObjectMapper . Defaults . NUMERIC_DETECTION ; public Builder ( String name ) { } public RootObjectMapper . Builder noDynamicDateTimeFormatter ( ) { } public RootObjectMapper . Builder dynamicDateTimeFormatter ( Iterable < FormatDateTimeFormatter > dateTimeFormatters ) { } public RootObjectMapper . Builder add ( DynamicTemplate dynamicTemplate ) { } public RootObjectMapper . Builder add ( DynamicTemplate ... dynamicTemplate ) { } @ Override protected ObjectMapper createMapper ( String name , String fullPath , boolean enabled , Nested nested , Dynamic dynamic , ContentPath . Type pathType , Map < String , Mapper > mappers ) { } } public static class TypeParser extends ObjectMapper . TypeParser { @ Override protected ObjectMapper . Builder createBuilder ( String name ) { } @ Override protected void processField ( ObjectMapper . Builder builder , String fieldName , Object fieldNode ) { } } private final FormatDateTimeFormatter [ ] dynamicDateTimeFormatters ; private final boolean dateDetection ; private final boolean numericDetection ; private volatile DynamicTemplate [ ] dynamicTemplates ; RootObjectMapper ( String name , boolean enabled , Dynamic dynamic , ContentPath . Type pathType , Map < String , Mapper > mappers , FormatDateTimeFormatter [ ] dynamicDateTimeFormatters , DynamicTemplate [ ] dynamicTemplates , boolean dateDetection , boolean numericDetection ) { } public boolean dateDetection ( ) { } public boolean numericDetection ( ) { } public FormatDateTimeFormatter [ ] dynamicDateTimeFormatters ( ) { } public Mapper . Builder findTemplateBuilder ( ParseContext context , String name , String dynamicType ) { DynamicTemplate dynamicTemplate = findTemplate ( context . path ( ) , name , dynamicType ) ; if ( dynamicTemplate == null ) { return null ; } Mapper . TypeParser . ParserContext parserContext = context . docMapperParser ( ) . parserContext ( ) ; String mappingType = dynamicTemplate . mappingType ( dynamicType ) ; Mapper . TypeParser typeParser = parserContext . typeParser ( mappingType ) ; if ( typeParser == null ) { throw new MapperParsingException ( ( ( ( ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>find<seq2seq4repair_space>type<seq2seq4repair_space>parsed<seq2seq4repair_space>[" + mappingType ) + "]<seq2seq4repair_space>for<seq2seq4repair_space>[" ) + name ) + "]" ) ) ; } <START_BUG> return typeParser . parse ( name , dynamicTemplate . mappingForName ( name , mappingType ) , parserContext ) ; <END_BUG> } public DynamicTemplate findTemplate ( ContentPath path , String name , String dynamicType ) { } @ Override protected void doMerge ( ObjectMapper mergeWith , MergeContext mergeContext ) { } @ Override protected void doXContent ( XContentBuilder builder , ToXContent . Params params ) throws IOException { } }<BUG2FIX>return typeParser . parse ( name , dynamicTemplate . mappingForName ( name , dynamicType ) , parserContext ) ;
public class BouncyAndroid extends AndroidApplication { @ Override public void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; <START_BUG> initialize ( new Bouncy ( ) , false ) ; <END_BUG> } }<BUG2FIX>initialize ( new Bouncy ( ) ) ;
public class PrismaticJointDef extends JointDef { public PrismaticJointDef ( ) { } public void initialize ( Body bodyA , Body bodyB , Vector2 anchor , Vector2 axis ) { this . bodyA = bodyA ; this . bodyB = bodyB ; localAnchorA . set ( bodyA . getLocalPoint ( anchor ) ) ; localAnchorB . set ( bodyB . getLocalPoint ( anchor ) ) ; <START_BUG> localAxis1 . set ( bodyA . getLocalVector ( anchor ) ) ; <END_BUG> referenceAngle = ( bodyB . getAngle ( ) ) - ( bodyA . getAngle ( ) ) ; } public final Vector2 localAnchorA = new Vector2 ( ) ; public final Vector2 localAnchorB = new Vector2 ( ) ; public final Vector2 localAxis1 = new Vector2 ( 1 , 0 ) ; public float referenceAngle = 0 ; public boolean enableLimit = false ; public float lowerTranslation = 0 ; public float upperTranslation = 0 ; public boolean enableMotor = false ; public float maxMotorForce = 0 ; public float motorSpeed = 0 ; }<BUG2FIX>localAxis1 . set ( bodyA . getLocalVector ( axis ) ) ;
public class StringFieldsFunctionDataComparator extends FieldComparator < String > { public static ExtendedFieldComparatorSource comparatorSource ( SearchScript script ) { } private static class InnerSource extends FieldDataType . ExtendedFieldComparatorSource { private final SearchScript script ; private InnerSource ( SearchScript script ) { } @ Override public FieldComparator newComparator ( String fieldname , int numHits , int sortPos , boolean reversed ) throws IOException { } @ Override public Type reducedType ( ) { } } private final SearchScript script ; private String [ ] values ; private String bottom ; public StringFieldsFunctionDataComparator ( int numHits , SearchScript script ) { } @ Override public FieldComparator < String > setNextReader ( AtomicReaderContext context ) throws IOException { <START_BUG> script . setNextReader ( context . reader ( ) ) ; <END_BUG> return this ; } @ Override public void setScorer ( Scorer scorer ) { } @ Override public int compare ( int slot1 , int slot2 ) { } @ Override public int compareBottom ( int doc ) { } @ Override public int compareDocToValue ( int doc , String val2 ) throws IOException { } @ Override public void copy ( int slot , int doc ) { } @ Override public void setBottom ( final int bottom ) { } @ Override public String value ( int slot ) { } }<BUG2FIX>script . setNextReader ( context ) ;
public final class ExceptionsHelper { private static final ESLogger logger = Loggers . getLogger ( ExceptionsHelper . class ) ; public static Throwable unwrapCause ( Throwable t ) { int counter = 0 ; Throwable result = t ; while ( result instanceof ElasticSearchWrapperException ) { if ( ( result . getCause ( ) ) == null ) { return result ; } if ( ( result . getCause ( ) ) == result ) { return result ; } if ( ( counter ++ ) > 10 ) { ExceptionsHelper . logger . warn ( "Exception<seq2seq4repair_space>cause<seq2seq4repair_space>unwrapping<seq2seq4repair_space>ran<seq2seq4repair_space>for<seq2seq4repair_space>10<seq2seq4repair_space>levels..." , t ) ; return result ; } <START_BUG> result = t . getCause ( ) ; <END_BUG> } return result ; } public static String detailedMessage ( Throwable t ) { } public static String detailedMessage ( Throwable t , boolean newLines , int initialCounter ) { } }<BUG2FIX>result = result . getCause ( ) ;
public class StillModel implements Model { public final StillSubMesh [ ] subMeshes ; public StillModel ( StillSubMesh [ ] subMeshes ) { } @ Override public void render ( ) { } @ Override public void render ( ShaderProgram program ) { } @ Override public Model getSubModel ( String ... subMeshNames ) { } @ Override <START_BUG> public SubMesh getSubMesh ( String name ) { <END_BUG> for ( StillSubMesh subMesh : subMeshes ) { if ( subMesh . name . equals ( name ) ) return subMesh ; } return null ; } @ Override public SubMesh [ ] getSubMeshes ( ) { } @ Override public void setMaterials ( Material ... materials ) { } @ Override public void setMaterial ( Material material ) { } private static final BoundingBox tmpBox = new BoundingBox ( ) ; @ Override public void getBoundingBox ( BoundingBox bbox ) { } }<BUG2FIX>public StillSubMesh getSubMesh ( String name ) {
public class TransportSearchQueryAndFetchAction extends TransportSearchTypeAction { @ Inject public TransportSearchQueryAndFetchAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportSearchCache transportSearchCache , SearchServiceTransportAction searchService , SearchPhaseController searchPhaseController ) { } @ Override protected void doExecute ( SearchRequest searchRequest , ActionListener < SearchResponse > listener ) { } private class AsyncAction extends BaseAsyncAction < QueryFetchSearchResult > { private final Map < SearchShardTarget , QueryFetchSearchResult > queryFetchResults = searchCache . obtainQueryFetchResults ( ) ; private AsyncAction ( SearchRequest request , ActionListener < SearchResponse > listener ) { } @ Override protected String firstPhaseName ( ) { } @ Override protected void sendExecuteFirstPhase ( DiscoveryNode node , InternalSearchRequest request , SearchServiceListener < QueryFetchSearchResult > listener ) { } @ Override protected void processFirstPhaseResult ( ShardRouting shard , QueryFetchSearchResult result ) { } @ Override protected void moveToSecondPhase ( ) throws Exception { sortedShardList = searchPhaseController . sortDocs ( queryFetchResults . values ( ) ) ; final InternalSearchResponse internalResponse = searchPhaseController . merge ( sortedShardList , queryFetchResults , queryFetchResults ) ; String scrollId = null ; if ( ( request . scroll ( ) ) != null ) { <START_BUG> scrollId = buildScrollId ( request . searchType ( ) , queryFetchResults . values ( ) ) ; <END_BUG> } listener . onResponse ( new SearchResponse ( internalResponse , scrollId , expectedSuccessfulOps , successulOps . get ( ) , buildTookInMillis ( ) , buildShardFailures ( ) ) ) ; searchCache . releaseQueryFetchResults ( queryFetchResults ) ; } } }<BUG2FIX>scrollId = buildScrollId ( request . searchType ( ) , queryFetchResults . values ( ) , null ) ;
public class ParentFieldMapper extends AbstractFieldMapper < Uid > implements InternalMapper , RootMapper { public static final String NAME = "_parent" ; public static final String CONTENT_TYPE = "_parent" ; public static class Defaults extends AbstractFieldMapper . Defaults { public static final String NAME = ParentFieldMapper . NAME ; public static final FieldType FIELD_TYPE = new FieldType ( AbstractFieldMapper . Defaults . FIELD_TYPE ) ; } public static class Builder extends Mapper . Builder < ParentFieldMapper . Builder , ParentFieldMapper > { protected String indexName ; private String type ; protected PostingsFormatProvider postingsFormat ; public Builder ( ) { } public ParentFieldMapper . Builder type ( String type ) { } protected ParentFieldMapper . Builder postingsFormat ( PostingsFormatProvider postingsFormat ) { } @ Override public ParentFieldMapper build ( BuilderContext context ) { } } public static class TypeParser implements Mapper . TypeParser { @ Override public Mapper . Builder parse ( String name , Map < String , Object > node , ParserContext parserContext ) throws MapperParsingException { } } private final String type ; private final BytesRef typeAsBytes ; protected ParentFieldMapper ( String name , String indexName , String type , PostingsFormatProvider postingsFormat , @ Nullable Settings fieldDataSettings ) { } public String type ( ) { } @ Override public FieldType defaultFieldType ( ) { } @ Override public FieldDataType defaultFieldDataType ( ) { } @ Override public void preParse ( ParseContext context ) throws IOException { } @ Override public void postParse ( ParseContext context ) throws IOException { } @ Override public void validate ( ParseContext context ) throws MapperParsingException { } @ Override public boolean includeInObject ( ) { } @ Override protected Field parseCreateField ( ParseContext context ) throws IOException { } @ Override public Uid value ( Object value ) { } @ Override public Object valueForSearch ( Object value ) { } @ Override public BytesRef indexedValueForSearch ( Object value ) { } @ Override public Query termQuery ( Object value , @ Nullable QueryParseContext context ) { } @ Override public Filter termFilter ( Object value , @ Nullable QueryParseContext context ) { } @ Override public Filter termsFilter ( List values , @ Nullable QueryParseContext context ) { if ( context == null ) { <START_BUG> return super . termFilter ( values , context ) ; <END_BUG> } List < BytesRef > bValues = new ArrayList < BytesRef > ( values . size ( ) ) ; for ( Object value : values ) { BytesRef bValue = BytesRefs . toBytesRef ( value ) ; for ( String type : context . mapperService ( ) . types ( ) ) { bValues . add ( Uid . createUidAsBytes ( type , bValue ) ) ; } } return new org . apache . lucene . queries . TermsFilter ( names . indexName ( ) , bValues ) ; } @ Override public boolean useTermQueryWithQueryString ( ) { } @ Override protected String contentType ( ) { } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } @ Override public void merge ( Mapper mergeWith , MergeContext mergeContext ) throws MergeMappingException { } }<BUG2FIX>return super . termsFilter ( values , context ) ;
public abstract class BaseG3dHudTest extends BaseG3dTest { public static final int PREF_HUDWIDTH = 640 ; public static final int PREF_HUDHEIGHT = 480 ; public static final float rotationSpeed = 0.02F * 360.0F ; public static final float moveSpeed = 0.25F ; protected Stage hud ; protected float hudWidth ; protected float hudHeight ; protected Skin skin ; protected Label fpsLabel ; protected BaseG3dHudTest . CollapsableWindow modelsWindow ; protected CheckBox gridCheckBox ; protected CheckBox rotateCheckBox ; protected CheckBox moveCheckBox ; protected final StringBuilder stringBuilder = new StringBuilder ( ) ; protected final Matrix4 transform = new Matrix4 ( ) ; protected float moveRadius = 2.0F ; protected String [ ] models = new String [ ] { "car.obj" , "cube.obj" , "scene.obj" , "scene2.obj" , "wheel.obj" , "g3d/invaders.g3dj" , "g3d/head.g3db" , "g3d/house.g3dj" , "g3d/knight.g3dj" , "g3d/knight.g3db" , "g3d/ship.obj" , "g3d/shapes/cube_1.0x1.0.g3dj" , "g3d/shapes/cube_1.5x1.5.g3dj" , "g3d/shapes/sphere.g3dj" , "g3d/shapes/teapot.g3dj" , "g3d/shapes/torus.g3dj" } ; @ Override public void create ( ) { } protected void createHUD ( ) { } protected BaseG3dHudTest . CollapsableWindow addListWindow ( String title , List list , float x , float y ) { } protected abstract void onModelClicked ( final String name ) { } protected void getStatus ( final StringBuilder stringBuilder ) { } protected float rotation ; protected float movement ; @ Override public void render ( ) { } @ Override public void resize ( int width , int height ) { super . resize ( width , height ) ; <START_BUG> hud . getViewport ( ) . update ( width , height ) ; <END_BUG> hudWidth = hud . getWidth ( ) ; hudHeight = hud . getHeight ( ) ; } @ Override public void dispose ( ) { } public static class CollapsableWindow extends Window { private boolean collapsed ; private float collapseHeight = 20.0F ; private float expandHeight ; public CollapsableWindow ( String title , Skin skin ) { } public void expand ( ) { } public void collapse ( ) { } public void toggleCollapsed ( ) { } public boolean isCollapsed ( ) { } } }<BUG2FIX>hud . getViewport ( ) . update ( width , height , true ) ;
public class LwjglCanvas implements Application { final LwjglGraphics graphics ; final OpenALAudio audio ; final LwjglFiles files ; final LwjglInput input ; final ApplicationListener listener ; final Canvas canvas ; final List < Runnable > runnables = new ArrayList < Runnable > ( ) ; boolean running = true ; public LwjglCanvas ( ApplicationListener listener , boolean useGL2 ) { } public Canvas getCanvas ( ) { } @ Override public Audio getAudio ( ) { } @ Override public Files getFiles ( ) { } @ Override public Graphics getGraphics ( ) { } @ Override public Input getInput ( ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } @ Override public void log ( String tag , String message ) { } void start ( ) { try { graphics . setupDisplay ( ) ; } catch ( LWJGLException e ) { throw new GdxRuntimeException ( e ) ; } Keyboard . enableRepeatEvents ( true ) ; listener . create ( ) ; listener . resize ( graphics . getWidth ( ) , graphics . getHeight ( ) ) ; final Runnable runnable = new Runnable ( ) { int lastWidth = Math . max ( 1 , graphics . getWidth ( ) ) ; int lastHeight = Math . max ( 1 , graphics . getHeight ( ) ) ; public void run ( ) { if ( ! ( running ) ) return ; graphics . updateTime ( ) ; synchronized ( runnables ) { for ( int i = 0 ; i < ( runnables . size ( ) ) ; i ++ ) { runnables . get ( i ) . run ( ) ; } runnables . clear ( ) ; } input . update ( ) ; int width = Math . max ( 1 , graphics . getWidth ( ) ) ; int height = Math . max ( 1 , graphics . getHeight ( ) ) ; if ( ( ( lastWidth ) != width ) || ( ( lastHeight ) != height ) ) { lastWidth = width ; lastHeight = height ; listener . resize ( width , height ) ; } <START_BUG> ( ( LwjglInput ) ( Gdx . input ) ) . processEvents ( ) ; <END_BUG> listener . render ( ) ; audio . update ( ) ; Display . update ( ) ; Display . sync ( 60 ) ; } } ; new Thread ( "LWJGL<seq2seq4repair_space>Canvas" ) { public void run ( ) { while ( ( running ) && ( ! ( Display . isCloseRequested ( ) ) ) ) { try { EventQueue . invokeAndWait ( runnable ) ; } catch ( Exception ex ) { throw new GdxRuntimeException ( ex ) ; } } } } . start ( ) ; } public void stop ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } Map < String , Preferences > preferences = new HashMap < String , Preferences > ( ) ; @ Override public Preferences getPreferences ( String name ) { } @ Override public void postRunnable ( Runnable runnable ) { } }<BUG2FIX>input . processEvents ( ) ;
public class GroupCullingTest extends GdxTest { private static final int count = 100 ; private Stage stage ; private Skin skin ; private Table root ; private Label drawnLabel ; int drawn ; public void create ( ) { stage = new Stage ( 0 , 0 , true ) ; input . setInputProcessor ( stage ) ; root = new Table ( ) ; root . setFillParent ( true ) ; stage . addActor ( root ) ; <START_BUG> skin = new Skin ( files . internal ( "data/uiskin.json" ) , files . internal ( "data/uiskin.png" ) ) ; <END_BUG> Table labels = new Table ( ) ; root . add ( new com . badlogic . gdx . scenes . scene2d . ui . ScrollPane ( labels , skin ) ) . expand ( ) . fill ( ) ; root . row ( ) ; root . add ( ( drawnLabel = new Label ( "" , skin ) ) ) ; for ( int i = 0 ; i < ( GroupCullingTest . count ) ; i ++ ) { labels . add ( new Label ( ( "Label:<seq2seq4repair_space>" + i ) , skin ) { public void draw ( SpriteBatch batch , float parentAlpha ) { super . draw ( batch , parentAlpha ) ; ( drawn ) ++ ; } } ) ; labels . row ( ) ; } } @ Override public void dispose ( ) { } public void resize ( int width , int height ) { } public void render ( ) { } public boolean needsGL20 ( ) { } }<BUG2FIX>skin = new Skin ( files . internal ( "data/uiskin.json" ) ) ;
public interface Application { public enum ApplicationType { Android , Desktop , Applet , WebGL , iOS ; } public static final int LOG_NONE = 0 ; public static final int LOG_DEBUG = 3 ; public static final int LOG_INFO = 2 ; public static final int LOG_ERROR = 1 ; public ApplicationListener getApplicationListener ( ) { } public Graphics getGraphics ( ) { } public Audio getAudio ( ) { } public Input getInput ( ) { } public Files getFiles ( ) { } public Net getNet ( ) { } public void log ( String tag , String message ) { } <START_BUG> public void log ( String tag , String message , Exception exception ) ; <END_BUG> public void error ( String tag , String message ) { } public void error ( String tag , String message , Throwable exception ) { } public void debug ( String tag , String message ) { } public void debug ( String tag , String message , Throwable exception ) { } public void setLogLevel ( int logLevel ) { } public int getLogLevel ( ) { } public Application . ApplicationType getType ( ) { } public int getVersion ( ) { } public long getJavaHeap ( ) { } public long getNativeHeap ( ) { } public Preferences getPreferences ( String name ) { } public Clipboard getClipboard ( ) { } public void postRunnable ( Runnable runnable ) { } public void exit ( ) { } public void addLifecycleListener ( LifecycleListener listener ) { } public void removeLifecycleListener ( LifecycleListener listener ) { } }<BUG2FIX>public void log ( String tag , String message , Throwable exception ) ;
public class TextureRenderTest implements GdxTest { private OrthographicCamera camera ; private Mesh mesh ; private Texture texture ; private ArrayList < TextureRenderTest . SimpleRect > rects = new ArrayList < TextureRenderTest . SimpleRect > ( ) ; Color color = new Color ( Color . GREEN ) ; @ Override public void surfaceCreated ( ) { camera = new OrthographicCamera ( ) ; camera . setViewport ( 480 , 320 ) ; camera . getPosition ( ) . set ( ( ( graphics . getWidth ( ) ) / 2 ) , ( ( graphics . getHeight ( ) ) / 2 ) , 0 ) ; Pixmap pixmap = graphics . newPixmap ( files . getFileHandle ( "data/badlogic.jpg" , Internal ) ) ; texture = graphics . newUnmanagedTexture ( pixmap , Linear , Linear , ClampToEdge , ClampToEdge ) ; float invTexWidth = 1.0F / ( texture . getWidth ( ) ) ; float invTexHeight = 1.0F / ( texture . getHeight ( ) ) ; rects = createRects ( ) ; if ( ( this . mesh ) == null ) <START_BUG> this . mesh = new Mesh ( false , false , ( ( 6 * 4 ) * ( rects . size ( ) ) ) , 0 , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . Position , 2 , "a_position" ) , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . TextureCoordinates , 2 , "a_texCoord" ) ) ; <END_BUG> final float [ ] vertices = new float [ ( ( rects . size ( ) ) * 6 ) * 4 ] ; int idx = 0 ; for ( int i = 0 ; i < ( rects . size ( ) ) ; i ++ ) { TextureRenderTest . SimpleRect rect = rects . get ( i ) ; float u = ( rect . x ) * invTexWidth ; float v = ( rect . y ) * invTexHeight ; float u2 = ( ( rect . x ) + ( rect . width ) ) * invTexWidth ; float v2 = ( ( rect . y ) + ( rect . height ) ) * invTexHeight ; float fx = rect . x ; float fy = rect . y ; float fx2 = ( rect . x ) + ( rect . width ) ; float fy2 = ( rect . y ) - ( rect . height ) ; vertices [ ( idx ++ ) ] = fx ; vertices [ ( idx ++ ) ] = fy ; vertices [ ( idx ++ ) ] = u ; vertices [ ( idx ++ ) ] = v ; vertices [ ( idx ++ ) ] = fx ; vertices [ ( idx ++ ) ] = fy2 ; vertices [ ( idx ++ ) ] = u ; vertices [ ( idx ++ ) ] = v2 ; vertices [ ( idx ++ ) ] = fx2 ; vertices [ ( idx ++ ) ] = fy2 ; vertices [ ( idx ++ ) ] = u2 ; vertices [ ( idx ++ ) ] = v2 ; vertices [ ( idx ++ ) ] = fx2 ; vertices [ ( idx ++ ) ] = fy2 ; vertices [ ( idx ++ ) ] = u2 ; vertices [ ( idx ++ ) ] = v2 ; vertices [ ( idx ++ ) ] = fx2 ; vertices [ ( idx ++ ) ] = fy ; vertices [ ( idx ++ ) ] = u2 ; vertices [ ( idx ++ ) ] = v ; vertices [ ( idx ++ ) ] = fx ; vertices [ ( idx ++ ) ] = fy ; vertices [ ( idx ++ ) ] = u ; vertices [ ( idx ++ ) ] = v ; } this . mesh . setVertices ( vertices ) ; } @ Override public void surfaceChanged ( int width , int height ) { } @ Override public void render ( ) { } @ Override public void dispose ( ) { } private ArrayList < TextureRenderTest . SimpleRect > createRects ( ) { } private static class SimpleRect { public int index ; public float x ; public float y ; public float height ; public float width ; private SimpleRect ( int index , float x , float y , float width , float height ) { } } @ Override public boolean needsGL20 ( ) { } }<BUG2FIX>this . mesh = new Mesh ( false , ( ( 6 * 4 ) * ( rects . size ( ) ) ) , 0 , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . Position , 2 , "a_position" ) , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . TextureCoordinates , 2 , "a_texCoord" ) ) ;
public class RestClearIndicesCacheAction extends BaseRestHandler { @ Inject public RestClearIndicesCacheAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { ClearIndicesCacheRequest clearIndicesCacheRequest = new ClearIndicesCacheRequest ( RestActions . splitIndices ( request . param ( "index" ) ) ) ; clearIndicesCacheRequest . listenerThreaded ( false ) ; if ( request . hasParam ( "ignore_indices" ) ) { clearIndicesCacheRequest . ignoreIndices ( IgnoreIndices . fromString ( request . param ( "ignore_indices" ) ) ) ; } try { clearIndicesCacheRequest . filterCache ( request . paramAsBoolean ( "filter" , clearIndicesCacheRequest . filterCache ( ) ) ) ; clearIndicesCacheRequest . fieldDataCache ( request . paramAsBoolean ( "field_data" , clearIndicesCacheRequest . fieldDataCache ( ) ) ) ; clearIndicesCacheRequest . idCache ( request . paramAsBoolean ( "id" , clearIndicesCacheRequest . idCache ( ) ) ) ; clearIndicesCacheRequest . fields ( request . paramAsStringArray ( "fields" , clearIndicesCacheRequest . fields ( ) ) ) ; clearIndicesCacheRequest . filterKeys ( request . paramAsStringArray ( "filter_keys" , clearIndicesCacheRequest . filterKeys ( ) ) ) ; BroadcastOperationThreading operationThreading = BroadcastOperationThreading . fromString ( request . param ( "operationThreading" ) , SINGLE_THREAD ) ; if ( operationThreading == ( BroadcastOperationThreading . NO_THREADS ) ) { operationThreading = BroadcastOperationThreading . THREAD_PER_SHARD ; } clearIndicesCacheRequest . operationThreading ( operationThreading ) ; } catch ( Exception e ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . BAD_REQUEST , builder . startObject ( ) . field ( "error" , e . getMessage ( ) ) . endObject ( ) ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } return ; } client . admin ( ) . indices ( ) . clearCache ( clearIndicesCacheRequest , new org . elasticsearch . action . ActionListener < ClearIndicesCacheResponse > ( ) { @ Override public void onResponse ( ClearIndicesCacheResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( "ok" , true ) ; buildBroadcastShardsHeader ( builder , response ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class RestNodesInfoAction extends BaseRestHandler { private final SettingsFilter settingsFilter ; @ Inject public RestNodesInfoAction ( Settings settings , Client client , RestController controller , SettingsFilter settingsFilter ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } void executeNodeRequest ( final RestRequest request , final RestChannel channel , NodesInfoRequest nodesInfoRequest ) { nodesInfoRequest . listenerThreaded ( false ) ; client . admin ( ) . cluster ( ) . nodesInfo ( nodesInfoRequest , new org . elasticsearch . action . ActionListener < NodesInfoResponse > ( ) { @ Override public void onResponse ( NodesInfoResponse response ) { try { response . settingsFilter ( settingsFilter ) ; XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( "ok" , true ) ; response . toXContent ( builder , request ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } class RestSettingsHandler implements RestHandler { @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } } class RestOsHandler implements RestHandler { @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } } class RestProcessHandler implements RestHandler { @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } } class RestJvmHandler implements RestHandler { @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } } class RestThreadPoolHandler implements RestHandler { @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } } class RestNetworkHandler implements RestHandler { @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } } class RestTransportHandler implements RestHandler { @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } } class RestHttpHandler implements RestHandler { @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } } }<BUG2FIX>} catch ( Throwable e ) {
public class Button extends Table implements Disableable { private Button . ButtonStyle style ; boolean isChecked ; boolean isDisabled ; ButtonGroup buttonGroup ; private ClickListener clickListener ; public Button ( Skin skin ) { } public Button ( Skin skin , String styleName ) { } public Button ( Actor child , Skin skin , String styleName ) { } public Button ( Actor child , Button . ButtonStyle style ) { } public Button ( Button . ButtonStyle style ) { } public Button ( ) { } private void initialize ( ) { } public Button ( Drawable up ) { } public Button ( Drawable up , Drawable down ) { } public Button ( Drawable up , Drawable down , Drawable checked ) { } public Button ( Actor child , Skin skin ) { } public void setChecked ( boolean isChecked ) { } public void toggle ( ) { } public boolean isChecked ( ) { } public boolean isPressed ( ) { } public boolean isOver ( ) { } public ClickListener getClickListener ( ) { } public boolean isDisabled ( ) { } public void setDisabled ( boolean isDisabled ) { } public void setStyle ( Button . ButtonStyle style ) { } public Button . ButtonStyle getStyle ( ) { } public void draw ( Batch batch , float parentAlpha ) { validate ( ) ; Drawable background = null ; float offsetX = 0 ; float offsetY = 0 ; if ( ( isPressed ( ) ) && ( ! ( isDisabled ( ) ) ) ) { background = ( ( style . down ) == null ) ? style . up : style . down ; offsetX = style . pressedOffsetX ; offsetY = style . pressedOffsetY ; } else { if ( ( isDisabled ( ) ) && ( ( style . disabled ) != null ) ) background = style . disabled ; else if ( ( isChecked ) && ( ( style . checked ) != null ) ) background = ( ( isOver ( ) ) && ( ( style . checkedOver ) != null ) ) ? style . checkedOver : style . checked ; else if ( ( isOver ( ) ) && ( ( style . over ) != null ) ) background = style . over ; else background = style . up ; offsetX = style . unpressedOffsetX ; offsetY = style . unpressedOffsetY ; } <START_BUG> setBackground ( background , ( background != null ) ) ; <END_BUG> Array < Actor > children = getChildren ( ) ; for ( int i = 0 ; i < ( children . size ) ; i ++ ) children . get ( i ) . moveBy ( offsetX , offsetY ) ; super . draw ( batch , parentAlpha ) ; for ( int i = 0 ; i < ( children . size ) ; i ++ ) children . get ( i ) . moveBy ( ( - offsetX ) , ( - offsetY ) ) ; } public float getPrefWidth ( ) { } public float getPrefHeight ( ) { } public float getMinWidth ( ) { } public float getMinHeight ( ) { } public static class ButtonStyle { public Drawable up ; public Drawable down ; public Drawable over ; public Drawable checked ; public Drawable checkedOver ; public Drawable disabled ; public float pressedOffsetX ; public float pressedOffsetY ; public float unpressedOffsetX ; public float unpressedOffsetY ; public ButtonStyle ( ) { } public ButtonStyle ( Drawable up , Drawable down , Drawable checked ) { } public ButtonStyle ( Button . ButtonStyle style ) { } } }<BUG2FIX>setBackground ( background ) ;
public class BumperElement extends FieldElement { Body pegBody ; Collection pegBodySet ; float radius ; float cx ; float cy ; float kick ; public void finishCreate ( Map params , World world ) { } @ Override public Collection getBodies ( ) { } @ Override public boolean shouldCallTick ( ) { } Vector2 impulseForBall ( Body ball ) { } @ Override public void handleCollision ( Body ball , Body bodyHit , Field field ) { Vector2 impulse = this . impulseForBall ( ball ) ; if ( impulse != null ) { <START_BUG> ball . applyLinearImpulse ( impulse , ball . getWorldCenter ( ) ) ; <END_BUG> flashForFrames ( 3 ) ; } } @ Override public void draw ( IFieldRenderer renderer ) { } }<BUG2FIX>ball . applyLinearImpulse ( impulse , ball . getWorldCenter ( ) , true ) ;
public class Pong implements RenderListener { private OrthographicCamera camera ; private Mesh paddleMesh ; private Mesh ballMesh ; private Font font ; private SpriteBatch spriteBatch ; private Vector2 leftPaddle = new Vector2 ( ) ; private Vector2 rightPaddle = new Vector2 ( ) ; private int leftScore = 0 ; private int rightScore = 0 ; private float leftPaddleMulti = 1 ; private final int BALL_SPEED = 100 ; private Vector2 ball = new Vector2 ( ) ; private Vector2 ballDirection = new Vector2 ( ) ; private int ballSpeed = BALL_SPEED ; private String score = "" ; @ Override public void surfaceCreated ( Application app ) { } private void setupGraphics ( Application app ) { paddleMesh = new Mesh ( app . getGraphics ( ) , true , true , false , 4 , 0 , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . Position , 2 , "a_position" ) ) ; paddleMesh . setVertices ( new float [ ] { - 5 , - 30 , 5 , - 30 , 5 , 30 , - 5 , 30 } ) ; ballMesh = new Mesh ( app . getGraphics ( ) , true , true , false , 4 , 0 , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . Position , 2 , "a_position" ) ) ; ballMesh . setVertices ( new float [ ] { - 5 , - 5 , 5 , - 5 , 5 , 5 , - 5 , 5 } ) ; font = app . getGraphics ( ) . newFont ( "Arial" , 30 , Plain , true ) ; score = "0<seq2seq4repair_space>:<seq2seq4repair_space>0" ; spriteBatch = new SpriteBatch ( app . getGraphics ( ) ) ; <START_BUG> camera = new OrthographicCamera ( ) ; <END_BUG> camera . setViewport ( 480 , 320 ) ; } private void setupGame ( ) { } @ Override public void dispose ( Application app ) { } @ Override public void render ( Application app ) { } private void updateGame ( Application app ) { } @ Override public void surfaceChanged ( Application app , int width , int height ) { } }<BUG2FIX>camera = new OrthographicCamera ( app . getGraphics ( ) ) ;
public class RestValidateQueryAction extends BaseRestHandler { @ Inject public RestValidateQueryAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { ValidateQueryRequest validateQueryRequest = new ValidateQueryRequest ( RestActions . splitIndices ( request . param ( "index" ) ) ) ; validateQueryRequest . listenerThreaded ( false ) ; if ( request . hasParam ( "ignore_indices" ) ) { validateQueryRequest . ignoreIndices ( IgnoreIndices . fromString ( request . param ( "ignore_indices" ) ) ) ; } try { BroadcastOperationThreading operationThreading = BroadcastOperationThreading . fromString ( request . param ( "operation_threading" ) , SINGLE_THREAD ) ; if ( operationThreading == ( BroadcastOperationThreading . NO_THREADS ) ) { operationThreading = BroadcastOperationThreading . SINGLE_THREAD ; } validateQueryRequest . operationThreading ( operationThreading ) ; if ( request . hasContent ( ) ) { validateQueryRequest . query ( request . content ( ) , request . contentUnsafe ( ) ) ; } else { String source = request . param ( "source" ) ; if ( source != null ) { validateQueryRequest . query ( source ) ; } else { BytesReference querySource = RestActions . parseQuerySource ( request ) ; if ( querySource != null ) { validateQueryRequest . query ( querySource , false ) ; } } } validateQueryRequest . types ( splitTypes ( request . param ( "type" ) ) ) ; if ( request . paramAsBoolean ( "explain" , false ) ) { validateQueryRequest . explain ( true ) ; } else { validateQueryRequest . explain ( false ) ; } } catch ( Exception e ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . BAD_REQUEST , builder . startObject ( ) . field ( "error" , e . getMessage ( ) ) . endObject ( ) ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } return ; } client . admin ( ) . indices ( ) . validateQuery ( validateQueryRequest , new org . elasticsearch . action . ActionListener < ValidateQueryResponse > ( ) { @ Override public void onResponse ( ValidateQueryResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( "valid" , response . isValid ( ) ) ; buildBroadcastShardsHeader ( builder , response ) ; if ( ( ( response . getQueryExplanation ( ) ) != null ) && ( ! ( response . getQueryExplanation ( ) . isEmpty ( ) ) ) ) { builder . startArray ( "explanations" ) ; for ( QueryExplanation explanation : response . getQueryExplanation ( ) ) { builder . startObject ( ) ; if ( ( explanation . getIndex ( ) ) != null ) { builder . field ( "index" , explanation . getIndex ( ) , NONE ) ; } builder . field ( "valid" , explanation . isValid ( ) ) ; if ( ( explanation . getError ( ) ) != null ) { builder . field ( "error" , explanation . getError ( ) ) ; } if ( ( explanation . getExplanation ( ) ) != null ) { builder . field ( "explanation" , explanation . getExplanation ( ) ) ; } builder . endObject ( ) ; } builder . endArray ( ) ; } builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class InterpolationTest extends GdxTest { private static final String [ ] interpolators = new String [ ] { "bounce" , "bounceIn" , "bounceOut" , "circle" , "circleIn" , "circleOut" , "elastic" , "elasticIn" , "elasticOut" , "exp10" , "exp10In" , "exp10Out" , "exp5" , "exp5In" , "exp5Out" , "fade" , "linear" , "pow2" , "pow2In" , "pow2Out" , "pow3" , "pow3In" , "pow3Out" , "pow4" , "pow4In" , "pow4Out" , "pow5" , "pow5In" , "pow5Out" , "sine" , "sineIn" , "sineOut" , "swing" , "swingIn" , "swingOut" } ; private Stage stage ; private Table root ; private List list ; private ShapeRenderer renderer ; Vector2 position = new Vector2 ( 300 , 20 ) ; Vector2 targetPosition = new Vector2 ( position ) ; Vector2 temp = new Vector2 ( ) ; float timer ; public void create ( ) { renderer = new ShapeRenderer ( ) ; stage = new Stage ( 0 , 0 , true ) ; input . setInputProcessor ( new com . badlogic . gdx . InputMultiplexer ( stage , new InputAdapter ( ) { public boolean touchDown ( int x , int y , int pointer , int button ) { Vector2 current = getCurrentPosition ( ) ; position . set ( current ) ; targetPosition . set ( ( x - 10 ) , ( ( ( graphics . getHeight ( ) ) - y ) - 10 ) ) ; timer = 0 ; return true ; } } ) ) ; root = new Table ( ) ; stage . addActor ( root ) ; root . pad ( 10 ) . top ( ) . left ( ) ; <START_BUG> Skin skin = new Skin ( files . internal ( "data/uiskin.json" ) , files . internal ( "data/uiskin.png" ) ) ; <END_BUG> list = new List ( InterpolationTest . interpolators , skin ) ; root . add ( new com . badlogic . gdx . scenes . scene2d . ui . ScrollPane ( list ) ) . expandY ( ) . fillY ( ) . prefWidth ( ( ( int ) ( list . getPrefWidth ( ) ) ) ) ; } public void resize ( int width , int height ) { } public void render ( ) { } Vector2 getCurrentPosition ( ) { } private Interpolation getInterpolation ( ) { } public boolean needsGL20 ( ) { } }<BUG2FIX>Skin skin = new Skin ( files . internal ( "data/uiskin.json" ) ) ;
public class GistFileFragment extends RoboSherlockFragment implements OnSharedPreferenceChangeListener { @ InjectView ( id . wv_code ) private WebView webView ; @ InjectExtra ( Intents . EXTRA_GIST_ID ) private String gistId ; private GistFile file ; private Gist gist ; @ Inject private GistStore store ; private SourceEditor editor ; private SharedPreferences codePrefs ; private MenuItem wrapItem ; @ Override public void onCreate ( Bundle savedInstanceState ) { } @ Override public void onDestroy ( ) { } public void onDestroyView ( ) { } @ Override public void onCreateOptionsMenu ( Menu optionsMenu , MenuInflater inflater ) { } private void updateWrapItem ( ) { } @ Override public boolean onOptionsItemSelected ( MenuItem item ) { } private void loadSource ( ) { } private void showSource ( ) { <START_BUG> editor . setSource ( file . getFilename ( ) , file . getContent ( ) ) ; <END_BUG> } @ Override public View onCreateView ( LayoutInflater inflater , ViewGroup container , Bundle savedInstanceState ) { } @ Override public void onViewCreated ( View view , Bundle savedInstanceState ) { } @ Override public void onSharedPreferenceChanged ( SharedPreferences sharedPreferences , String key ) { } }<BUG2FIX>editor . setSource ( file . getFilename ( ) , file . getContent ( ) , false ) ;
public class AbstarctS3BlobContainer extends AbstractBlobContainer { protected final S3BlobStore blobStore ; protected final String keyPath ; public AbstarctS3BlobContainer ( BlobPath path , S3BlobStore blobStore ) { } @ Override public boolean blobExists ( String blobName ) { } @ Override public boolean deleteBlob ( String blobName ) throws IOException { } @ Override public void readBlob ( final String blobName , final ReadBlobListener listener ) { } @ Override public ImmutableMap < String , BlobMetaData > listBlobsByPrefix ( @ Nullable String blobNamePrefix ) throws IOException { Builder < String , BlobMetaData > blobsBuilder = ImmutableMap . builder ( ) ; ObjectListing prevListing = null ; while ( true ) { ObjectListing list ; if ( prevListing != null ) { list = blobStore . client ( ) . listNextBatchOfObjects ( prevListing ) ; } else { if ( blobNamePrefix != null ) { list = blobStore . client ( ) . listObjects ( blobStore . bucket ( ) , buildKey ( blobNamePrefix ) ) ; } else { list = blobStore . client ( ) . listObjects ( blobStore . bucket ( ) , keyPath ) ; } } for ( S3ObjectSummary summary : list . getObjectSummaries ( ) ) { String name = summary . getKey ( ) . substring ( keyPath . length ( ) ) ; <START_BUG> blobsBuilder . put ( name , new org . elasticsearch . common . blobstore . support . PlainBlobMetaData ( name , summary . getSize ( ) , null ) ) ; <END_BUG> } if ( list . isTruncated ( ) ) { prevListing = list ; } else { break ; } } return blobsBuilder . build ( ) ; } @ Override public ImmutableMap < String , BlobMetaData > listBlobs ( ) throws IOException { } protected String buildKey ( String blobName ) { } }<BUG2FIX>blobsBuilder . put ( name , new org . elasticsearch . common . blobstore . support . PlainBlobMetaData ( name , summary . getSize ( ) ) ) ;
public class ScrollPaneTest extends GdxTest { private Stage stage ; private Table container ; public void create ( ) { } public void render ( ) { } public void resize ( int width , int height ) { <START_BUG> stage . getViewport ( ) . update ( width , height ) ; <END_BUG> } public void dispose ( ) { } public boolean needsGL20 ( ) { } }<BUG2FIX>stage . getViewport ( ) . update ( width , height , true ) ;
public abstract class GistsFragment extends PagedItemFragment < Gist > { @ Inject protected AvatarLoader avatarHelper ; @ Inject protected GistService service ; @ Inject protected GistStore store ; @ Override public void onListItemClick ( ListView l , View v , int position , long id ) { } @ Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; <START_BUG> setEmptyText ( getString ( no_gists ) ) ; <END_BUG> } @ Override public boolean onOptionsItemSelected ( MenuItem item ) { } @ Override public void onActivityResult ( int requestCode , int resultCode , Intent data ) { } @ Override public void onLoadFinished ( Loader < List < Gist > > loader , List < Gist > items ) { } @ Override protected int getLoadingMessage ( ) { } @ Override protected ItemListAdapter < Gist , ? extends ItemView > createAdapter ( List < Gist > items ) { } }<BUG2FIX>setEmptyText ( no_gists ) ;
public class PreloaderBundleGenerator extends Generator { private class Asset { FileWrapper file ; AssetType type ; public Asset ( FileWrapper file , AssetType type ) { } } @ Override public String generate ( TreeLogger logger , GeneratorContext context , String typeName ) throws UnableToCompleteException { } private void copyFile ( FileWrapper source , FileWrapper dest , AssetFilter filter , ArrayList < PreloaderBundleGenerator . Asset > assets ) { } private void copyDirectory ( FileWrapper sourceDir , FileWrapper destDir , AssetFilter filter , ArrayList < PreloaderBundleGenerator . Asset > assets ) { } private AssetFilter getAssetFilter ( GeneratorContext context ) { } private String getAssetPath ( GeneratorContext context ) { } private String getAssetOutputPath ( GeneratorContext context ) { ConfigurationProperty assetPathProperty = null ; try { assetPathProperty = context . getPropertyOracle ( ) . getConfigurationProperty ( "gdx.assetoutputpath" ) ; } catch ( BadPropertyValueException e ) { return null ; } if ( ( assetPathProperty . getValues ( ) . size ( ) ) == 0 ) { return null ; } String paths = assetPathProperty . getValues ( ) . get ( 0 ) ; if ( paths == null ) { return null ; } else { ArrayList < String > existingPaths = new ArrayList < String > ( ) ; String [ ] tokens = paths . split ( "," ) ; String path = null ; for ( String token : tokens ) { <START_BUG> if ( ( new FileWrapper ( token ) . exists ( ) ) || ( new FileWrapper ( token ) . mkdirs ( ) ) ) { <END_BUG> path = token ; } } if ( ( path != null ) && ( ! ( path . endsWith ( "/" ) ) ) ) { path += "/" ; } return path ; } } private List < String > getClasspathFiles ( GeneratorContext context ) { } private String createDummyClass ( TreeLogger logger , GeneratorContext context ) { } }<BUG2FIX>if ( new FileWrapper ( token ) . exists ( ) ) {
public class RestTermsAction extends BaseRestHandler { private static final Pattern fieldsPattern ; @ Inject public RestTermsAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { TermsRequest termsRequest = new TermsRequest ( splitIndices ( request . param ( "index" ) ) ) ; termsRequest . listenerThreaded ( false ) ; try { BroadcastOperationThreading operationThreading = BroadcastOperationThreading . fromString ( request . param ( "operationThreading" ) , SINGLE_THREAD ) ; if ( operationThreading == ( BroadcastOperationThreading . NO_THREADS ) ) { operationThreading = BroadcastOperationThreading . SINGLE_THREAD ; } termsRequest . operationThreading ( operationThreading ) ; List < String > fields = request . params ( "field" ) ; if ( fields == null ) { fields = new ArrayList < String > ( ) ; } String sField = request . param ( "fields" ) ; if ( sField != null ) { String [ ] sFields = RestTermsAction . fieldsPattern . split ( sField ) ; if ( sFields != null ) { for ( String field : sFields ) { fields . add ( field ) ; } } } termsRequest . fields ( fields . toArray ( new String [ fields . size ( ) ] ) ) ; termsRequest . from ( request . param ( "from" ) ) ; termsRequest . to ( request . param ( "to" ) ) ; termsRequest . fromInclusive ( request . paramAsBoolean ( "fromInclusive" , termsRequest . fromInclusive ( ) ) ) ; termsRequest . toInclusive ( request . paramAsBoolean ( "toInclusive" , termsRequest . toInclusive ( ) ) ) ; termsRequest . exact ( request . paramAsBoolean ( "exact" , termsRequest . exact ( ) ) ) ; termsRequest . minFreq ( request . paramAsInt ( "minFreq" , termsRequest . minFreq ( ) ) ) ; termsRequest . maxFreq ( request . paramAsInt ( "maxFreq" , termsRequest . maxFreq ( ) ) ) ; termsRequest . size ( request . paramAsInt ( "size" , termsRequest . size ( ) ) ) ; termsRequest . convert ( request . paramAsBoolean ( "convert" , termsRequest . convert ( ) ) ) ; termsRequest . prefix ( request . param ( "prefix" ) ) ; termsRequest . regexp ( request . param ( "regexp" ) ) ; termsRequest . sortType ( SortType . fromString ( request . param ( "sort" ) , termsRequest . sortType ( ) ) ) ; } catch ( Exception e ) { try { channel . sendResponse ( new JsonRestResponse ( request , BAD_REQUEST , JsonBuilder . jsonBuilder ( ) . startObject ( ) . field ( "error" , e . getMessage ( ) ) . endObject ( ) ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } return ; } <START_BUG> final boolean termsAsArray = request . paramAsBoolean ( "termsAsArray" , false ) ; <END_BUG> client . execTerms ( termsRequest , new org . elasticsearch . action . ActionListener < TermsResponse > ( ) { @ Override public void onResponse ( TermsResponse response ) { try { JsonBuilder builder = RestJsonBuilder . cached ( request ) ; builder . startObject ( ) ; buildBroadcastShardsHeader ( builder , response ) ; builder . startObject ( "docs" ) ; builder . field ( "numDocs" , response . numDocs ( ) ) ; builder . field ( "maxDoc" , response . maxDoc ( ) ) ; builder . field ( "deletedDocs" , response . deletedDocs ( ) ) ; builder . endObject ( ) ; builder . startObject ( "fields" ) ; for ( FieldTermsFreq fieldTermsFreq : response . fields ( ) ) { builder . startObject ( fieldTermsFreq . fieldName ( ) ) ; if ( ! termsAsArray ) { builder . startObject ( "terms" ) ; for ( TermFreq termFreq : fieldTermsFreq . termsFreqs ( ) ) { builder . startObject ( termFreq . term ( ) ) ; builder . field ( "docFreq" , termFreq . docFreq ( ) ) ; builder . endObject ( ) ; } builder . endObject ( ) ; } else { builder . startArray ( "terms" ) ; for ( TermFreq termFreq : fieldTermsFreq . termsFreqs ( ) ) { builder . startObject ( ) ; builder . field ( "term" , termFreq . term ( ) ) ; builder . field ( "docFreq" , termFreq . docFreq ( ) ) ; builder . endObject ( ) ; } builder . endArray ( ) ; } builder . endObject ( ) ; } builder . endObject ( ) ; builder . endObject ( ) ; channel . sendResponse ( new JsonRestResponse ( request , OK , builder ) ) ; } catch ( Exception e ) { onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new JsonThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>final boolean termsAsArray = request . paramAsBoolean ( "termsAsArray" , true ) ;
public class FieldsTermsStringFacetExecutor extends FacetExecutor { private final ComparatorType comparatorType ; private final int size ; private final int shardSize ; private final IndexFieldData [ ] indexFieldDatas ; private final SearchScript script ; private final HashedAggregator aggregator ; long missing ; long total ; public FieldsTermsStringFacetExecutor ( FieldMapper [ ] fieldMappers , int size , int shardSize , InternalStringTermsFacet . ComparatorType comparatorType , boolean allTerms , SearchContext context , ImmutableSet < BytesRef > excluded , Pattern pattern , SearchScript script ) { } @ Override public FieldsTermsStringFacetExecutor . Collector collector ( ) { } @ Override public InternalFacet buildFacet ( String facetName ) { } class Collector extends FacetExecutor . Collector { private final HashedAggregator aggregator ; private BytesValues [ ] values ; public Collector ( HashedAggregator aggregator ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override public void setNextReader ( AtomicReaderContext context ) throws IOException { for ( int i = 0 ; i < ( indexFieldDatas . length ) ; i ++ ) { <START_BUG> values [ i ] = indexFieldDatas [ i ] . load ( context ) . getBytesValues ( true ) ; <END_BUG> } if ( ( script ) != null ) { script . setNextReader ( context ) ; } } @ Override public void collect ( int doc ) throws IOException { } @ Override public void postCollection ( ) { } } }<BUG2FIX>values [ i ] = indexFieldDatas [ i ] . load ( context ) . getBytesValues ( ) ;
public class TransportGetAliasesAction extends TransportMasterNodeReadOperationAction < GetAliasesRequest , GetAliasesResponse > { @ Inject public TransportGetAliasesAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool ) { } @ Override protected String transportAction ( ) { } @ Override protected String executor ( ) { } @ Override protected GetAliasesRequest newRequest ( ) { } @ Override protected GetAliasesResponse newResponse ( ) { } @ Override protected void masterOperation ( GetAliasesRequest request , ClusterState state , ActionListener < GetAliasesResponse > listener ) throws ElasticsearchException { <START_BUG> String [ ] concreteIndices = state . metaData ( ) . concreteIndices ( request . indices ( ) , request . indicesOptions ( ) ) ; <END_BUG> request . indices ( concreteIndices ) ; @ SuppressWarnings ( "unchecked" ) ImmutableOpenMap < String , List < AliasMetaData > > result = ( ( ImmutableOpenMap ) ( state . metaData ( ) . findAliases ( request . aliases ( ) , request . indices ( ) ) ) ) ; listener . onResponse ( new GetAliasesResponse ( result ) ) ; } }<BUG2FIX>String [ ] concreteIndices = state . metaData ( ) . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ;
public class SnapshotsService extends AbstractComponent implements ClusterStateListener { private final ClusterService clusterService ; private final RepositoriesService repositoriesService ; private final ThreadPool threadPool ; private final IndicesService indicesService ; private final TransportService transportService ; private volatile ImmutableMap < SnapshotId , SnapshotsService . SnapshotShards > shardSnapshots = ImmutableMap . of ( ) ; private final CopyOnWriteArrayList < SnapshotsService . SnapshotCompletionListener > snapshotCompletionListeners = new CopyOnWriteArrayList < > ( ) ; @ Inject public SnapshotsService ( Settings settings , ClusterService clusterService , RepositoriesService repositoriesService , ThreadPool threadPool , IndicesService indicesService , TransportService transportService ) { } public Snapshot snapshot ( SnapshotId snapshotId ) { } public ImmutableList < Snapshot > snapshots ( String repositoryName ) { } public void createSnapshot ( final SnapshotsService . SnapshotRequest request , final SnapshotsService . CreateSnapshotListener listener ) { final SnapshotId snapshotId = new SnapshotId ( request . repository ( ) , request . name ( ) ) ; clusterService . submitStateUpdateTask ( request . cause ( ) , new TimeoutClusterStateUpdateTask ( ) { private Entry newSnapshot = null ; @ Override public ClusterState execute ( ClusterState currentState ) { validate ( request , currentState ) ; MetaData metaData = currentState . metaData ( ) ; MetaData . Builder mdBuilder = MetaData . builder ( currentState . metaData ( ) ) ; SnapshotMetaData snapshots = metaData . custom ( TYPE ) ; if ( ( snapshots == null ) || ( snapshots . entries ( ) . isEmpty ( ) ) ) { <START_BUG> ImmutableList < String > indices = ImmutableList . copyOf ( metaData . concreteIndices ( request . indices ( ) , request . indicesOptions ( ) ) ) ; <END_BUG> logger . trace ( "[{}][{}]<seq2seq4repair_space>creating<seq2seq4repair_space>snapshot<seq2seq4repair_space>for<seq2seq4repair_space>indices<seq2seq4repair_space>[{}]" , request . repository ( ) , request . name ( ) , indices ) ; newSnapshot = new SnapshotMetaData . Entry ( snapshotId , request . includeGlobalState ( ) , State . INIT , indices , null ) ; snapshots = new SnapshotMetaData ( newSnapshot ) ; } else { throw new ConcurrentSnapshotExecutionException ( snapshotId , "a<seq2seq4repair_space>snapshot<seq2seq4repair_space>is<seq2seq4repair_space>already<seq2seq4repair_space>running" ) ; } mdBuilder . putCustom ( TYPE , snapshots ) ; return ClusterState . builder ( currentState ) . metaData ( mdBuilder ) . build ( ) ; } @ Override public void onFailure ( String source , Throwable t ) { logger . warn ( "[{}][{}]<seq2seq4repair_space>failed<seq2seq4repair_space>to<seq2seq4repair_space>create<seq2seq4repair_space>snapshot" , t , request . repository ( ) , request . name ( ) ) ; newSnapshot = null ; listener . onFailure ( t ) ; } @ Override public void clusterStateProcessed ( String source , ClusterState oldState , final ClusterState newState ) { if ( ( newSnapshot ) != null ) { threadPool . executor ( ThreadPool . Names . SNAPSHOT ) . execute ( new Runnable ( ) { @ Override public void run ( ) { beginSnapshot ( newState , newSnapshot , request . partial , listener ) ; } } ) ; } } @ Override public TimeValue timeout ( ) { return request . masterNodeTimeout ( ) ; } } ) ; } private void validate ( SnapshotsService . SnapshotRequest request , ClusterState state ) throws ElasticsearchException { } private void beginSnapshot ( ClusterState clusterState , final SnapshotMetaData . Entry snapshot , final boolean partial , final SnapshotsService . CreateSnapshotListener userCreateSnapshotListener ) { } public ImmutableList < SnapshotMetaData . Entry > currentSnapshots ( String repository , String [ ] snapshots ) { } public ImmutableMap < ShardId , IndexShardSnapshotStatus > currentSnapshotShards ( SnapshotId snapshotId ) { } public ImmutableMap < ShardId , IndexShardSnapshotStatus > snapshotShards ( SnapshotId snapshotId ) { } private SnapshotShardFailure findShardFailure ( ImmutableList < SnapshotShardFailure > shardFailures , ShardId shardId ) { } @ Override public void clusterChanged ( ClusterChangedEvent event ) { } private void processSnapshotsOnRemovedNodes ( ClusterChangedEvent event ) { } private boolean removedNodesCleanupNeeded ( ClusterChangedEvent event ) { } private void processIndexShardSnapshots ( SnapshotMetaData snapshotMetaData ) { } private void updateIndexShardSnapshotStatus ( SnapshotsService . UpdateIndexShardSnapshotStatusRequest request ) { } private boolean completed ( Collection < SnapshotMetaData . ShardSnapshotStatus > shards ) { } private Set < String > indicesWithMissingShards ( ImmutableMap < ShardId , SnapshotMetaData . ShardSnapshotStatus > shards ) { } private void innerUpdateSnapshotState ( final SnapshotsService . UpdateIndexShardSnapshotStatusRequest request ) { } private void endSnapshot ( SnapshotMetaData . Entry entry ) { } private void endSnapshot ( final SnapshotMetaData . Entry entry , final String failure ) { } private void removeSnapshotFromClusterState ( final SnapshotId snapshotId , final SnapshotInfo snapshot , final Throwable t ) { } public void deleteSnapshot ( final SnapshotId snapshotId , final SnapshotsService . DeleteSnapshotListener listener ) { } public static boolean isRepositoryInUse ( ClusterState clusterState , String repository ) { } private void deleteSnapshotFromRepository ( final SnapshotId snapshotId , final SnapshotsService . DeleteSnapshotListener listener ) { } private ImmutableMap < ShardId , SnapshotMetaData . ShardSnapshotStatus > shards ( SnapshotId snapshotId , ClusterState clusterState , ImmutableList < String > indices ) { } public void addListener ( SnapshotsService . SnapshotCompletionListener listener ) { } public void removeListener ( SnapshotsService . SnapshotCompletionListener listener ) { } public static interface CreateSnapshotListener { void onResponse ( ) { } void onFailure ( Throwable t ) { } } public static interface DeleteSnapshotListener { void onResponse ( ) { } void onFailure ( Throwable t ) { } } public static interface SnapshotCompletionListener { void onSnapshotCompletion ( SnapshotId snapshotId , SnapshotInfo snapshot ) { } void onSnapshotFailure ( SnapshotId snapshotId , Throwable t ) { } } public static class SnapshotRequest { private String cause ; private String name ; private String repository ; private String [ ] indices ; private IndicesOptions indicesOptions = IndicesOptions . strictExpandOpen ( ) ; private boolean partial ; private Settings settings ; private boolean includeGlobalState ; private TimeValue masterNodeTimeout ; public SnapshotRequest ( String cause , String name , String repository ) { } public SnapshotsService . SnapshotRequest indices ( String [ ] indices ) { } public SnapshotsService . SnapshotRequest settings ( Settings settings ) { }<BUG2FIX>ImmutableList < String > indices = ImmutableList . copyOf ( metaData . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ) ;
public class ParentChildAtomicFieldData extends AbstractAtomicParentChildFieldData { private final ImmutableOpenMap < String , AtomicOrdinalsFieldData > typeToIds ; private final long memorySizeInBytes ; public ParentChildAtomicFieldData ( ImmutableOpenMap < String , AtomicOrdinalsFieldData > typeToIds ) { } @ Override public long ramBytesUsed ( ) { } @ Override public Set < String > types ( ) { } @ Override public SortedDocValues getOrdinalsValues ( String type ) { AtomicOrdinalsFieldData atomicFieldData = typeToIds . get ( type ) ; if ( atomicFieldData != null ) { <START_BUG> return MIN . select ( atomicFieldData . getOrdinalsValues ( ) , ( - 1 ) ) ; <END_BUG> } else { return DocValues . emptySorted ( ) ; } } public AtomicOrdinalsFieldData getAtomicFieldData ( String type ) { } @ Override public void close ( ) { } }<BUG2FIX>return MIN . select ( atomicFieldData . getOrdinalsValues ( ) ) ;
lowest = t ; } } } if ( ( ( ray . origin . x ) >= ( box . max . x ) ) && ( ( ray . direction . x ) < 0 ) ) { t = ( ( box . max . x ) - ( ray . origin . x ) ) / ( ray . direction . x ) ; if ( t >= 0 ) { Vector3 . tmp3 . set ( ray . direction ) . scl ( t ) . add ( ray . origin ) ; if ( ( ( ( ( ( Vector3 . tmp3 . y ) >= ( box . min . y ) ) && ( ( Vector3 . tmp3 . y ) <= ( box . max . y ) ) ) && ( ( Vector3 . tmp3 . z ) >= ( box . min . z ) ) ) && ( ( Vector3 . tmp3 . z ) <= ( box . max . z ) ) ) && ( ( ! hit ) || ( t < lowest ) ) ) { hit = true ; lowest = t ; } } } if ( ( ( ray . origin . y ) <= ( box . min . y ) ) && ( ( ray . direction . y ) > 0 ) ) { t = ( ( box . min . y ) - ( ray . origin . y ) ) / ( ray . direction . y ) ; if ( t >= 0 ) { Vector3 . tmp3 . set ( ray . direction ) . scl ( t ) . add ( ray . origin ) ; if ( ( ( ( ( ( Vector3 . tmp3 . x ) >= ( box . min . x ) ) && ( ( Vector3 . tmp3 . x ) <= ( box . max . x ) ) ) && ( ( Vector3 . tmp3 . z ) >= ( box . min . z ) ) ) && ( ( Vector3 . tmp3 . z ) <= ( box . max . z ) ) ) && ( ( ! hit ) || ( t < lowest ) ) ) { hit = true ; lowest = t ; } } } if ( ( ( ray . origin . y ) >= ( box . max . y ) ) && ( ( ray . direction . y ) < 0 ) ) { t = ( ( box . max . y ) - ( ray . origin . y ) ) / ( ray . direction . y ) ; if ( t >= 0 ) { Vector3 . tmp3 . set ( ray . direction ) . scl ( t ) . add ( ray . origin ) ; if ( ( ( ( ( ( Vector3 . tmp3 . x ) >= ( box . min . x ) ) && ( ( Vector3 . tmp3 . x ) <= ( box . max . x ) ) ) && ( ( Vector3 . tmp3 . z ) >= ( box . min . z ) ) ) && ( ( Vector3 . tmp3 . z ) <= ( box . max . z ) ) ) && ( ( ! hit ) || ( t < lowest ) ) ) { hit = true ; lowest = t ; } } } <START_BUG> if ( ( ( ray . origin . z ) <= ( box . min . y ) ) && ( ( ray . direction . z ) > 0 ) ) { <END_BUG> t = ( ( box . min . z ) - ( ray . origin . z ) ) / ( ray . direction . z ) ; if ( t >= 0 ) { Vector3 . tmp3 . set ( ray . direction ) . scl ( t ) . add ( ray . origin ) ; if ( ( ( ( ( ( Vector3 . tmp3 . x ) >= ( box . min . x ) ) && ( ( Vector3 . tmp3 . x ) <= ( box . max . x ) ) ) && ( ( Vector3 . tmp3 . y ) >= ( box . min . y ) ) ) && ( ( Vector3 . tmp3 . y ) <= ( box . max . y ) ) ) && ( ( ! hit ) || ( t < lowest ) ) ) { hit = true ; lowest = t ; } } } if ( ( ( ray . origin . z ) >= ( box . max . z ) ) && ( ( ray . direction . z ) < 0 ) ) { t = ( ( box . max . z ) - ( ray . origin . z ) ) / ( ray . direction . z ) ; if ( t >= 0 ) { Vector3 . tmp3 . set ( ray . direction ) . scl ( t ) . add ( ray . origin ) ; if ( ( ( ( ( ( Vector3 . tmp3 . x ) >= ( box . min . x ) ) && ( ( Vector3 . tmp3 . x ) <= ( box . max . x ) ) ) && ( ( Vector3 . tmp3 . y ) >= ( box . min . y ) ) ) && ( ( Vector3 . tmp3 . y ) <= ( box . max . y ) ) ) && ( ( ! hit ) || ( t < lowest ) ) ) { hit = true ; lowest = t ; } }<BUG2FIX>if ( ( ( ray . origin . z ) <= ( box . min . z ) ) && ( ( ray . direction . z ) > 0 ) ) {
public class ClusterHealthResponse extends ActionResponse implements Iterable < ClusterIndexHealth > { private String clusterName ; int numberOfNodes = 0 ; int numberOfDataNodes = 0 ; int activeShards = 0 ; int relocatingShards = 0 ; int activePrimaryShards = 0 ; int initializingShards = 0 ; int unassignedShards = 0 ; boolean timedOut = false ; ClusterHealthStatus status = ClusterHealthStatus . RED ; private List < String > validationFailures ; Map < String , ClusterIndexHealth > indices = Maps . newHashMap ( ) ; ClusterHealthResponse ( ) { } public ClusterHealthResponse ( String clusterName , List < String > validationFailures ) { } public String clusterName ( ) { } public String getClusterName ( ) { } public List < String > validationFailures ( ) { } public List < String > getValidationFailures ( ) { } public List < String > allValidationFailures ( ) { } public List < String > getAllValidationFailures ( ) { } public int activeShards ( ) { } public int getActiveShards ( ) { } public int relocatingShards ( ) { } public int getRelocatingShards ( ) { } public int activePrimaryShards ( ) { } public int getActivePrimaryShards ( ) { } public int initializingShards ( ) { } public int getInitializingShards ( ) { } public int unassignedShards ( ) { } public int getUnassignedShards ( ) { } public int numberOfNodes ( ) { } public int getNumberOfNodes ( ) { } public int numberOfDataNodes ( ) { } public int getNumberOfDataNodes ( ) { } public boolean timedOut ( ) { } public boolean isTimedOut ( ) { } public ClusterHealthStatus status ( ) { } public ClusterHealthStatus getStatus ( ) { } public Map < String , ClusterIndexHealth > indices ( ) { } public Map < String , ClusterIndexHealth > getIndices ( ) { } @ Override public Iterator < ClusterIndexHealth > iterator ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { super . writeTo ( out ) ; out . writeString ( clusterName ) ; out . writeVInt ( activePrimaryShards ) ; out . writeVInt ( activeShards ) ; out . writeVInt ( relocatingShards ) ; out . writeVInt ( initializingShards ) ; out . writeVInt ( unassignedShards ) ; out . writeVInt ( numberOfNodes ) ; out . writeVInt ( numberOfDataNodes ) ; out . writeByte ( status . value ( ) ) ; out . writeVInt ( indices . size ( ) ) ; for ( ClusterIndexHealth indexHealth : this ) { indexHealth . writeTo ( out ) ; } out . writeBoolean ( timedOut ) ; out . writeVInt ( validationFailures . size ( ) ) ; for ( String failure : validationFailures ) { <START_BUG> out . writeUTF ( failure ) ; <END_BUG> } } }<BUG2FIX>out . writeString ( failure ) ;
public class ImmutableSettings implements Settings { private ImmutableMap < String , String > settings ; private transient ClassLoader classLoader ; private ImmutableSettings ( Map < String , String > settings , ClassLoader classLoader ) { } @ Override public ClassLoader getClassLoader ( ) { } @ Override public ClassLoader getClassLoaderIfSet ( ) { } @ Override public ImmutableMap < String , String > getAsMap ( ) { } @ Override public Settings getComponentSettings ( Class component ) { } @ Override public Settings getComponentSettings ( String prefix , Class component ) { } @ Override public Settings getByPrefix ( String prefix ) { } @ Override public String get ( String setting ) { } @ Override public String get ( String setting , String defaultValue ) { } @ Override public Float getAsFloat ( String setting , Float defaultValue ) { } @ Override public Double getAsDouble ( String setting , Double defaultValue ) { } @ Override public Integer getAsInt ( String setting , Integer defaultValue ) { } @ Override public Long getAsLong ( String setting , Long defaultValue ) { } @ Override public Boolean getAsBoolean ( String setting , Boolean defaultValue ) { } @ Override public TimeValue getAsTime ( String setting , TimeValue defaultValue ) { } @ Override public ByteSizeValue getAsBytesSize ( String setting , ByteSizeValue defaultValue ) throws SettingsException { } @ Override public SizeValue getAsSize ( String setting , SizeValue defaultValue ) throws SettingsException { } @ SuppressWarnings ( { "unchecked" } ) @ Override public < T > Class < ? extends T > getAsClass ( String setting , Class < ? extends T > defaultClazz ) throws NoClassSettingsException { } @ SuppressWarnings ( { "unchecked" } ) @ Override public < T > Class < ? extends T > getAsClass ( String setting , Class < ? extends T > defaultClazz , String prefixPackage , String suffixClassName ) throws NoClassSettingsException { String sValue = get ( setting ) ; if ( sValue == null ) { return defaultClazz ; } String fullClassName = sValue ; try { return ( ( Class < ? extends T > ) ( getClassLoader ( ) . loadClass ( fullClassName ) ) ) ; } catch ( ClassNotFoundException e ) { String prefixValue = prefixPackage ; int packageSeparator = sValue . lastIndexOf ( '.' ) ; if ( packageSeparator > 0 ) { prefixValue = sValue . substring ( 0 , ( packageSeparator + 1 ) ) ; sValue = sValue . substring ( ( packageSeparator + 1 ) ) ; } fullClassName = ( prefixValue + ( Strings . capitalize ( Strings . toCamelCase ( sValue ) ) ) ) + suffixClassName ; try { return ( ( Class < ? extends T > ) ( getClassLoader ( ) . loadClass ( fullClassName ) ) ) ; } catch ( ClassNotFoundException e1 ) { fullClassName = ( ( ( prefixValue + ( Strings . toCamelCase ( sValue ) . toLowerCase ( ) ) ) + "." ) + ( Strings . capitalize ( Strings . toCamelCase ( sValue ) ) ) ) + suffixClassName ; try { return ( ( Class < ? extends T > ) ( getClassLoader ( ) . loadClass ( fullClassName ) ) ) ; } catch ( ClassNotFoundException e2 ) { <START_BUG> throw new NoClassSettingsException ( ( ( ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>load<seq2seq4repair_space>class<seq2seq4repair_space>setting<seq2seq4repair_space>[" + setting ) + "]<seq2seq4repair_space>with<seq2seq4repair_space>value<seq2seq4repair_space>[" ) + ( get ( setting ) ) ) + "]" ) , e ) ; <END_BUG> } } } } @ Override public String [ ] getAsArray ( String settingPrefix ) throws SettingsException { } @ Override public String [ ] getAsArray ( String settingPrefix , String [ ] defaultArray ) throws SettingsException { } @ Override public Map < String , Settings > getGroups ( String settingPrefix ) throws SettingsException { } @ Override public Version getAsVersion ( String setting , Version defaultVersion ) throws SettingsException { } @ Override public String toDelimitedString ( char delimiter ) { } @ Override public boolean equals ( Object o ) { } @ Override public int hashCode ( ) { } public static Settings readSettingsFromStream ( StreamInput in ) throws IOException { } public static void writeSettingsToStream ( Settings settings , StreamOutput out ) throws IOException { } public static ImmutableSettings . Builder builder ( ) { } public static ImmutableSettings . Builder settingsBuilder ( ) { } public static class Builder implements Settings . Builder { public static final Settings EMPTY_SETTINGS = new ImmutableSettings . Builder ( ) . build ( ) ; private final Map < String , String > map = new LinkedHashMap < String , String > ( ) ; private ClassLoader classLoader ; private Builder ( ) { } public Map < String , String > internalMap ( ) { } public String remove ( String key ) { } public String get ( String key ) { } public ImmutableSettings . Builder put ( String key , String value ) { } public ImmutableSettings . Builder put ( String key , Class clazz ) { } public ImmutableSettings . Builder put ( String setting , boolean value ) { } public ImmutableSettings . Builder put ( String setting , int value ) { } public ImmutableSettings . Builder put ( String setting , Version version ) { } public ImmutableSettings . Builder put ( String setting , long value ) { } public ImmutableSettings . Builder put ( String setting , float value ) { } public ImmutableSettings . Builder put ( String setting , double value ) { } public ImmutableSettings . Builder put ( String setting , long value , TimeUnit timeUnit ) { } public ImmutableSettings . Builder put ( String setting , long value , ByteSizeUnit sizeUnit ) { } public ImmutableSettings . Builder putArray ( String setting , String ... values ) { }<BUG2FIX>throw new NoClassSettingsException ( ( ( ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>load<seq2seq4repair_space>class<seq2seq4repair_space>setting<seq2seq4repair_space>[" + setting ) + "]<seq2seq4repair_space>with<seq2seq4repair_space>value<seq2seq4repair_space>[" ) + ( get ( setting ) ) ) + "]" ) , e2 ) ;
public class IntArrayRef extends AbstractList < Integer > implements RandomAccess { public static final IntArrayRef EMPTY = new IntArrayRef ( new int [ 0 ] ) ; public int [ ] values ; public int start ; public int end ; public IntArrayRef ( int [ ] values ) { } public IntArrayRef ( int [ ] values , int length ) { } public IntArrayRef ( int [ ] values , int start , int end ) { } public void reset ( int newLength ) { } public void growIfNeeded ( int index ) { } @ Override public int size ( ) { } @ Override public boolean isEmpty ( ) { <START_BUG> return ( size ( ) ) != 0 ; <END_BUG> } @ Override public Integer get ( int index ) { } @ Override public boolean contains ( Object target ) { } @ Override public int indexOf ( Object target ) { } @ Override public int lastIndexOf ( Object target ) { } @ Override public Integer set ( int index , Integer element ) { } @ Override public boolean equals ( Object object ) { } @ Override public int hashCode ( ) { } @ Override public String toString ( ) { } private static int indexOf ( int [ ] array , int target , int start , int end ) { } private static int lastIndexOf ( int [ ] array , int target , int start , int end ) { } }<BUG2FIX>return ( size ( ) ) == 0 ;
public class MultiValueFloatFieldData extends FloatFieldData { private static final int VALUE_CACHE_SIZE = 10 ; private ThreadLocal < ThreadLocals . CleanableValue < double [ ] [ ] > > doublesValuesCache = new ThreadLocal < ThreadLocals . CleanableValue < double [ ] [ ] > > ( ) { @ Override protected ThreadLocals . CleanableValue < double [ ] [ ] > initialValue ( ) { } } ; private ThreadLocal < ThreadLocals . CleanableValue < float [ ] [ ] > > valuesCache = new ThreadLocal < ThreadLocals . CleanableValue < float [ ] [ ] > > ( ) { @ Override protected ThreadLocals . CleanableValue < float [ ] [ ] > initialValue ( ) { } } ; private final int [ ] [ ] ordinals ; public MultiValueFloatFieldData ( String fieldName , int [ ] [ ] ordinals , float [ ] values ) { } @ Override protected long computeSizeInBytes ( ) { } @ Override public boolean multiValued ( ) { } @ Override public boolean hasValue ( int docId ) { } @ Override public void forEachValueInDoc ( int docId , StringValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , DoubleValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , LongValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , MissingDoubleValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , MissingLongValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , ValueInDocProc proc ) { } @ Override public void forEachOrdinalInDoc ( int docId , OrdinalInDocProc proc ) { boolean found = false ; for ( int [ ] ordinal : ordinals ) { int loc = ordinal [ docId ] ; if ( loc != 0 ) { found = true ; <START_BUG> proc . onOrdinal ( docId , ordinal [ docId ] ) ; <END_BUG> } } if ( ! found ) { proc . onOrdinal ( docId , 0 ) ; } } @ Override public double [ ] doubleValues ( int docId ) { } @ Override public float value ( int docId ) { } @ Override public float [ ] values ( int docId ) { } }<BUG2FIX>proc . onOrdinal ( docId , loc ) ;
public class RestMainAction extends BaseRestHandler { private final Version version ; @ Inject public RestMainAction ( Settings settings , Version version , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { ClusterStateRequest clusterStateRequest = new ClusterStateRequest ( ) ; clusterStateRequest . listenerThreaded ( false ) ; clusterStateRequest . masterNodeTimeout ( TimeValue . timeValueMillis ( 0 ) ) ; clusterStateRequest . local ( true ) ; clusterStateRequest . filterAll ( ) . filterBlocks ( false ) ; client . admin ( ) . cluster ( ) . state ( clusterStateRequest , new org . elasticsearch . action . ActionListener < ClusterStateResponse > ( ) { @ Override public void onResponse ( ClusterStateResponse response ) { RestStatus status = RestStatus . OK ; if ( response . getState ( ) . blocks ( ) . hasGlobalBlock ( SERVICE_UNAVAILABLE ) ) { status = RestStatus . SERVICE_UNAVAILABLE ; } if ( ( request . method ( ) ) == ( Method . HEAD ) ) { channel . sendResponse ( new StringRestResponse ( status ) ) ; return ; } try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; if ( ! ( request . hasParam ( "pretty" ) ) ) { <START_BUG> builder . prettyPrint ( ) . lfAtEnd ( ) ; <END_BUG> } builder . startObject ( ) ; builder . field ( "ok" , true ) ; builder . field ( "status" , status . getStatus ( ) ) ; if ( ( settings . get ( "name" ) ) != null ) { builder . field ( "name" , settings . get ( "name" ) ) ; } builder . startObject ( "version" ) . field ( "number" , version . number ( ) ) . field ( "build_hash" , CURRENT . hash ( ) ) . field ( "build_timestamp" , CURRENT . timestamp ( ) ) . field ( "build_snapshot" , version . snapshot ) . field ( "lucene_version" , LUCENE_MAIN_VERSION ) . endObject ( ) ; builder . field ( "tagline" , "You<seq2seq4repair_space>Know,<seq2seq4repair_space>for<seq2seq4repair_space>Search" ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , status , builder ) ) ; } catch ( Throwable e ) { onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { if ( ( request . method ( ) ) == ( HEAD ) ) { channel . sendResponse ( new StringRestResponse ( ExceptionsHelper . status ( e ) ) ) ; } else { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } } catch ( Exception e1 ) { logger . warn ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>response" , e ) ; } } } ) ; } }<BUG2FIX>builder . prettyPrint ( ) ;
public class Lucene { public static final Version VERSION = Version . LUCENE_44 ; public static final Version ANALYZER_VERSION = Lucene . VERSION ; public static final Version QUERYPARSER_VERSION = Lucene . VERSION ; public static final NamedAnalyzer STANDARD_ANALYZER = new NamedAnalyzer ( "_standard" , AnalyzerScope . GLOBAL , new org . apache . lucene . analysis . standard . StandardAnalyzer ( Lucene . ANALYZER_VERSION ) ) ; public static final NamedAnalyzer KEYWORD_ANALYZER = new NamedAnalyzer ( "_keyword" , AnalyzerScope . GLOBAL , new KeywordAnalyzer ( ) ) ; public static final int NO_DOC = - 1 ; public static ScoreDoc [ ] EMPTY_SCORE_DOCS = new ScoreDoc [ 0 ] ; @ SuppressWarnings ( "deprecation" ) public static Version parseVersion ( @ Nullable String version , Version defaultVersion , ESLogger logger ) { } public static SegmentInfos readSegmentInfos ( Directory directory ) throws IOException { } public static long count ( IndexSearcher searcher , Query query ) throws IOException { } public static boolean safeClose ( IndexWriter writer ) { if ( writer == null ) { return true ; } try { writer . close ( ) ; return true ; <START_BUG> } catch ( IOException e ) { <END_BUG> return false ; } } public static TopDocs readTopDocs ( StreamInput in ) throws IOException { } public static void writeTopDocs ( StreamOutput out , TopDocs topDocs , int from ) throws IOException { } public static Type readSortType ( StreamInput in ) throws IOException { } public static void writeSortType ( StreamOutput out , SortField . Type sortType ) throws IOException { } public static Explanation readExplanation ( StreamInput in ) throws IOException { } public static void writeExplanation ( StreamOutput out , Explanation explanation ) throws IOException { } public static class ExistsCollector extends Collector { private boolean exists ; public void reset ( ) { } public boolean exists ( ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override public void collect ( int doc ) throws IOException { } @ Override public void setNextReader ( AtomicReaderContext context ) throws IOException { } @ Override public boolean acceptsDocsOutOfOrder ( ) { } } private Lucene ( ) { } public static final boolean indexExists ( final Directory directory ) throws IOException { } }<BUG2FIX>} catch ( Throwable e ) {
public class RestClusterHealthAction extends BaseRestHandler { @ Inject public RestClusterHealthAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { ClusterHealthRequest clusterHealthRequest = clusterHealthRequest ( org . elasticsearch . rest . action . support . RestActions . splitIndices ( request . param ( "index" ) ) ) ; int level = 0 ; try { clusterHealthRequest . masterNodeTimeout ( request . paramAsTime ( "master_timeout" , clusterHealthRequest . masterNodeTimeout ( ) ) ) ; clusterHealthRequest . timeout ( request . paramAsTime ( "timeout" , clusterHealthRequest . timeout ( ) ) ) ; String waitForStatus = request . param ( "wait_for_status" ) ; if ( waitForStatus != null ) { clusterHealthRequest . waitForStatus ( ClusterHealthStatus . valueOf ( waitForStatus . toUpperCase ( ) ) ) ; } clusterHealthRequest . waitForRelocatingShards ( request . paramAsInt ( "wait_for_relocating_shards" , clusterHealthRequest . waitForRelocatingShards ( ) ) ) ; clusterHealthRequest . waitForActiveShards ( request . paramAsInt ( "wait_for_active_shards" , clusterHealthRequest . waitForActiveShards ( ) ) ) ; clusterHealthRequest . waitForNodes ( request . param ( "wait_for_nodes" , clusterHealthRequest . waitForNodes ( ) ) ) ; String sLevel = request . param ( "level" ) ; if ( sLevel != null ) { <START_BUG> if ( "cluster" . equals ( "sLevel" ) ) { <END_BUG> level = 0 ; } else if ( "indices" . equals ( sLevel ) ) { level = 1 ; } else if ( "shards" . equals ( sLevel ) ) { level = 2 ; } } } catch ( Exception e ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . PRECONDITION_FAILED , builder . startObject ( ) . field ( "error" , e . getMessage ( ) ) . endObject ( ) ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } return ; } final int fLevel = level ; client . admin ( ) . cluster ( ) . health ( clusterHealthRequest , new org . elasticsearch . action . ActionListener < ClusterHealthResponse > ( ) { @ Override public void onResponse ( ClusterHealthResponse response ) { try { RestStatus status = RestStatus . OK ; XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( RestClusterHealthAction . Fields . CLUSTER_NAME , response . clusterName ( ) ) ; builder . field ( RestClusterHealthAction . Fields . STATUS , response . status ( ) . name ( ) . toLowerCase ( ) ) ; builder . field ( RestClusterHealthAction . Fields . TIMED_OUT , response . timedOut ( ) ) ; builder . field ( RestClusterHealthAction . Fields . NUMBER_OF_NODES , response . numberOfNodes ( ) ) ; builder . field ( RestClusterHealthAction . Fields . NUMBER_OF_DATA_NODES , response . numberOfDataNodes ( ) ) ; builder . field ( RestClusterHealthAction . Fields . ACTIVE_PRIMARY_SHARDS , response . activePrimaryShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . ACTIVE_SHARDS , response . activeShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . RELOCATING_SHARDS , response . relocatingShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . INITIALIZING_SHARDS , response . initializingShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . UNASSIGNED_SHARDS , response . unassignedShards ( ) ) ; if ( ! ( response . validationFailures ( ) . isEmpty ( ) ) ) { builder . startArray ( RestClusterHealthAction . Fields . VALIDATION_FAILURES ) ; for ( String validationFailure : response . validationFailures ( ) ) { builder . value ( validationFailure ) ; } if ( fLevel == 0 ) { for ( ClusterIndexHealth indexHealth : response ) { builder . startObject ( indexHealth . index ( ) ) ; if ( ! ( indexHealth . validationFailures ( ) . isEmpty ( ) ) ) { builder . startArray ( RestClusterHealthAction . Fields . VALIDATION_FAILURES ) ; for ( String validationFailure : indexHealth . validationFailures ( ) ) { builder . value ( validationFailure ) ; } builder . endArray ( ) ; } builder . endObject ( ) ; } } builder . endArray ( ) ; } if ( fLevel > 0 ) { builder . startObject ( RestClusterHealthAction . Fields . INDICES ) ; for ( ClusterIndexHealth indexHealth : response ) { builder . startObject ( indexHealth . index ( ) , NONE ) ; builder . field ( RestClusterHealthAction . Fields . STATUS , indexHealth . status ( ) . name ( ) . toLowerCase ( ) ) ; builder . field ( RestClusterHealthAction . Fields . NUMBER_OF_SHARDS , indexHealth . numberOfShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . NUMBER_OF_REPLICAS , indexHealth . numberOfReplicas ( ) ) ; builder . field ( RestClusterHealthAction . Fields . ACTIVE_PRIMARY_SHARDS , indexHealth . activePrimaryShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . ACTIVE_SHARDS , indexHealth . activeShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . RELOCATING_SHARDS , indexHealth . relocatingShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . INITIALIZING_SHARDS , indexHealth . initializingShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . UNASSIGNED_SHARDS , indexHealth . unassignedShards ( ) ) ; if ( ! ( indexHealth . validationFailures ( ) . isEmpty ( ) ) ) { builder . startArray ( RestClusterHealthAction . Fields . VALIDATION_FAILURES ) ; for ( String validationFailure : indexHealth . validationFailures ( ) ) { builder . value ( validationFailure ) ; } builder . endArray ( ) ; } if ( fLevel > 1 ) { builder . startObject ( RestClusterHealthAction . Fields . SHARDS ) ;<BUG2FIX>if ( "cluster" . equals ( sLevel ) ) {
public class TransportUpdateSettingsAction extends TransportMasterNodeOperationAction < UpdateSettingsRequest , UpdateSettingsResponse > { private final MetaDataUpdateSettingsService updateSettingsService ; @ Inject public TransportUpdateSettingsAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool , MetaDataUpdateSettingsService updateSettingsService ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected UpdateSettingsRequest newRequest ( ) { } @ Override protected UpdateSettingsResponse newResponse ( ) { } @ Override protected void doExecute ( UpdateSettingsRequest request , ActionListener < UpdateSettingsResponse > listener ) { <START_BUG> request . indices ( clusterService . state ( ) . metaData ( ) . concreteIndices ( request . indices ( ) , request . indicesOptions ( ) ) ) ; <END_BUG> super . doExecute ( request , listener ) ; } @ Override protected void masterOperation ( final UpdateSettingsRequest request , final ClusterState state , final ActionListener < UpdateSettingsResponse > listener ) throws ElasticsearchException { } }<BUG2FIX>request . indices ( clusterService . state ( ) . metaData ( ) . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ) ;
} } } if ( lookupType == null ) { throw new QueryParsingException ( parseContext . index ( ) , "[terms]<seq2seq4repair_space>filter<seq2seq4repair_space>lookup<seq2seq4repair_space>element<seq2seq4repair_space>requires<seq2seq4repair_space>specifying<seq2seq4repair_space>the<seq2seq4repair_space>type" ) ; } if ( lookupId == null ) { throw new QueryParsingException ( parseContext . index ( ) , "[terms]<seq2seq4repair_space>filter<seq2seq4repair_space>lookup<seq2seq4repair_space>element<seq2seq4repair_space>requires<seq2seq4repair_space>specifying<seq2seq4repair_space>the<seq2seq4repair_space>id" ) ; } if ( lookupPath == null ) { throw new QueryParsingException ( parseContext . index ( ) , "[terms]<seq2seq4repair_space>filter<seq2seq4repair_space>lookup<seq2seq4repair_space>element<seq2seq4repair_space>requires<seq2seq4repair_space>specifying<seq2seq4repair_space>the<seq2seq4repair_space>path" ) ; } } else if ( token . isValue ( ) ) { if ( "execution" . equals ( currentFieldName ) ) { execution = parser . text ( ) ; } else if ( "_name" . equals ( currentFieldName ) ) { filterName = parser . text ( ) ; } else if ( "_cache" . equals ( currentFieldName ) ) { cache = parser . booleanValue ( ) ; } else if ( ( "_cache_key" . equals ( currentFieldName ) ) || ( "_cacheKey" . equals ( currentFieldName ) ) ) { cacheKey = new CacheKeyFilter . Key ( parser . text ( ) ) ; } else { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[terms]<seq2seq4repair_space>filter<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>support<seq2seq4repair_space>[" + currentFieldName ) + "]" ) ) ; } } } if ( fieldName == null ) { throw new QueryParsingException ( parseContext . index ( ) , "terms<seq2seq4repair_space>filter<seq2seq4repair_space>requires<seq2seq4repair_space>a<seq2seq4repair_space>field<seq2seq4repair_space>name,<seq2seq4repair_space>followed<seq2seq4repair_space>by<seq2seq4repair_space>array<seq2seq4repair_space>of<seq2seq4repair_space>terms" ) ; } FieldMapper fieldMapper = null ; smartNameFieldMappers = parseContext . smartFieldMappers ( fieldName ) ; String [ ] previousTypes = null ; if ( smartNameFieldMappers != null ) { if ( smartNameFieldMappers . hasMapper ( ) ) { fieldMapper = smartNameFieldMappers . mapper ( ) ; fieldName = fieldMapper . names ( ) . indexName ( ) ; } if ( smartNameFieldMappers . explicitTypeInNameWithDocMapper ( ) ) { previousTypes = QueryParseContext . setTypesWithPrevious ( new String [ ] { smartNameFieldMappers . docMapper ( ) . type ( ) } ) ; } } if ( lookupId != null ) { if ( fieldMapper == null ) { return Queries . MATCH_NO_FILTER ; } TermsLookup termsLookup = new TermsLookup ( fieldMapper , lookupIndex , lookupType , lookupId , lookupRouting , lookupPath , parseContext ) ; Filter filter = termsFilterCache . termsFilter ( termsLookup , lookupCache , cacheKey ) ; if ( filter == null ) { return null ; } if ( ( cache == null ) || cache ) { filter = parseContext . cacheFilter ( filter , cacheKey ) ; } return filter ; } if ( terms . isEmpty ( ) ) { return Queries . MATCH_NO_FILTER ; } try { Filter filter ; if ( "plain" . equals ( execution ) ) { if ( fieldMapper != null ) { filter = fieldMapper . termsFilter ( terms , parseContext ) ; } else { BytesRef [ ] filterValues = new BytesRef [ terms . size ( ) ] ; for ( int i = 0 ; i < ( filterValues . length ) ; i ++ ) { filterValues [ i ] = BytesRefs . toBytesRef ( terms . get ( i ) ) ; } filter = new org . apache . lucene . queries . TermsFilter ( fieldName , filterValues ) ; } if ( ( cache == null ) || cache ) { filter = parseContext . cacheFilter ( filter , cacheKey ) ; } } else if ( "fielddata" . equals ( execution ) ) { if ( fieldMapper == null ) { return Queries . MATCH_NO_FILTER ; } <START_BUG> filter = fieldMapper . termsFilter ( parseContext . fieldData ( ) , terms , parseContext ) ; <END_BUG> if ( ( cache != null ) && cache ) { filter = parseContext . cacheFilter ( filter , cacheKey ) ; } } else if ( "bool" . equals ( execution ) ) { XBooleanFilter boolFiler = new XBooleanFilter ( ) ; if ( fieldMapper != null ) { for ( Object term : terms ) { boolFiler . add ( parseContext . cacheFilter ( fieldMapper . termFilter ( term , parseContext ) , null ) , SHOULD ) ; } } else { for ( Object term : terms ) { boolFiler . add ( parseContext . cacheFilter ( new TermFilter ( new org . apache . lucene . index . Term ( fieldName , BytesRefs . toBytesRef ( term ) ) ) , null ) , SHOULD ) ; } } filter = boolFiler ; if ( ( cache != null ) && cache ) { filter = parseContext . cacheFilter ( filter , cacheKey ) ; } } else if ( "bool_nocache" . equals ( execution ) ) { XBooleanFilter boolFiler = new XBooleanFilter ( ) ; if ( fieldMapper != null ) { for ( Object term : terms ) { boolFiler . add ( fieldMapper . termFilter ( term , parseContext ) , SHOULD ) ; } } else { for ( Object term : terms ) { boolFiler . add ( new TermFilter ( new org . apache . lucene . index . Term ( fieldName , BytesRefs . toBytesRef ( term ) ) ) , SHOULD ) ; } } filter = boolFiler ; if ( ( cache == null ) || cache ) { filter = parseContext . cacheFilter ( filter , cacheKey ) ; } } else if ( "and" . equals ( execution ) ) { List < Filter > filters = Lists . newArrayList ( ) ; if ( fieldMapper != null ) { for ( Object term : terms ) { filters . add ( parseContext . cacheFilter ( fieldMapper . termFilter ( term , parseContext ) , null ) ) ; } } else { for ( Object term : terms ) { filters . add ( parseContext . cacheFilter ( new TermFilter ( new org . apache . lucene . index . Term ( fieldName , BytesRefs . toBytesRef ( term ) ) ) , null ) ) ; }<BUG2FIX>filter = fieldMapper . termsFilter ( parseContext , terms , parseContext ) ;
public class EvenShardsCountAllocator extends AbstractComponent implements ShardsAllocator { @ Inject public EvenShardsCountAllocator ( Settings settings ) { } @ Override public void applyStartedShards ( StartedRerouteAllocation allocation ) { } @ Override public void applyFailedShards ( FailedRerouteAllocation allocation ) { } @ Override public boolean allocateUnassigned ( RoutingAllocation allocation ) { } @ Override public boolean rebalance ( RoutingAllocation allocation ) { } @ Override public boolean move ( MutableShardRouting shardRouting , RoutingNode node , RoutingAllocation allocation ) { } private RoutingNode [ ] sortedNodesLeastToHigh ( RoutingAllocation allocation ) { <START_BUG> final ObjectIntOpenHashMap < String > nodeCounts = new ObjectIntOpenHashMap < String > ( ) ; <END_BUG> for ( RoutingNode node : allocation . routingNodes ( ) ) { for ( int i = 0 ; i < ( node . size ( ) ) ; i ++ ) { ShardRouting shardRouting = node . get ( i ) ; String nodeId = ( shardRouting . relocating ( ) ) ? shardRouting . relocatingNodeId ( ) : shardRouting . currentNodeId ( ) ; nodeCounts . addTo ( nodeId , 1 ) ; } } RoutingNode [ ] nodes = allocation . routingNodes ( ) . toArray ( ) ; Arrays . sort ( nodes , new Comparator < RoutingNode > ( ) { @ Override public int compare ( RoutingNode o1 , RoutingNode o2 ) { return ( nodeCounts . get ( o1 . nodeId ( ) ) ) - ( nodeCounts . get ( o2 . nodeId ( ) ) ) ; } } ) ; return nodes ; } }<BUG2FIX>final ObjectIntOpenHashMap < String > nodeCounts = new ObjectIntOpenHashMap ( ) ;
public class ScriptTermsStringFieldFacetExecutor extends FacetExecutor { private final ComparatorType comparatorType ; private final int size ; private final SearchScript script ; private final Matcher matcher ; private final ImmutableSet < BytesRef > excluded ; private final int numberOfShards ; final TObjectIntHashMap < BytesRef > facets ; long missing ; long total ; public ScriptTermsStringFieldFacetExecutor ( int size , InternalStringTermsFacet . ComparatorType comparatorType , SearchContext context , ImmutableSet < BytesRef > excluded , Pattern pattern , String scriptLang , String script , Map < String , Object > params ) { } @ Override public ScriptTermsStringFieldFacetExecutor . Collector collector ( ) { } @ Override public InternalFacet buildFacet ( String facetName ) { } class Collector extends FacetExecutor . Collector { private final Matcher matcher ; private final ImmutableSet < BytesRef > excluded ; private final SearchScript script ; private final TObjectIntHashMap < BytesRef > facets ; long missing ; long total ; Collector ( Matcher matcher , ImmutableSet < BytesRef > excluded , SearchScript script , TObjectIntHashMap < BytesRef > facets ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override public void setNextReader ( AtomicReaderContext context ) throws IOException { } @ Override public void collect ( int doc ) throws IOException { } @ Override public void postCollection ( ) { ScriptTermsStringFieldFacetExecutor . this . missing = missing ; <START_BUG> ScriptTermsStringFieldFacetExecutor . this . total = missing ; <END_BUG> } private boolean match ( String value ) { } } }<BUG2FIX>ScriptTermsStringFieldFacetExecutor . this . total = total ;
public class TerrainTest implements GdxTest { ImmediateModeRenderer renderer ; TerrainTest . TerrainChunk chunk ; Mesh mesh ; PerspectiveCamera camera ; Vector3 intersection = new Vector3 ( ) ; boolean intersected = false ; long lastTime = System . nanoTime ( ) ; @ Override public void surfaceCreated ( ) { if ( ( chunk ) == null ) { renderer = new ImmediateModeRenderer ( ) ; chunk = new TerrainTest . TerrainChunk ( 32 , 32 , 4 ) ; Random rand = new Random ( ) ; int len = chunk . vertices . length ; for ( int i = 3 ; i < len ; i += 4 ) chunk . vertices [ i ] = Color . toFloatBits ( rand . nextInt ( 255 ) , rand . nextInt ( 255 ) , rand . nextInt ( 255 ) , 255 ) ; <START_BUG> mesh = new Mesh ( true , false , ( ( chunk . vertices . length ) / 3 ) , chunk . indices . length , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . Position , 3 , "a_position" ) , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . ColorPacked , 4 , "a_color" ) ) ; <END_BUG> mesh . setVertices ( chunk . vertices ) ; mesh . setIndices ( chunk . indices ) ; camera = new PerspectiveCamera ( ) ; camera . getPosition ( ) . set ( 0 , 5 , 5 ) ; camera . getDirection ( ) . set ( 0 , 0 , 0 ) . sub ( camera . getPosition ( ) ) . nor ( ) ; camera . setViewport ( graphics . getWidth ( ) , graphics . getHeight ( ) ) ; camera . setNear ( 0.5F ) ; camera . setFar ( 300 ) ; camera . setFov ( 67 ) ; } } @ Override public void surfaceChanged ( int width , int height ) { } @ Override public void render ( ) { } private void handleInput ( Input input , float delta ) { } @ Override public void dispose ( ) { } static final class TerrainChunk { public final byte [ ] heightMap ; public final short width ; public final short height ; public final float [ ] vertices ; public final short [ ] indices ; public final int vertexSize ; public TerrainChunk ( int width , int height , int vertexSize ) { } public void buildVertices ( ) { } private void buildIndices ( ) { } } @ Override public boolean needsGL20 ( ) { } }<BUG2FIX>mesh = new Mesh ( true , ( ( chunk . vertices . length ) / 3 ) , chunk . indices . length , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . Position , 3 , "a_position" ) , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . ColorPacked , 4 , "a_color" ) ) ;
public class LocalGateway extends AbstractLifecycleComponent < Gateway > implements Gateway , ClusterStateListener { private File location ; private final ClusterService clusterService ; private final NodeEnvironment nodeEnv ; private final MetaDataCreateIndexService createIndexService ; private final TransportNodesListGatewayMetaState listGatewayMetaState ; private final TransportNodesListGatewayStartedShards listGatewayStartedShards ; private volatile LocalGatewayMetaState currentMetaState ; private volatile LocalGatewayStartedShards currentStartedShards ; private volatile ExecutorService executor ; private volatile boolean initialized = false ; @ Inject public LocalGateway ( Settings settings , ClusterService clusterService , MetaDataCreateIndexService createIndexService , NodeEnvironment nodeEnv , TransportNodesListGatewayMetaState listGatewayMetaState , TransportNodesListGatewayStartedShards listGatewayStartedShards ) { } @ Override public String type ( ) { } public LocalGatewayMetaState currentMetaState ( ) { } public LocalGatewayStartedShards currentStartedShards ( ) { } @ Override protected void doStart ( ) throws ElasticSearchException { } @ Override protected void doStop ( ) throws ElasticSearchException { } @ Override protected void doClose ( ) throws ElasticSearchException { } @ Override public void performStateRecovery ( final GatewayStateRecoveredListener listener ) throws GatewayException { } @ Override public Class < ? extends Module > suggestIndexGateway ( ) { } @ Override public void reset ( ) throws Exception { } @ Override public void clusterChanged ( final ClusterChangedEvent event ) { } private synchronized void lazyInitialize ( ) { if ( initialized ) { return ; } initialized = true ; <START_BUG> if ( ( ! ( clusterService . localNode ( ) . masterNode ( ) ) ) || ( ! ( clusterService . localNode ( ) . dataNode ( ) ) ) ) { <END_BUG> location = null ; } else { this . location = new File ( nodeEnv . nodeDataLocation ( ) , "_state" ) ; this . location . mkdirs ( ) ; if ( clusterService . localNode ( ) . masterNode ( ) ) { try { long version = findLatestMetaStateVersion ( ) ; if ( version != ( - 1 ) ) { this . currentMetaState = readMetaState ( Streams . copyToByteArray ( new FileInputStream ( new File ( location , ( "metadata-" + version ) ) ) ) ) ; } } catch ( Exception e ) { logger . warn ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>read<seq2seq4repair_space>local<seq2seq4repair_space>state" , e ) ; } } if ( clusterService . localNode ( ) . dataNode ( ) ) { try { long version = findLatestStartedShardsVersion ( ) ; if ( version != ( - 1 ) ) { this . currentStartedShards = readStartedShards ( Streams . copyToByteArray ( new FileInputStream ( new File ( location , ( "shards-" + version ) ) ) ) ) ; } } catch ( Exception e ) { logger . warn ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>read<seq2seq4repair_space>local<seq2seq4repair_space>state" , e ) ; } } } } private long findLatestStartedShardsVersion ( ) throws IOException { } private long findLatestMetaStateVersion ( ) throws IOException { } private LocalGatewayMetaState readMetaState ( byte [ ] data ) throws IOException { } private LocalGatewayStartedShards readStartedShards ( byte [ ] data ) throws IOException { } }<BUG2FIX>if ( ( ! ( clusterService . localNode ( ) . masterNode ( ) ) ) && ( ! ( clusterService . localNode ( ) . dataNode ( ) ) ) ) {
public class ETC1TextureData implements TextureData { FileHandle file ; ETC1Data data ; boolean useMipMaps ; int width = 0 ; int height = 0 ; boolean isPrepared = false ; public ETC1TextureData ( FileHandle file ) { } public ETC1TextureData ( FileHandle file , boolean useMipMaps ) { } public ETC1TextureData ( ETC1Data encodedImage , boolean useMipMaps ) { } @ Override public TextureDataType getType ( ) { } @ Override public boolean isPrepared ( ) { } @ Override public void prepare ( ) { } @ Override public void consumeCompressedData ( int target ) { if ( ! ( isPrepared ) ) throw new GdxRuntimeException ( "Call<seq2seq4repair_space>prepare()<seq2seq4repair_space>before<seq2seq4repair_space>calling<seq2seq4repair_space>consumeCompressedData()" ) ; if ( ( ! ( graphics . supportsExtension ( "GL_OES_compressed_ETC1_RGB8_texture" ) ) ) || ( ( graphics . isGL20Available ( ) ) == false ) ) { Pixmap pixmap = ETC1 . decodeImage ( data , RGB565 ) ; gl . glTexImage2D ( target , 0 , pixmap . getGLInternalFormat ( ) , pixmap . getWidth ( ) , pixmap . getHeight ( ) , 0 , pixmap . getGLFormat ( ) , pixmap . getGLType ( ) , pixmap . getPixels ( ) ) ; if ( useMipMaps ) <START_BUG> MipMapGenerator . generateMipMap ( target , pixmap , pixmap . getWidth ( ) , pixmap . getHeight ( ) , false ) ; <END_BUG> pixmap . dispose ( ) ; useMipMaps = false ; } else { gl . glCompressedTexImage2D ( target , 0 , ETC1_RGB8_OES , width , height , 0 , ( ( data . compressedData . capacity ( ) ) - ( data . dataOffset ) ) , data . compressedData ) ; if ( useMipMaps ( ) ) gl20 . glGenerateMipmap ( GL_TEXTURE_2D ) ; } data . dispose ( ) ; data = null ; isPrepared = false ; } @ Override public Pixmap consumePixmap ( ) { } @ Override public boolean disposePixmap ( ) { } @ Override public int getWidth ( ) { } @ Override public int getHeight ( ) { } @ Override public Format getFormat ( ) { } @ Override public boolean useMipMaps ( ) { } @ Override public boolean isManaged ( ) { } }<BUG2FIX>MipMapGenerator . generateMipMap ( target , pixmap , pixmap . getWidth ( ) , pixmap . getHeight ( ) ) ;
public class ManagedTest implements RenderListener { MeshRenderer mesh ; Texture texture ; @ Override public void surfaceCreated ( Application app ) { } @ Override public void render ( Application app ) { GL10 gl = app . getGraphics ( ) . getGL10 ( ) ; gl . glViewport ( 0 , 0 , app . getGraphics ( ) . getWidth ( ) , app . getGraphics ( ) . getHeight ( ) ) ; gl . glClearColor ( 0.7F , 0.7F , 0.7F , 1 ) ; gl . glClear ( GL_COLOR_BUFFER_BIT ) ; gl . glEnable ( GL_TEXTURE_2D ) ; texture . bind ( ) ; <START_BUG> mesh . render ( GL_TRIANGLE_FAN , 0 , 4 ) ; <END_BUG> } @ Override public void dispose ( Application app ) { } @ Override public void surfaceChanged ( Application app , int width , int height ) { } public static void main ( String [ ] argv ) { } }<BUG2FIX>mesh . render ( GL_TRIANGLE_FAN ) ;
public class GwtTestWrapper extends GdxTest { Stage ui ; Table container ; Skin skin ; BitmapFont font ; GdxTest test ; boolean dispose ; @ Override public void create ( ) { ui = new Stage ( graphics . getWidth ( ) , graphics . getHeight ( ) , true ) ; <START_BUG> skin = new Skin ( files . internal ( "data/uiskin.json" ) , files . internal ( "data/uiskin.png" ) ) ; <END_BUG> font = new BitmapFont ( files . internal ( "data/arial-15.fnt" ) , false ) ; container = new Table ( ) ; ui . addActor ( container ) ; container . debug ( ) ; Table table = new Table ( ) ; ScrollPane scroll = new ScrollPane ( table ) ; container . add ( scroll ) . expand ( ) . fill ( ) ; table . pad ( 10 ) . defaults ( ) . expandX ( ) . space ( 4 ) ; for ( final GwtTestWrapper . Instancer instancer : tests ) { table . row ( ) ; TextButton button = new TextButton ( instancer . instance ( ) . getClass ( ) . getName ( ) , skin ) ; button . addListener ( new ClickListener ( ) { @ Override public void clicked ( ActorEvent event , float x , float y ) { ( ( GwtTestWrapper . InputWrapper ) ( Gdx . input ) ) . multiplexer . removeProcessor ( ui ) ; test = instancer . instance ( ) ; test . create ( ) ; test . resize ( graphics . getWidth ( ) , graphics . getHeight ( ) ) ; } } ) ; table . add ( button ) . expandX ( ) . fillX ( ) ; } container . row ( ) ; container . add ( new Label ( "Click<seq2seq4repair_space>on<seq2seq4repair_space>a<seq2seq4repair_space>test<seq2seq4repair_space>to<seq2seq4repair_space>start<seq2seq4repair_space>it,<seq2seq4repair_space>press<seq2seq4repair_space>ESC<seq2seq4repair_space>to<seq2seq4repair_space>close<seq2seq4repair_space>it." , new com . badlogic . gdx . scenes . scene2d . ui . Label . LabelStyle ( font , Color . WHITE ) ) ) . pad ( 5 , 5 , 5 , 5 ) ; Gdx . input = new GwtTestWrapper . InputWrapper ( Gdx . input ) { @ Override public boolean keyUp ( int keycode ) { if ( keycode == ( Keys . ESCAPE ) ) { dispose = true ; } return false ; } } ; ( ( GwtTestWrapper . InputWrapper ) ( Gdx . input ) ) . multiplexer . addProcessor ( ui ) ; } public void render ( ) { } public void resize ( int width , int height ) { } class InputWrapper extends InputAdapter implements Input { Input input ; InputProcessor lastProcessor ; InputMultiplexer multiplexer ; public InputWrapper ( Input input ) { } @ Override public float getAccelerometerX ( ) { } @ Override public float getAccelerometerY ( ) { } @ Override public float getAccelerometerZ ( ) { } @ Override public int getX ( ) { } @ Override public int getX ( int pointer ) { } @ Override public int getDeltaX ( ) { } @ Override public int getDeltaX ( int pointer ) { } @ Override public int getY ( ) { } @ Override public int getY ( int pointer ) { } @ Override public int getDeltaY ( ) { } @ Override public int getDeltaY ( int pointer ) { } @ Override public boolean isTouched ( ) { } @ Override public boolean justTouched ( ) { } @ Override public boolean isTouched ( int pointer ) { } @ Override public boolean isButtonPressed ( int button ) { } @ Override public boolean isKeyPressed ( int key ) { } @ Override public void getTextInput ( TextInputListener listener , String title , String text ) { } @ Override public void getPlaceholderTextInput ( TextInputListener listener , String title , String placeholder ) { } @ Override public void setOnscreenKeyboardVisible ( boolean visible ) { } @ Override public void vibrate ( int milliseconds ) { } @ Override public void vibrate ( long [ ] pattern , int repeat ) { } @ Override public void cancelVibrate ( ) { } @ Override public float getAzimuth ( ) { } @ Override public float getPitch ( ) { } @ Override public float getRoll ( ) { } @ Override public void getRotationMatrix ( float [ ] matrix ) { } @ Override public long getCurrentEventTime ( ) { } @ Override public void setCatchBackKey ( boolean catchBack ) { } @ Override public void setCatchMenuKey ( boolean catchMenu ) { } @ Override public void setInputProcessor ( InputProcessor processor ) { } @ Override public InputProcessor getInputProcessor ( ) { } @ Override public boolean isPeripheralAvailable ( Peripheral peripheral ) { } @ Override public int getRotation ( ) { } @ Override public Orientation getNativeOrientation ( ) { } @ Override public void setCursorCatched ( boolean catched ) { } @ Override public boolean isCursorCatched ( ) { } @ Override public void setCursorPosition ( int x , int y ) { } } interface Instancer { public GdxTest instance ( ) { } } GwtTestWrapper . Instancer [ ] tests = new GwtTestWrapper . Instancer [ ] { new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } }<BUG2FIX>skin = new Skin ( files . internal ( "data/uiskin.json" ) ) ;
public abstract class AbstractFsBlobContainer extends AbstractBlobContainer { protected final FsBlobStore blobStore ; protected final File path ; public AbstractFsBlobContainer ( FsBlobStore blobStore , BlobPath blobPath , File path ) { } public ImmutableMap < String , BlobMetaData > listBlobs ( ) throws IOException { File [ ] files = path . listFiles ( ) ; if ( ( files == null ) || ( ( files . length ) == 0 ) ) { return ImmutableMap . of ( ) ; } Builder < String , BlobMetaData > builder = ImmutableMap . builder ( ) ; for ( File file : files ) { <START_BUG> builder . put ( file . getName ( ) , new PlainBlobMetaData ( file . getName ( ) , file . length ( ) , null ) ) ; <END_BUG> } return builder . build ( ) ; } public boolean deleteBlob ( String blobName ) throws IOException { } @ Override public boolean blobExists ( String blobName ) { } @ Override public void readBlob ( final String blobName , final ReadBlobListener listener ) { } }<BUG2FIX>builder . put ( file . getName ( ) , new PlainBlobMetaData ( file . getName ( ) , file . length ( ) ) ) ;
public void removeMapping ( final DeleteMappingClusterStateUpdateRequest request , final ActionListener < ClusterStateUpdateResponse > listener ) { } public void putMapping ( final PutMappingClusterStateUpdateRequest request , final ActionListener < ClusterStateUpdateResponse > listener ) { clusterService . submitStateUpdateTask ( ( ( "put-mapping<seq2seq4repair_space>[" + ( request . type ( ) ) ) + "]" ) , HIGH , new org . elasticsearch . cluster . AckedClusterStateUpdateTask < ClusterStateUpdateResponse > ( request , listener ) { @ Override protected ClusterStateUpdateResponse newResponse ( boolean acknowledged ) { return new ClusterStateUpdateResponse ( acknowledged ) ; } @ Override public ClusterState execute ( final ClusterState currentState ) throws Exception { List < String > indicesToClose = Lists . newArrayList ( ) ; try { for ( String index : request . indices ( ) ) { if ( ! ( currentState . metaData ( ) . hasIndex ( index ) ) ) { throw new org . elasticsearch . indices . IndexMissingException ( new Index ( index ) ) ; } } for ( String index : request . indices ( ) ) { if ( indicesService . hasIndex ( index ) ) { continue ; } final IndexMetaData indexMetaData = currentState . metaData ( ) . index ( index ) ; IndexService indexService = indicesService . createIndex ( indexMetaData . index ( ) , indexMetaData . settings ( ) , clusterService . localNode ( ) . id ( ) ) ; indicesToClose . add ( indexMetaData . index ( ) ) ; if ( indexMetaData . mappings ( ) . containsKey ( DEFAULT_MAPPING ) ) { indexService . mapperService ( ) . merge ( DEFAULT_MAPPING , indexMetaData . mappings ( ) . get ( DEFAULT_MAPPING ) . source ( ) , false ) ; } if ( indexMetaData . mappings ( ) . containsKey ( request . type ( ) ) ) { indexService . mapperService ( ) . merge ( request . type ( ) , indexMetaData . mappings ( ) . get ( request . type ( ) ) . source ( ) , false ) ; } } Map < String , DocumentMapper > newMappers = Maps . newHashMap ( ) ; Map < String , DocumentMapper > existingMappers = Maps . newHashMap ( ) ; for ( String index : request . indices ( ) ) { IndexService indexService = indicesService . indexServiceSafe ( index ) ; DocumentMapper newMapper ; DocumentMapper existingMapper = indexService . mapperService ( ) . documentMapper ( request . type ( ) ) ; if ( DEFAULT_MAPPING . equals ( request . type ( ) ) ) { newMapper = indexService . mapperService ( ) . parse ( request . type ( ) , new CompressedString ( request . source ( ) ) , false ) ; } else { <START_BUG> newMapper = indexService . mapperService ( ) . parse ( request . type ( ) , new CompressedString ( request . source ( ) ) , ( existingMapper == null ) ) ; <END_BUG> if ( existingMapper != null ) { DocumentMapper . MergeResult mergeResult = existingMapper . merge ( newMapper , mergeFlags ( ) . simulate ( true ) ) ; if ( ( ! ( request . ignoreConflicts ( ) ) ) && ( mergeResult . hasConflicts ( ) ) ) { throw new org . elasticsearch . index . mapper . MergeMappingException ( mergeResult . conflicts ( ) ) ; } } } newMappers . put ( index , newMapper ) ; if ( existingMapper != null ) { existingMappers . put ( index , existingMapper ) ; } } String mappingType = request . type ( ) ; if ( mappingType == null ) { mappingType = newMappers . values ( ) . iterator ( ) . next ( ) . type ( ) ; } else if ( ! ( mappingType . equals ( newMappers . values ( ) . iterator ( ) . next ( ) . type ( ) ) ) ) { throw new InvalidTypeNameException ( "Type<seq2seq4repair_space>name<seq2seq4repair_space>provided<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>match<seq2seq4repair_space>type<seq2seq4repair_space>name<seq2seq4repair_space>within<seq2seq4repair_space>mapping<seq2seq4repair_space>definition" ) ; } if ( ( ( ! ( DEFAULT_MAPPING . equals ( mappingType ) ) ) && ( ! ( TYPE_NAME . equals ( mappingType ) ) ) ) && ( ( mappingType . charAt ( 0 ) ) == '_' ) ) { throw new InvalidTypeNameException ( "Document<seq2seq4repair_space>mapping<seq2seq4repair_space>type<seq2seq4repair_space>name<seq2seq4repair_space>can't<seq2seq4repair_space>start<seq2seq4repair_space>with<seq2seq4repair_space>'_'" ) ; } final Map < String , MappingMetaData > mappings = Maps . newHashMap ( ) ; for ( Map . Entry < String , DocumentMapper > entry : newMappers . entrySet ( ) ) { String index = entry . getKey ( ) ; DocumentMapper newMapper = entry . getValue ( ) ; IndexService indexService = indicesService . indexService ( index ) ; if ( indexService == null ) { continue ; } CompressedString existingSource = null ; if ( existingMappers . containsKey ( entry . getKey ( ) ) ) { existingSource = existingMappers . get ( entry . getKey ( ) ) . mappingSource ( ) ; } DocumentMapper mergedMapper = indexService . mapperService ( ) . merge ( newMapper . type ( ) , newMapper . mappingSource ( ) , false ) ; CompressedString updatedSource = mergedMapper . mappingSource ( ) ; if ( existingSource != null ) { if ( existingSource . equals ( updatedSource ) ) { } else { mappings . put ( index , new MappingMetaData ( mergedMapper ) ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "[{}]<seq2seq4repair_space>update_mapping<seq2seq4repair_space>[{}]<seq2seq4repair_space>with<seq2seq4repair_space>source<seq2seq4repair_space>[{}]" , index , mergedMapper . type ( ) , updatedSource ) ; } else if ( logger . isInfoEnabled ( ) ) { logger . info ( "[{}]<seq2seq4repair_space>update_mapping<seq2seq4repair_space>[{}]" , index , mergedMapper . type ( ) ) ; } } } else { mappings . put ( index , new MappingMetaData ( mergedMapper ) ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "[{}]<seq2seq4repair_space>create_mapping<seq2seq4repair_space>[{}]<seq2seq4repair_space>with<seq2seq4repair_space>source<seq2seq4repair_space>[{}]" , index , newMapper . type ( ) , updatedSource ) ; } else if ( logger . isInfoEnabled ( ) ) { logger . info ( "[{}]<seq2seq4repair_space>create_mapping<seq2seq4repair_space>[{}]"<BUG2FIX>newMapper = indexService . mapperService ( ) . parse ( request . type ( ) , new CompressedString ( request . source ( ) ) ) ;
public class JsonLongFieldMapper extends JsonNumberFieldMapper < Long > { public static final String JSON_TYPE = "long" ; public static class Defaults extends JsonNumberFieldMapper . Defaults { public static final Long NULL_VALUE = null ; } public static class Builder extends JsonNumberFieldMapper . Builder < JsonLongFieldMapper . Builder , JsonLongFieldMapper > { protected Long nullValue = JsonLongFieldMapper . Defaults . NULL_VALUE ; public Builder ( String name ) { } public JsonLongFieldMapper . Builder nullValue ( long nullValue ) { } @ Override public JsonLongFieldMapper build ( BuilderContext context ) { } } public static class TypeParser implements JsonTypeParser { @ Override public JsonMapper . Builder parse ( String name , JsonNode node , ParserContext parserContext ) throws MapperParsingException { } } private final Long nullValue ; private final String nullValueAsString ; protected JsonLongFieldMapper ( Names names , int precisionStep , Field . Index index , Field . Store store , float boost , boolean omitNorms , boolean omitTermFreqAndPositions , Long nullValue ) { } @ Override protected int maxPrecisionStep ( ) { } @ Override public Long value ( Fieldable field ) { byte [ ] value = field . getBinaryValue ( ) ; if ( value == null ) { <START_BUG> return Long . MIN_VALUE ; <END_BUG> } return Numbers . bytesToLong ( value ) ; } @ Override public String indexedValue ( String value ) { } @ Override public String indexedValue ( Long value ) { } @ Override public Object valueFromTerm ( String term ) { } @ Override public Object valueFromString ( String text ) { } @ Override public Query rangeQuery ( String lowerTerm , String upperTerm , boolean includeLower , boolean includeUpper ) { } @ Override public Filter rangeFilter ( String lowerTerm , String upperTerm , boolean includeLower , boolean includeUpper ) { } @ Override protected Field parseCreateField ( JsonParseContext jsonContext ) throws IOException { } @ Override public int sortType ( ) { } @ Override protected String jsonType ( ) { } @ Override protected void doJsonBody ( JsonBuilder builder ) throws IOException { } }<BUG2FIX>return null ;
public class MetagunDesktop { public static void main ( String [ ] argv ) { <START_BUG> new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new Metagun ( ) , "Metagun" , 320 , 240 ) ; <END_BUG> } }<BUG2FIX>new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new Metagun ( ) , "Metagun" , 320 , 240 , false ) ;
public class FilesTest extends GdxTest { String message = "" ; boolean success ; BitmapFont font ; SpriteBatch batch ; @ Override public void create ( ) { } private void testClasspath ( ) throws IOException { } private void testInternal ( ) throws IOException { } private void testExternal ( ) throws IOException { } private void testAbsolute ( ) throws IOException { } private void testLocal ( ) throws IOException { String path = "meow" ; FileHandle handle = files . local ( path ) ; handle . delete ( ) ; if ( handle . exists ( ) ) fail ( ) ; if ( handle . isDirectory ( ) ) fail ( ) ; if ( handle . delete ( ) ) fail ( ) ; if ( ( handle . list ( ) . length ) != 0 ) fail ( ) ; if ( handle . child ( "meow" ) . exists ( ) ) fail ( ) ; <START_BUG> if ( handle . parent ( ) . exists ( ) ) <END_BUG> fail ( ) ; try { handle . read ( ) . close ( ) ; fail ( ) ; } catch ( Exception ignored ) { } handle . mkdirs ( ) ; if ( ! ( handle . exists ( ) ) ) fail ( ) ; if ( ! ( handle . isDirectory ( ) ) ) fail ( ) ; if ( ( handle . list ( ) . length ) != 0 ) fail ( ) ; handle . child ( "meow" ) . mkdirs ( ) ; if ( ( handle . list ( ) . length ) != 1 ) fail ( ) ; FileHandle child = handle . list ( ) [ 0 ] ; if ( ! ( child . name ( ) . equals ( "meow" ) ) ) fail ( ) ; if ( ! ( child . parent ( ) . exists ( ) ) ) fail ( ) ; if ( ! ( handle . deleteDirectory ( ) ) ) fail ( ) ; if ( handle . exists ( ) ) fail ( ) ; OutputStream output = handle . write ( false ) ; output . write ( "moo" . getBytes ( ) ) ; output . close ( ) ; if ( ! ( handle . exists ( ) ) ) fail ( ) ; if ( ( handle . length ( ) ) != 3 ) fail ( ) ; FileHandle copy = files . local ( ( path + "-copy" ) ) ; copy . delete ( ) ; if ( copy . exists ( ) ) fail ( ) ; handle . copyTo ( copy ) ; if ( ! ( copy . exists ( ) ) ) fail ( ) ; if ( ( copy . length ( ) ) != 3 ) fail ( ) ; FileHandle move = files . local ( ( path + "-move" ) ) ; move . delete ( ) ; if ( move . exists ( ) ) fail ( ) ; copy . moveTo ( move ) ; if ( ! ( move . exists ( ) ) ) fail ( ) ; if ( ( move . length ( ) ) != 3 ) fail ( ) ; move . deleteDirectory ( ) ; if ( move . exists ( ) ) fail ( ) ; InputStream input = handle . read ( ) ; byte [ ] bytes = new byte [ 6 ] ; if ( ( input . read ( bytes ) ) != 3 ) fail ( ) ; input . close ( ) ; if ( ! ( new String ( bytes , 0 , 3 ) . equals ( "moo" ) ) ) fail ( ) ; output = handle . write ( true ) ; output . write ( "cow" . getBytes ( ) ) ; output . close ( ) ; if ( ( handle . length ( ) ) != 6 ) fail ( ) ; input = handle . read ( ) ; if ( ( input . read ( bytes ) ) != 6 ) fail ( ) ; input . close ( ) ; if ( ! ( new String ( bytes , 0 , 6 ) . equals ( "moocow" ) ) ) fail ( ) ; if ( handle . isDirectory ( ) ) fail ( ) ; if ( ( handle . list ( ) . length ) != 0 ) fail ( ) ; if ( ! ( handle . name ( ) . equals ( "meow" ) ) ) fail ( ) ; if ( ! ( handle . nameWithoutExtension ( ) . equals ( "meow" ) ) ) fail ( ) ; if ( ! ( handle . extension ( ) . equals ( "" ) ) ) fail ( ) ; handle . deleteDirectory ( ) ; if ( handle . exists ( ) ) fail ( ) ; if ( handle . isDirectory ( ) ) fail ( ) ; handle . delete ( ) ; handle . deleteDirectory ( ) ; } private void fail ( ) { } private void fail ( String msg ) { } @ Override public void render ( ) { } @ Override public void dispose ( ) { } @ Override public boolean needsGL20 ( ) { } }<BUG2FIX>if ( ! ( handle . parent ( ) . exists ( ) ) )
public class Circle implements Serializable { public float x ; public float y ; public float radius ; public Circle ( ) { } public Circle ( float x , float y , float radius ) { } public Circle ( Vector2 position , float radius ) { } public void set ( float x , float y , float radius ) { } public boolean contains ( float x , float y ) { } public boolean contains ( Vector2 point ) { } public boolean overlaps ( Circle c ) { float dx = ( x ) - ( c . x ) ; float dy = ( y ) - ( c . y ) ; float distance = ( dx * dx ) + ( dy * dy ) ; float radiusSum = ( radius ) + ( c . radius ) ; <START_BUG> return distance <= ( radiusSum * radiusSum ) ; <END_BUG> } public String toString ( ) { } }<BUG2FIX>return distance < ( radiusSum * radiusSum ) ;
public class ClusterStateResponse implements ActionResponse { private ClusterName clusterName ; private ClusterState clusterState ; ClusterStateResponse ( ) { } ClusterStateResponse ( ClusterName clusterName , ClusterState clusterState ) { } public ClusterState state ( ) { } public ClusterState getState ( ) { } public ClusterName clusterName ( ) { } public ClusterName getClusterName ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { clusterName = ClusterName . readClusterName ( in ) ; <START_BUG> clusterState = Builder . readFrom ( in , null , null ) ; <END_BUG> } @ Override public void writeTo ( StreamOutput out ) throws IOException { } }<BUG2FIX>clusterState = Builder . readFrom ( in , null ) ;
public class GistsActivity extends RoboFragmentActivity implements OnItemClickListener { private static final int REQUEST_CREATE = 1 ; private static final int REQUEST_VIEW = ( GistsActivity . REQUEST_CREATE ) + 1 ; @ Inject private Context context ; @ Inject private ContextScopedProvider < GistService > serviceProvider ; private GistsFragment gists ; @ Override protected void onCreate ( Bundle savedInstanceState ) { } private void randomGist ( ) { } private void openGist ( ) { } @ Override public boolean onCreateOptionsMenu ( Menu options ) { } @ Override public boolean onOptionsItemSelected ( MenuItem item ) { } public void onActivityResult ( int requestCode , int resultCode , Intent data ) { } public void onItemClick ( AdapterView < ? > list , View view , int position , long id ) { Gist gist = ( ( Gist ) ( list . getItemAtPosition ( position ) ) ) ; <START_BUG> startActivityForResult ( ViewGistActivity . createIntent ( gist . getId ( ) ) , GistsActivity . REQUEST_VIEW ) ; <END_BUG> } }<BUG2FIX>startActivityForResult ( ViewGistActivity . createIntent ( gist ) , GistsActivity . REQUEST_VIEW ) ;
public abstract class AbstractSimpleTranslogTests { protected final ShardId shardId = new ShardId ( new Index ( "index" ) , 1 ) ; protected Translog translog ; @ BeforeMethod public void setUp ( ) { } @ AfterMethod public void tearDown ( ) { <START_BUG> translog . close ( ) ; <END_BUG> } protected abstract Translog create ( ) { } @ Test public void testSimpleOperations ( ) { } @ Test public void testSnapshot ( ) { } @ Test public void testSnapshotWithNewTranslog ( ) { } @ Test public void testSnapshotWithSeekForward ( ) { } private Term newUid ( String id ) { } }<BUG2FIX>translog . close ( true ) ;
public static final int PRECISION = GeoHashUtils . PRECISION ; public static final boolean NORMALIZE_LAT = true ; public static final boolean NORMALIZE_LON = true ; public static final boolean VALIDATE_LAT = true ; public static final boolean VALIDATE_LON = true ; public static final FieldType FIELD_TYPE = new FieldType ( StringFieldMapper . Defaults . FIELD_TYPE ) ; } public static class Builder extends Mapper . Builder < GeoPointFieldMapper . Builder , GeoPointFieldMapper > { private Type pathType = GeoPointFieldMapper . Defaults . PATH_TYPE ; private boolean enableGeoHash = GeoPointFieldMapper . Defaults . ENABLE_GEOHASH ; private boolean enableLatLon = GeoPointFieldMapper . Defaults . ENABLE_LATLON ; private Integer precisionStep ; private int precision = GeoPointFieldMapper . Defaults . PRECISION ; private boolean store = GeoPointFieldMapper . Defaults . STORE ; boolean validateLat = GeoPointFieldMapper . Defaults . VALIDATE_LAT ; boolean validateLon = GeoPointFieldMapper . Defaults . VALIDATE_LON ; boolean normalizeLat = GeoPointFieldMapper . Defaults . NORMALIZE_LAT ; boolean normalizeLon = GeoPointFieldMapper . Defaults . NORMALIZE_LON ; public Builder ( String name ) { } public GeoPointFieldMapper . Builder pathType ( ContentPath . Type pathType ) { } public GeoPointFieldMapper . Builder enableGeoHash ( boolean enableGeoHash ) { } public GeoPointFieldMapper . Builder enableLatLon ( boolean enableLatLon ) { } public GeoPointFieldMapper . Builder precisionStep ( int precisionStep ) { } public GeoPointFieldMapper . Builder precision ( int precision ) { } public GeoPointFieldMapper . Builder store ( boolean store ) { } @ Override public GeoPointFieldMapper build ( BuilderContext context ) { } } public static class TypeParser implements Mapper . TypeParser { @ Override public Mapper . Builder parse ( String name , Map < String , Object > node , ParserContext parserContext ) throws MapperParsingException { } } private final String name ; private final Type pathType ; private final boolean enableLatLon ; private final boolean enableGeoHash ; private final Integer precisionStep ; private final int precision ; private final DoubleFieldMapper latMapper ; private final DoubleFieldMapper lonMapper ; private final StringFieldMapper geohashMapper ; private final GeoPointFieldMapper . GeoStringFieldMapper geoStringMapper ; private final boolean validateLon ; private final boolean validateLat ; private final boolean normalizeLon ; private final boolean normalizeLat ; public GeoPointFieldMapper ( String name , ContentPath . Type pathType , boolean enableLatLon , boolean enableGeoHash , Integer precisionStep , int precision , DoubleFieldMapper latMapper , DoubleFieldMapper lonMapper , StringFieldMapper geohashMapper , GeoPointFieldMapper . GeoStringFieldMapper geoStringMapper , boolean validateLon , boolean validateLat , boolean normalizeLon , boolean normalizeLat ) { } @ Override public String name ( ) { } public DoubleFieldMapper latMapper ( ) { } public DoubleFieldMapper lonMapper ( ) { } public GeoPointFieldMapper . GeoStringFieldMapper stringMapper ( ) { } public boolean isEnableLatLon ( ) { } @ Override public void parse ( ParseContext context ) throws IOException { } private void parseStringLatLon ( ParseContext context ) throws IOException { } private void parseObjectLatLon ( ParseContext context ) throws IOException { } private void parseLatLon ( ParseContext context , double lat , double lon ) throws IOException { } private void parseGeohash ( ParseContext context , String geohash ) throws IOException { GeoPoint point = GeoHashUtils . decode ( geohash ) ; if ( ( normalizeLat ) || ( normalizeLon ) ) { GeoUtils . normalizePoint ( point , normalizeLat , normalizeLon ) ; } if ( validateLat ) { if ( ( ( point . lat ( ) ) > 90.0 ) || ( ( point . lat ( ) ) < ( - 90.0 ) ) ) { throw new org . elasticsearch . ElasticSearchIllegalArgumentException ( ( ( ( "illegal<seq2seq4repair_space>latitude<seq2seq4repair_space>value<seq2seq4repair_space>[" + ( point . lat ( ) ) ) + "]<seq2seq4repair_space>for<seq2seq4repair_space>" ) + ( name ) ) ) ; } } if ( validateLon ) { if ( ( ( point . lon ( ) ) > 180.0 ) || ( ( point . lon ( ) ) < ( - 180 ) ) ) { throw new org . elasticsearch . ElasticSearchIllegalArgumentException ( ( ( ( "illegal<seq2seq4repair_space>longitude<seq2seq4repair_space>value<seq2seq4repair_space>[" + ( point . lon ( ) ) ) + "]<seq2seq4repair_space>for<seq2seq4repair_space>" ) + ( name ) ) ) ; } } <START_BUG> context . externalValue ( ( ( ( Double . toString ( point . lat ( ) ) ) + ',' ) + ( Double . toString ( point . lat ( ) ) ) ) ) ; <END_BUG> geoStringMapper . parse ( context ) ; if ( enableGeoHash ) { context . externalValue ( geohash ) ; geohashMapper . parse ( context ) ; } if ( enableLatLon ) { context . externalValue ( point . lat ( ) ) ; latMapper . parse ( context ) ; context . externalValue ( point . lon ( ) ) ; lonMapper . parse ( context ) ; } } @ Override public void close ( ) { } @ Override public void merge ( Mapper mergeWith , MergeContext mergeContext ) throws MergeMappingException { } @ Override public void traverse ( FieldMapperListener fieldMapperListener ) { } @ Override public void traverse ( ObjectMapperListener objectMapperListener ) { } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } public static class GeoStringFieldMapper extends StringFieldMapper { public static class Builder extends OpenBuilder < GeoPointFieldMapper . GeoStringFieldMapper . Builder , StringFieldMapper > { protected String nullValue = NULL_VALUE ; public Builder ( String name ) { } public GeoPointFieldMapper . GeoStringFieldMapper . Builder nullValue ( String nullValue ) { } @ Override public GeoPointFieldMapper . GeoStringFieldMapper . Builder includeInAll ( Boolean includeInAll ) { } @ Override public GeoPointFieldMapper . GeoStringFieldMapper build ( BuilderContext context ) { } } GeoPointFieldMapper geoMapper ; public GeoStringFieldMapper ( GeoPointFieldMapper . Names names , float boost , FieldType fieldType , String nullValue , NamedAnalyzer indexAnalyzer , NamedAnalyzer searchAnalyzer , PostingsFormatProvider provider , @ Nullable Settings fieldDataSettings ) { } @ Override public FieldType defaultFieldType ( ) { } @ Override public FieldDataType defaultFieldDataType ( ) { } public GeoPointFieldMapper geoMapper ( ) { } } }<BUG2FIX>context . externalValue ( ( ( ( Double . toString ( point . lat ( ) ) ) + ',' ) + ( Double . toString ( point . lon ( ) ) ) ) ) ;
public class TermsLongFacetCollector extends AbstractFacetCollector { static ThreadLocal < ThreadLocals . CleanableValue < Deque < TLongIntHashMap > > > cache = new ThreadLocal < ThreadLocals . CleanableValue < Deque < TLongIntHashMap > > > ( ) { @ Override protected ThreadLocals . CleanableValue < Deque < TLongIntHashMap > > initialValue ( ) { } } ; private final FieldDataCache fieldDataCache ; private final String indexFieldName ; private final ComparatorType comparatorType ; private final int size ; private final int numberOfShards ; private final FieldDataType fieldDataType ; private LongFieldData fieldData ; private final TermsLongFacetCollector . StaticAggregatorValueProc aggregator ; private final SearchScript script ; public TermsLongFacetCollector ( String facetName , String fieldName , int size , TermsFacet . ComparatorType comparatorType , boolean allTerms , SearchContext context , ImmutableSet < BytesRef > excluded , String scriptLang , String script , Map < String , Object > params ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override protected void doSetNextReader ( AtomicReaderContext context ) throws IOException { fieldData = ( ( LongFieldData ) ( fieldDataCache . cache ( fieldDataType , context . reader ( ) , indexFieldName ) ) ) ; if ( ( script ) != null ) { <START_BUG> script . setNextReader ( context . reader ( ) ) ; <END_BUG> } } @ Override protected void doCollect ( int doc ) throws IOException { } @ Override public Facet facet ( ) { } public static class AggregatorValueProc extends TermsLongFacetCollector . StaticAggregatorValueProc { private final SearchScript script ; private final TLongHashSet excluded ; public AggregatorValueProc ( TLongIntHashMap facets , Set < BytesRef > excluded , SearchScript script ) { } @ Override public void onValue ( int docId , long value ) { } } public static class StaticAggregatorValueProc implements LongFieldData . ValueInDocProc , LongFieldData . ValueProc { private final TLongIntHashMap facets ; private int missing ; private int total ; public StaticAggregatorValueProc ( TLongIntHashMap facets ) { } @ Override public void onValue ( long value ) { } @ Override public void onValue ( int docId , long value ) { } @ Override public void onMissing ( int docId ) { } public final TLongIntHashMap facets ( ) { } public final int missing ( ) { } public final int total ( ) { } } }<BUG2FIX>script . setNextReader ( context ) ;
public class IOSMusic implements Music { private final OALAudioTrack track ; OnCompletionListener onCompletionListener ; public IOSMusic ( OALAudioTrack track ) { } @ Override public void play ( ) { } @ Override public void pause ( ) { } @ Override public void stop ( ) { } @ Override public boolean isPlaying ( ) { } @ Override public void setLooping ( boolean isLooping ) { } @ Override public boolean isLooping ( ) { } @ Override public void setVolume ( float volume ) { } public void setPosition ( float position ) { } @ Override public float getPosition ( ) { <START_BUG> return ( ( float ) ( ( track . getCurrentTime ( ) ) * 1000.0 ) ) ; <END_BUG> } @ Override public void dispose ( ) { } @ Override public float getVolume ( ) { } @ Override public void setPan ( float pan , float volume ) { } @ Override public void setOnCompletionListener ( OnCompletionListener listener ) { } }<BUG2FIX>return ( ( float ) ( track . getCurrentTime ( ) ) ) ;
public class FsTranslog extends AbstractIndexShardComponent implements Translog { private final File location ; private final boolean useStream ; private final Object mutex = new Object ( ) ; private boolean syncOnEachOperation = false ; private volatile long id = 0 ; private final AtomicInteger operationCounter = new AtomicInteger ( ) ; private long lastPosition = 0 ; private RafReference raf ; @ Inject public FsTranslog ( ShardId shardId , @ IndexSettings Settings indexSettings , NodeEnvironment nodeEnv ) { } public FsTranslog ( ShardId shardId , @ IndexSettings Settings indexSettings , File location ) { } public FsTranslog ( ShardId shardId , @ IndexSettings Settings indexSettings , File location , boolean useStream ) { } public File location ( ) { } @ Override public long currentId ( ) { } @ Override public int size ( ) { } @ Override public ByteSizeValue estimateMemorySize ( ) { } @ Override public void clearUnreferenced ( ) { } @ Override public void newTranslog ( ) throws TranslogException { } @ Override public void newTranslog ( long id ) throws TranslogException { } @ Override public void add ( Operation operation ) throws TranslogException { } @ Override public Snapshot snapshot ( ) throws TranslogException { } @ Override public Snapshot snapshot ( Snapshot snapshot ) { synchronized ( mutex ) { if ( ( currentId ( ) ) != ( snapshot . translogId ( ) ) ) { return snapshot ( ) ; } try { raf . increaseRefCount ( ) ; if ( useStream ) { FsStreamSnapshot newSnapshot = new FsStreamSnapshot ( shardId , id , raf , lastPosition , operationCounter . get ( ) , ( ( operationCounter . get ( ) ) - ( snapshot . totalOperations ( ) ) ) ) ; newSnapshot . seekForward ( snapshot . position ( ) ) ; return newSnapshot ; } else { FsChannelSnapshot newSnapshot = new FsChannelSnapshot ( shardId , id , raf , lastPosition , operationCounter . get ( ) , ( ( operationCounter . get ( ) ) - ( snapshot . totalOperations ( ) ) ) ) ; newSnapshot . seekForward ( snapshot . position ( ) ) ; return newSnapshot ; } <START_BUG> } catch ( IOException e ) { <END_BUG> throw new TranslogException ( shardId , "Failed<seq2seq4repair_space>to<seq2seq4repair_space>snapshot" , e ) ; } } } @ Override public void sync ( ) { } @ Override public void syncOnEachOperation ( boolean syncOnEachOperation ) { } @ Override public void close ( boolean delete ) { } }<BUG2FIX>} catch ( Exception e ) {
public class ParticleEffectLoader extends SynchronousAssetLoader < ParticleEffect , ParticleEffectLoader . ParticleEffectParameter > { public ParticleEffectLoader ( FileHandleResolver resolver ) { } @ Override public ParticleEffect load ( AssetManager am , String fileName , FileHandle file , ParticleEffectLoader . ParticleEffectParameter param ) { } @ Override public Array < AssetDescriptor > getDependencies ( String fileName , FileHandle file , ParticleEffectLoader . ParticleEffectParameter param ) { Array < AssetDescriptor > deps = null ; if ( ( param != null ) && ( ( param . atlasFile ) != null ) ) { <START_BUG> deps = new Array < AssetDescriptor > ( ) ; <END_BUG> deps . add ( new AssetDescriptor < TextureAtlas > ( param . atlasFile , TextureAtlas . class ) ) ; } return deps ; } public static class ParticleEffectParameter extends AssetLoaderParameters < ParticleEffect > { public String atlasFile ; public FileHandle imagesDir ; } }<BUG2FIX>deps = new Array ( ) ;
public class IndicesAliasesRequestBuilder extends MasterNodeOperationRequestBuilder < IndicesAliasesRequest , IndicesAliasesResponse , IndicesAliasesRequestBuilder > { public IndicesAliasesRequestBuilder ( IndicesAdminClient indicesClient ) { } public IndicesAliasesRequestBuilder addAlias ( String index , String alias ) { } public IndicesAliasesRequestBuilder addAlias ( String index , String alias , String filter ) { } public IndicesAliasesRequestBuilder addAlias ( String index , String alias , Map < String , Object > filter ) { } public IndicesAliasesRequestBuilder addAlias ( String index , String alias , FilterBuilder filterBuilder ) { } public IndicesAliasesRequestBuilder addAliasAction ( AliasAction aliasAction ) { } public IndicesAliasesRequestBuilder removeAlias ( String index , String alias ) { } public IndicesAliasesRequestBuilder setTimeout ( TimeValue timeout ) { <START_BUG> request . timeout ( timeout ) ; <END_BUG> return this ; } @ Override protected void doExecute ( ActionListener < IndicesAliasesResponse > listener ) { } }<BUG2FIX>request . setTimeout ( timeout ) ;
public class BitmapFont implements Disposable { private static final int LOG2_PAGE_SIZE = 9 ; private static final int PAGE_SIZE = 1 << ( BitmapFont . LOG2_PAGE_SIZE ) ; private static final int PAGES = 65536 / ( BitmapFont . PAGE_SIZE ) ; public static final char [ ] xChars = new char [ ] { 'x' , 'e' , 'a' , 'o' , 'n' , 's' , 'r' , 'c' , 'u' , 'm' , 'v' , 'w' , 'z' } ; public static final char [ ] capChars = new char [ ] { 'M' , 'N' , 'B' , 'D' , 'C' , 'E' , 'F' , 'K' , 'A' , 'G' , 'H' , 'I' , 'J' , 'L' , 'O' , 'P' , 'Q' , 'R' , 'S' , 'T' , 'U' , 'V' , 'W' , 'X' , 'Y' , 'Z' } ; final BitmapFont . BitmapFontData data ; TextureRegion region ; private final BitmapFontCache cache = new BitmapFontCache ( this ) ; private boolean flipped ; private boolean integer ; private boolean ownsTexture ; public BitmapFont ( ) { } public BitmapFont ( boolean flip ) { } public BitmapFont ( FileHandle fontFile , TextureRegion region , boolean flip ) { } public BitmapFont ( FileHandle fontFile , boolean flip ) { } public BitmapFont ( FileHandle fontFile , FileHandle imageFile , boolean flip ) { } public BitmapFont ( FileHandle fontFile , FileHandle imageFile , boolean flip , boolean integer ) { } public BitmapFont ( BitmapFont . BitmapFontData data , TextureRegion region , boolean integer ) { } private void load ( BitmapFont . BitmapFontData data ) { } public BitmapFont . TextBounds draw ( SpriteBatch spriteBatch , CharSequence str , float x , float y ) { } public BitmapFont . TextBounds draw ( SpriteBatch spriteBatch , CharSequence str , float x , float y , int start , int end ) { } public BitmapFont . TextBounds drawMultiLine ( SpriteBatch spriteBatch , CharSequence str , float x , float y ) { } public BitmapFont . TextBounds drawMultiLine ( SpriteBatch spriteBatch , CharSequence str , float x , float y , float alignmentWidth , BitmapFont . HAlignment alignment ) { } public BitmapFont . TextBounds drawWrapped ( SpriteBatch spriteBatch , CharSequence str , float x , float y , float wrapWidth ) { } public BitmapFont . TextBounds drawWrapped ( SpriteBatch spriteBatch , CharSequence str , float x , float y , float wrapWidth , BitmapFont . HAlignment alignment ) { } public BitmapFont . TextBounds getBounds ( CharSequence str ) { } public BitmapFont . TextBounds getBounds ( CharSequence str , BitmapFont . TextBounds textBounds ) { } public BitmapFont . TextBounds getBounds ( CharSequence str , int start , int end ) { } public BitmapFont . TextBounds getBounds ( CharSequence str , int start , int end , BitmapFont . TextBounds textBounds ) { } public BitmapFont . TextBounds getMultiLineBounds ( CharSequence str ) { } public BitmapFont . TextBounds getMultiLineBounds ( CharSequence str , BitmapFont . TextBounds textBounds ) { } public BitmapFont . TextBounds getWrappedBounds ( CharSequence str , float wrapWidth ) { } public BitmapFont . TextBounds getWrappedBounds ( CharSequence str , float wrapWidth , BitmapFont . TextBounds textBounds ) { } public void computeGlyphAdvancesAndPositions ( CharSequence str , FloatArray glyphAdvances , FloatArray glyphPositions ) { } public int computeVisibleGlyphs ( CharSequence str , int start , int end , float availableWidth ) { } public void setColor ( float color ) { } public void setColor ( Color color ) { } public void setColor ( float r , float g , float b , float a ) { } public Color getColor ( ) { } public void setScale ( float scaleX , float scaleY ) { BitmapFont . BitmapFontData data = this . data ; float x = scaleX / ( data . scaleX ) ; float y = scaleY / ( data . scaleY ) ; <START_BUG> data . lineHeight = ( data . lineHeight ) * y ; <END_BUG> data . spaceWidth = ( data . spaceWidth ) * x ; data . xHeight = ( data . xHeight ) * y ; data . capHeight = ( data . capHeight ) * y ; data . ascent = ( data . ascent ) * y ; data . descent = ( data . descent ) * y ; data . down = ( data . down ) * y ; data . scaleX = scaleX ; data . scaleY = scaleY ; } public void setScale ( float scaleXY ) { } public void scale ( float amount ) { } public float getScaleX ( ) { } public float getScaleY ( ) { } public TextureRegion getRegion ( ) { } public float getLineHeight ( ) { } public float getSpaceWidth ( ) { } public float getXHeight ( ) { } public float getCapHeight ( ) { } public float getAscent ( ) { } public float getDescent ( ) { } public boolean isFlipped ( ) { } public void dispose ( ) { } public void setFixedWidthGlyphs ( CharSequence glyphs ) { } public boolean containsCharacter ( char character ) { } public void setUseIntegerPositions ( boolean integer ) { } public boolean usesIntegerPositions ( ) { } public BitmapFont . BitmapFontData getData ( ) { } public static class Glyph { public int srcX ; public int srcY ; public int width ; public int height ; public float u ; public float v ; public float u2 ; public float v2 ; public int xoffset ; public int yoffset ; public int xadvance ; public byte [ ] [ ] kerning ; public int getKerning ( char ch ) { } public void setKerning ( int ch , int value ) { } } static int indexOf ( CharSequence text , char ch , int start ) { }<BUG2FIX>data . lineHeight = ( data . lineHeight ) * x ;
public class MD5Test extends GdxTest implements InputProcessor { PerspectiveCamera camera ; MD5Model model ; MD5Animation anim ; MD5AnimationInfo animInfo ; MD5Joints skeleton ; MD5Renderer renderer ; SpriteBatch batch ; BitmapFont font ; @ Override public void create ( ) { app . log ( "MD5<seq2seq4repair_space>Test" , "created" ) ; <START_BUG> model = MD5Loader . loadModel ( files . internal ( "data/zfat.md5mesh" ) . read ( ) , false ) ; <END_BUG> anim = MD5Loader . loadAnimation ( files . internal ( "data/walk1.md5anim" ) . read ( ) ) ; skeleton = new MD5Joints ( ) ; skeleton . joints = new float [ anim . frames [ 0 ] . joints . length ] ; animInfo = new MD5AnimationInfo ( anim . frames . length , anim . secondsPerFrame ) ; renderer = new MD5Renderer ( model , true , false ) ; renderer . setSkeleton ( model . baseSkeleton ) ; camera = new PerspectiveCamera ( 60 , graphics . getWidth ( ) , graphics . getHeight ( ) ) ; camera . position . set ( 0 , 25 , 100 ) ; camera . near = 1 ; camera . far = 1000 ; batch = new SpriteBatch ( ) ; font = new BitmapFont ( ) ; graphics . getGL10 ( ) . glViewport ( 0 , 0 , graphics . getWidth ( ) , graphics . getHeight ( ) ) ; input . setInputProcessor ( this ) ; } float angle = 0 ; @ Override public void render ( ) { } @ Override public void dispose ( ) { } @ Override public boolean keyDown ( int keycode ) { } @ Override public boolean keyTyped ( char character ) { } @ Override public boolean keyUp ( int keycode ) { } @ Override public boolean touchDown ( int x , int y , int pointer , int newParam ) { } @ Override public boolean touchDragged ( int x , int y , int pointer ) { } @ Override public boolean touchUp ( int x , int y , int pointer , int button ) { } @ Override public boolean needsGL20 ( ) { } @ Override public boolean touchMoved ( int x , int y ) { } @ Override public boolean scrolled ( int amount ) { } }<BUG2FIX>model = MD5Loader . loadModel ( files . internal ( "data/zfat.md5mesh" ) . read ( ) , true ) ;
public class FileTextureData implements TextureData { public static boolean copyToPOT ; final FileHandle file ; int width = 0 ; int height = 0 ; Format format ; Pixmap pixmap ; boolean useMipMaps ; boolean isPrepared = false ; public FileTextureData ( FileHandle file , Pixmap preloadedPixmap , Format format , boolean useMipMaps ) { } @ Override public boolean isPrepared ( ) { } @ Override public void prepare ( ) { } private Pixmap ensurePot ( Pixmap pixmap ) { } @ Override public Pixmap consumePixmap ( ) { } @ Override public boolean disposePixmap ( ) { } @ Override public int getWidth ( ) { } @ Override public int getHeight ( ) { } @ Override public Format getFormat ( ) { } @ Override public boolean useMipMaps ( ) { } @ Override public boolean isManaged ( ) { } public FileHandle getFileHandle ( ) { } @ Override public TextureDataType getType ( ) { } @ Override <START_BUG> public void consumeCompressedData ( int target ) { <END_BUG> throw new GdxRuntimeException ( "This<seq2seq4repair_space>TextureData<seq2seq4repair_space>implementation<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>upload<seq2seq4repair_space>data<seq2seq4repair_space>itself" ) ; } }<BUG2FIX>public void consumeCompressedData ( ) {
public class TextAreaTest extends GdxTest { private Stage stage ; private Skin skin ; @ Override public void create ( ) { } @ Override public void render ( ) { } @ Override public void resize ( int width , int height ) { <START_BUG> stage . getViewport ( ) . update ( width , height ) ; <END_BUG> } @ Override public void dispose ( ) { } }<BUG2FIX>stage . getViewport ( ) . update ( width , height , true ) ;
public abstract class UserNewsFragment extends NewsFragment implements OrganizationSelectionListener { protected User org ; @ Override public void onAttach ( Activity activity ) { } @ Override protected void viewRepository ( Repository repository ) { } @ Override public void onOrganizationSelected ( User organization ) { int previousOrgId = ( ( org ) != null ) ? org . getId ( ) : - 1 ; org = organization ; <START_BUG> if ( ( ( getView ( ) ) != null ) && ( previousOrgId != ( org . getId ( ) ) ) ) <END_BUG> refreshWithProgress ( ) ; } }<BUG2FIX>if ( previousOrgId != ( org . getId ( ) ) )
public class GeoDistanceSortParser implements SortParser { @ Override public String [ ] names ( ) { } @ Override public SortField parse ( XContentParser parser , SearchContext context ) throws Exception { String fieldName = null ; GeoPoint point = new GeoPoint ( ) ; <START_BUG> DistanceUnit unit = DistanceUnit . KILOMETERS ; <END_BUG> GeoDistance geoDistance = GeoDistance . DEFAULT ; boolean reverse = false ; SortMode sortMode = null ; String nestedPath = null ; Filter nestedFilter = null ; boolean normalizeLon = true ; boolean normalizeLat = true ; XContentParser . Token token ; String currentName = parser . currentName ( ) ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentName = parser . currentName ( ) ; } else if ( token == ( Token . START_ARRAY ) ) { GeoPoint . parse ( parser , point ) ; fieldName = currentName ; } else if ( token == ( Token . START_OBJECT ) ) { if ( ( "nested_filter" . equals ( currentName ) ) || ( "nestedFilter" . equals ( currentName ) ) ) { ParsedFilter parsedFilter = context . queryParserService ( ) . parseInnerFilter ( parser ) ; nestedFilter = ( parsedFilter == null ) ? null : parsedFilter . filter ( ) ; } else { fieldName = currentName ; GeoPoint . parse ( parser , point ) ; } } else if ( token . isValue ( ) ) { if ( "reverse" . equals ( currentName ) ) { reverse = parser . booleanValue ( ) ; } else if ( "order" . equals ( currentName ) ) { reverse = "desc" . equals ( parser . text ( ) ) ; } else if ( currentName . equals ( "unit" ) ) { unit = DistanceUnit . fromString ( parser . text ( ) ) ; } else if ( ( currentName . equals ( "distance_type" ) ) || ( currentName . equals ( "distanceType" ) ) ) { geoDistance = GeoDistance . fromString ( parser . text ( ) ) ; } else if ( "normalize" . equals ( currentName ) ) { normalizeLat = parser . booleanValue ( ) ; normalizeLon = parser . booleanValue ( ) ; } else if ( ( ( "sort_mode" . equals ( currentName ) ) || ( "sortMode" . equals ( currentName ) ) ) || ( "mode" . equals ( currentName ) ) ) { sortMode = SortMode . fromString ( parser . text ( ) ) ; } else if ( ( "nested_path" . equals ( currentName ) ) || ( "nestedPath" . equals ( currentName ) ) ) { nestedPath = parser . text ( ) ; } else { point . resetFromString ( parser . text ( ) ) ; fieldName = currentName ; } } } if ( normalizeLat || normalizeLon ) { GeoUtils . normalizePoint ( point , normalizeLat , normalizeLon ) ; } if ( sortMode == null ) { sortMode = ( reverse ) ? SortMode . MAX : SortMode . MIN ; } if ( sortMode == ( SortMode . SUM ) ) { throw new ElasticsearchIllegalArgumentException ( "sort_mode<seq2seq4repair_space>[sum]<seq2seq4repair_space>isn't<seq2seq4repair_space>supported<seq2seq4repair_space>for<seq2seq4repair_space>sorting<seq2seq4repair_space>by<seq2seq4repair_space>geo<seq2seq4repair_space>distance" ) ; } FieldMapper mapper = context . smartNameFieldMapper ( fieldName ) ; if ( mapper == null ) { throw new ElasticsearchIllegalArgumentException ( ( ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>find<seq2seq4repair_space>mapper<seq2seq4repair_space>for<seq2seq4repair_space>[" + fieldName ) + "]<seq2seq4repair_space>for<seq2seq4repair_space>geo<seq2seq4repair_space>distance<seq2seq4repair_space>based<seq2seq4repair_space>sort" ) ) ; } IndexGeoPointFieldData indexFieldData = context . fieldData ( ) . getForField ( mapper ) ; IndexFieldData . XFieldComparatorSource geoDistanceComparatorSource = new org . elasticsearch . index . fielddata . fieldcomparator . GeoDistanceComparatorSource ( indexFieldData , point . lat ( ) , point . lon ( ) , unit , geoDistance , sortMode ) ; ObjectMapper objectMapper ; if ( nestedPath != null ) { ObjectMappers objectMappers = context . mapperService ( ) . objectMapper ( nestedPath ) ; if ( objectMappers == null ) { throw new ElasticsearchIllegalArgumentException ( ( ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>find<seq2seq4repair_space>nested<seq2seq4repair_space>object<seq2seq4repair_space>mapping<seq2seq4repair_space>for<seq2seq4repair_space>explicit<seq2seq4repair_space>nested<seq2seq4repair_space>path<seq2seq4repair_space>[" + nestedPath ) + "]" ) ) ; } objectMapper = objectMappers . mapper ( ) ; if ( ! ( objectMapper . nested ( ) . isNested ( ) ) ) { throw new ElasticsearchIllegalArgumentException ( ( ( "mapping<seq2seq4repair_space>for<seq2seq4repair_space>explicit<seq2seq4repair_space>nested<seq2seq4repair_space>path<seq2seq4repair_space>is<seq2seq4repair_space>not<seq2seq4repair_space>mapped<seq2seq4repair_space>as<seq2seq4repair_space>nested:<seq2seq4repair_space>[" + nestedPath ) + "]" ) ) ; } } else { objectMapper = context . mapperService ( ) . resolveClosestNestedObjectMapper ( fieldName ) ; } if ( ( objectMapper != null ) && ( objectMapper . nested ( ) . isNested ( ) ) ) { Filter rootDocumentsFilter = context . filterCache ( ) . cache ( INSTANCE ) ; Filter innerDocumentsFilter ; if ( nestedFilter != null ) { innerDocumentsFilter = context . filterCache ( ) . cache ( nestedFilter ) ; } else { innerDocumentsFilter = context . filterCache ( ) . cache ( objectMapper . nestedTypeFilter ( ) ) ; } geoDistanceComparatorSource = new org . elasticsearch . index . search . nested . NestedFieldComparatorSource ( sortMode , geoDistanceComparatorSource , rootDocumentsFilter , innerDocumentsFilter ) ; } return new SortField ( fieldName , geoDistanceComparatorSource , reverse ) ; } }<BUG2FIX>DistanceUnit unit = DistanceUnit . DEFAULT ;
public interface ToXContent { public static interface Params { String param ( String key ) { } String param ( String key , String defaultValue ) { } boolean paramAsBoolean ( String key , boolean defaultValue ) { } Boolean paramAsBoolean ( String key , Boolean defaultValue ) { } } public static final ToXContent . Params EMPTY_PARAMS = new ToXContent . Params ( ) { @ Override public String param ( String key ) { } @ Override public String param ( String key , String defaultValue ) { } @ Override public boolean paramAsBoolean ( String key , boolean defaultValue ) { } @ Override public Boolean paramAsBoolean ( String key , Boolean defaultValue ) { } } ; public static class MapParams implements ToXContent . Params { private final Map < String , String > params ; public MapParams ( Map < String , String > params ) { } @ Override public String param ( String key ) { } @ Override public String param ( String key , String defaultValue ) { } @ Override public boolean paramAsBoolean ( String key , boolean defaultValue ) { } @ Override public Boolean paramAsBoolean ( String key , Boolean defaultValue ) { } } <START_BUG> void toXContent ( XContentBuilder builder , ToXContent . Params params ) throws IOException ; <END_BUG> }<BUG2FIX>XContentBuilder toXContent ( XContentBuilder builder , ToXContent . Params params ) throws IOException ;
public class CountRequest extends BroadcastOperationRequest { private static final XContentType contentType = Requests . CONTENT_TYPE ; public static final float DEFAULT_MIN_SCORE = - 1.0F ; private float minScore = CountRequest . DEFAULT_MIN_SCORE ; @ Nullable protected String queryHint ; @ Nullable protected String routing ; private BytesReference querySource ; private boolean querySourceUnsafe ; private String [ ] types = Strings . EMPTY_ARRAY ; CountRequest ( ) { } public CountRequest ( String ... indices ) { } @ Override public ActionRequestValidationException validate ( ) { } public String queryHint ( ) { } @ Override public CountRequest operationThreading ( BroadcastOperationThreading operationThreading ) { } @ Override protected void beforeStart ( ) { } @ Override public CountRequest listenerThreaded ( boolean threadedListener ) { } public CountRequest indices ( String ... indices ) { } public CountRequest queryHint ( String queryHint ) { } float minScore ( ) { } public CountRequest minScore ( float minScore ) { } BytesReference querySource ( ) { } @ Required public CountRequest query ( QueryBuilder queryBuilder ) { } @ Required public CountRequest query ( Map querySource ) { } @ Required public CountRequest query ( XContentBuilder builder ) { } @ Required public CountRequest query ( String querySource ) { } @ Required public CountRequest query ( byte [ ] querySource ) { } @ Required public CountRequest query ( byte [ ] querySource , int offset , int length , boolean unsafe ) { } @ Required public CountRequest query ( BytesReference querySource , boolean unsafe ) { } String [ ] types ( ) { } public CountRequest types ( String ... types ) { } public String routing ( ) { } public CountRequest routing ( String routing ) { } public CountRequest routing ( String ... routings ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { super . writeTo ( out ) ; out . writeFloat ( minScore ) ; if ( ( queryHint ) == null ) { out . writeBoolean ( false ) ; } else { out . writeBoolean ( true ) ; out . writeUTF ( queryHint ) ; } if ( ( routing ) == null ) { out . writeBoolean ( false ) ; } else { out . writeBoolean ( true ) ; out . writeUTF ( routing ) ; } <START_BUG> out . writeBytesReference ( querySource , true ) ; <END_BUG> out . writeVInt ( types . length ) ; for ( String type : types ) { out . writeUTF ( type ) ; } } @ Override public String toString ( ) { } }<BUG2FIX>out . writeBytesReference ( querySource ) ;
public class RefUtils { private static final String PREFIX_REFS = "refs/" ; private static final String PREFIX_TAG = "refs/tags/" ; private static final String PREFIX_HEADS = "refs/heads/" ; public static boolean isBranch ( final Reference ref ) { } public static boolean isTag ( final Reference ref ) { } public static String getPath ( final Reference ref ) { if ( ref == null ) return null ; String name = ref . getRef ( ) ; if ( ( ! ( TextUtils . isEmpty ( name ) ) ) && ( name . startsWith ( RefUtils . PREFIX_REFS ) ) ) return name . substring ( RefUtils . PREFIX_REFS . length ( ) ) ; else <START_BUG> return null ; <END_BUG> } public static String getName ( final Reference ref ) { } public static boolean isValid ( final Reference ref ) { } }<BUG2FIX>return name ;
public abstract class InternalSingleBucketAggregation extends InternalAggregation implements SingleBucketAggregation { private long docCount ; private InternalAggregations aggregations ; protected InternalSingleBucketAggregation ( ) { } protected InternalSingleBucketAggregation ( String name , long docCount , InternalAggregations aggregations ) { } @ Override public long getDocCount ( ) { } @ Override public InternalAggregations getAggregations ( ) { } protected abstract InternalSingleBucketAggregation newAggregation ( String name , long docCount , InternalAggregations subAggregations ) { } @ Override public InternalAggregation reduce ( ReduceContext reduceContext ) { List < InternalAggregation > aggregations = reduceContext . aggregations ( ) ; long docCount = 0L ; List < InternalAggregations > subAggregationsList = new java . util . ArrayList ( aggregations . size ( ) ) ; for ( InternalAggregation aggregation : aggregations ) { assert aggregation . getName ( ) . equals ( getName ( ) ) ; docCount += ( ( InternalSingleBucketAggregation ) ( aggregation ) ) . docCount ; subAggregationsList . add ( ( ( InternalSingleBucketAggregation ) ( aggregation ) ) . aggregations ) ; } <START_BUG> final InternalAggregations aggs = InternalAggregations . reduce ( subAggregationsList , reduceContext . bigArrays ( ) ) ; <END_BUG> return newAggregation ( getName ( ) , docCount , aggs ) ; } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } @ Override public XContentBuilder doXContentBody ( XContentBuilder builder , Params params ) throws IOException { } }<BUG2FIX>final InternalAggregations aggs = InternalAggregations . reduce ( subAggregationsList , reduceContext ) ;
lowest = t ; } } } if ( ( ( ray . origin . x ) >= ( box . max . x ) ) && ( ( ray . direction . x ) < 0 ) ) { t = ( ( box . max . x ) - ( ray . origin . x ) ) / ( ray . direction . x ) ; if ( t >= 0 ) { Vector3 . tmp3 . set ( ray . direction ) . scl ( t ) . add ( ray . origin ) ; if ( ( ( ( ( ( Vector3 . tmp3 . y ) >= ( box . min . y ) ) && ( ( Vector3 . tmp3 . y ) <= ( box . max . y ) ) ) && ( ( Vector3 . tmp3 . z ) >= ( box . min . z ) ) ) && ( ( Vector3 . tmp3 . z ) <= ( box . max . z ) ) ) && ( ( ! hit ) || ( t < lowest ) ) ) { hit = true ; lowest = t ; } } } if ( ( ( ray . origin . y ) <= ( box . min . y ) ) && ( ( ray . direction . y ) > 0 ) ) { t = ( ( box . min . y ) - ( ray . origin . y ) ) / ( ray . direction . y ) ; if ( t >= 0 ) { Vector3 . tmp3 . set ( ray . direction ) . scl ( t ) . add ( ray . origin ) ; if ( ( ( ( ( ( Vector3 . tmp3 . x ) >= ( box . min . x ) ) && ( ( Vector3 . tmp3 . x ) <= ( box . max . x ) ) ) && ( ( Vector3 . tmp3 . z ) >= ( box . min . z ) ) ) && ( ( Vector3 . tmp3 . z ) <= ( box . max . z ) ) ) && ( ( ! hit ) || ( t < lowest ) ) ) { hit = true ; lowest = t ; } } } if ( ( ( ray . origin . y ) >= ( box . max . y ) ) && ( ( ray . direction . y ) < 0 ) ) { t = ( ( box . max . y ) - ( ray . origin . y ) ) / ( ray . direction . y ) ; if ( t >= 0 ) { Vector3 . tmp3 . set ( ray . direction ) . scl ( t ) . add ( ray . origin ) ; if ( ( ( ( ( ( Vector3 . tmp3 . x ) >= ( box . min . x ) ) && ( ( Vector3 . tmp3 . x ) <= ( box . max . x ) ) ) && ( ( Vector3 . tmp3 . z ) >= ( box . min . z ) ) ) && ( ( Vector3 . tmp3 . z ) <= ( box . max . z ) ) ) && ( ( ! hit ) || ( t < lowest ) ) ) { hit = true ; lowest = t ; } } } <START_BUG> if ( ( ( ray . origin . z ) <= ( box . min . z ) ) && ( ( ray . direction . z ) > 0 ) ) { <END_BUG> t = ( ( box . min . z ) - ( ray . origin . z ) ) / ( ray . direction . z ) ; if ( t >= 0 ) { Vector3 . tmp3 . set ( ray . direction ) . scl ( t ) . add ( ray . origin ) ; if ( ( ( ( ( ( Vector3 . tmp3 . x ) >= ( box . min . x ) ) && ( ( Vector3 . tmp3 . x ) <= ( box . max . x ) ) ) && ( ( Vector3 . tmp3 . y ) >= ( box . min . y ) ) ) && ( ( Vector3 . tmp3 . y ) <= ( box . max . y ) ) ) && ( ( ! hit ) || ( t < lowest ) ) ) { hit = true ; lowest = t ; } } } if ( ( ( ray . origin . z ) >= ( box . max . z ) ) && ( ( ray . direction . z ) < 0 ) ) { t = ( ( box . max . z ) - ( ray . origin . z ) ) / ( ray . direction . z ) ; if ( t >= 0 ) { Vector3 . tmp3 . set ( ray . direction ) . scl ( t ) . add ( ray . origin ) ; if ( ( ( ( ( ( Vector3 . tmp3 . x ) >= ( box . min . x ) ) && ( ( Vector3 . tmp3 . x ) <= ( box . max . x ) ) ) && ( ( Vector3 . tmp3 . y ) >= ( box . min . y ) ) ) && ( ( Vector3 . tmp3 . y ) <= ( box . max . y ) ) ) && ( ( ! hit ) || ( t < lowest ) ) ) { hit = true ; lowest = t ; } }<BUG2FIX>if ( ( ( ray . origin . z ) <= ( box . min . y ) ) && ( ( ray . direction . z ) > 0 ) ) {
@ Test public class BytesStreamsTests { @ Test public void testSimpleStreams ( ) throws Exception { BytesStreamOutput out = CachedStreamOutput . popEntry ( ) . cachedBytes ( ) ; out . writeBoolean ( false ) ; out . writeByte ( ( ( byte ) ( 1 ) ) ) ; out . writeShort ( ( ( short ) ( - 1 ) ) ) ; out . writeInt ( ( - 1 ) ) ; out . writeVInt ( 2 ) ; out . writeLong ( ( - 3 ) ) ; out . writeVLong ( 4 ) ; out . writeFloat ( 1.1F ) ; out . writeDouble ( 2.2 ) ; out . writeUTF ( "hello" ) ; out . writeUTF ( "goodbye" ) ; <START_BUG> BytesStreamInput in = new BytesStreamInput ( out . copiedByteArray ( ) ) ; <END_BUG> assertThat ( in . readBoolean ( ) , equalTo ( false ) ) ; assertThat ( in . readByte ( ) , equalTo ( ( ( byte ) ( 1 ) ) ) ) ; assertThat ( in . readShort ( ) , equalTo ( ( ( short ) ( - 1 ) ) ) ) ; assertThat ( in . readInt ( ) , equalTo ( ( - 1 ) ) ) ; assertThat ( in . readVInt ( ) , equalTo ( 2 ) ) ; assertThat ( in . readLong ( ) , equalTo ( ( ( long ) ( - 3 ) ) ) ) ; assertThat ( in . readVLong ( ) , equalTo ( ( ( long ) ( 4 ) ) ) ) ; assertThat ( ( ( double ) ( in . readFloat ( ) ) ) , closeTo ( 1.1 , 1.0E-4 ) ) ; assertThat ( in . readDouble ( ) , closeTo ( 2.2 , 1.0E-4 ) ) ; assertThat ( in . readUTF ( ) , equalTo ( "hello" ) ) ; assertThat ( in . readUTF ( ) , equalTo ( "goodbye" ) ) ; } }<BUG2FIX>BytesStreamInput in = new BytesStreamInput ( out . copiedByteArray ( ) , false ) ;
public class BooleanArray { public boolean [ ] items ; public int size ; public boolean ordered ; public BooleanArray ( ) { } public BooleanArray ( int capacity ) { } public BooleanArray ( boolean ordered , int capacity ) { } public BooleanArray ( BooleanArray array ) { } public BooleanArray ( boolean [ ] array ) { } public BooleanArray ( boolean ordered , boolean [ ] array , int startIndex , int count ) { } public void add ( boolean value ) { } public void addAll ( BooleanArray array ) { } public void addAll ( BooleanArray array , int offset , int length ) { } public void addAll ( boolean [ ] array ) { } public void addAll ( boolean [ ] array , int offset , int length ) { boolean [ ] items = this . items ; <START_BUG> int sizeNeeded = ( ( size ) + length ) - offset ; <END_BUG> if ( sizeNeeded >= ( items . length ) ) items = resize ( Math . max ( 8 , ( ( int ) ( sizeNeeded * 1.75F ) ) ) ) ; System . arraycopy ( array , offset , items , size , length ) ; size += length ; } public boolean get ( int index ) { } public void set ( int index , boolean value ) { } public void insert ( int index , boolean value ) { } public void swap ( int first , int second ) { } public boolean removeIndex ( int index ) { } public boolean removeAll ( BooleanArray array ) { } public boolean pop ( ) { } public boolean peek ( ) { } public boolean first ( ) { } public void clear ( ) { } public void shrink ( ) { } public boolean [ ] ensureCapacity ( int additionalCapacity ) { } protected boolean [ ] resize ( int newSize ) { } public void reverse ( ) { } public void shuffle ( ) { } public void truncate ( int newSize ) { } public boolean random ( ) { } public boolean [ ] toArray ( ) { } public boolean equals ( Object object ) { } public String toString ( ) { } public String toString ( String separator ) { } }<BUG2FIX>int sizeNeeded = ( size ) + length ;
public class Label extends Widget { private static final Color tempColor = new Color ( ) ; private Label . LabelStyle style ; private final TextBounds bounds = new TextBounds ( ) ; private final StringBuilder text = new StringBuilder ( ) ; private StringBuilder tempText ; private BitmapFontCache cache ; private int labelAlign = Align . left ; private HAlignment lineAlign = HAlignment . LEFT ; private boolean wrap ; private float lastPrefHeight ; private boolean sizeInvalid = true ; private float fontScaleX = 1 ; private float fontScaleY = 1 ; private boolean ellipse ; public Label ( CharSequence text , Skin skin ) { } public Label ( CharSequence text , Skin skin , String styleName ) { } public Label ( CharSequence text , Skin skin , String fontName , Color color ) { } public Label ( CharSequence text , Skin skin , String fontName , String colorName ) { } public Label ( CharSequence text , Label . LabelStyle style ) { } public void setStyle ( Label . LabelStyle style ) { } public Label . LabelStyle getStyle ( ) { } public void setText ( CharSequence newText ) { } public boolean textEquals ( CharSequence other ) { } <START_BUG> public StringBuilder getText ( ) { <END_BUG> return text ; } public void invalidate ( ) { } private void scaleAndComputeSize ( ) { } private void computeSize ( ) { } public void layout ( ) { } public void draw ( Batch batch , float parentAlpha ) { } public float getPrefWidth ( ) { } public float getPrefHeight ( ) { } public TextBounds getTextBounds ( ) { } public void setWrap ( boolean wrap ) { } public void setAlignment ( int alignment ) { } public void setAlignment ( int labelAlign , int lineAlign ) { } public void setFontScale ( float fontScale ) { } public void setFontScale ( float fontScaleX , float fontScaleY ) { } public float getFontScaleX ( ) { } public void setFontScaleX ( float fontScaleX ) { } public float getFontScaleY ( ) { } public void setFontScaleY ( float fontScaleY ) { } public void setEllipse ( boolean ellipse ) { } protected BitmapFontCache getBitmapFontCache ( ) { } public static class LabelStyle { public BitmapFont font ; public Color fontColor ; public Drawable background ; public LabelStyle ( ) { } public LabelStyle ( BitmapFont font , Color fontColor ) { } public LabelStyle ( Label . LabelStyle style ) { } } }<BUG2FIX>public CharSequence getText ( ) {
@ Override public short lastIndex ( ) { } @ Override public short vertex ( final float ... values ) { } @ Override public short vertex ( final VertexInfo info ) { } @ Override public void index ( final short value ) { } @ Override public void index ( final short value1 , final short value2 ) { } @ Override public void index ( final short value1 , final short value2 , final short value3 ) { } @ Override public void index ( final short value1 , final short value2 , final short value3 , final short value4 ) { } @ Override public void index ( short value1 , short value2 , short value3 , short value4 , short value5 , short value6 ) { } @ Override public void index ( short value1 , short value2 , short value3 , short value4 , short value5 , short value6 , short value7 , short value8 ) { } @ Override public void line ( short index1 , short index2 ) { } @ Override public void line ( VertexInfo p1 , VertexInfo p2 ) { } @ Override public void line ( Vector3 p1 , Vector3 p2 ) { } @ Override public void line ( float x1 , float y1 , float z1 , float x2 , float y2 , float z2 ) { } @ Override public void line ( Vector3 p1 , Color c1 , Vector3 p2 , Color c2 ) { } @ Override public void triangle ( short index1 , short index2 , short index3 ) { } @ Override public void triangle ( VertexInfo p1 , VertexInfo p2 , VertexInfo p3 ) { } @ Override public void triangle ( Vector3 p1 , Vector3 p2 , Vector3 p3 ) { } @ Override public void triangle ( Vector3 p1 , Color c1 , Vector3 p2 , Color c2 , Vector3 p3 , Color c3 ) { } @ Override public void rect ( short corner00 , short corner10 , short corner11 , short corner01 ) { } @ Override public void rect ( VertexInfo corner00 , VertexInfo corner10 , VertexInfo corner11 , VertexInfo corner01 ) { } @ Override public void rect ( Vector3 corner00 , Vector3 corner10 , Vector3 corner11 , Vector3 corner01 , Vector3 normal ) { } @ Override public void rect ( float x00 , float y00 , float z00 , float x10 , float y10 , float z10 , float x11 , float y11 , float z11 , float x01 , float y01 , float z01 , float normalX , float normalY , float normalZ ) { } @ Override public void patch ( VertexInfo corner00 , VertexInfo corner10 , VertexInfo corner11 , VertexInfo corner01 , int divisionsU , int divisionsV ) { } @ Override public void patch ( Vector3 corner00 , Vector3 corner10 , Vector3 corner11 , Vector3 corner01 , Vector3 normal , int divisionsU , int divisionsV ) { } public void patch ( float x00 , float y00 , float z00 , float x10 , float y10 , float z10 , float x11 , float y11 , float z11 , float x01 , float y01 , float z01 , float normalX , float normalY , float normalZ , int divisionsU , int divisionsV ) { } @ Override public void box ( VertexInfo corner000 , VertexInfo corner010 , VertexInfo corner100 , VertexInfo corner110 , VertexInfo corner001 , VertexInfo corner011 , VertexInfo corner101 , VertexInfo corner111 ) { ensureVertices ( 8 ) ; final short i000 = vertex ( corner000 ) ; final short i100 = vertex ( corner100 ) ; final short i110 = vertex ( corner110 ) ; final short i010 = vertex ( corner010 ) ; final short i001 = vertex ( corner001 ) ; final short i101 = vertex ( corner101 ) ; final short i111 = vertex ( corner111 ) ; final short i011 = vertex ( corner011 ) ; if ( ( primitiveType ) == ( GL10 . GL_LINES ) ) { ensureIndices ( 24 ) ; rect ( i000 , i100 , i110 , i010 ) ; rect ( i101 , i001 , i011 , i111 ) ; index ( i000 , i001 , i010 , i011 , i110 , i111 , i100 , i101 ) ; } else <START_BUG> if ( ( primitiveType ) == ( GL10 . GL_POINTS ) ) { <END_BUG> ensureRectangleIndices ( 2 ) ; rect ( i000 , i100 , i110 , i010 ) ; rect ( i101 , i001 , i011 , i111 ) ; } else { ensureRectangleIndices ( 6 ) ; rect ( i000 , i100 , i110 , i010 ) ; rect ( i101 , i001 , i011 , i111 ) ; rect ( i000 , i010 , i011 , i001 ) ; rect ( i101 , i111 , i110 , i100 ) ; rect ( i101 , i100 , i000 , i001 ) ; rect ( i110 , i111 , i011 , i010 ) ; } } @ Override public void box ( Vector3 corner000 , Vector3 corner010 , Vector3 corner100 , Vector3 corner110 , Vector3 corner001 , Vector3 corner011 , Vector3 corner101 , Vector3 corner111 ) { } @ Override public void box ( Matrix4 transform ) { } @ Override public void box ( float width , float height , float depth ) { } @ Override public void box ( float x , float y , float z , float width , float height , float depth ) { } @ Override public void circle ( float radius , int divisions , float centerX , float centerY , float centerZ , float normalX , float normalY , float normalZ ) { } @ Override public void circle ( float radius , int divisions , final Vector3 center , final Vector3 normal ) { }<BUG2FIX>if ( ( primitiveType ) != ( GL10 . GL_POINTS ) ) {
public class GeoDistanceParser implements Aggregator . Parser { private static final ParseField ORIGIN_FIELD = new ParseField ( "origin" , "center" , "point" , "por" ) ; @ Override public String type ( ) { } private static String key ( String key , double from , double to ) { } @ Override public AggregatorFactory parse ( String aggregationName , XContentParser parser , SearchContext context ) throws IOException { } private static class GeoDistanceFactory extends ValuesSourceAggregatorFactory < ValuesSource . GeoPoint > { private final GeoPoint origin ; private final DistanceUnit unit ; private final GeoDistance distanceType ; private final Factory rangeFactory ; private final List < RangeAggregator . Range > ranges ; private final boolean keyed ; public GeoDistanceFactory ( String name , ValuesSourceConfig < ValuesSource . GeoPoint > valueSourceConfig , InternalRange . Factory rangeFactory , GeoPoint origin , DistanceUnit unit , GeoDistance distanceType , List < RangeAggregator . Range > ranges , boolean keyed ) { } @ Override protected Aggregator createUnmapped ( AggregationContext aggregationContext , Aggregator parent ) { } @ Override protected Aggregator create ( final ValuesSource . GeoPoint valuesSource , long expectedBucketsCount , AggregationContext aggregationContext , Aggregator parent ) { } private static class DistanceSource extends ValuesSource . Numeric implements ReaderContextAware { private final GeoPoint source ; private final GeoDistance distanceType ; private final DistanceUnit unit ; private final GeoPoint origin ; private final MetaData metaData ; private SortedNumericDoubleValues distanceValues ; public DistanceSource ( ValuesSource . GeoPoint source , GeoDistance distanceType , GeoPoint origin , DistanceUnit unit ) { } @ Override public void setNextReader ( AtomicReaderContext reader ) { final MultiGeoPointValues geoValues = source . geoPointValues ( ) ; final FixedSourceDistance distance = distanceType . fixedSourceDistance ( origin . getLat ( ) , origin . getLon ( ) , unit ) ; <START_BUG> distanceValues = GeoDistance . distanceValues ( distance , geoValues ) ; <END_BUG> } @ Override public MetaData metaData ( ) { } @ Override public boolean isFloatingPoint ( ) { } @ Override public SortedNumericDocValues longValues ( ) { } @ Override public SortedNumericDoubleValues doubleValues ( ) { } @ Override public SortedBinaryDocValues bytesValues ( ) { } } } }<BUG2FIX>distanceValues = GeoDistance . distanceValues ( geoValues , distance ) ;
public class EditIssueActivityTest extends ActivityTest < EditIssueActivity > { public EditIssueActivityTest ( ) { } @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; Repository repo = new Repository ( ) ; repo . setName ( "repo" ) ; repo . setOwner ( new User ( ) . setLogin ( "owner" ) ) ; <START_BUG> setActivityIntent ( EditIssueActivity . createIntent ( repo , "an<seq2seq4repair_space>issue" ) ) ; <END_BUG> } public void testSaveMenuEnabled ( ) throws Throwable { } }<BUG2FIX>setActivityIntent ( EditIssueActivity . createIntent ( repo ) ) ;
private volatile SearcherManager searcherManager ; private volatile boolean closed = false ; private volatile boolean dirty = false ; private volatile boolean possibleMergeNeeded = false ; private final AtomicBoolean optimizeMutex = new AtomicBoolean ( ) ; private volatile boolean flushNeeded = false ; private final AtomicInteger flushing = new AtomicInteger ( ) ; private final Lock flushLock = new ReentrantLock ( ) ; private final InternalEngine . RecoveryCounter onGoingRecoveries = new InternalEngine . RecoveryCounter ( ) ; private final ConcurrentMap < HashedBytesRef , InternalEngine . VersionValue > versionMap ; private final Object [ ] dirtyLocks ; private final Object refreshMutex = new Object ( ) ; private final InternalEngine . ApplySettings applySettings = new InternalEngine . ApplySettings ( ) ; private volatile boolean failOnMergeFailure ; private Throwable failedEngine = null ; private final Object failedEngineMutex = new Object ( ) ; private final CopyOnWriteArrayList < FailedEngineListener > failedEngineListeners = new CopyOnWriteArrayList < FailedEngineListener > ( ) ; private final AtomicLong translogIdGenerator = new AtomicLong ( ) ; private SegmentInfos lastCommittedSegmentInfos ; @ Inject public InternalEngine ( ShardId shardId , @ IndexSettings Settings indexSettings , ThreadPool threadPool , IndexSettingsService indexSettingsService , ShardIndexingService indexingService , @ Nullable IndicesWarmer warmer , Store store , SnapshotDeletionPolicy deletionPolicy , Translog translog , MergePolicyProvider mergePolicyProvider , MergeSchedulerProvider mergeScheduler , AnalysisService analysisService , SimilarityService similarityService , CodecService codecService ) throws EngineException { } @ Override public void updateIndexingBufferSize ( ByteSizeValue indexingBufferSize ) { } @ Override public void addFailedEngineListener ( FailedEngineListener listener ) { } @ Override public void start ( ) throws EngineException { } private void readLastCommittedSegmentsInfo ( ) throws IOException { } @ Override public TimeValue defaultRefreshInterval ( ) { } @ Override public void enableGcDeletes ( boolean enableGcDeletes ) { } public GetResult get ( Get get ) throws EngineException { } @ Override public void create ( Create create ) throws EngineException { } private void innerCreate ( Create create , IndexWriter writer ) throws IOException { } @ Override public void index ( Index index ) throws EngineException { } private void innerIndex ( Index index , IndexWriter writer ) throws IOException { } @ Override public void delete ( Delete delete ) throws EngineException { } private void innerDelete ( Delete delete , IndexWriter writer ) throws IOException { } @ Override public void delete ( DeleteByQuery delete ) throws EngineException { } @ Override public final Searcher acquireSearcher ( String source ) throws EngineException { } protected Searcher newSearcher ( String source , IndexSearcher searcher , SearcherManager manager ) { } @ Override public boolean refreshNeeded ( ) { } @ Override public boolean possibleMergeNeeded ( ) { } @ Override public void refresh ( Refresh refresh ) throws EngineException { } @ Override public void flush ( Flush flush ) throws EngineException { } private void ensureOpen ( ) { } private void refreshVersioningTable ( long time ) { } @ Override public void maybeMerge ( ) throws EngineException { } @ Override public void optimize ( Optimize optimize ) throws EngineException { } @ Override public < T > T snapshot ( SnapshotHandler < T > snapshotHandler ) throws EngineException { } @ Override public SnapshotIndexCommit snapshotIndex ( ) throws EngineException { } @ Override public void recover ( RecoveryHandler recoveryHandler ) throws EngineException { } private static long getReaderRamBytesUsed ( AtomicReaderContext reader ) { } @ Override public SegmentsStats segmentsStats ( ) { } @ Override public List < Segment > segments ( ) { } @ Override public void close ( ) throws ElasticsearchException { } class FailEngineOnMergeFailure implements MergeSchedulerProvider . FailureListener { @ Override public void onFailedMerge ( MergePolicy . MergeException e ) { } } private void failEngine ( Throwable failure ) { } private void innerClose ( ) { if ( closed ) { return ; } indexSettingsService . removeListener ( applySettings ) ; closed = true ; this . versionMap . clear ( ) ; this . failedEngineListeners . clear ( ) ; try { try { IOUtils . close ( searcherManager ) ; } catch ( Throwable t ) { logger . warn ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>close<seq2seq4repair_space>SearcherManager" , t ) ; } if ( ( indexWriter ) != null ) { try { indexWriter . rollback ( ) ; } catch ( AlreadyClosedException e ) { } } } catch ( Throwable e ) { <START_BUG> logger . debug ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>rollback<seq2seq4repair_space>writer<seq2seq4repair_space>on<seq2seq4repair_space>close" , e ) ; <END_BUG> } finally { indexWriter = null ; } } private HashedBytesRef versionKey ( Term uid ) { } private Object dirtyLock ( BytesRef uid ) { } private Object dirtyLock ( Term uid ) { } private long loadCurrentVersionFromIndex ( Term uid ) throws IOException { } private static boolean isMergedSegment ( AtomicReader reader ) { } private IndexWriter createWriter ( ) throws IOException { } public static final String INDEX_INDEX_CONCURRENCY = "index.index_concurrency" ; public static final String INDEX_COMPOUND_ON_FLUSH = "index.compound_on_flush" ; public static final String INDEX_GC_DELETES = "index.gc_deletes" ; public static final String INDEX_FAIL_ON_MERGE_FAILURE = "index.fail_on_merge_failure" ; class ApplySettings implements IndexSettingsService . Listener { @ Override public void onRefreshSettings ( Settings settings ) { } } private SearcherManager buildSearchManager ( IndexWriter indexWriter ) throws IOException { } class EngineSearcher implements Searcher { private final String source ; private final IndexSearcher searcher ; private final SearcherManager manager ; private final AtomicBoolean released ; private EngineSearcher ( String source , IndexSearcher searcher , SearcherManager manager ) { } @ Override public String source ( ) { } @ Override public IndexReader reader ( ) { } @ Override public IndexSearcher searcher ( ) { } @ Override public boolean release ( ) throws ElasticsearchException { } } static class VersionValue { private final long version ; private final boolean delete ; private final long time ; private final Location translogLocation ; VersionValue ( long version , boolean delete , long time , Translog . Location translogLocation ) { } public long time ( ) { } public long version ( ) { }<BUG2FIX>logger . warn ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>rollback<seq2seq4repair_space>writer<seq2seq4repair_space>on<seq2seq4repair_space>close" , e ) ;
public class InternalTickTest extends BaseBulletTest { static class TestInternalTickCallback extends InternalTickCallback { public TestInternalTickCallback ( btDynamicsWorld dynamicsWorld ) { } @ Override public void onInternalTick ( btDynamicsWorld dynamicsWorld , float timeStep ) { } } final int BOXCOUNT_X = 5 ; final int BOXCOUNT_Y = 5 ; final int BOXCOUNT_Z = 1 ; final float BOXOFFSET_X = - 2.5F ; final float BOXOFFSET_Y = 0.5F ; final float BOXOFFSET_Z = 0.0F ; InternalTickTest . TestInternalTickCallback internalTickCallback ; @ Override public void create ( ) { } @ Override public void dispose ( ) { super . dispose ( ) ; if ( ( internalTickCallback ) != null ) <START_BUG> internalTickCallback . delete ( ) ; <END_BUG> internalTickCallback = null ; } float toggleTime = 0.0F ; boolean toggleAttach = false ; @ Override public void render ( ) { } @ Override public boolean tap ( float x , float y , int count , int button ) { } }<BUG2FIX>internalTickCallback . dispose ( ) ;
public class FullHistogramFacetExecutor extends FacetExecutor { private final IndexNumericFieldData indexFieldData ; private final ComparatorType comparatorType ; final long interval ; final Recycler . V < LongObjectOpenHashMap < InternalFullHistogramFacet . FullEntry > > entries ; public FullHistogramFacetExecutor ( IndexNumericFieldData indexFieldData , long interval , HistogramFacet . ComparatorType comparatorType , SearchContext context ) { } @ Override public FullHistogramFacetExecutor . Collector collector ( ) { } @ Override public InternalFacet buildFacet ( String facetName ) { List < InternalFullHistogramFacet . FullEntry > fullEntries = new java . util . ArrayList ( entries . v ( ) . size ( ) ) ; boolean [ ] states = entries . v ( ) . allocated ; Object [ ] values = entries . v ( ) . values ; for ( int i = 0 ; i < ( states . length ) ; i ++ ) { if ( states [ i ] ) { fullEntries . add ( ( ( InternalFullHistogramFacet . FullEntry ) ( values [ i ] ) ) ) ; } } <START_BUG> entries . release ( ) ; <END_BUG> return new InternalFullHistogramFacet ( facetName , comparatorType , fullEntries ) ; } public static long bucket ( double value , long interval ) { } class Collector extends FacetExecutor . Collector { private final FullHistogramFacetExecutor . HistogramProc histoProc ; private DoubleValues values ; Collector ( ) { } @ Override public void setNextReader ( AtomicReaderContext context ) throws IOException { } @ Override public void collect ( int doc ) throws IOException { } @ Override public void postCollection ( ) { } } public static final class HistogramProc extends DoubleFacetAggregatorBase { final long interval ; final LongObjectOpenHashMap < InternalFullHistogramFacet . FullEntry > entries ; public HistogramProc ( long interval , LongObjectOpenHashMap < InternalFullHistogramFacet . FullEntry > entries ) { } @ Override public void onValue ( int docId , double value ) { } } }<BUG2FIX>entries . close ( ) ;
public class XContentRestResponse extends AbstractRestResponse { private static final byte [ ] END_JSONP ; private static ThreadLocal < BytesRef > prefixCache = new ThreadLocal < BytesRef > ( ) { @ Override protected BytesRef initialValue ( ) { } } ; private final BytesRef prefixUtf8Result ; private final RestStatus status ; private final XContentBuilder builder ; public XContentRestResponse ( RestRequest request , RestStatus status , XContentBuilder builder ) throws IOException { } public XContentBuilder builder ( ) { } @ Override public String contentType ( ) { } @ Override public boolean contentThreadSafe ( ) { <START_BUG> return false ; <END_BUG> } @ Override public byte [ ] content ( ) throws IOException { } @ Override public int contentLength ( ) throws IOException { } @ Override public int contentOffset ( ) throws IOException { } @ Override public RestStatus status ( ) { } @ Override public byte [ ] prefixContent ( ) { } @ Override public int prefixContentLength ( ) { } @ Override public int prefixContentOffset ( ) { } @ Override public byte [ ] suffixContent ( ) { } @ Override public int suffixContentLength ( ) { } @ Override public int suffixContentOffset ( ) { } private static BytesRef startJsonp ( RestRequest request ) { } }<BUG2FIX>return true ;
public class AliasesExistRequestBuilder extends BaseAliasesRequestBuilder < AliasesExistResponse , AliasesExistRequestBuilder > { public AliasesExistRequestBuilder ( IndicesAdminClient client , String ... aliases ) { } @ Override protected void doExecute ( ActionListener < AliasesExistResponse > listener ) { <START_BUG> ( ( IndicesAdminClient ) ( client ) ) . aliasesExist ( request , listener ) ; <END_BUG> } }<BUG2FIX>client . aliasesExist ( request , listener ) ;
public abstract class DoubleArrayAtomicFieldData extends AbstractAtomicNumericFieldData { public static DoubleArrayAtomicFieldData empty ( ) { } protected long size = - 1 ; public DoubleArrayAtomicFieldData ( ) { } @ Override public void close ( ) { } static class Empty extends DoubleArrayAtomicFieldData { Empty ( ) { } @ Override public LongValues getLongValues ( ) { } @ Override public DoubleValues getDoubleValues ( ) { } @ Override public boolean isMultiValued ( ) { } @ Override public long getNumberUniqueValues ( ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override <START_BUG> public BytesValues getBytesValues ( boolean needsHashes ) { <END_BUG> return BytesValues . EMPTY ; } @ Override public ScriptDocValues getScriptValues ( ) { } } public static class WithOrdinals extends DoubleArrayAtomicFieldData { private final DoubleArray values ; private final Ordinals ordinals ; public WithOrdinals ( DoubleArray values , Ordinals ordinals ) { } @ Override public boolean isMultiValued ( ) { } @ Override public long getNumberUniqueValues ( ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override public DoubleArrayAtomicFieldData . WithOrdinals . LongValues getLongValues ( ) { } @ Override public DoubleArrayAtomicFieldData . WithOrdinals . DoubleValues getDoubleValues ( ) { } static class LongValues extends org . elasticsearch . index . fielddata . LongValues . WithOrdinals { private final DoubleArray values ; LongValues ( DoubleArray values , Ordinals . Docs ordinals ) { } @ Override public final long getValueByOrd ( long ord ) { } } static class DoubleValues extends org . elasticsearch . index . fielddata . DoubleValues . WithOrdinals { private final DoubleArray values ; DoubleValues ( DoubleArray values , Ordinals . Docs ordinals ) { } @ Override public double getValueByOrd ( long ord ) { } } } public static class SingleFixedSet extends DoubleArrayAtomicFieldData { private final DoubleArray values ; private final FixedBitSet set ; private final long numOrds ; public SingleFixedSet ( DoubleArray values , FixedBitSet set , long numOrds ) { } @ Override public boolean isMultiValued ( ) { } @ Override public long getNumberUniqueValues ( ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override public DoubleArrayAtomicFieldData . SingleFixedSet . LongValues getLongValues ( ) { } @ Override public DoubleArrayAtomicFieldData . SingleFixedSet . DoubleValues getDoubleValues ( ) { } static class LongValues extends org . elasticsearch . index . fielddata . LongValues { private final DoubleArray values ; private final FixedBitSet set ; LongValues ( DoubleArray values , FixedBitSet set ) { } @ Override public int setDocument ( int docId ) { } @ Override public long nextValue ( ) { } } static class DoubleValues extends org . elasticsearch . index . fielddata . DoubleValues { private final DoubleArray values ; private final FixedBitSet set ; DoubleValues ( DoubleArray values , FixedBitSet set ) { } @ Override public int setDocument ( int docId ) { } @ Override public double nextValue ( ) { } } } public static class Single extends DoubleArrayAtomicFieldData { private final DoubleArray values ; private final long numOrds ; public Single ( DoubleArray values , long numOrds ) { } @ Override public boolean isMultiValued ( ) { } @ Override public long getNumberUniqueValues ( ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override public DoubleArrayAtomicFieldData . Single . LongValues getLongValues ( ) { } @ Override public DoubleArrayAtomicFieldData . Single . DoubleValues getDoubleValues ( ) { } static final class LongValues extends DenseLongValues { private final DoubleArray values ; LongValues ( DoubleArray values ) { } @ Override public long nextValue ( ) { } } static final class DoubleValues extends DenseDoubleValues { private final DoubleArray values ; DoubleValues ( DoubleArray values ) { } @ Override public double nextValue ( ) { } } } }<BUG2FIX>public BytesValues getBytesValues ( ) {
public class BitmapFont implements Disposable { private static final int LOG2_PAGE_SIZE = 9 ; private static final int PAGE_SIZE = 1 << ( BitmapFont . LOG2_PAGE_SIZE ) ; private static final int PAGES = 65536 / ( BitmapFont . PAGE_SIZE ) ; public static final char [ ] xChars = new char [ ] { 'x' , 'e' , 'a' , 'o' , 'n' , 's' , 'r' , 'c' , 'u' , 'm' , 'v' , 'w' , 'z' } ; public static final char [ ] capChars = new char [ ] { 'M' , 'N' , 'B' , 'D' , 'C' , 'E' , 'F' , 'K' , 'A' , 'G' , 'H' , 'I' , 'J' , 'L' , 'O' , 'P' , 'Q' , 'R' , 'S' , 'T' , 'U' , 'V' , 'W' , 'X' , 'Y' , 'Z' } ; final BitmapFont . BitmapFontData data ; TextureRegion region ; private final BitmapFontCache cache = new BitmapFontCache ( this ) ; private boolean flipped ; private boolean integer ; private boolean ownsTexture ; public BitmapFont ( ) { } public BitmapFont ( boolean flip ) { } public BitmapFont ( FileHandle fontFile , TextureRegion region , boolean flip ) { } public BitmapFont ( FileHandle fontFile , boolean flip ) { } public BitmapFont ( FileHandle fontFile , FileHandle imageFile , boolean flip ) { } public BitmapFont ( FileHandle fontFile , FileHandle imageFile , boolean flip , boolean integer ) { } public BitmapFont ( BitmapFont . BitmapFontData data , TextureRegion region , boolean integer ) { } private void load ( BitmapFont . BitmapFontData data ) { } public BitmapFont . TextBounds draw ( SpriteBatch spriteBatch , CharSequence str , float x , float y ) { } public BitmapFont . TextBounds draw ( SpriteBatch spriteBatch , CharSequence str , float x , float y , int start , int end ) { } public BitmapFont . TextBounds drawMultiLine ( SpriteBatch spriteBatch , CharSequence str , float x , float y ) { } public BitmapFont . TextBounds drawMultiLine ( SpriteBatch spriteBatch , CharSequence str , float x , float y , float alignmentWidth , BitmapFont . HAlignment alignment ) { } public BitmapFont . TextBounds drawWrapped ( SpriteBatch spriteBatch , CharSequence str , float x , float y , float wrapWidth ) { } public BitmapFont . TextBounds drawWrapped ( SpriteBatch spriteBatch , CharSequence str , float x , float y , float wrapWidth , BitmapFont . HAlignment alignment ) { } public BitmapFont . TextBounds getBounds ( CharSequence str ) { } public BitmapFont . TextBounds getBounds ( CharSequence str , BitmapFont . TextBounds textBounds ) { } public BitmapFont . TextBounds getBounds ( CharSequence str , int start , int end ) { } public BitmapFont . TextBounds getBounds ( CharSequence str , int start , int end , BitmapFont . TextBounds textBounds ) { } public BitmapFont . TextBounds getMultiLineBounds ( CharSequence str ) { } public BitmapFont . TextBounds getMultiLineBounds ( CharSequence str , BitmapFont . TextBounds textBounds ) { } public BitmapFont . TextBounds getWrappedBounds ( CharSequence str , float wrapWidth ) { } public BitmapFont . TextBounds getWrappedBounds ( CharSequence str , float wrapWidth , BitmapFont . TextBounds textBounds ) { } public void computeGlyphAdvancesAndPositions ( CharSequence str , FloatArray glyphAdvances , FloatArray glyphPositions ) { } public int computeVisibleGlyphs ( CharSequence str , int start , int end , float availableWidth ) { } public void setColor ( float color ) { } public void setColor ( Color color ) { } public void setColor ( float r , float g , float b , float a ) { } public Color getColor ( ) { } public void setScale ( float scaleX , float scaleY ) { BitmapFont . BitmapFontData data = this . data ; float x = scaleX / ( data . scaleX ) ; float y = scaleY / ( data . scaleY ) ; <START_BUG> data . lineHeight = ( data . lineHeight ) * x ; <END_BUG> data . spaceWidth = ( data . spaceWidth ) * x ; data . xHeight = ( data . xHeight ) * y ; data . capHeight = ( data . capHeight ) * y ; data . ascent = ( data . ascent ) * y ; data . descent = ( data . descent ) * y ; data . down = ( data . down ) * y ; data . scaleX = scaleX ; data . scaleY = scaleY ; } public void setScale ( float scaleXY ) { } public void scale ( float amount ) { } public float getScaleX ( ) { } public float getScaleY ( ) { } public TextureRegion getRegion ( ) { } public float getLineHeight ( ) { } public float getSpaceWidth ( ) { } public float getXHeight ( ) { } public float getCapHeight ( ) { } public float getAscent ( ) { } public float getDescent ( ) { } public boolean isFlipped ( ) { } public void dispose ( ) { } public void setFixedWidthGlyphs ( CharSequence glyphs ) { } public boolean containsCharacter ( char character ) { } public void setUseIntegerPositions ( boolean integer ) { } public boolean usesIntegerPositions ( ) { } public BitmapFont . BitmapFontData getData ( ) { } public static class Glyph { public int srcX ; public int srcY ; public int width ; public int height ; public float u ; public float v ; public float u2 ; public float v2 ; public int xoffset ; public int yoffset ; public int xadvance ; public byte [ ] [ ] kerning ; public int getKerning ( char ch ) { } public void setKerning ( int ch , int value ) { } } static int indexOf ( CharSequence text , char ch , int start ) { }<BUG2FIX>data . lineHeight = ( data . lineHeight ) * y ;
public class TermsStringOrdinalsFacetExecutor extends FacetExecutor { private final WithOrdinals indexFieldData ; final CacheRecycler cacheRecycler ; final BigArrays bigArrays ; private final ComparatorType comparatorType ; private final int size ; private final int shardSize ; private final int minCount ; private final ImmutableSet < BytesRef > excluded ; private final Matcher matcher ; final int ordinalsCacheAbove ; final List < TermsStringOrdinalsFacetExecutor . ReaderAggregator > aggregators ; long missing ; long total ; public TermsStringOrdinalsFacetExecutor ( IndexFieldData . WithOrdinals indexFieldData , int size , int shardSize , TermsFacet . ComparatorType comparatorType , boolean allTerms , SearchContext context , ImmutableSet < BytesRef > excluded , Pattern pattern , int ordinalsCacheAbove ) { } @ Override public TermsStringOrdinalsFacetExecutor . Collector collector ( ) { } @ Override public InternalFacet buildFacet ( String facetName ) { } class Collector extends FacetExecutor . Collector { private long missing ; private long total ; private BytesValues . WithOrdinals values ; private TermsStringOrdinalsFacetExecutor . ReaderAggregator current ; private Docs ordinals ; @ Override public void setNextReader ( AtomicReaderContext context ) throws IOException { if ( ( current ) != null ) { missing += current . missing ; total += current . total ; if ( ( current . values . ordinals ( ) . getMaxOrd ( ) ) > ( Ordinals . MIN_ORDINAL ) ) { aggregators . add ( current ) ; } else { Releasables . close ( current ) ; } } <START_BUG> values = indexFieldData . load ( context ) . getBytesValues ( false ) ; <END_BUG> current = new TermsStringOrdinalsFacetExecutor . ReaderAggregator ( values , ordinalsCacheAbove , cacheRecycler ) ; ordinals = values . ordinals ( ) ; } @ Override public void collect ( int doc ) throws IOException { } @ Override public void postCollection ( ) { } } public final class ReaderAggregator implements Releasable { private final long maxOrd ; final BytesValues . WithOrdinals values ; final IntArray counts ; int missing = 0 ; long position = ( Ordinals . MIN_ORDINAL ) - 1 ; BytesRef current ; int total ; public ReaderAggregator ( BytesValues . WithOrdinals values , int ordinalsCacheLimit , CacheRecycler cacheRecycler ) { } final void onOrdinal ( int docId , long ordinal ) { } final void incrementMissing ( int numMissing ) { } public boolean nextPosition ( ) { } public BytesRef copyCurrent ( ) { } @ Override public void close ( ) { } } public static class AggregatorPriorityQueue extends PriorityQueue < TermsStringOrdinalsFacetExecutor . ReaderAggregator > { public AggregatorPriorityQueue ( int size ) { } @ Override protected boolean lessThan ( TermsStringOrdinalsFacetExecutor . ReaderAggregator a , TermsStringOrdinalsFacetExecutor . ReaderAggregator b ) { } } }<BUG2FIX>values = indexFieldData . load ( context ) . getBytesValues ( ) ;
public class MultiValueShortFieldData extends ShortFieldData { private static final int VALUE_CACHE_SIZE = 10 ; private ThreadLocal < ThreadLocals . CleanableValue < double [ ] [ ] > > doublesValuesCache = new ThreadLocal < ThreadLocals . CleanableValue < double [ ] [ ] > > ( ) { @ Override protected ThreadLocals . CleanableValue < double [ ] [ ] > initialValue ( ) { } } ; private ThreadLocal < ThreadLocals . CleanableValue < short [ ] [ ] > > valuesCache = new ThreadLocal < ThreadLocals . CleanableValue < short [ ] [ ] > > ( ) { @ Override protected ThreadLocals . CleanableValue < short [ ] [ ] > initialValue ( ) { } } ; private final int [ ] [ ] ordinals ; public MultiValueShortFieldData ( String fieldName , int [ ] [ ] ordinals , short [ ] values ) { } @ Override protected long computeSizeInBytes ( ) { } @ Override public boolean multiValued ( ) { } @ Override public boolean hasValue ( int docId ) { } @ Override public void forEachValueInDoc ( int docId , StringValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , DoubleValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , LongValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , MissingDoubleValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , MissingLongValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , ValueInDocProc proc ) { } @ Override public void forEachOrdinalInDoc ( int docId , OrdinalInDocProc proc ) { boolean found = false ; for ( int [ ] ordinal : ordinals ) { int loc = ordinal [ docId ] ; if ( loc != 0 ) { found = true ; <START_BUG> proc . onOrdinal ( docId , ordinal [ docId ] ) ; <END_BUG> } } if ( ! found ) { proc . onOrdinal ( docId , 0 ) ; } } @ Override public double [ ] doubleValues ( int docId ) { } @ Override public short value ( int docId ) { } @ Override public short [ ] values ( int docId ) { } }<BUG2FIX>proc . onOrdinal ( docId , loc ) ;
public class GeoPointBinaryDVIndexFieldData extends DocValuesIndexFieldData implements IndexGeoPointFieldData < AtomicGeoPointFieldData < ScriptDocValues > > { public GeoPointBinaryDVIndexFieldData ( Index index , Names fieldNames , FieldDataType fieldDataType ) { } @ Override public boolean valuesOrdered ( ) { } @ Override public final XFieldComparatorSource comparatorSource ( @ Nullable Object missingValue , SortMode sortMode ) { } @ Override public AtomicGeoPointFieldData < ScriptDocValues > load ( AtomicReaderContext context ) { try { <START_BUG> return new GeoPointBinaryDVAtomicFieldData ( context . reader ( ) , context . reader ( ) . getBinaryDocValues ( fieldNames . indexName ( ) ) ) ; <END_BUG> } catch ( IOException e ) { throw new ElasticsearchIllegalStateException ( "Cannot<seq2seq4repair_space>load<seq2seq4repair_space>doc<seq2seq4repair_space>values" , e ) ; } } @ Override public AtomicGeoPointFieldData < ScriptDocValues > loadDirect ( AtomicReaderContext context ) throws Exception { } public static class Builder implements IndexFieldData . Builder { @ Override public IndexFieldData < ? > build ( Index index , Settings indexSettings , FieldMapper < ? > mapper , IndexFieldDataCache cache , CircuitBreakerService breakerService , MapperService mapperService , GlobalOrdinalsBuilder globalOrdinalBuilder ) { } } }<BUG2FIX>return new GeoPointBinaryDVAtomicFieldData ( context . reader ( ) . getBinaryDocValues ( fieldNames . indexName ( ) ) ) ;
public class ValueScriptHistogramFacetExecutor extends FacetExecutor { private final IndexNumericFieldData indexFieldData ; private final ComparatorType comparatorType ; final SearchScript valueScript ; final long interval ; final Recycler . V < LongObjectOpenHashMap < InternalFullHistogramFacet . FullEntry > > entries ; public ValueScriptHistogramFacetExecutor ( IndexNumericFieldData indexFieldData , String scriptLang , String valueScript , Map < String , Object > params , long interval , HistogramFacet . ComparatorType comparatorType , SearchContext context ) { } @ Override public ValueScriptHistogramFacetExecutor . Collector collector ( ) { } @ Override public InternalFacet buildFacet ( String facetName ) { List < InternalFullHistogramFacet . FullEntry > entries1 = new java . util . ArrayList ( entries . v ( ) . size ( ) ) ; final boolean [ ] states = entries . v ( ) . allocated ; final Object [ ] values = entries . v ( ) . values ; for ( int i = 0 ; i < ( states . length ) ; i ++ ) { if ( states [ i ] ) { InternalFullHistogramFacet . FullEntry value = ( ( InternalFullHistogramFacet . FullEntry ) ( values [ i ] ) ) ; entries1 . add ( value ) ; } } <START_BUG> entries . release ( ) ; <END_BUG> return new InternalFullHistogramFacet ( facetName , comparatorType , entries1 ) ; } public static long bucket ( double value , long interval ) { } class Collector extends FacetExecutor . Collector { private DoubleValues values ; private final ValueScriptHistogramFacetExecutor . HistogramProc histoProc ; public Collector ( ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override public void setNextReader ( AtomicReaderContext context ) throws IOException { } @ Override public void collect ( int doc ) throws IOException { } @ Override public void postCollection ( ) { } } public static class HistogramProc extends DoubleFacetAggregatorBase { private final long interval ; private final SearchScript valueScript ; final LongObjectOpenHashMap < InternalFullHistogramFacet . FullEntry > entries ; public HistogramProc ( long interval , SearchScript valueScript , LongObjectOpenHashMap < InternalFullHistogramFacet . FullEntry > entries ) { } @ Override public void onValue ( int docId , double value ) { } } }<BUG2FIX>entries . close ( ) ;
public class SpanNotQueryBuilder extends BaseQueryBuilder implements BoostableQueryBuilder < SpanNotQueryBuilder > , SpanQueryBuilder { private SpanQueryBuilder include ; private SpanQueryBuilder exclude ; private float boost = - 1 ; public SpanNotQueryBuilder include ( SpanQueryBuilder include ) { } public SpanNotQueryBuilder exclude ( SpanQueryBuilder exclude ) { } public SpanNotQueryBuilder boost ( float boost ) { } @ Override protected void doXContent ( XContentBuilder builder , Params params ) throws IOException { if ( ( include ) == null ) { throw new QueryBuilderException ( "Must<seq2seq4repair_space>specify<seq2seq4repair_space>include<seq2seq4repair_space>when<seq2seq4repair_space>using<seq2seq4repair_space>spanNot<seq2seq4repair_space>query" ) ; } if ( ( exclude ) == null ) { throw new QueryBuilderException ( "Must<seq2seq4repair_space>specify<seq2seq4repair_space>exclude<seq2seq4repair_space>when<seq2seq4repair_space>using<seq2seq4repair_space>spanNot<seq2seq4repair_space>query" ) ; } builder . startObject ( NAME ) ; builder . field ( "include" ) ; include . toXContent ( builder , params ) ; builder . field ( "exclude" ) ; exclude . toXContent ( builder , params ) ; <START_BUG> if ( ( boost ) == ( - 1 ) ) { <END_BUG> builder . field ( "boost" , boost ) ; } builder . endObject ( ) ; } }<BUG2FIX>if ( ( boost ) != ( - 1 ) ) {
public class FilesTest extends GdxTest { String message = "" ; boolean success ; BitmapFont font ; SpriteBatch batch ; @ Override public void create ( ) { } private void testClasspath ( ) throws IOException { } private void testInternal ( ) throws IOException { } private void testExternal ( ) throws IOException { } private void testAbsolute ( ) throws IOException { } private void testLocal ( ) throws IOException { String path = "meow" ; FileHandle handle = files . local ( path ) ; handle . delete ( ) ; if ( handle . exists ( ) ) fail ( ) ; if ( handle . isDirectory ( ) ) fail ( ) ; if ( handle . delete ( ) ) fail ( ) ; if ( ( handle . list ( ) . length ) != 0 ) fail ( ) ; if ( handle . child ( "meow" ) . exists ( ) ) fail ( ) ; <START_BUG> if ( handle . parent ( ) . exists ( ) ) <END_BUG> fail ( ) ; try { handle . read ( ) . close ( ) ; fail ( ) ; } catch ( Exception ignored ) { } handle . mkdirs ( ) ; if ( ! ( handle . exists ( ) ) ) fail ( ) ; if ( ! ( handle . isDirectory ( ) ) ) fail ( ) ; if ( ( handle . list ( ) . length ) != 0 ) fail ( ) ; handle . child ( "meow" ) . mkdirs ( ) ; if ( ( handle . list ( ) . length ) != 1 ) fail ( ) ; FileHandle child = handle . list ( ) [ 0 ] ; if ( ! ( child . name ( ) . equals ( "meow" ) ) ) fail ( ) ; if ( ! ( child . parent ( ) . exists ( ) ) ) fail ( ) ; if ( ! ( handle . deleteDirectory ( ) ) ) fail ( ) ; if ( handle . exists ( ) ) fail ( ) ; OutputStream output = handle . write ( false ) ; output . write ( "moo" . getBytes ( ) ) ; output . close ( ) ; if ( ! ( handle . exists ( ) ) ) fail ( ) ; if ( ( handle . length ( ) ) != 3 ) fail ( ) ; FileHandle copy = files . local ( ( path + "-copy" ) ) ; copy . delete ( ) ; if ( copy . exists ( ) ) fail ( ) ; handle . copyTo ( copy ) ; if ( ! ( copy . exists ( ) ) ) fail ( ) ; if ( ( copy . length ( ) ) != 3 ) fail ( ) ; FileHandle move = files . local ( ( path + "-move" ) ) ; move . delete ( ) ; if ( move . exists ( ) ) fail ( ) ; copy . moveTo ( move ) ; if ( ! ( move . exists ( ) ) ) fail ( ) ; if ( ( move . length ( ) ) != 3 ) fail ( ) ; move . deleteDirectory ( ) ; if ( move . exists ( ) ) fail ( ) ; InputStream input = handle . read ( ) ; byte [ ] bytes = new byte [ 6 ] ; if ( ( input . read ( bytes ) ) != 3 ) fail ( ) ; input . close ( ) ; if ( ! ( new String ( bytes , 0 , 3 ) . equals ( "moo" ) ) ) fail ( ) ; output = handle . write ( true ) ; output . write ( "cow" . getBytes ( ) ) ; output . close ( ) ; if ( ( handle . length ( ) ) != 6 ) fail ( ) ; input = handle . read ( ) ; if ( ( input . read ( bytes ) ) != 6 ) fail ( ) ; input . close ( ) ; if ( ! ( new String ( bytes , 0 , 6 ) . equals ( "moocow" ) ) ) fail ( ) ; if ( handle . isDirectory ( ) ) fail ( ) ; if ( ( handle . list ( ) . length ) != 0 ) fail ( ) ; if ( ! ( handle . name ( ) . equals ( "meow" ) ) ) fail ( ) ; if ( ! ( handle . nameWithoutExtension ( ) . equals ( "meow" ) ) ) fail ( ) ; if ( ! ( handle . extension ( ) . equals ( "" ) ) ) fail ( ) ; handle . deleteDirectory ( ) ; if ( handle . exists ( ) ) fail ( ) ; if ( handle . isDirectory ( ) ) fail ( ) ; handle . delete ( ) ; handle . deleteDirectory ( ) ; } private void fail ( ) { } private void fail ( String msg ) { } @ Override public void render ( ) { } @ Override public void dispose ( ) { } }<BUG2FIX>if ( ! ( handle . parent ( ) . exists ( ) ) )
public class RestFlushAction extends BaseRestHandler { @ Inject public RestFlushAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { FlushRequest flushRequest = new FlushRequest ( RestActions . splitIndices ( request . param ( "index" ) ) ) ; flushRequest . listenerThreaded ( false ) ; if ( request . hasParam ( "ignore_indices" ) ) { flushRequest . ignoreIndices ( IgnoreIndices . fromString ( request . param ( "ignore_indices" ) ) ) ; } BroadcastOperationThreading operationThreading = BroadcastOperationThreading . fromString ( request . param ( "operationThreading" ) , SINGLE_THREAD ) ; if ( operationThreading == ( BroadcastOperationThreading . NO_THREADS ) ) { operationThreading = BroadcastOperationThreading . THREAD_PER_SHARD ; } flushRequest . operationThreading ( operationThreading ) ; flushRequest . refresh ( request . paramAsBoolean ( "refresh" , flushRequest . refresh ( ) ) ) ; flushRequest . full ( request . paramAsBoolean ( "full" , flushRequest . full ( ) ) ) ; flushRequest . force ( request . paramAsBoolean ( "force" , flushRequest . force ( ) ) ) ; client . admin ( ) . indices ( ) . flush ( flushRequest , new org . elasticsearch . action . ActionListener < FlushResponse > ( ) { @ Override public void onResponse ( FlushResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( "ok" , true ) ; buildBroadcastShardsHeader ( builder , response ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class DateHistogramFacetProcessor extends AbstractComponent implements FacetProcessor { private final ImmutableMap < String , DateHistogramFacetProcessor . DateFieldParser > dateFieldParsers ; private final TObjectIntHashMap < String > rounding = new TObjectIntHashMap < String > ( Constants . DEFAULT_CAPACITY , Constants . DEFAULT_LOAD_FACTOR , ( - 1 ) ) ; @ Inject public DateHistogramFacetProcessor ( Settings settings ) { } @ Override public String [ ] types ( ) { } @ Override public FacetCollector parse ( String facetName , XContentParser parser , SearchContext context ) throws IOException { String keyField = null ; String valueField = null ; String valueScript = null ; String scriptLang = null ; Map < String , Object > params = null ; boolean intervalSet = false ; long interval = 1 ; String sInterval = null ; MutableDateTime dateTime = new MutableDateTime ( DateTimeZone . UTC ) ; DateHistogramFacet . ComparatorType comparatorType = ComparatorType . TIME ; XContentParser . Token token ; String fieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { fieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_OBJECT ) ) { if ( "params" . equals ( fieldName ) ) { params = parser . map ( ) ; } } else if ( token . isValue ( ) ) { if ( "field" . equals ( fieldName ) ) { keyField = parser . text ( ) ; } else if ( ( "key_field" . equals ( fieldName ) ) || ( "keyField" . equals ( fieldName ) ) ) { keyField = parser . text ( ) ; } else if ( ( "value_field" . equals ( fieldName ) ) || ( "valueField" . equals ( fieldName ) ) ) { valueField = parser . text ( ) ; } else if ( "interval" . equals ( fieldName ) ) { intervalSet = true ; if ( token == ( Token . VALUE_NUMBER ) ) { interval = parser . longValue ( ) ; } else { sInterval = parser . text ( ) ; } } else if ( ( "time_zone" . equals ( fieldName ) ) || ( "timeZone" . equals ( fieldName ) ) ) { if ( token == ( Token . VALUE_NUMBER ) ) { dateTime . setZone ( DateTimeZone . forOffsetHours ( parser . intValue ( ) ) ) ; } else { String text = parser . text ( ) ; int index = text . indexOf ( ':' ) ; if ( index != ( - 1 ) ) { dateTime . setZone ( DateTimeZone . forOffsetHoursMinutes ( Integer . parseInt ( text . substring ( 0 , index ) ) , Integer . parseInt ( text . substring ( ( index + 1 ) ) ) ) ) ; } else { dateTime . setZone ( DateTimeZone . forID ( text ) ) ; } } } else if ( ( "value_script" . equals ( fieldName ) ) || ( "valueScript" . equals ( fieldName ) ) ) { valueScript = parser . text ( ) ; } else if ( ( "order" . equals ( fieldName ) ) || ( "comparator" . equals ( fieldName ) ) ) { comparatorType = ComparatorType . fromString ( parser . text ( ) ) ; } else if ( "lang" . equals ( fieldName ) ) { scriptLang = parser . text ( ) ; } } } if ( keyField == null ) { throw new FacetPhaseExecutionException ( facetName , "key<seq2seq4repair_space>field<seq2seq4repair_space>is<seq2seq4repair_space>required<seq2seq4repair_space>to<seq2seq4repair_space>be<seq2seq4repair_space>set<seq2seq4repair_space>for<seq2seq4repair_space>histogram<seq2seq4repair_space>facet,<seq2seq4repair_space>either<seq2seq4repair_space>using<seq2seq4repair_space>[field]<seq2seq4repair_space>or<seq2seq4repair_space>using<seq2seq4repair_space>[key_field]" ) ; } <START_BUG> FieldMapper mapper = context . mapperService ( ) . smartNameFieldMapper ( keyField ) ; <END_BUG> if ( mapper == null ) { throw new FacetPhaseExecutionException ( facetName , ( ( "(key)<seq2seq4repair_space>field<seq2seq4repair_space>[" + keyField ) + "]<seq2seq4repair_space>not<seq2seq4repair_space>found" ) ) ; } if ( ( mapper . fieldDataType ( ) ) != ( DefaultTypes . LONG ) ) { throw new FacetPhaseExecutionException ( facetName , ( ( "(key)<seq2seq4repair_space>field<seq2seq4repair_space>[" + keyField ) + "]<seq2seq4repair_space>is<seq2seq4repair_space>not<seq2seq4repair_space>of<seq2seq4repair_space>type<seq2seq4repair_space>date" ) ) ; } if ( ! intervalSet ) { throw new FacetPhaseExecutionException ( facetName , "[interval]<seq2seq4repair_space>is<seq2seq4repair_space>required<seq2seq4repair_space>to<seq2seq4repair_space>be<seq2seq4repair_space>set<seq2seq4repair_space>for<seq2seq4repair_space>histogram<seq2seq4repair_space>facet" ) ; } if ( sInterval != null ) { int index = sInterval . indexOf ( ':' ) ; if ( index != ( - 1 ) ) { DateHistogramFacetProcessor . DateFieldParser fieldParser = dateFieldParsers . get ( sInterval . substring ( 0 , index ) ) ; if ( fieldParser == null ) { throw new FacetPhaseExecutionException ( facetName , ( ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>parse<seq2seq4repair_space>interval<seq2seq4repair_space>[" + sInterval ) + "]<seq2seq4repair_space>with<seq2seq4repair_space>custom<seq2seq4repair_space>rounding<seq2seq4repair_space>using<seq2seq4repair_space>built<seq2seq4repair_space>in<seq2seq4repair_space>intervals<seq2seq4repair_space>(year/month/...)" ) ) ; } DateTimeField field = fieldParser . parse ( dateTime . getChronology ( ) ) ; int rounding = this . rounding . get ( sInterval . substring ( ( index + 1 ) ) ) ; if ( rounding == ( - 1 ) ) { throw new FacetPhaseExecutionException ( facetName , ( ( ( ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>parse<seq2seq4repair_space>interval<seq2seq4repair_space>[" + sInterval ) + "],<seq2seq4repair_space>rounding<seq2seq4repair_space>type<seq2seq4repair_space>[" ) + ( sInterval . substring ( ( index + 1 ) ) ) ) + "]<seq2seq4repair_space>not<seq2seq4repair_space>found" ) ) ; } dateTime . setRounding ( field , rounding ) ; } else { DateHistogramFacetProcessor . DateFieldParser fieldParser = dateFieldParsers . get ( sInterval ) ; if ( fieldParser != null ) { DateTimeField field = fieldParser . parse ( dateTime . getChronology ( ) ) ; dateTime . setRounding ( field , ROUND_FLOOR ) ; } else { try { interval = TimeValue . parseTimeValue ( sInterval , null ) . millis ( ) ; } catch ( Exception e ) { throw new FacetPhaseExecutionException ( facetName , ( ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>parse<seq2seq4repair_space>interval<seq2seq4repair_space>[" + sInterval ) + "],<seq2seq4repair_space>tried<seq2seq4repair_space>both<seq2seq4repair_space>as<seq2seq4repair_space>built<seq2seq4repair_space>in<seq2seq4repair_space>intervals<seq2seq4repair_space>(year/month/...)<seq2seq4repair_space>and<seq2seq4repair_space>as<seq2seq4repair_space>a<seq2seq4repair_space>time<seq2seq4repair_space>format" ) ) ; } } } } if ( valueScript != null ) { return new ValueScriptDateHistogramFacetCollector ( facetName , keyField , scriptLang , valueScript , params , dateTime , interval , comparatorType , context ) ; }<BUG2FIX>FieldMapper mapper = context . smartNameFieldMapper ( keyField ) ;
public class LongValuesComparatorSource extends IndexFieldData . XFieldComparatorSource { private final IndexNumericFieldData indexFieldData ; private final Object missingValue ; public LongValuesComparatorSource ( IndexNumericFieldData indexFieldData , @ Nullable Object missingValue ) { } @ Override public Type reducedType ( ) { } @ Override public FieldComparator < ? > newComparator ( String fieldname , int numHits , int sortPos , boolean reversed ) throws IOException { assert fieldname . equals ( indexFieldData . getFieldNames ( ) . indexName ( ) ) ; long dMissingValue ; if ( ( ( missingValue ) == null ) || ( "_last" . equals ( missingValue ) ) ) { dMissingValue = ( reversed ) ? Long . MIN_VALUE : Long . MAX_VALUE ; } else if ( "_first" . equals ( missingValue ) ) { dMissingValue = ( reversed ) ? Long . MAX_VALUE : Long . MIN_VALUE ; } else { dMissingValue = ( ( missingValue ) instanceof Number ) ? ( ( Number ) ( missingValue ) ) . longValue ( ) : Long . parseLong ( missingValue . toString ( ) ) ; } <START_BUG> return new LongValuesComparator ( indexFieldData , dMissingValue , numHits ) ; <END_BUG> } }<BUG2FIX>return new LongValuesComparator ( indexFieldData , dMissingValue , numHits , reversed ) ;
public class BitmapFontCache { private final BitmapFont font ; private float [ ] [ ] vertexData ; private int [ ] idx ; private int [ ] tmpGlyphCount ; private float x ; private float y ; private float color = WHITE . toFloatBits ( ) ; private final Color tempColor = new Color ( 1 , 1 , 1 , 1 ) ; private final TextBounds textBounds = new TextBounds ( ) ; private boolean integer = true ; private int glyphCount = 0 ; private IntArray [ ] glyphIndices ; public BitmapFontCache ( BitmapFont font ) { } public BitmapFontCache ( BitmapFont font , boolean integer ) { } public void setPosition ( float x , float y ) { } public void translate ( float xAmount , float yAmount ) { } public void setColors ( float color ) { } public void setColors ( Color tint ) { } public void setColors ( float r , float g , float b , float a ) { } public void setColors ( Color tint , int start , int end ) { } public void setColor ( Color tint ) { } public void setColor ( float r , float g , float b , float a ) { } public void setColor ( float color ) { } public Color getColor ( ) { } public void draw ( Batch spriteBatch ) { TextureRegion [ ] regions = font . getRegions ( ) ; for ( int j = 0 , n = vertexData . length ; j < n ; j ++ ) { <START_BUG> if ( ( idx [ j ] ) >= 0 ) { <END_BUG> float [ ] vertices = vertexData [ j ] ; spriteBatch . draw ( regions [ j ] . getTexture ( ) , vertices , 0 , idx [ j ] ) ; } } } public void draw ( Batch spriteBatch , int start , int end ) { } public void draw ( Batch spriteBatch , float alphaModulation ) { } public void clear ( ) { } private void requireSequence ( CharSequence seq , int start , int end ) { } private void require ( int page , int glyphCount ) { } private float addToCache ( CharSequence str , float x , float y , int start , int end ) { } private void addGlyph ( Glyph glyph , float x , float y , float width , float height ) { } public TextBounds setText ( CharSequence str , float x , float y ) { } public TextBounds setText ( CharSequence str , float x , float y , int start , int end ) { } public TextBounds addText ( CharSequence str , float x , float y ) { } public TextBounds addText ( CharSequence str , float x , float y , int start , int end ) { } public TextBounds setMultiLineText ( CharSequence str , float x , float y ) { } public TextBounds setMultiLineText ( CharSequence str , float x , float y , float alignmentWidth , HAlignment alignment ) { } public TextBounds addMultiLineText ( CharSequence str , float x , float y ) { } public TextBounds addMultiLineText ( CharSequence str , float x , float y , float alignmentWidth , HAlignment alignment ) { } public TextBounds setWrappedText ( CharSequence str , float x , float y , float wrapWidth ) { } public TextBounds setWrappedText ( CharSequence str , float x , float y , float wrapWidth , HAlignment alignment ) { } public TextBounds addWrappedText ( CharSequence str , float x , float y , float wrapWidth ) { } public TextBounds addWrappedText ( CharSequence str , float x , float y , float wrapWidth , HAlignment alignment ) { } public TextBounds getBounds ( ) { } public float getX ( ) { } public float getY ( ) { } public BitmapFont getFont ( ) { } public void setUseIntegerPositions ( boolean use ) { } public boolean usesIntegerPositions ( ) { } public float [ ] getVertices ( ) { } public float [ ] getVertices ( int page ) { } }<BUG2FIX>if ( ( idx [ j ] ) > 0 ) {
public class FsChannelSnapshot implements Translog . Snapshot { private final ShardId shardId ; private final long id ; private final int totalOperations ; private final int snapshotOperations ; private final RafReference raf ; private final FileChannel channel ; private final long length ; private Operation lastOperationRead = null ; private int position = 0 ; private ByteBuffer cacheBuffer ; public FsChannelSnapshot ( ShardId shardId , long id , RafReference raf , long length , int totalOperations , int snapshotOperations ) throws FileNotFoundException { } @ Override public long translogId ( ) { } @ Override public long position ( ) { } @ Override public long length ( ) { } @ Override public int totalOperations ( ) { } @ Override public int snapshotOperations ( ) { } @ Override public InputStream stream ( ) throws IOException { } @ Override public long lengthInBytes ( ) { } @ Override public boolean hasNext ( ) { } @ Override public Operation next ( ) { } @ Override public void seekForward ( long length ) { } @ Override public boolean release ( ) throws ElasticSearchException { <START_BUG> raf . decreaseRefCount ( ) ; <END_BUG> return true ; } }<BUG2FIX>raf . decreaseRefCount ( true ) ;
public class AnalyzeResponse implements Iterable < AnalyzeResponse . AnalyzeToken > , ActionResponse , ToXContent { public static class AnalyzeToken implements Streamable { private String term ; private int startOffset ; private int endOffset ; private int position ; private String type ; AnalyzeToken ( ) { } public AnalyzeToken ( String term , int position , int startOffset , int endOffset , String type ) { } public String term ( ) { } public String getTerm ( ) { } public int startOffset ( ) { } public int getStartOffset ( ) { } public int endOffset ( ) { } public int getEndOffset ( ) { } public int position ( ) { } public int getPosition ( ) { } public String type ( ) { } public String getType ( ) { } public static AnalyzeResponse . AnalyzeToken readAnalyzeToken ( StreamInput in ) throws IOException { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { out . writeUTF ( term ) ; out . writeInt ( startOffset ) ; out . writeInt ( endOffset ) ; out . writeVInt ( position ) ; if ( ( type ) == null ) { out . writeBoolean ( false ) ; } else { <START_BUG> out . writeBoolean ( false ) ; <END_BUG> out . writeUTF ( type ) ; } } } private List < AnalyzeResponse . AnalyzeToken > tokens ; AnalyzeResponse ( ) { } public AnalyzeResponse ( List < AnalyzeResponse . AnalyzeToken > tokens ) { } public List < AnalyzeResponse . AnalyzeToken > tokens ( ) { } public List < AnalyzeResponse . AnalyzeToken > getTokens ( ) { } @ Override public Iterator < AnalyzeResponse . AnalyzeToken > iterator ( ) { } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { out . writeVInt ( tokens . size ( ) ) ; for ( AnalyzeResponse . AnalyzeToken token : tokens ) { token . writeTo ( out ) ; } } }<BUG2FIX>out . writeBoolean ( true ) ;
public class GdxSetup { public void build ( String outputDir , String appName , String packageName , String mainClass ) { Project project = new Project ( ) ; String packageDir = packageName . replace ( '.' , '/' ) ; project . files . add ( new ProjectFile ( "build.gradle" , true ) ) ; project . files . add ( new ProjectFile ( "settings.gradle" ) ) ; project . files . add ( new ProjectFile ( "gradlew" , false ) ) ; project . files . add ( new ProjectFile ( "gradlew.bat" , false ) ) ; project . files . add ( new ProjectFile ( "gradle/wrapper/gradle-wrapper.jar" , false ) ) ; project . files . add ( new ProjectFile ( "gradle/wrapper/gradle-wrapper.properties" , false ) ) ; project . files . add ( new ProjectFile ( "core/build.gradle" ) ) ; project . files . add ( new ProjectFile ( "core/src/MainClass" , ( ( ( ( "core/src/" + packageDir ) + "/" ) + mainClass ) + ".java" ) , true ) ) ; project . files . add ( new ProjectFile ( "core/CoreGdxDefinition" , ( ( ( ( "core/src/" + packageDir ) + "/" ) + mainClass ) + ".gwt.xml" ) , true ) ) ; project . files . add ( new ProjectFile ( "desktop/build.gradle" ) ) ; project . files . add ( new ProjectFile ( "desktop/src/DesktopLauncher" , ( ( "desktop/src/" + packageDir ) + "/desktop/DesktopLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "android/assets/badlogic.jpg" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/values/strings.xml" ) ) ; project . files . add ( new ProjectFile ( "android/res/values/styles.xml" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-hdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-mdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-xhdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-xxhdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/src/AndroidLauncher" , ( ( "android/src/" + packageDir ) + "/android/AndroidLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "android/AndroidManifest.xml" ) ) ; <START_BUG> project . files . add ( new ProjectFile ( "android/build.gradle" ) ) ; <END_BUG> project . files . add ( new ProjectFile ( "android/ic_launcher-web.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/proguard-project.txt" , false ) ) ; project . files . add ( new ProjectFile ( "android/project.properties" , false ) ) ; project . files . add ( new ProjectFile ( "gwt/build.gradle" ) ) ; project . files . add ( new ProjectFile ( "gwt/src/GwtLauncher" , ( ( "gwt/src/" + packageDir ) + "/client/GwtLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "gwt/GdxDefinition" , ( ( "gwt/src/" + packageDir ) + "/GdxDefinition.gwt.xml" ) , true ) ) ; project . files . add ( new ProjectFile ( "gwt/GdxDefinitionSuperdev" , ( ( "gwt/src/" + packageDir ) + "/GdxDefinitionSuperdev.gwt.xml" ) , true ) ) ; project . files . add ( new ProjectFile ( "gwt/war/index" , "gwt/webapp/index.html" , true ) ) ; project . files . add ( new ProjectFile ( "gwt/war/soundmanager2-jsmin.js" , "gwt/webapp/soundmanager2-jsmin.js" , false ) ) ; project . files . add ( new ProjectFile ( "gwt/war/soundmanager2-setup.js" , "gwt/webapp/soundmanager2-setup.js" , false ) ) ; project . files . add ( new ProjectFile ( "gwt/war/WEB-INF/web.xml" , "gwt/webapp/WEB-INF/web.xml" , true ) ) ; project . files . add ( new ProjectFile ( "ios/src/IOSLauncher" , ( ( "ios/src/" + packageDir ) + "/IOSLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "ios/build.gradle" , true ) ) ; project . files . add ( new ProjectFile ( "ios/Info.plist.xml" , false ) ) ; project . files . add ( new ProjectFile ( "ios/robovm.properties" ) ) ; project . files . add ( new ProjectFile ( "ios/robovm.xml" , false ) ) ; Map < String , String > values = new HashMap < String , String > ( ) ; values . put ( "%APP_NAME%" , appName ) ; values . put ( "%PACKAGE%" , packageName ) ; values . put ( "%MAIN_CLASS%" , mainClass ) ; copyAndReplace ( outputDir , project , values ) ; new File ( outputDir , "gradlew" ) . setExecutable ( true ) ; } private void copyAndReplace ( String outputDir , Project project , Map < String , String > values ) { } private byte [ ] readResource ( String resource ) { } private String readResourceAsString ( String resource ) { } private void writeFile ( File outFile , byte [ ] bytes ) { } private void writeFile ( File outFile , String text ) { } private void copyFile ( ProjectFile file , File out , Map < String , String > values ) { } private String replace ( String txt , Map < String , String > values ) { } private static void printHelp ( ) { } private static Map < String , String > parseArgs ( String [ ] args ) { } public static void main ( String [ ] args ) { } }<BUG2FIX>project . files . add ( new ProjectFile ( "android/build.gradle" , true ) ) ;
public class SimpleAnimationTest extends GdxTest implements InputProcessor { @ Override public boolean needsGL20 ( ) { } private Animation currentWalk ; private float currentFrameTime ; private Vector2 position ; private Texture tex ; private Animation downWalk ; private Animation leftWalk ; private Animation rightWalk ; private Animation upWalk ; private SpriteBatch spriteBatch ; private static final float ANIMATION_SPEED = 0.2F ; @ Override public void create ( ) { } @ Override public void render ( ) { } @ Override public boolean touchDown ( int x , int y , int pointer , int button ) { position . x = x ; <START_BUG> position . y = ( - y ) + 48 ; <END_BUG> return true ; } @ Override public boolean keyDown ( int keycode ) { } @ Override public boolean keyUp ( int keycode ) { } @ Override public boolean keyTyped ( char character ) { } @ Override public boolean touchUp ( int x , int y , int pointer , int button ) { } @ Override public boolean touchDragged ( int x , int y , int pointer ) { } @ Override public boolean touchMoved ( int x , int y ) { } @ Override public boolean scrolled ( int amount ) { } }<BUG2FIX>position . y = y ;
public class MatchQuery { public static enum Type { BOOLEAN , PHRASE , PHRASE_PREFIX ; } public static enum ZeroTermsQuery { NONE , ALL ; } protected final QueryParseContext parseContext ; protected String analyzer ; protected Occur occur = Occur . SHOULD ; protected boolean enablePositionIncrements = true ; protected int phraseSlop = 0 ; protected Fuzziness fuzziness = null ; protected int fuzzyPrefixLength = FuzzyQuery . defaultPrefixLength ; protected int maxExpansions = FuzzyQuery . defaultMaxExpansions ; protected boolean transpositions = false ; protected RewriteMethod rewriteMethod ; protected RewriteMethod fuzzyRewriteMethod ; protected boolean lenient ; protected MatchQuery . ZeroTermsQuery zeroTermsQuery = MatchQuery . ZeroTermsQuery . NONE ; protected Float commonTermsCutoff = null ; public MatchQuery ( QueryParseContext parseContext ) { } public void setAnalyzer ( String analyzer ) { } public void setOccur ( BooleanClause . Occur occur ) { } public void setCommonTermsCutoff ( float cutoff ) { } public void setEnablePositionIncrements ( boolean enablePositionIncrements ) { } public void setPhraseSlop ( int phraseSlop ) { } public void setFuzziness ( Fuzziness fuzziness ) { } public void setFuzzyPrefixLength ( int fuzzyPrefixLength ) { } public void setMaxExpansions ( int maxExpansions ) { } public void setTranspositions ( boolean transpositions ) { } public void setRewriteMethod ( MultiTermQuery . RewriteMethod rewriteMethod ) { } public void setFuzzyRewriteMethod ( MultiTermQuery . RewriteMethod fuzzyRewriteMethod ) { } public void setLenient ( boolean lenient ) { } public void setZeroTermsQuery ( MatchQuery . ZeroTermsQuery zeroTermsQuery ) { } protected boolean forceAnalyzeQueryString ( ) { } protected Analyzer getAnalyzer ( FieldMapper mapper , MapperService . SmartNameFieldMappers smartNameFieldMappers ) { } public Query parse ( MatchQuery . Type type , String fieldName , Object value ) throws IOException { } protected Query zeroTermsQuery ( ) { } private class MatchQueryBuilder extends QueryBuilder { private final FieldMapper mapper ; public MatchQueryBuilder ( Analyzer analyzer , @ Nullable FieldMapper mapper ) { } @ Override protected Query newTermQuery ( Term term ) { } public Query createPhrasePrefixQuery ( String field , String queryText , int phraseSlop , int maxExpansions ) { } public Query createCommonTermsQuery ( String field , String queryText , Occur highFreqOccur , Occur lowFreqOccur , float maxTermFrequency , FieldMapper < ? > mapper ) { <START_BUG> Query booleanQuery = createBooleanQuery ( field , queryText , SHOULD ) ; <END_BUG> if ( ( booleanQuery != null ) && ( booleanQuery instanceof BooleanQuery ) ) { BooleanQuery bq = ( ( BooleanQuery ) ( booleanQuery ) ) ; ExtendedCommonTermsQuery query = new ExtendedCommonTermsQuery ( highFreqOccur , lowFreqOccur , maxTermFrequency , ( ( BooleanQuery ) ( booleanQuery ) ) . isCoordDisabled ( ) , mapper ) ; for ( BooleanClause clause : bq . clauses ( ) ) { if ( ! ( ( clause . getQuery ( ) ) instanceof TermQuery ) ) { return booleanQuery ; } query . add ( ( ( TermQuery ) ( clause . getQuery ( ) ) ) . getTerm ( ) ) ; } return query ; } return booleanQuery ; } } protected Query blendTermQuery ( Term term , FieldMapper mapper ) { } }<BUG2FIX>Query booleanQuery = createBooleanQuery ( field , queryText , lowFreqOccur ) ;
public class TextButtonTestGL2 extends TextButtonTest { @ Override public boolean needsGL20 ( ) { <START_BUG> return super . needsGL20 ( ) ; <END_BUG> } }<BUG2FIX>return true ;
public class HasChildFilterParser implements FilterParser { public static final String NAME = "has_child" ; @ Inject public HasChildFilterParser ( ) { } @ Override public String [ ] names ( ) { } @ Override public Filter parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; Query query = null ; String childType = null ; String scope = null ; String filterName = null ; String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_OBJECT ) ) { if ( "query" . equals ( currentFieldName ) ) { query = parseContext . parseInnerQuery ( ) ; } } else if ( token . isValue ( ) ) { if ( "type" . equals ( currentFieldName ) ) { childType = parser . text ( ) ; } else if ( "_scope" . equals ( currentFieldName ) ) { scope = parser . text ( ) ; } else if ( "_name" . equals ( currentFieldName ) ) { filterName = parser . text ( ) ; } } } if ( query == null ) { throw new QueryParsingException ( parseContext . index ( ) , "[child]<seq2seq4repair_space>filter<seq2seq4repair_space>requires<seq2seq4repair_space>'query'<seq2seq4repair_space>field" ) ; } if ( childType == null ) { throw new QueryParsingException ( parseContext . index ( ) , "[child]<seq2seq4repair_space>filter<seq2seq4repair_space>requires<seq2seq4repair_space>'type'<seq2seq4repair_space>field" ) ; } DocumentMapper childDocMapper = parseContext . mapperService ( ) . documentMapper ( childType ) ; if ( childDocMapper == null ) { throw new QueryParsingException ( parseContext . index ( ) , ( ( "No<seq2seq4repair_space>mapping<seq2seq4repair_space>for<seq2seq4repair_space>for<seq2seq4repair_space>type<seq2seq4repair_space>[" + childType ) + "]" ) ) ; } if ( ( childDocMapper . parentFieldMapper ( ) ) == null ) { throw new QueryParsingException ( parseContext . index ( ) , ( ( "Type<seq2seq4repair_space>[" + childType ) + "]<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>have<seq2seq4repair_space>parent<seq2seq4repair_space>mapping" ) ) ; } String parentType = childDocMapper . parentFieldMapper ( ) . type ( ) ; <START_BUG> query = new org . apache . lucene . search . FilteredQuery ( query , parseContext . cacheFilter ( childDocMapper . typeFilter ( ) ) ) ; <END_BUG> SearchContext searchContext = SearchContext . current ( ) ; HasChildFilter childFilter = new HasChildFilter ( query , scope , childType , parentType , searchContext ) ; searchContext . addScopePhase ( childFilter ) ; if ( filterName != null ) { parseContext . addNamedFilter ( filterName , childFilter ) ; } return childFilter ; } }<BUG2FIX>query = new org . apache . lucene . search . FilteredQuery ( query , parseContext . cacheFilter ( childDocMapper . typeFilter ( ) , null ) ) ;
public class UserNewsFragment extends ListLoadingFragment < Event > { @ InjectExtra ( EXTRA_USER ) private User user ; @ Inject private EventService service ; @ Override public Loader < List < Event > > onCreateLoader ( int id , Bundle bundle ) { return new com . github . mobile . android . ThrowableLoader < List < Event > > ( getActivity ( ) , listItems ) { public List < Event > loadData ( ) throws Exception { try { List < Event > events = new ArrayList < Event > ( service . pageUserReceivedEvents ( user . getLogin ( ) , false ) . next ( ) ) ; Iterator < Event > iter = events . iterator ( ) ; while ( iter . hasNext ( ) ) <START_BUG> if ( ! ( NewsEventViewHolder . isValid ( iter . next ( ) . getType ( ) ) ) ) <END_BUG> iter . remove ( ) ; return events ; } catch ( NoSuchPageException e ) { throw e . getCause ( ) ; } } } ; } @ Override protected ViewHoldingListAdapter < Event > adapterFor ( List < Event > items ) { } }<BUG2FIX>if ( ! ( NewsEventViewHolder . isValid ( iter . next ( ) ) ) )
public class SortParseElement implements SearchParseElement { private static final SortField SORT_SCORE = new SortField ( null , SortField . SCORE ) ; private static final SortField SORT_SCORE_REVERSE = new SortField ( null , SortField . SCORE , true ) ; private static final SortField SORT_DOC = new SortField ( null , SortField . DOC ) ; private static final SortField SORT_DOC_REVERSE = new SortField ( null , SortField . DOC , true ) ; public static final String SCORE_FIELD_NAME = "_score" ; public static final String DOC_FIELD_NAME = "_doc" ; private final ImmutableMap < String , SortParser > parsers ; public SortParseElement ( ) { } private void addParser ( Builder < String , SortParser > parsers , SortParser parser ) { } @ Override public void parse ( XContentParser parser , SearchContext context ) throws Exception { } private void addCompoundSortField ( XContentParser parser , SearchContext context , List < SortField > sortFields ) throws Exception { } private void addSortField ( SearchContext context , List < SortField > sortFields , String fieldName , boolean reverse , @ Nullable final String missing ) { if ( SortParseElement . SCORE_FIELD_NAME . equals ( fieldName ) ) { if ( reverse ) { sortFields . add ( SortParseElement . SORT_SCORE_REVERSE ) ; } else { sortFields . add ( SortParseElement . SORT_SCORE ) ; } } else if ( SortParseElement . DOC_FIELD_NAME . equals ( fieldName ) ) { if ( reverse ) { sortFields . add ( SortParseElement . SORT_DOC_REVERSE ) ; } else { sortFields . add ( SortParseElement . SORT_DOC ) ; } } else { <START_BUG> FieldMapper fieldMapper = context . mapperService ( ) . smartNameFieldMapper ( fieldName ) ; <END_BUG> if ( fieldMapper == null ) { throw new org . elasticsearch . search . SearchParseException ( context , ( ( "No<seq2seq4repair_space>mapping<seq2seq4repair_space>found<seq2seq4repair_space>for<seq2seq4repair_space>[" + fieldName ) + "]" ) ) ; } sortFields . add ( new SortField ( fieldMapper . names ( ) . indexName ( ) , fieldMapper . fieldDataType ( ) . newFieldComparatorSource ( context . fieldDataCache ( ) , missing ) , reverse ) ) ; } } }<BUG2FIX>FieldMapper fieldMapper = context . smartNameFieldMapper ( fieldName ) ;
public class GeoDistanceParser implements Aggregator . Parser { @ Override public String type ( ) { } private static String key ( String key , double from , double to ) { } @ Override public AggregatorFactory parse ( String aggregationName , XContentParser parser , SearchContext context ) throws IOException { String field = null ; List < RangeAggregator . Range > ranges = null ; GeoPoint origin = null ; <START_BUG> DistanceUnit unit = DistanceUnit . KILOMETERS ; <END_BUG> GeoDistance distanceType = GeoDistance . DEFAULT ; boolean keyed = false ; XContentParser . Token token ; String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . VALUE_STRING ) ) { if ( "field" . equals ( currentFieldName ) ) { field = parser . text ( ) ; } else if ( "unit" . equals ( currentFieldName ) ) { unit = DistanceUnit . fromString ( parser . text ( ) ) ; } else if ( ( "distance_type" . equals ( currentFieldName ) ) || ( "distanceType" . equals ( currentFieldName ) ) ) { distanceType = GeoDistance . fromString ( parser . text ( ) ) ; } else if ( ( ( "point" . equals ( currentFieldName ) ) || ( "origin" . equals ( currentFieldName ) ) ) || ( "center" . equals ( currentFieldName ) ) ) { origin = new GeoPoint ( ) ; origin . resetFromString ( parser . text ( ) ) ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( ( ( "Unknown<seq2seq4repair_space>key<seq2seq4repair_space>for<seq2seq4repair_space>a<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>[" ) + aggregationName ) + "]:<seq2seq4repair_space>[" ) + currentFieldName ) + "]." ) ) ; } } else if ( token == ( Token . VALUE_BOOLEAN ) ) { if ( "keyed" . equals ( currentFieldName ) ) { keyed = parser . booleanValue ( ) ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( ( ( "Unknown<seq2seq4repair_space>key<seq2seq4repair_space>for<seq2seq4repair_space>a<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>[" ) + aggregationName ) + "]:<seq2seq4repair_space>[" ) + currentFieldName ) + "]." ) ) ; } } else if ( token == ( Token . START_ARRAY ) ) { if ( "ranges" . equals ( currentFieldName ) ) { ranges = new ArrayList < RangeAggregator . Range > ( ) ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_ARRAY ) ) { String fromAsStr = null ; String toAsStr = null ; double from = 0.0 ; double to = Double . POSITIVE_INFINITY ; String key = null ; String toOrFromOrKey = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { toOrFromOrKey = parser . currentName ( ) ; } else if ( token == ( Token . VALUE_NUMBER ) ) { if ( "from" . equals ( toOrFromOrKey ) ) { from = parser . doubleValue ( ) ; } else if ( "to" . equals ( toOrFromOrKey ) ) { to = parser . doubleValue ( ) ; } } else if ( token == ( Token . VALUE_STRING ) ) { if ( "key" . equals ( toOrFromOrKey ) ) { key = parser . text ( ) ; } else if ( "from" . equals ( toOrFromOrKey ) ) { fromAsStr = parser . text ( ) ; } else if ( "to" . equals ( toOrFromOrKey ) ) { toAsStr = parser . text ( ) ; } } } ranges . add ( new RangeAggregator . Range ( GeoDistanceParser . key ( key , from , to ) , from , fromAsStr , to , toAsStr ) ) ; } } else if ( ( ( "point" . equals ( currentFieldName ) ) || ( "origin" . equals ( currentFieldName ) ) ) || ( "center" . equals ( currentFieldName ) ) ) { double lat = Double . NaN ; double lon = Double . NaN ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_ARRAY ) ) { if ( Double . isNaN ( lon ) ) { lon = parser . doubleValue ( ) ; } else if ( Double . isNaN ( lat ) ) { lat = parser . doubleValue ( ) ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( "malformed<seq2seq4repair_space>[origin]<seq2seq4repair_space>geo<seq2seq4repair_space>point<seq2seq4repair_space>array<seq2seq4repair_space>in<seq2seq4repair_space>geo_distance<seq2seq4repair_space>aggregator<seq2seq4repair_space>[" + aggregationName ) + "].<seq2seq4repair_space>" ) + "a<seq2seq4repair_space>geo<seq2seq4repair_space>point<seq2seq4repair_space>array<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>of<seq2seq4repair_space>the<seq2seq4repair_space>form<seq2seq4repair_space>[lon,<seq2seq4repair_space>lat]" ) ) ; } } origin = new GeoPoint ( lat , lon ) ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( ( ( "Unknown<seq2seq4repair_space>key<seq2seq4repair_space>for<seq2seq4repair_space>a<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>[" ) + aggregationName ) + "]:<seq2seq4repair_space>[" ) + currentFieldName ) + "]." ) ) ; } } else if ( token == ( Token . START_OBJECT ) ) { if ( ( ( "point" . equals ( currentFieldName ) ) || ( "origin" . equals ( currentFieldName ) ) ) || ( "center" . equals ( currentFieldName ) ) ) { double lat = Double . NaN ; double lon = Double . NaN ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . VALUE_NUMBER ) ) { if ( "lat" . equals ( currentFieldName ) ) { lat = parser . doubleValue ( ) ;<BUG2FIX>DistanceUnit unit = DistanceUnit . DEFAULT ;
public class DoubleValuesComparatorSource extends IndexFieldData . XFieldComparatorSource { private final IndexNumericFieldData indexFieldData ; private final Object missingValue ; public DoubleValuesComparatorSource ( IndexNumericFieldData indexFieldData , @ Nullable Object missingValue ) { } @ Override public Type reducedType ( ) { } @ Override public FieldComparator < ? > newComparator ( String fieldname , int numHits , int sortPos , boolean reversed ) throws IOException { assert fieldname . equals ( indexFieldData . getFieldNames ( ) . indexName ( ) ) ; double dMissingValue ; if ( ( ( missingValue ) == null ) || ( "_last" . equals ( missingValue ) ) ) { dMissingValue = ( reversed ) ? Double . NEGATIVE_INFINITY : Double . POSITIVE_INFINITY ; } else if ( "_first" . equals ( missingValue ) ) { dMissingValue = ( reversed ) ? Double . POSITIVE_INFINITY : Double . NEGATIVE_INFINITY ; } else { dMissingValue = ( ( missingValue ) instanceof Number ) ? ( ( Number ) ( missingValue ) ) . doubleValue ( ) : Double . parseDouble ( missingValue . toString ( ) ) ; } <START_BUG> return new DoubleValuesComparator ( indexFieldData , dMissingValue , numHits ) ; <END_BUG> } }<BUG2FIX>return new DoubleValuesComparator ( indexFieldData , dMissingValue , numHits , reversed ) ;
public class NewsListAdapter extends ItemListAdapter < Event , NewsItemView > { public static boolean isValid ( final Event event ) { } private static void appendComment ( final StyledText details , final Comment comment ) { } private static void appendCommitComment ( final StyledText details , final CommitComment comment ) { } private static void appendText ( final StyledText details , String text ) { } private static void formatCommitComment ( Event event , StyledText main , StyledText details ) { } private static void formatDownload ( Event event , StyledText main , StyledText details ) { } private static void formatCreate ( Event event , StyledText main , StyledText details ) { main . bold ( event . getActor ( ) . getLogin ( ) ) ; main . append ( "<seq2seq4repair_space>created<seq2seq4repair_space>" ) ; CreatePayload payload = ( ( CreatePayload ) ( event . getPayload ( ) ) ) ; String refType = payload . getRefType ( ) ; main . append ( refType ) ; main . append ( '<seq2seq4repair_space>' ) ; String repoName = event . getRepo ( ) . getName ( ) ; if ( ! ( "repository" . equals ( refType ) ) ) { main . append ( payload . getRef ( ) ) ; main . append ( "<seq2seq4repair_space>at<seq2seq4repair_space>" ) ; } else repoName = repoName . substring ( ( ( repoName . indexOf ( '/' ) ) + 1 ) ) ; <START_BUG> main . bold ( event . getRepo ( ) . getName ( ) ) ; <END_BUG> } private static void formatDelete ( Event event , StyledText main , StyledText details ) { } private static void formatFollow ( Event event , StyledText main , StyledText details ) { } private static void formatFork ( Event event , StyledText main , StyledText details ) { } private static void formatGist ( Event event , StyledText main , StyledText details ) { } private static void formatWiki ( Event event , StyledText main , StyledText details ) { } private static void formatIssueComment ( Event event , StyledText main , StyledText details ) { } private static void formatIssues ( Event event , StyledText main , StyledText details ) { } private static void formatAddMember ( Event event , StyledText main , StyledText details ) { } private static void formatPublic ( Event event , StyledText main , StyledText details ) { } private static void formatWatch ( Event event , StyledText main , StyledText details ) { } private static void formatReviewComment ( Event event , StyledText main , StyledText details ) { } private static void formatPullRequest ( Event event , StyledText main , StyledText details ) { } private static void formatPush ( Event event , StyledText main , StyledText details ) { } private static void formatTeamAdd ( Event event , StyledText main , StyledText details ) { } private final AvatarLoader avatars ; public NewsListAdapter ( LayoutInflater inflater , Event [ ] elements , AvatarLoader avatars ) { } public NewsListAdapter ( LayoutInflater inflater , AvatarLoader avatars ) { } @ Override public long getItemId ( final int position ) { } @ Override protected void update ( final int position , final NewsItemView view , final Event event ) { } @ Override protected NewsItemView createView ( final View view ) { } }<BUG2FIX>main . bold ( repoName ) ;
public class GdxSetup { public void build ( String outputDir , String appName , String packageName , String mainClass ) { Project project = new Project ( ) ; String packageDir = packageName . replace ( '.' , '/' ) ; project . files . add ( new ProjectFile ( "build.gradle" , true ) ) ; project . files . add ( new ProjectFile ( "settings.gradle" ) ) ; project . files . add ( new ProjectFile ( "gradlew" , false ) ) ; project . files . add ( new ProjectFile ( "gradlew.bat" , false ) ) ; project . files . add ( new ProjectFile ( "gradle/wrapper/gradle-wrapper.jar" , false ) ) ; project . files . add ( new ProjectFile ( "gradle/wrapper/gradle-wrapper.properties" , false ) ) ; project . files . add ( new ProjectFile ( "core/build.gradle" ) ) ; project . files . add ( new ProjectFile ( "core/src/MainClass" , ( ( ( ( "core/src/" + packageDir ) + "/" ) + mainClass ) + ".java" ) , true ) ) ; project . files . add ( new ProjectFile ( "core/CoreGdxDefinition" , ( ( ( ( "core/src/" + packageDir ) + "/" ) + mainClass ) + ".gwt.xml" ) , true ) ) ; project . files . add ( new ProjectFile ( "desktop/build.gradle" ) ) ; project . files . add ( new ProjectFile ( "desktop/src/DesktopLauncher" , ( ( "desktop/src/" + packageDir ) + "/desktop/DesktopLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "android/assets/badlogic.jpg" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/values/strings.xml" ) ) ; project . files . add ( new ProjectFile ( "android/res/values/styles.xml" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-hdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-mdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-xhdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-xxhdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/src/AndroidLauncher" , ( ( "android/src/" + packageDir ) + "/android/AndroidLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "android/AndroidManifest.xml" ) ) ; project . files . add ( new ProjectFile ( "android/build.gradle" ) ) ; project . files . add ( new ProjectFile ( "android/ic_launcher-web.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/proguard-project.txt" , false ) ) ; project . files . add ( new ProjectFile ( "android/project.properties" , false ) ) ; project . files . add ( new ProjectFile ( "gwt/build.gradle" ) ) ; project . files . add ( new ProjectFile ( "gwt/src/GwtLauncher" , ( ( "gwt/src/" + packageDir ) + "/client/GwtLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "gwt/GdxDefinition" , ( ( "gwt/src/" + packageDir ) + "/GdxDefinition.gwt.xml" ) , true ) ) ; project . files . add ( new ProjectFile ( "gwt/war/index" , ( "gwt/webapp/" + "index.html" ) , true ) ) ; project . files . add ( new ProjectFile ( "gwt/war/WEB-INF/web.xml" , "gwt/webapp/WEB-INF/web.xml" , true ) ) ; project . files . add ( new ProjectFile ( "ios/src/IOSLauncher" , ( ( "ios/src/" + packageDir ) + "/IOSLauncher.java" ) , true ) ) ; <START_BUG> project . files . add ( new ProjectFile ( "ios/build.gradle" , false ) ) ; <END_BUG> project . files . add ( new ProjectFile ( "ios/Info.plist.xml" , false ) ) ; project . files . add ( new ProjectFile ( "ios/robovm.properties" ) ) ; project . files . add ( new ProjectFile ( "ios/robovm.xml" , false ) ) ; Map < String , String > values = new HashMap < String , String > ( ) ; values . put ( "%APP_NAME%" , appName ) ; values . put ( "%PACKAGE%" , packageName ) ; values . put ( "%MAIN_CLASS%" , mainClass ) ; copyAndReplace ( outputDir , project , values ) ; new File ( outputDir , "gradlew" ) . setExecutable ( true ) ; } private void copyAndReplace ( String outputDir , Project project , Map < String , String > values ) { } private byte [ ] readResource ( String resource ) { } private String readResourceAsString ( String resource ) { } private void writeFile ( File outFile , byte [ ] bytes ) { } private void writeFile ( File outFile , String text ) { } private void copyFile ( ProjectFile file , File out , Map < String , String > values ) { } private String replace ( String txt , Map < String , String > values ) { } private static void printHelp ( ) { } private static Map < String , String > parseArgs ( String [ ] args ) { } public static void main ( String [ ] args ) { } }<BUG2FIX>project . files . add ( new ProjectFile ( "ios/build.gradle" , true ) ) ;
public class MultiPhrasePrefixQuery extends Query { private String field ; private ArrayList < Term [ ] > termArrays = new ArrayList < Term [ ] > ( ) ; private ArrayList < Integer > positions = new ArrayList < Integer > ( ) ; private int maxExpansions = Integer . MAX_VALUE ; private int slop = 0 ; public void setSlop ( int s ) { } public void setMaxExpansions ( int maxExpansions ) { } public int getSlop ( ) { } public void add ( Term term ) { } public void add ( Term [ ] terms ) { } public void add ( Term [ ] terms , int position ) { } public List < Term [ ] > getTermArrays ( ) { } public int [ ] getPositions ( ) { } @ Override public Query rewrite ( IndexReader reader ) throws IOException { } private void getPrefixTerms ( List < Term > terms , final Term prefix , final IndexReader reader ) throws IOException { TermEnum enumerator = reader . terms ( prefix ) ; try { do { Term term = enumerator . term ( ) ; if ( ( ( term != null ) && ( term . text ( ) . startsWith ( prefix . text ( ) ) ) ) && ( term . field ( ) . equals ( field ) ) ) { terms . add ( term ) ; } else { break ; } <START_BUG> if ( ( terms . size ( ) ) > ( maxExpansions ) ) { <END_BUG> break ; } } while ( enumerator . next ( ) ) ; } finally { enumerator . close ( ) ; } } @ Override public final String toString ( String f ) { } @ Override public boolean equals ( Object o ) { } @ Override public int hashCode ( ) { } private int termArraysHashCode ( ) { } private boolean termArraysEquals ( List < Term [ ] > termArrays1 , List < Term [ ] > termArrays2 ) { } }<BUG2FIX>if ( ( terms . size ( ) ) >= ( maxExpansions ) ) {
public class TopChildrenQueryParser implements QueryParser { public static final String NAME = "top_children" ; @ Inject public TopChildrenQueryParser ( ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; Query query = null ; float boost = 1.0F ; String childType = null ; String scope = null ; TopChildrenQuery . ScoreType scoreType = ScoreType . MAX ; int factor = 5 ; int incrementalFactor = 2 ; String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_OBJECT ) ) { if ( "query" . equals ( currentFieldName ) ) { query = parseContext . parseInnerQuery ( ) ; } } else if ( token . isValue ( ) ) { if ( "type" . equals ( currentFieldName ) ) { childType = parser . text ( ) ; } else if ( "_scope" . equals ( currentFieldName ) ) { scope = parser . text ( ) ; } else if ( "score" . equals ( currentFieldName ) ) { scoreType = ScoreType . fromString ( parser . text ( ) ) ; } else if ( "boost" . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } else if ( "factor" . equals ( currentFieldName ) ) { factor = parser . intValue ( ) ; } else if ( ( "incremental_factor" . equals ( currentFieldName ) ) || ( "incrementalFactor" . equals ( currentFieldName ) ) ) { incrementalFactor = parser . intValue ( ) ; } } } if ( query == null ) { throw new QueryParsingException ( parseContext . index ( ) , "[child]<seq2seq4repair_space>requires<seq2seq4repair_space>'query'<seq2seq4repair_space>field" ) ; } if ( childType == null ) { throw new QueryParsingException ( parseContext . index ( ) , "[child]<seq2seq4repair_space>requires<seq2seq4repair_space>'type'<seq2seq4repair_space>field" ) ; } DocumentMapper childDocMapper = parseContext . mapperService ( ) . documentMapper ( childType ) ; if ( childDocMapper == null ) { throw new QueryParsingException ( parseContext . index ( ) , ( ( "No<seq2seq4repair_space>mapping<seq2seq4repair_space>for<seq2seq4repair_space>for<seq2seq4repair_space>type<seq2seq4repair_space>[" + childType ) + "]" ) ) ; } if ( ( childDocMapper . parentFieldMapper ( ) ) == null ) { throw new QueryParsingException ( parseContext . index ( ) , ( ( "Type<seq2seq4repair_space>[" + childType ) + "]<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>have<seq2seq4repair_space>parent<seq2seq4repair_space>mapping" ) ) ; } String parentType = childDocMapper . parentFieldMapper ( ) . type ( ) ; query . setBoost ( boost ) ; <START_BUG> query = new org . apache . lucene . search . FilteredQuery ( query , parseContext . cacheFilter ( childDocMapper . typeFilter ( ) ) ) ; <END_BUG> SearchContext searchContext = SearchContext . current ( ) ; TopChildrenQuery childQuery = new TopChildrenQuery ( query , scope , childType , parentType , scoreType , factor , incrementalFactor ) ; searchContext . addScopePhase ( childQuery ) ; return childQuery ; } }<BUG2FIX>query = new org . apache . lucene . search . FilteredQuery ( query , parseContext . cacheFilter ( childDocMapper . typeFilter ( ) , null ) ) ;
public abstract class NewsFragment extends PagedItemFragment < Event > { protected final IssueEventMatcher issueMatcher = new IssueEventMatcher ( ) ; protected final GistEventMatcher gistMatcher = new GistEventMatcher ( ) ; protected final RepositoryEventMatcher repoMatcher = new RepositoryEventMatcher ( ) ; protected final UserEventMatcher userMatcher = new UserEventMatcher ( ) ; @ Inject private AvatarLoader avatars ; @ Inject protected EventService service ; @ Override public void onActivityCreated ( Bundle savedInstanceState ) { } @ Override public void onListItemClick ( ListView l , View v , int position , long id ) { Event event = ( ( Event ) ( l . getItemAtPosition ( position ) ) ) ; if ( TYPE_DOWNLOAD . equals ( event . getType ( ) ) ) { openDownload ( event ) ; return ; } Issue issue = issueMatcher . getIssue ( event ) ; <START_BUG> if ( ! ( IssueUtils . isPullRequest ( issue ) ) ) { <END_BUG> viewIssue ( issue ) ; return ; } Gist gist = gistMatcher . getGist ( event ) ; if ( gist != null ) { startActivity ( GistsViewActivity . createIntent ( gist ) ) ; return ; } Repository repo = repoMatcher . getRepository ( event ) ; if ( repo != null ) viewRepository ( repo ) ; UserPair users = userMatcher . getUsers ( event ) ; if ( users != null ) viewUser ( users ) ; } private void openDownload ( Event event ) { } protected void viewRepository ( Repository repository ) { } protected void viewUser ( UserPair users ) { } protected void viewIssue ( Issue issue ) { } @ Override protected ItemListAdapter < Event , ? extends ItemView > createAdapter ( List < Event > items ) { } @ Override protected int getLoadingMessage ( ) { } @ Override protected int getErrorMessage ( Exception exception ) { } }<BUG2FIX>if ( ( issue != null ) && ( ! ( IssueUtils . isPullRequest ( issue ) ) ) ) {
public class Bresenham2 { private final Array < GridPoint2 > points = new Array < GridPoint2 > ( ) ; private final Pool < GridPoint2 > pool = new Pool < GridPoint2 > ( ) { @ Override protected GridPoint2 newObject ( ) { } } ; public Array < GridPoint2 > line ( GridPoint2 start , GridPoint2 end ) { <START_BUG> return line ( start . x , start . y , end . x , end . y ) ; <END_BUG> } public Array < GridPoint2 > line ( int startX , int startY , int endX , int endY ) { } public Array < GridPoint2 > line ( int startX , int startY , int endX , int endY , Pool < GridPoint2 > pool , Array < GridPoint2 > output ) { } }<BUG2FIX>return line ( start . x , start . y , end . y , end . y ) ;
public class GestureDetector extends InputAdapter { final GestureDetector . GestureListener listener ; private float tapSquareSize ; private long tapCountInterval ; private float longPressSeconds ; private long maxFlingDelay ; private boolean inTapSquare ; private int tapCount ; private long lastTapTime ; private float lastTapX ; private float lastTapY ; private int lastTapButton ; private int lastTapPointer ; boolean longPressFired ; private boolean pinching ; private boolean panning ; private final GestureDetector . VelocityTracker tracker = new GestureDetector . VelocityTracker ( ) ; private float tapSquareCenterX ; private float tapSquareCenterY ; private long gestureStartTime ; Vector2 pointer1 = new Vector2 ( ) ; private final Vector2 pointer2 = new Vector2 ( ) ; private final Vector2 initialPointer1 = new Vector2 ( ) ; private final Vector2 initialPointer2 = new Vector2 ( ) ; private final Task longPressTask = new Task ( ) { @ Override public void run ( ) { } } ; public GestureDetector ( GestureDetector . GestureListener listener ) { } public GestureDetector ( float halfTapSquareSize , float tapCountInterval , float longPressDuration , float maxFlingDelay , GestureDetector . GestureListener listener ) { } @ Override public boolean touchDown ( int x , int y , int pointer , int button ) { } public boolean touchDown ( float x , float y , int pointer , int button ) { } @ Override public boolean touchDragged ( int x , int y , int pointer ) { } public boolean touchDragged ( float x , float y , int pointer ) { } @ Override public boolean touchUp ( int x , int y , int pointer , int button ) { } public boolean touchUp ( float x , float y , int pointer , int button ) { } public void cancel ( ) { } public boolean isLongPressed ( ) { } public boolean isLongPressed ( float duration ) { } public boolean isPanning ( ) { } public void reset ( ) { } private boolean isWithinTapSquare ( float x , float y , float centerX , float centerY ) { } public void invalidateTapSquare ( ) { } <START_BUG> public void setTapSquareSize ( float tapSquareSize ) { <END_BUG> this . tapSquareSize = tapSquareSize ; } public void setTapCountInterval ( float tapCountInterval ) { } public void setLongPressSeconds ( float longPressSeconds ) { } public void setMaxFlingDelay ( long maxFlingDelay ) { } public static interface GestureListener { public boolean touchDown ( float x , float y , int pointer , int button ) { } public boolean tap ( float x , float y , int count , int button ) { } public boolean longPress ( float x , float y ) { } public boolean fling ( float velocityX , float velocityY , int button ) { } public boolean pan ( float x , float y , float deltaX , float deltaY ) { } public boolean panStop ( float x , float y , int pointer , int button ) { } public boolean zoom ( float initialDistance , float distance ) { } public boolean pinch ( Vector2 initialPointer1 , Vector2 initialPointer2 , Vector2 pointer1 , Vector2 pointer2 ) { } } public static class GestureAdapter implements GestureDetector . GestureListener { @ Override public boolean touchDown ( float x , float y , int pointer , int button ) { } @ Override public boolean tap ( float x , float y , int count , int button ) { } @ Override public boolean longPress ( float x , float y ) { } @ Override public boolean fling ( float velocityX , float velocityY , int button ) { } @ Override public boolean pan ( float x , float y , float deltaX , float deltaY ) { } @ Override public boolean panStop ( float x , float y , int pointer , int button ) { } @ Override public boolean zoom ( float initialDistance , float distance ) { } @ Override public boolean pinch ( Vector2 initialPointer1 , Vector2 initialPointer2 , Vector2 pointer1 , Vector2 pointer2 ) { } } static class VelocityTracker { int sampleSize = 10 ; float lastX ; float lastY ; float deltaX ; float deltaY ; long lastTime ; int numSamples ; float [ ] meanX = new float [ sampleSize ] ; float [ ] meanY = new float [ sampleSize ] ; long [ ] meanTime = new long [ sampleSize ] ; public void start ( float x , float y , long timeStamp ) { } public void update ( float x , float y , long timeStamp ) { } public float getVelocityX ( ) { } public float getVelocityY ( ) { } private float getAverage ( float [ ] values , int numSamples ) { } private long getAverage ( long [ ] values , int numSamples ) { } private float getSum ( float [ ] values , int numSamples ) { } } }<BUG2FIX>public void setTapSquareSize ( int tapSquareSize ) {
public class RestClusterUpdateSettingsAction extends BaseRestHandler { @ Inject public RestClusterUpdateSettingsAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { final ClusterUpdateSettingsRequest clusterUpdateSettingsRequest = Requests . clusterUpdateSettingsRequest ( ) ; clusterUpdateSettingsRequest . listenerThreaded ( false ) ; try { Map < String , Object > source = XContentFactory . xContent ( request . content ( ) ) . createParser ( request . content ( ) ) . mapAndClose ( ) ; if ( source . containsKey ( "transient" ) ) { clusterUpdateSettingsRequest . transientSettings ( ( ( Map ) ( source . get ( "transient" ) ) ) ) ; } if ( source . containsKey ( "persistent" ) ) { clusterUpdateSettingsRequest . persistentSettings ( ( ( Map ) ( source . get ( "persistent" ) ) ) ) ; } } catch ( Exception e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . warn ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>response" , e1 ) ; } return ; } client . admin ( ) . cluster ( ) . updateSettings ( clusterUpdateSettingsRequest , new org . elasticsearch . action . ActionListener < ClusterUpdateSettingsResponse > ( ) { @ Override public void onResponse ( ClusterUpdateSettingsResponse response ) { try { channel . sendResponse ( new StringRestResponse ( RestStatus . OK ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>handle<seq2seq4repair_space>cluster<seq2seq4repair_space>state" , e ) ; } try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class LwjglCanvas implements Application { LwjglGraphics graphics ; OpenALAudio audio ; LwjglFiles files ; LwjglInput input ; LwjglNet net ; ApplicationListener listener ; Canvas canvas ; final List < Runnable > runnables = new ArrayList ( ) ; final List < Runnable > executedRunnables = new ArrayList ( ) ; final Array < LifecycleListener > lifecycleListeners = new Array < LifecycleListener > ( ) ; boolean running = true ; int logLevel = LOG_INFO ; Cursor cursor ; public LwjglCanvas ( ApplicationListener listener , boolean useGL2 ) { } public LwjglCanvas ( ApplicationListener listener , LwjglApplicationConfiguration config ) { } private void initialize ( ApplicationListener listener , LwjglApplicationConfiguration config ) { } protected void setDisplayMode ( int width , int height ) { } protected void setTitle ( String title ) { } @ Override public ApplicationListener getApplicationListener ( ) { } public Canvas getCanvas ( ) { } @ Override public Audio getAudio ( ) { } @ Override public Files getFiles ( ) { } @ Override public Graphics getGraphics ( ) { } @ Override public Input getInput ( ) { } @ Override public Net getNet ( ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } void create ( ) { } protected int getFrameRate ( ) { int frameRate = ( Display . isActive ( ) ) ? graphics . config . foregroundFPS : graphics . config . backgroundFPS ; if ( frameRate == ( - 1 ) ) frameRate = 10 ; if ( frameRate == 0 ) frameRate = graphics . config . backgroundFPS ; if ( frameRate == 0 ) frameRate = 30 ; <START_BUG> return frameRate ; <END_BUG> } protected void exception ( Throwable ex ) { } protected void start ( ) { } protected void resize ( int width , int height ) { } protected void stopped ( ) { } public void stop ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } Map < String , Preferences > preferences = new HashMap < String , Preferences > ( ) ; @ Override public Preferences getPreferences ( String name ) { } @ Override public Clipboard getClipboard ( ) { } @ Override public void postRunnable ( Runnable runnable ) { } @ Override public void debug ( String tag , String message ) { } @ Override public void debug ( String tag , String message , Throwable exception ) { } public void log ( String tag , String message ) { } @ Override public void log ( String tag , String message , Exception exception ) { } @ Override public void error ( String tag , String message ) { } @ Override public void error ( String tag , String message , Throwable exception ) { } @ Override public void setLogLevel ( int logLevel ) { } @ Override public void exit ( ) { } public void setCursor ( Cursor cursor ) { } @ Override public void addLifecycleListener ( LifecycleListener listener ) { } @ Override public void removeLifecycleListener ( LifecycleListener listener ) { } }<BUG2FIX>return 0 ;
public abstract class NetworkUtils { private static final ESLogger logger = Loggers . getLogger ( NetworkUtils . class ) ; public static enum StackType { IPv4 , IPv6 , Unknown ; } public static final String IPv4_SETTING = "java.net.preferIPv4Stack" ; public static final String IPv6_SETTING = "java.net.preferIPv6Addresses" ; public static final String NON_LOOPBACK_ADDRESS = "non_loopback_address" ; private static final InetAddress localAddress ; public static Boolean defaultReuseAddress ( ) { } public static boolean isIPv4 ( ) { } public static InetAddress getIPv4Localhost ( ) throws UnknownHostException { } public static InetAddress getIPv6Localhost ( ) throws UnknownHostException { } public static InetAddress getLocalAddress ( ) { } public static InetAddress getLocalhost ( NetworkUtils . StackType ip_version ) throws UnknownHostException { } public static boolean canBindToMcastAddress ( ) { } public static InetAddress getFirstNonLoopbackAddress ( NetworkUtils . StackType ip_version ) throws SocketException { } public static InetAddress getFirstNonLoopbackAddress ( NetworkInterface intf , NetworkUtils . StackType ipVersion ) throws SocketException { } public static boolean interfaceHasIPAddresses ( NetworkInterface intf , NetworkUtils . StackType ipVersion ) throws SocketException , UnknownHostException { } public static NetworkUtils . StackType getIpStackType ( ) { } public static boolean isStackAvailable ( boolean ipv4 ) { } public static List < NetworkInterface > getAllAvailableInterfaces ( ) throws SocketException { List < NetworkInterface > allInterfaces = new ArrayList < NetworkInterface > ( ) ; for ( Enumeration < NetworkInterface > interfaces = NetworkInterface . getNetworkInterfaces ( ) ; interfaces . hasMoreElements ( ) ; ) { NetworkInterface intf = interfaces . nextElement ( ) ; <START_BUG> allInterfaces . add ( interfaces . nextElement ( ) ) ; <END_BUG> Enumeration < NetworkInterface > subInterfaces = intf . getSubInterfaces ( ) ; if ( ( subInterfaces != null ) && ( subInterfaces . hasMoreElements ( ) ) ) { while ( subInterfaces . hasMoreElements ( ) ) { allInterfaces . add ( subInterfaces . nextElement ( ) ) ; } } } return allInterfaces ; } public static Collection < InetAddress > getAllAvailableAddresses ( ) { } private NetworkUtils ( ) { } }<BUG2FIX>allInterfaces . add ( intf ) ;
public abstract class PackedArrayAtomicFieldData extends AbstractAtomicNumericFieldData { public static PackedArrayAtomicFieldData empty ( ) { } protected long size = - 1 ; public PackedArrayAtomicFieldData ( ) { } @ Override public void close ( ) { } static class Empty extends PackedArrayAtomicFieldData { @ Override public LongValues getLongValues ( ) { } @ Override public DoubleValues getDoubleValues ( ) { } @ Override public boolean isMultiValued ( ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override public long getNumberUniqueValues ( ) { } @ Override <START_BUG> public BytesValues getBytesValues ( boolean needsHashes ) { <END_BUG> return BytesValues . EMPTY ; } @ Override public ScriptDocValues getScriptValues ( ) { } } public static class WithOrdinals extends PackedArrayAtomicFieldData { private final MonotonicAppendingLongBuffer values ; private final Ordinals ordinals ; public WithOrdinals ( MonotonicAppendingLongBuffer values , Ordinals ordinals ) { } @ Override public boolean isMultiValued ( ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override public long getNumberUniqueValues ( ) { } @ Override public PackedArrayAtomicFieldData . WithOrdinals . LongValues getLongValues ( ) { } @ Override public PackedArrayAtomicFieldData . WithOrdinals . DoubleValues getDoubleValues ( ) { } static class LongValues extends org . elasticsearch . index . fielddata . LongValues . WithOrdinals { private final MonotonicAppendingLongBuffer values ; LongValues ( MonotonicAppendingLongBuffer values , Ordinals . Docs ordinals ) { } @ Override public long getValueByOrd ( long ord ) { } } static class DoubleValues extends org . elasticsearch . index . fielddata . DoubleValues . WithOrdinals { private final MonotonicAppendingLongBuffer values ; DoubleValues ( MonotonicAppendingLongBuffer values , Ordinals . Docs ordinals ) { } @ Override public double getValueByOrd ( long ord ) { } } } public static class SingleSparse extends PackedArrayAtomicFieldData { private final Mutable values ; private final long minValue ; private final long missingValue ; private final long numOrds ; public SingleSparse ( PackedInts . Mutable values , long minValue , long missingValue , long numOrds ) { } @ Override public boolean isMultiValued ( ) { } @ Override public long getNumberUniqueValues ( ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override public PackedArrayAtomicFieldData . SingleSparse . LongValues getLongValues ( ) { } @ Override public PackedArrayAtomicFieldData . SingleSparse . DoubleValues getDoubleValues ( ) { } static class LongValues extends org . elasticsearch . index . fielddata . LongValues { private final Mutable values ; private final long minValue ; private final long missingValue ; LongValues ( PackedInts . Mutable values , long minValue , long missingValue ) { } @ Override public int setDocument ( int docId ) { } @ Override public long nextValue ( ) { } } static class DoubleValues extends org . elasticsearch . index . fielddata . DoubleValues { private final Mutable values ; private final long minValue ; private final long missingValue ; DoubleValues ( PackedInts . Mutable values , long minValue , long missingValue ) { } @ Override public int setDocument ( int docId ) { } @ Override public double nextValue ( ) { } } } public static class Single extends PackedArrayAtomicFieldData { private final Mutable values ; private final long minValue ; private final long numOrds ; public Single ( PackedInts . Mutable values , long minValue , long numOrds ) { } @ Override public boolean isMultiValued ( ) { } @ Override public long getNumberUniqueValues ( ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override public PackedArrayAtomicFieldData . Single . LongValues getLongValues ( ) { } @ Override public PackedArrayAtomicFieldData . Single . DoubleValues getDoubleValues ( ) { } static class LongValues extends DenseLongValues { private final Mutable values ; private final long minValue ; LongValues ( PackedInts . Mutable values , long minValue ) { } @ Override public long nextValue ( ) { } } static class DoubleValues extends org . elasticsearch . index . fielddata . DoubleValues { private final Mutable values ; private final long minValue ; DoubleValues ( PackedInts . Mutable values , long minValue ) { } @ Override public int setDocument ( int docId ) { } @ Override public double nextValue ( ) { } } } public static class PagedSingle extends PackedArrayAtomicFieldData { private final AppendingDeltaPackedLongBuffer values ; private final long numOrds ; public PagedSingle ( AppendingDeltaPackedLongBuffer values , long numOrds ) { } @ Override public boolean isMultiValued ( ) { } @ Override public long getNumberUniqueValues ( ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override public PackedArrayAtomicFieldData . PagedSingle . LongValues getLongValues ( ) { } @ Override public PackedArrayAtomicFieldData . PagedSingle . DoubleValues getDoubleValues ( ) { } static class LongValues extends DenseLongValues { private final AppendingDeltaPackedLongBuffer values ; LongValues ( AppendingDeltaPackedLongBuffer values ) { } @ Override public long nextValue ( ) { } } static class DoubleValues extends org . elasticsearch . index . fielddata . DoubleValues { private final AppendingDeltaPackedLongBuffer values ; DoubleValues ( AppendingDeltaPackedLongBuffer values ) { } @ Override public int setDocument ( int docId ) { } @ Override public double nextValue ( ) { } } } public static class PagedSingleSparse extends PackedArrayAtomicFieldData { private final AppendingDeltaPackedLongBuffer values ; private final FixedBitSet docsWithValue ; private final long numOrds ; public PagedSingleSparse ( AppendingDeltaPackedLongBuffer values , FixedBitSet docsWithValue , long numOrds ) { } @ Override public boolean isMultiValued ( ) { } @ Override public long getNumberUniqueValues ( ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override public PackedArrayAtomicFieldData . PagedSingleSparse . LongValues getLongValues ( ) { } @ Override public PackedArrayAtomicFieldData . PagedSingleSparse . DoubleValues getDoubleValues ( ) { } static class LongValues extends org . elasticsearch . index . fielddata . LongValues { private final AppendingDeltaPackedLongBuffer values ; private final FixedBitSet docsWithValue ; LongValues ( AppendingDeltaPackedLongBuffer values , FixedBitSet docsWithValue ) { } @ Override public int setDocument ( int docId ) { }<BUG2FIX>public BytesValues getBytesValues ( ) {
public abstract class AtomicGeoPointFieldData < Script extends ScriptDocValues > implements AtomicFieldData < Script > { public abstract GeoPointValues getGeoPointValues ( ) { } @ Override <START_BUG> public BytesValues getBytesValues ( boolean needsHashes ) { <END_BUG> final GeoPointValues values = getGeoPointValues ( ) ; return new BytesValues ( values . isMultiValued ( ) ) { @ Override public int setDocument ( int docId ) { this . docId = docId ; return values . setDocument ( docId ) ; } @ Override public BytesRef nextValue ( ) { GeoPoint value = values . nextValue ( ) ; scratch . copyChars ( GeoHashUtils . encode ( value . lat ( ) , value . lon ( ) ) ) ; return scratch ; } } ; } }<BUG2FIX>public BytesValues getBytesValues ( ) {
public class Executor { public interface CharCallback { public void character ( char c ) { } } public static boolean execute ( File workingDir , String windowsFile , String unixFile , String parameters , Executor . CharCallback callback ) { } private static boolean startProcess ( String command , File directory , final Executor . CharCallback callback ) { try { final Process process = new ProcessBuilder ( command . split ( "<seq2seq4repair_space>" ) ) . redirectErrorStream ( true ) . directory ( directory ) . start ( ) ; Thread t = new Thread ( new Runnable ( ) { @ Override public void run ( ) { BufferedReader reader = new BufferedReader ( new InputStreamReader ( process . getInputStream ( ) ) , 1 ) ; try { int c = 0 ; <START_BUG> while ( ( ( c = reader . read ( ) ) != ( - 1 ) ) && ( process . isAlive ( ) ) ) { <END_BUG> callback . character ( ( ( char ) ( c ) ) ) ; } } catch ( IOException e ) { } } } ) ; t . setDaemon ( true ) ; t . start ( ) ; process . waitFor ( ) ; t . interrupt ( ) ; return ( process . exitValue ( ) ) == 0 ; } catch ( Exception e ) { e . printStackTrace ( ) ; return false ; } } }<BUG2FIX>while ( ( c = reader . read ( ) ) != ( - 1 ) ) {
public class SimpleStageCullingTest extends GdxTest { private class CullableActor extends Image { final OrthographicCamera camera ; boolean visible = false ; public CullableActor ( String name , Texture texture , OrthographicCamera camera ) { } public void draw ( Batch batch , float parentAlpha ) { } Rectangle actorRect = new Rectangle ( ) ; Rectangle camRect = new Rectangle ( ) ; private boolean isCulled ( ) { } } OrthoCamController camController ; Stage stage ; Texture texture ; SpriteBatch batch ; BitmapFont font ; @ Override public void create ( ) { <START_BUG> stage = new Stage ( 480 , 320 , false ) ; <END_BUG> camController = new OrthoCamController ( ( ( OrthographicCamera ) ( stage . getCamera ( ) ) ) ) ; input . setInputProcessor ( camController ) ; texture = new Texture ( files . internal ( "data/badlogicsmall.jpg" ) ) ; for ( int i = 0 ; i < 5000 ; i ++ ) { Actor img = new SimpleStageCullingTest . CullableActor ( ( "img" + i ) , texture , ( ( OrthographicCamera ) ( stage . getCamera ( ) ) ) ) ; img . setX ( ( ( ( ( float ) ( Math . random ( ) ) ) * 480 ) * 10 ) ) ; img . setY ( ( ( ( ( float ) ( Math . random ( ) ) ) * 320 ) * 10 ) ) ; stage . addActor ( img ) ; } batch = new SpriteBatch ( ) ; font = new BitmapFont ( files . internal ( "data/arial-15.fnt" ) , false ) ; } public void render ( ) { } @ Override public void dispose ( ) { } }<BUG2FIX>stage = new Stage ( ) ;
public class RestGetSettingsAction extends BaseRestHandler { private final SettingsFilter settingsFilter ; @ Inject public RestGetSettingsAction ( Settings settings , Client client , RestController controller , SettingsFilter settingsFilter ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { final String [ ] indices = splitIndices ( request . param ( "index" ) ) ; ClusterStateRequest clusterStateRequest = Requests . clusterStateRequest ( ) . filterRoutingTable ( true ) . filterNodes ( true ) . filteredIndices ( indices ) ; clusterStateRequest . listenerThreaded ( false ) ; client . admin ( ) . cluster ( ) . state ( clusterStateRequest , new org . elasticsearch . action . ActionListener < ClusterStateResponse > ( ) { @ Override public void onResponse ( ClusterStateResponse response ) { try { MetaData metaData = response . getState ( ) . metaData ( ) ; if ( ( metaData . indices ( ) . isEmpty ( ) ) && ( ( indices . length ) > 0 ) ) { channel . sendResponse ( new XContentThrowableRestResponse ( request , new org . elasticsearch . indices . IndexMissingException ( new Index ( indices [ 0 ] ) ) ) ) ; return ; } boolean foundAny = false ; XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; for ( IndexMetaData indexMetaData : metaData ) { builder . startObject ( indexMetaData . index ( ) , NONE ) ; foundAny = true ; builder . startObject ( "settings" ) ; Settings settings = settingsFilter . filterSettings ( indexMetaData . settings ( ) ) ; for ( Map . Entry < String , String > entry : settings . getAsMap ( ) . entrySet ( ) ) { builder . field ( entry . getKey ( ) , entry . getValue ( ) ) ; } builder . endObject ( ) ; builder . endObject ( ) ; } builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , ( foundAny ? RestStatus . OK : RestStatus . NOT_FOUND ) , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class ExistsFilterParser implements FilterParser { public static final String NAME = "exists" ; @ Inject public ExistsFilterParser ( ) { } @ Override public String [ ] names ( ) { } @ Override public Filter parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; String fieldName = null ; String filterName = null ; XContentParser . Token token ; String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token . isValue ( ) ) { if ( "field" . equals ( currentFieldName ) ) { fieldName = parser . text ( ) ; } else if ( "_name" . equals ( currentFieldName ) ) { filterName = parser . text ( ) ; } } } if ( fieldName == null ) { throw new QueryParsingException ( parseContext . index ( ) , "exists<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>provided<seq2seq4repair_space>with<seq2seq4repair_space>a<seq2seq4repair_space>[field]" ) ; } Filter filter = null ; MapperService . SmartNameFieldMappers smartNameFieldMappers = parseContext . smartFieldMappers ( fieldName ) ; if ( smartNameFieldMappers != null ) { if ( smartNameFieldMappers . hasMapper ( ) ) { filter = smartNameFieldMappers . mapper ( ) . rangeFilter ( null , null , true , true ) ; } } if ( filter == null ) { filter = new TermRangeFilter ( fieldName , null , null , true , true ) ; } <START_BUG> filter = parseContext . cacheFilter ( filter ) ; <END_BUG> filter = wrapSmartNameFilter ( filter , smartNameFieldMappers , parseContext ) ; if ( filterName != null ) { parseContext . addNamedFilter ( filterName , filter ) ; } return filter ; } }<BUG2FIX>filter = parseContext . cacheFilter ( filter , null ) ;
public class BinaryFieldMapper extends AbstractFieldMapper < byte [ ] > { public static final String CONTENT_TYPE = "binary" ; public static class Defaults extends AbstractFieldMapper . Defaults { public static final long COMPRESS_THRESHOLD = - 1 ; public static final Store STORE = Store . YES ; } public static class Builder extends AbstractFieldMapper . Builder < BinaryFieldMapper . Builder , BinaryFieldMapper > { private Boolean compress = null ; private long compressThreshold = BinaryFieldMapper . Defaults . COMPRESS_THRESHOLD ; public Builder ( String name ) { } public BinaryFieldMapper . Builder compress ( boolean compress ) { } public BinaryFieldMapper . Builder compressThreshold ( long compressThreshold ) { } @ Override public BinaryFieldMapper . Builder indexName ( String indexName ) { } @ Override public BinaryFieldMapper build ( BuilderContext context ) { } } public static class TypeParser implements Mapper . TypeParser { @ Override public Mapper . Builder parse ( String name , Map < String , Object > node , ParserContext parserContext ) throws MapperParsingException { } } private Boolean compress ; private long compressThreshold ; protected BinaryFieldMapper ( Names names , Field . Store store , Boolean compress , long compressThreshold ) { } @ Override public Object valueForSearch ( Fieldable field ) { } @ Override public byte [ ] value ( Fieldable field ) { } @ Override public byte [ ] valueFromString ( String value ) { } @ Override public String valueAsString ( Fieldable field ) { } @ Override public String indexedValue ( String value ) { } @ Override protected Field parseCreateField ( ParseContext context ) throws IOException { if ( ! ( stored ( ) ) ) { return null ; } byte [ ] value ; if ( ( context . parser ( ) . currentToken ( ) ) == ( Token . VALUE_NULL ) ) { return null ; } else { value = context . parser ( ) . binaryValue ( ) ; if ( ( ( ( compress ) != null ) && ( compress ) ) && ( ! ( CompressorFactory . isCompressed ( value , 0 , value . length ) ) ) ) { if ( ( ( compressThreshold ) == ( - 1 ) ) || ( ( value . length ) > ( compressThreshold ) ) ) { CachedStreamOutput . Entry cachedEntry = CachedStreamOutput . popEntry ( ) ; <START_BUG> StreamOutput streamOutput = cachedEntry . cachedBytes ( CompressorFactory . defaultCompressor ( ) ) ; <END_BUG> streamOutput . writeBytes ( value , 0 , value . length ) ; streamOutput . close ( ) ; value = cachedEntry . bytes ( ) . copiedByteArray ( ) ; CachedStreamOutput . pushEntry ( cachedEntry ) ; } } } if ( value == null ) { return null ; } return new Field ( names . indexName ( ) , value ) ; } @ Override protected String contentType ( ) { } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } @ Override public void merge ( Mapper mergeWith , MergeContext mergeContext ) throws MergeMappingException { } }<BUG2FIX>StreamOutput streamOutput = cachedEntry . bytes ( CompressorFactory . defaultCompressor ( ) ) ;
public class FsStreamSnapshot implements Translog . Snapshot { private final ShardId shardId ; private final long id ; private final int totalOperations ; private final int snapshotOperations ; private final RafReference raf ; private final long length ; private final DataInputStream dis ; private Operation lastOperationRead = null ; private int position = 0 ; private byte [ ] cachedData ; public FsStreamSnapshot ( ShardId shardId , long id , RafReference raf , long length , int totalOperations , int snapshotOperations ) throws FileNotFoundException { } @ Override public long translogId ( ) { } @ Override public long position ( ) { } @ Override public long length ( ) { } @ Override public int totalOperations ( ) { } @ Override public int snapshotOperations ( ) { } @ Override public InputStream stream ( ) throws IOException { } @ Override public long lengthInBytes ( ) { } @ Override public boolean hasNext ( ) { } @ Override public Operation next ( ) { } @ Override public void seekForward ( long length ) { } @ Override public boolean release ( ) throws ElasticSearchException { try { dis . close ( ) ; } catch ( IOException e ) { } <START_BUG> raf . decreaseRefCount ( ) ; <END_BUG> return true ; } }<BUG2FIX>raf . decreaseRefCount ( true ) ;
public class FieldsTermsStringFacetCollector extends AbstractFacetCollector { private final FieldDataCache fieldDataCache ; private final String [ ] fieldsNames ; private final String [ ] indexFieldsNames ; private final ComparatorType comparatorType ; private final int size ; private final int numberOfShards ; private final FieldDataType [ ] fieldsDataType ; private FieldData [ ] fieldsData ; private final FieldsTermsStringFacetCollector . StaticAggregatorValueProc aggregator ; private final SearchScript script ; public FieldsTermsStringFacetCollector ( String facetName , String [ ] fieldsNames , int size , InternalStringTermsFacet . ComparatorType comparatorType , SearchContext context , ImmutableSet < String > excluded , Pattern pattern , String scriptLang , String script , Map < String , Object > params ) { } @ Override protected void doSetNextReader ( IndexReader reader , int docBase ) throws IOException { } @ Override protected void doCollect ( int doc ) throws IOException { } @ Override public Facet facet ( ) { TObjectIntHashMap < String > facets = aggregator . facets ( ) ; if ( facets . isEmpty ( ) ) { TermsStringFacetCollector . pushFacets ( facets ) ; return new InternalStringTermsFacet ( facetName , arrayToCommaDelimitedString ( fieldsNames ) , comparatorType , size , ImmutableList . < InternalStringTermsFacet . StringEntry > of ( ) ) ; } else { <START_BUG> BoundedTreeSet < InternalStringTermsFacet . StringEntry > ordered = new BoundedTreeSet < InternalStringTermsFacet . StringEntry > ( COUNT . comparator ( ) , ( ( size ) * ( numberOfShards ) ) ) ; <END_BUG> for ( TObjectIntIterator < String > it = facets . iterator ( ) ; it . hasNext ( ) ; ) { it . advance ( ) ; ordered . add ( new InternalStringTermsFacet . StringEntry ( it . key ( ) , it . value ( ) ) ) ; } TermsStringFacetCollector . pushFacets ( facets ) ; return new InternalStringTermsFacet ( facetName , arrayToCommaDelimitedString ( fieldsNames ) , comparatorType , size , ordered ) ; } } public static class AggregatorValueProc extends FieldsTermsStringFacetCollector . StaticAggregatorValueProc { private final ImmutableSet < String > excluded ; private final Matcher matcher ; private final SearchScript script ; private final Map < String , Object > scriptParams ; public AggregatorValueProc ( TObjectIntHashMap < String > facets , ImmutableSet < String > excluded , Pattern pattern , SearchScript script ) { } @ Override public void onValue ( int docId , String value ) { } } public static class StaticAggregatorValueProc implements FieldData . StringValueInDocProc { private final TObjectIntHashMap < String > facets ; public StaticAggregatorValueProc ( TObjectIntHashMap < String > facets ) { } @ Override public void onValue ( int docId , String value ) { } public final TObjectIntHashMap < String > facets ( ) { } } }<BUG2FIX>BoundedTreeSet < InternalStringTermsFacet . StringEntry > ordered = new BoundedTreeSet < InternalStringTermsFacet . StringEntry > ( comparatorType . comparator ( ) , ( ( size ) * ( numberOfShards ) ) ) ;
public class ValueScriptDateHistogramFacetCollector extends AbstractFacetCollector { private final String indexFieldName ; private final ComparatorType comparatorType ; private final FieldDataCache fieldDataCache ; private final FieldDataType fieldDataType ; private LongFieldData fieldData ; private final SearchScript valueScript ; private final ValueScriptDateHistogramFacetCollector . DateHistogramProc histoProc ; public ValueScriptDateHistogramFacetCollector ( String facetName , String fieldName , String scriptLang , String valueScript , Map < String , Object > params , TimeZoneRounding tzRounding , DateHistogramFacet . ComparatorType comparatorType , SearchContext context ) { } @ Override protected void doCollect ( int doc ) throws IOException { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override protected void doSetNextReader ( AtomicReaderContext context ) throws IOException { fieldData = ( ( LongFieldData ) ( fieldDataCache . cache ( fieldDataType , context . reader ( ) , indexFieldName ) ) ) ; <START_BUG> valueScript . setNextReader ( context . reader ( ) ) ; <END_BUG> } @ Override public Facet facet ( ) { } public static class DateHistogramProc implements LongFieldData . LongValueInDocProc { private final TimeZoneRounding tzRounding ; protected final SearchScript valueScript ; final ExtTLongObjectHashMap < InternalFullDateHistogramFacet . FullEntry > entries = CacheRecycler . popLongObjectMap ( ) ; public DateHistogramProc ( TimeZoneRounding tzRounding , SearchScript valueScript ) { } @ Override public void onValue ( int docId , long value ) { } } }<BUG2FIX>valueScript . setNextReader ( context ) ;
public class RepoListFragment extends ItemListFragment < Repository > implements OrganizationSelectionListener { @ Inject private AccountDataManager cache ; private final AtomicReference < User > org = new AtomicReference < User > ( ) ; private final AtomicReference < RecentRepositories > recentRepos = new AtomicReference < RecentRepositories > ( ) ; @ Override public void onAttach ( Activity activity ) { } @ Override public void onOrganizationSelected ( final User organization ) { User previousOrg = org . get ( ) ; int previousOrgId = ( previousOrg != null ) ? previousOrg . getId ( ) : - 1 ; org . set ( organization ) ; RecentRepositories recent = recentRepos . get ( ) ; if ( recent != null ) recent . saveAsync ( ) ; Activity activity = getActivity ( ) ; if ( ( activity != null ) && ( previousOrgId != ( organization . getId ( ) ) ) ) recentRepos . set ( new RecentRepositories ( activity , organization ) ) ; <START_BUG> if ( ( ( getView ( ) ) != null ) && ( previousOrgId != ( organization . getId ( ) ) ) ) <END_BUG> refreshWithProgress ( ) ; } @ Override public void onActivityCreated ( Bundle savedInstanceState ) { } @ Override public void onListItemClick ( ListView list , View v , int position , long id ) { } @ Override public void onStop ( ) { } @ Override public Loader < List < Repository > > onCreateLoader ( int id , final Bundle args ) { } @ Override protected ItemListAdapter < Repository , ? extends ItemView > createAdapter ( List < Repository > items ) { } @ Override public void onLoadFinished ( Loader < List < Repository > > loader , List < Repository > items ) { } }<BUG2FIX>if ( previousOrgId != ( organization . getId ( ) ) )
public class TransportBulkAction extends TransportAction < BulkRequest , BulkResponse > { private final AutoCreateIndex autoCreateIndex ; private final boolean allowIdGeneration ; private final ClusterService clusterService ; private final TransportShardBulkAction shardBulkAction ; private final TransportCreateIndexAction createIndexAction ; @ Inject public TransportBulkAction ( Settings settings , ThreadPool threadPool , TransportService transportService , ClusterService clusterService , TransportShardBulkAction shardBulkAction , TransportCreateIndexAction createIndexAction ) { } @ Override protected void doExecute ( final BulkRequest bulkRequest , final ActionListener < BulkResponse > listener ) { } private void executeBulk ( final BulkRequest bulkRequest , final long startTime , final ActionListener < BulkResponse > listener ) { } class TransportHandler extends BaseTransportRequestHandler < BulkRequest > { @ Override public BulkRequest newInstance ( ) { } @ Override public void messageReceived ( final BulkRequest request , final TransportChannel channel ) throws Exception { request . listenerThreaded ( false ) ; execute ( request , new ActionListener < BulkResponse > ( ) { @ Override public void onResponse ( BulkResponse result ) { try { channel . sendResponse ( result ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( e ) ; } catch ( Exception e1 ) { logger . warn ( ( ( ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>error<seq2seq4repair_space>response<seq2seq4repair_space>for<seq2seq4repair_space>action<seq2seq4repair_space>[" + ( BulkAction . NAME ) ) + "]<seq2seq4repair_space>and<seq2seq4repair_space>request<seq2seq4repair_space>[" ) + request ) + "]" ) , e1 ) ; } } } ) ; } @ Override public String executor ( ) { } } }<BUG2FIX>} catch ( Throwable e ) {
public final class TestCluster implements Iterable < Client > { private final ESLogger logger = Loggers . getLogger ( getClass ( ) ) ; private final TreeMap < String , TestCluster . NodeAndClient > nodes = Maps . newTreeMap ( ) ; private final Set < File > dataDirToClean = new HashSet < File > ( ) ; private final String clusterName ; private final AtomicBoolean open = new AtomicBoolean ( true ) ; private final Settings defaultSettings ; private Random random ; private AtomicInteger nextNodeId = new AtomicInteger ( 0 ) ; private final int numSharedNodes ; private final long [ ] sharedNodesSeeds ; private double transportClientRatio = 0.0 ; private final NodeSettingsSource nodeSettingsSource ; TestCluster ( long clusterSeed , String clusterName ) { } TestCluster ( long clusterSeed , int numNodes , String clusterName , NodeSettingsSource nodeSettingsSource ) { } private static boolean isLocalTransportConfigured ( ) { } private Settings getSettings ( int nodeOrdinal , Settings others ) { } static String clusterName ( String prefix , String childVMId , long clusterSeed ) { } private void ensureOpen ( ) { } private synchronized TestCluster . NodeAndClient getOrBuildRandomNode ( ) { } private synchronized TestCluster . NodeAndClient getRandomNodeAndClient ( ) { } private synchronized TestCluster . NodeAndClient getRandomNodeAndClient ( Predicate < TestCluster . NodeAndClient > predicate ) { } public synchronized void ensureAtLeastNumNodes ( int n ) { } public synchronized void ensureAtMostNumNodes ( int n ) { } private TestCluster . NodeAndClient buildNode ( Settings settings ) { } private TestCluster . NodeAndClient buildNode ( ) { } private TestCluster . NodeAndClient buildNode ( int nodeId , long seed , Settings settings ) { } private String buildNodeName ( int id ) { } synchronized Client client ( ) { } public synchronized Client masterClient ( ) { } public synchronized Client nonMasterClient ( ) { } public synchronized Client clientNodeClient ( ) { } public synchronized Client client ( String nodeName ) { } public synchronized Client smartClient ( ) { } public synchronized Client client ( final Predicate < Settings > filterPredicate ) { } void close ( ) { } private final class NodeAndClient implements Closeable { private InternalNode node ; private Client client ; private Client nodeClient ; private final AtomicBoolean closed = new AtomicBoolean ( false ) ; private final TestCluster . ClientFactory clientFactory ; private final String name ; NodeAndClient ( String name , Node node , TestCluster . ClientFactory factory ) { } Node node ( ) { } Client client ( Random random ) { } Client nodeClient ( ) { } void resetClient ( ) { } void restart ( TestCluster . RestartCallback callback ) throws Exception { } @ Override public void close ( ) { } } static class ClientFactory { public Client client ( Node node , String clusterName , Random random ) { } } static class TransportClientFactory extends TestCluster . ClientFactory { private boolean sniff ; public static TestCluster . TransportClientFactory NO_SNIFF_CLIENT_FACTORY = new TestCluster . TransportClientFactory ( false ) ; public static TestCluster . TransportClientFactory SNIFF_CLIENT_FACTORY = new TestCluster . TransportClientFactory ( true ) ; public TransportClientFactory ( boolean sniff ) { } @ Override public Client client ( Node node , String clusterName , Random random ) { } } class RandomClientFactory extends TestCluster . ClientFactory { @ Override public Client client ( Node node , String clusterName , Random random ) { } } synchronized void beforeTest ( Random random , double transportClientRatio ) { } private synchronized void reset ( Random random , boolean wipeData , double transportClientRatio ) { } synchronized void afterTest ( ) { } private void resetClients ( ) { } private void wipeDataDirectories ( ) { if ( ! ( dataDirToClean . isEmpty ( ) ) ) { logger . info ( "Wipe<seq2seq4repair_space>data<seq2seq4repair_space>directory<seq2seq4repair_space>for<seq2seq4repair_space>all<seq2seq4repair_space>nodes<seq2seq4repair_space>locations:<seq2seq4repair_space>{}" , this . dataDirToClean ) ; try { <START_BUG> FileSystemUtils . deleteRecursively ( dataDirToClean . toArray ( new File [ 0 ] ) ) ; <END_BUG> } finally { this . dataDirToClean . clear ( ) ; } } } public synchronized ClusterService clusterService ( ) { } public synchronized < T > Iterable < T > getInstances ( Class < T > clazz ) { } public synchronized < T > T getInstance ( Class < T > clazz , final String node ) { } public synchronized < T > T getInstance ( Class < T > clazz ) { } private synchronized < T > T getInstanceFromNode ( Class < T > clazz , InternalNode node ) { } public synchronized int size ( ) { } public synchronized void stopRandomNode ( ) { } public synchronized void stopRandomNode ( final Predicate < Settings > filter ) { } public synchronized void stopCurrentMasterNode ( ) { } public void stopRandomNonMasterNode ( ) { } public void restartRandomNode ( ) throws Exception { } public void restartRandomNode ( TestCluster . RestartCallback callback ) throws Exception { } private void restartAllNodes ( boolean rollingRestart , TestCluster . RestartCallback callback ) throws Exception { } private static final TestCluster . RestartCallback EMPTY_CALLBACK = new TestCluster . RestartCallback ( ) { public Settings onNodeStopped ( String node ) { } } ; public void fullRestart ( ) throws Exception { } public void rollingRestart ( ) throws Exception { } public void rollingRestart ( TestCluster . RestartCallback function ) throws Exception { } public void fullRestart ( TestCluster . RestartCallback function ) throws Exception { } private String getMasterName ( ) { } synchronized Set < String > allButN ( int numNodes ) { } private synchronized Set < String > nRandomNodes ( int numNodes ) { } public synchronized void startNodeClient ( Settings settings ) { } public synchronized Set < String > nodesInclude ( String index ) { } public String startNode ( ) { } public String startNode ( Settings . Builder settings ) { } public String startNode ( Settings settings ) { }<BUG2FIX>FileSystemUtils . deleteRecursively ( dataDirToClean . toArray ( new File [ dataDirToClean . size ( ) ] ) ) ;
public class SignReadScreen extends Screen { private Screen parent ; private String [ ] [ ] signs = new String [ ] [ ] { new String [ ] { "READING" , "" , "PRESS<seq2seq4repair_space>UP<seq2seq4repair_space>TO<seq2seq4repair_space>READ<seq2seq4repair_space>SIGNS" } , new String [ ] { "JUMPING" , "" , "PRESS<seq2seq4repair_space>Z<seq2seq4repair_space>TO<seq2seq4repair_space>JUMP" , "YOU<seq2seq4repair_space>CAN<seq2seq4repair_space>JUMP<seq2seq4repair_space>HIGHER<seq2seq4repair_space>BY" , "GETTING<seq2seq4repair_space>A<seq2seq4repair_space>RUNNING<seq2seq4repair_space>START" , "OR<seq2seq4repair_space>HOLDING<seq2seq4repair_space>DOWN<seq2seq4repair_space>Z" } , new String [ ] { "PROGRESSING" , "" , "LEAVE<seq2seq4repair_space>A<seq2seq4repair_space>ROOM<seq2seq4repair_space>THROUGH<seq2seq4repair_space>ANY" , "EXIT<seq2seq4repair_space>TO<seq2seq4repair_space>CONTINUE<seq2seq4repair_space>YOUR" , "ADVENTURE" } , new String [ ] { "DYING" , "" , "IF<seq2seq4repair_space>YOU<seq2seq4repair_space>DIE,<seq2seq4repair_space>YOU<seq2seq4repair_space>RESTART" , "AT<seq2seq4repair_space>THE<seq2seq4repair_space>BEGINNING<seq2seq4repair_space>OF<seq2seq4repair_space>THE" , "CURRENT<seq2seq4repair_space>ROOM" } , new String [ ] { "DODGING" , "" , "THE<seq2seq4repair_space>GUNNERS<seq2seq4repair_space>DON'T<seq2seq4repair_space>LIKE<seq2seq4repair_space>YOU" , "AND<seq2seq4repair_space>SHOOT<seq2seq4repair_space>AT<seq2seq4repair_space>YOU." , "IT<seq2seq4repair_space>WOULD<seq2seq4repair_space>BE<seq2seq4repair_space>WISE<seq2seq4repair_space>TO<seq2seq4repair_space>STAY<seq2seq4repair_space>AWAY" } , new String [ ] { "THE<seq2seq4repair_space>LAUNCHER" , "" , "AS<seq2seq4repair_space>YOU<seq2seq4repair_space>PICK<seq2seq4repair_space>UP<seq2seq4repair_space>THE<seq2seq4repair_space>LAUNCHER," , "YOU<seq2seq4repair_space>REALIZE<seq2seq4repair_space>IT'S<seq2seq4repair_space>NOT<seq2seq4repair_space>YOUR" , "AVERAGE<seq2seq4repair_space>LAUNCHER." , "" , "PRESS<seq2seq4repair_space>UP<seq2seq4repair_space>AND<seq2seq4repair_space>DOWN<seq2seq4repair_space>TO<seq2seq4repair_space>AIM" , "PRESS<seq2seq4repair_space>X<seq2seq4repair_space>TO<seq2seq4repair_space>FIRE<seq2seq4repair_space>THE<seq2seq4repair_space>LAUNCHER" } , new String [ ] { "JONESING" , "" , "DON'T<seq2seq4repair_space>FORGET<seq2seq4repair_space>YOUR<seq2seq4repair_space>FEDORA!" } , new String [ ] { "EXPLODING" , "" , "TNT<seq2seq4repair_space>BLOCKS<seq2seq4repair_space>ARE<seq2seq4repair_space>HIGHLY" , "EXPLOSIVE,<seq2seq4repair_space>AND<seq2seq4repair_space>WILL" , "REACT<seq2seq4repair_space>POORLY<seq2seq4repair_space>TO<seq2seq4repair_space>BEING" , "SHOT." } , new String [ ] { "PUSHING" , "" , "THE<seq2seq4repair_space>CAMARADERIE<seq2seq4repair_space>BOX<seq2seq4repair_space>IS" , "SOMETHING<seq2seq4repair_space>SOMETHING" , "" , "IT'S<seq2seq4repair_space>FROM<seq2seq4repair_space>PORTAL." } , new String [ ] { "BATTLING" , "" , "THE<seq2seq4repair_space>GREMLIN<seq2seq4repair_space>IS<seq2seq4repair_space>LARGE" , "AND<seq2seq4repair_space>IN<seq2seq4repair_space>YOUR<seq2seq4repair_space>WAY." , "OVERHEAT<seq2seq4repair_space>IT<seq2seq4repair_space>TO<seq2seq4repair_space>DESTROY" , "IT<seq2seq4repair_space>AND<seq2seq4repair_space>CLAIM<seq2seq4repair_space>YOUR<seq2seq4repair_space>PRIZE" } , new String [ ] { "EVADING" , "" , "THE<seq2seq4repair_space>GUNNERS<seq2seq4repair_space>SHOTS<seq2seq4repair_space>WILL" , "PASS<seq2seq4repair_space>THROUGH<seq2seq4repair_space>GLASS." , "YOU,<seq2seq4repair_space>HOWEVER,<seq2seq4repair_space>WILL<seq2seq4repair_space>NOT" } , new String [ ] { "SWEATING" , "" , "THESE<seq2seq4repair_space>SLIGHTLY<seq2seq4repair_space>MORE" , "SOPHISTICATED<seq2seq4repair_space>GREMLINS" , "HAVE<seq2seq4repair_space>LEARNED<seq2seq4repair_space>A<seq2seq4repair_space>NEW" , "TRICK" } , new String [ ] { "CONVEYING" , "" , "TIME<seq2seq4repair_space>TO<seq2seq4repair_space>BURN<seq2seq4repair_space>OFF<seq2seq4repair_space>SOME" , "FAT<seq2seq4repair_space>AND<seq2seq4repair_space>HAVE<seq2seq4repair_space>FUN<seq2seq4repair_space>WHILE" , "DOING<seq2seq4repair_space>IT!" } , new String [ ] { "BOSSFIGHTING" , "" , "BEHIND<seq2seq4repair_space>THIS<seq2seq4repair_space>DOOR,<seq2seq4repair_space>MEGAN" , "AWAITS!<seq2seq4repair_space>WHO<seq2seq4repair_space>IS<seq2seq4repair_space>MEGAN?" , "ARE<seq2seq4repair_space>YOU<seq2seq4repair_space>MEGAN?" } , new String [ ] { "THE<seq2seq4repair_space>NEW<seq2seq4repair_space>LAUNCHER" , "" , "WELL,<seq2seq4repair_space>THIS<seq2seq4repair_space>IS<seq2seq4repair_space>BAD." } , new String [ ] { "FEEDING" , "" , "THE<seq2seq4repair_space>JABBERWOCKY<seq2seq4repair_space>IS" , "HUNGRY,<seq2seq4repair_space>AND<seq2seq4repair_space>WILL<seq2seq4repair_space>EAT" , "WAY<seq2seq4repair_space>MORE<seq2seq4repair_space>THAN<seq2seq4repair_space>IT<seq2seq4repair_space>SHOULD" , "" , "PLEASE<seq2seq4repair_space>DO<seq2seq4repair_space>NOT<seq2seq4repair_space>FEED!" } , new String [ ] { "HOVERING" , "" , "THE<seq2seq4repair_space>RECOIL<seq2seq4repair_space>ON<seq2seq4repair_space>THE<seq2seq4repair_space>NEW" , "LAUNCHER<seq2seq4repair_space>SURE<seq2seq4repair_space>IS" , "POWERFUL!" } , new String [ ] { "FLYING" , "" , "SERIOUSLY,<seq2seq4repair_space>THE<seq2seq4repair_space>RECOIL" , "IS<seq2seq4repair_space>OUT<seq2seq4repair_space>OF<seq2seq4repair_space>THIS<seq2seq4repair_space>WORLD!" } , new String [ ] { "WINNING" , "" , "YOUR<seq2seq4repair_space>FINAL<seq2seq4repair_space>CHALLENGE" , "IS<seq2seq4repair_space>RIGHT<seq2seq4repair_space>DOWN<seq2seq4repair_space>THIS" , "HALLWAY." } , new String [ ] { "FRESHERERST" , "" , "BIG<seq2seq4repair_space>ADAM,<seq2seq4repair_space>GIANT<seq2seq4repair_space>SISTER." , "IT<seq2seq4repair_space>IS<seq2seq4repair_space>KNOWN<seq2seq4repair_space>BY<seq2seq4repair_space>MANY<seq2seq4repair_space>NAMES" , "BUT<seq2seq4repair_space>JUDITH<seq2seq4repair_space>4HRPG<seq2seq4repair_space>BLUEBERRY." , "" , "FISSION<seq2seq4repair_space>MAILED!" } } ; private int delay = 15 ; private int id ; public SignReadScreen ( Screen parent , int id ) { } public void render ( ) { } public void tick ( Input input ) { <START_BUG> if ( ( ( ! ( input . oldButtons [ Input . ESCAPE ] ) ) && ( input . buttons [ Input . ESCAPE ] ) ) || ( input . isTouched ( ) ) ) { <END_BUG> setScreen ( parent ) ; return ; } if ( ( delay ) > 0 ) ( delay ) -- ; if ( ( ( ( delay ) == 0 ) && ( input . buttons [ Input . SHOOT ] ) ) && ( ! ( input . oldButtons [ Input . SHOOT ] ) ) ) { setScreen ( parent ) ; } } }<BUG2FIX>if ( ( ! ( input . oldButtons [ Input . ESCAPE ] ) ) && ( input . buttons [ Input . ESCAPE ] ) ) {
private static final int UPDATE_ANGLE = 1 << 1 ; private static final int UPDATE_ROTATION = 1 << 2 ; private static final int UPDATE_VELOCITY = 1 << 3 ; private static final int UPDATE_WIND = 1 << 4 ; private static final int UPDATE_GRAVITY = 1 << 5 ; private static final int UPDATE_TINT = 1 << 6 ; private ParticleEmitter . RangedNumericValue delayValue = new ParticleEmitter . RangedNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue lifeOffsetValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . RangedNumericValue durationValue = new ParticleEmitter . RangedNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue lifeValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue emissionValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue scaleValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue rotationValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue velocityValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue angleValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue windValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue gravityValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue transparencyValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . GradientColorValue tintValue = new ParticleEmitter . GradientColorValue ( ) ; private ParticleEmitter . RangedNumericValue xOffsetValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . RangedNumericValue yOffsetValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue spawnWidthValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue spawnHeightValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . SpawnShapeValue spawnShapeValue = new ParticleEmitter . SpawnShapeValue ( ) ; private float accumulator ; private Sprite sprite ; private ParticleEmitter . Particle [ ] particles ; private int minParticleCount ; private int maxParticleCount = 4 ; private float x ; private float y ; private String name ; private String imagePath ; private int activeCount ; private BitSet active ; private boolean firstUpdate ; private boolean flipX ; private boolean flipY ; private int updateFlags ; private boolean allowCompletion ; private int emission ; private int emissionDiff ; private int emissionDelta ; private int lifeOffset ; private int lifeOffsetDiff ; private int life ; private int lifeDiff ; private int spawnWidth ; private int spawnWidthDiff ; private int spawnHeight ; private int spawnHeightDiff ; public float duration = 1 ; public float durationTimer ; private float delay ; private float delayTimer ; private boolean attached ; private boolean continuous ; private boolean aligned ; private boolean behind ; private boolean additive = true ; public ParticleEmitter ( ) { } public ParticleEmitter ( BufferedReader reader ) throws IOException { } public ParticleEmitter ( ParticleEmitter emitter ) { } private void initialize ( ) { } public void setMaxParticleCount ( int maxParticleCount ) { } public void addParticle ( ) { } public void addParticles ( int count ) { } public void draw ( SpriteBatch spriteBatch , float delta ) { } public void start ( ) { } public void reset ( ) { } private void restart ( ) { } private void activateParticle ( int index ) { } private boolean updateParticle ( int index , float delta , int deltaMillis ) { } public void setPosition ( float x , float y ) { } public void setSprite ( Sprite sprite ) { this . sprite = sprite ; if ( sprite == null ) return ; float originX = sprite . getOriginX ( ) ; float originY = sprite . getOriginY ( ) ; Texture texture = sprite . getTexture ( ) ; for ( int i = 0 , n = particles . length ; i < n ; i ++ ) { ParticleEmitter . Particle particle = particles [ i ] ; if ( particle == null ) <START_BUG> continue ; <END_BUG> particle . setTexture ( texture ) ; particle . setOrigin ( originX , originY ) ; } } public void allowCompletion ( ) { } public Sprite getSprite ( ) { } public String getName ( ) { } public void setName ( String name ) { } public ParticleEmitter . ScaledNumericValue getLife ( ) { } public ParticleEmitter . ScaledNumericValue getScale ( ) { } public ParticleEmitter . ScaledNumericValue getRotation ( ) { } public ParticleEmitter . GradientColorValue getTint ( ) { } public ParticleEmitter . ScaledNumericValue getVelocity ( ) { } public ParticleEmitter . ScaledNumericValue getWind ( ) { } public ParticleEmitter . ScaledNumericValue getGravity ( ) { } public ParticleEmitter . ScaledNumericValue getAngle ( ) { } public ParticleEmitter . ScaledNumericValue getEmission ( ) { } public ParticleEmitter . ScaledNumericValue getTransparency ( ) { } public ParticleEmitter . RangedNumericValue getDuration ( ) { } public ParticleEmitter . RangedNumericValue getDelay ( ) { } public ParticleEmitter . ScaledNumericValue getLifeOffset ( ) { } public ParticleEmitter . RangedNumericValue getXOffsetValue ( ) { } public ParticleEmitter . RangedNumericValue getYOffsetValue ( ) { } public ParticleEmitter . ScaledNumericValue getSpawnWidth ( ) { } public ParticleEmitter . ScaledNumericValue getSpawnHeight ( ) { } public ParticleEmitter . SpawnShapeValue getSpawnShape ( ) { } public boolean isAttached ( ) { } public void setAttached ( boolean attached ) { } public boolean isContinuous ( ) { } public void setContinuous ( boolean continuous ) { } public boolean isAligned ( ) { } public void setAligned ( boolean aligned ) { } public boolean isAdditive ( ) { } public void setAdditive ( boolean additive ) { } public boolean isBehind ( ) { } public void setBehind ( boolean behind ) { } public int getMinParticleCount ( ) { } public void setMinParticleCount ( int minParticleCount ) { } public int getMaxParticleCount ( ) { } public boolean isComplete ( ) { } public float getPercentComplete ( ) { }<BUG2FIX>break ;
public class MissingFieldQueryExtension implements FieldQueryExtension { public static final String NAME = "_missing_" ; @ Override public Query query ( QueryParseContext parseContext , String queryText ) { String fieldName = queryText ; Filter filter = null ; MapperService . SmartNameFieldMappers smartNameFieldMappers = parseContext . smartFieldMappers ( fieldName ) ; if ( smartNameFieldMappers != null ) { if ( smartNameFieldMappers . hasMapper ( ) ) { filter = smartNameFieldMappers . mapper ( ) . rangeFilter ( null , null , true , true ) ; } } if ( filter == null ) { filter = new TermRangeFilter ( fieldName , null , null , true , true ) ; } filter = parseContext . cacheFilter ( filter ) ; filter = new org . elasticsearch . common . lucene . search . NotFilter ( filter ) ; filter = parseContext . cacheFilter ( filter ) ; filter = wrapSmartNameFilter ( filter , smartNameFieldMappers , parseContext ) ; <START_BUG> return new org . apache . lucene . search . DeletionAwareConstantScoreQuery ( filter , true ) ; <END_BUG> } }<BUG2FIX>return new org . apache . lucene . search . DeletionAwareConstantScoreQuery ( filter ) ;
public class PublishClusterStateAction extends AbstractComponent { public static interface NewClusterStateListener { void onNewClusterState ( ClusterState clusterState ) { } } private final TransportService transportService ; private final DiscoveryNodesProvider nodesProvider ; private final PublishClusterStateAction . NewClusterStateListener listener ; public PublishClusterStateAction ( Settings settings , TransportService transportService , DiscoveryNodesProvider nodesProvider , PublishClusterStateAction . NewClusterStateListener listener ) { } public void close ( ) { } public void publish ( ClusterState clusterState ) { } private class PublishClusterStateRequest implements Streamable { private ClusterState clusterState ; private PublishClusterStateRequest ( ) { } private PublishClusterStateRequest ( ClusterState clusterState ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { <START_BUG> clusterState = Builder . readFrom ( in , settings , nodesProvider . nodes ( ) . localNode ( ) ) ; <END_BUG> } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } private class PublishClusterStateRequestHandler extends BaseTransportRequestHandler < PublishClusterStateAction . PublishClusterStateRequest > { static final String ACTION = "discovery/zen/publish" ; @ Override public PublishClusterStateAction . PublishClusterStateRequest newInstance ( ) { } @ Override public void messageReceived ( PublishClusterStateAction . PublishClusterStateRequest request , TransportChannel channel ) throws Exception { } @ Override public boolean spawn ( ) { } } }<BUG2FIX>clusterState = Builder . readFrom ( in , nodesProvider . nodes ( ) . localNode ( ) ) ;
public class IndicesExistsRequestBuilder extends MasterNodeOperationRequestBuilder < IndicesExistsRequest , IndicesExistsResponse , IndicesExistsRequestBuilder > { public IndicesExistsRequestBuilder ( IndicesAdminClient indicesClient , String ... indices ) { } public IndicesExistsRequestBuilder setIndices ( String ... indices ) { <START_BUG> request . indices ( indices ) ; <END_BUG> return this ; } @ Override protected void doExecute ( ActionListener < IndicesExistsResponse > listener ) { } }<BUG2FIX>request . setIndices ( indices ) ;
public class RestMultiSearchAction extends BaseRestHandler { @ Inject public RestMultiSearchAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { MultiSearchRequest multiSearchRequest = new MultiSearchRequest ( ) ; multiSearchRequest . listenerThreaded ( false ) ; String [ ] indices = RestActions . splitIndices ( request . param ( "index" ) ) ; String [ ] types = RestActions . splitTypes ( request . param ( "type" ) ) ; IgnoreIndices ignoreIndices = null ; if ( request . hasParam ( "ignore_indices" ) ) { ignoreIndices = IgnoreIndices . fromString ( request . param ( "ignore_indices" ) ) ; } try { multiSearchRequest . add ( request . content ( ) , request . contentUnsafe ( ) , indices , types , request . param ( "search_type" ) , ignoreIndices ) ; } catch ( Exception e ) { try { XContentBuilder builder = restContentBuilder ( request ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . BAD_REQUEST , builder . startObject ( ) . field ( "error" , e . getMessage ( ) ) . endObject ( ) ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } return ; } client . multiSearch ( multiSearchRequest , new org . elasticsearch . action . ActionListener < MultiSearchResponse > ( ) { @ Override public void onResponse ( MultiSearchResponse response ) { try { XContentBuilder builder = restContentBuilder ( request ) ; builder . startObject ( ) ; response . toXContent ( builder , request ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public void writeOptionalString ( @ Nullable String str ) throws IOException { } public void writeText ( Text text ) throws IOException { } public void writeString ( String str ) throws IOException { } @ Deprecated public void writeUTF ( String str ) throws IOException { } public void writeFloat ( float v ) throws IOException { } public void writeDouble ( double v ) throws IOException { } private static byte ZERO = 0 ; private static byte ONE = 1 ; public void writeBoolean ( boolean b ) throws IOException { } public abstract void flush ( ) throws IOException { } public abstract void close ( ) throws IOException { } public abstract void reset ( ) throws IOException { } @ Override public void write ( int b ) throws IOException { } @ Override public void write ( byte [ ] b , int off , int len ) throws IOException { } public void writeStringArray ( String [ ] array ) throws IOException { } public void writeStringArrayNullable ( @ Nullable String [ ] array ) throws IOException { } public void writeMap ( @ Nullable Map < String , Object > map ) throws IOException { } public void writeGenericValue ( @ Nullable Object value ) throws IOException { if ( value == null ) { writeByte ( ( ( byte ) ( - 1 ) ) ) ; return ; } Class type = value . getClass ( ) ; if ( type == ( String . class ) ) { writeByte ( ( ( byte ) ( 0 ) ) ) ; writeString ( ( ( String ) ( value ) ) ) ; } else if ( type == ( Integer . class ) ) { writeByte ( ( ( byte ) ( 1 ) ) ) ; writeInt ( ( ( Integer ) ( value ) ) ) ; } else if ( type == ( Long . class ) ) { writeByte ( ( ( byte ) ( 2 ) ) ) ; writeLong ( ( ( Long ) ( value ) ) ) ; } else if ( type == ( Float . class ) ) { writeByte ( ( ( byte ) ( 3 ) ) ) ; writeFloat ( ( ( Float ) ( value ) ) ) ; } else if ( type == ( Double . class ) ) { writeByte ( ( ( byte ) ( 4 ) ) ) ; writeDouble ( ( ( Double ) ( value ) ) ) ; } else if ( type == ( Boolean . class ) ) { writeByte ( ( ( byte ) ( 5 ) ) ) ; writeBoolean ( ( ( Boolean ) ( value ) ) ) ; } else if ( type == ( byte [ ] . class ) ) { writeByte ( ( ( byte ) ( 6 ) ) ) ; writeVInt ( ( ( byte [ ] ) ( value ) ) . length ) ; writeBytes ( ( ( byte [ ] ) ( value ) ) ) ; } else if ( value instanceof List ) { writeByte ( ( ( byte ) ( 7 ) ) ) ; List list = ( ( List ) ( value ) ) ; writeVInt ( list . size ( ) ) ; for ( Object o : list ) { writeGenericValue ( o ) ; } } else if ( value instanceof Object [ ] ) { writeByte ( ( ( byte ) ( 8 ) ) ) ; Object [ ] list = ( ( Object [ ] ) ( value ) ) ; writeVInt ( list . length ) ; for ( Object o : list ) { writeGenericValue ( o ) ; } } else if ( value instanceof Map ) { if ( value instanceof LinkedHashMap ) { writeByte ( ( ( byte ) ( 9 ) ) ) ; } else { writeByte ( ( ( byte ) ( 10 ) ) ) ; } Map < String , Object > map = ( ( Map < String , Object > ) ( value ) ) ; writeVInt ( map . size ( ) ) ; for ( Map . Entry < String , Object > entry : map . entrySet ( ) ) { writeString ( entry . getKey ( ) ) ; writeGenericValue ( entry . getValue ( ) ) ; } } else if ( type == ( Byte . class ) ) { writeByte ( ( ( byte ) ( 11 ) ) ) ; writeByte ( ( ( Byte ) ( value ) ) ) ; } else if ( type == ( Date . class ) ) { writeByte ( ( ( byte ) ( 12 ) ) ) ; writeLong ( ( ( Date ) ( value ) ) . getTime ( ) ) ; } else if ( value instanceof ReadableInstant ) { writeByte ( ( ( byte ) ( 13 ) ) ) ; writeLong ( ( ( ReadableInstant ) ( value ) ) . getMillis ( ) ) ; } else if ( value instanceof BytesReference ) { writeByte ( ( ( byte ) ( 14 ) ) ) ; writeBytesReference ( ( ( BytesReference ) ( value ) ) ) ; } else if ( value instanceof Text ) { writeByte ( ( ( byte ) ( 15 ) ) ) ; writeText ( ( ( Text ) ( value ) ) ) ; } else <START_BUG> if ( value == ( Short . class ) ) { <END_BUG> writeByte ( ( ( byte ) ( 16 ) ) ) ; writeShort ( ( ( Short ) ( value ) ) ) ; } else { throw new IOException ( ( ( "Can't<seq2seq4repair_space>write<seq2seq4repair_space>type<seq2seq4repair_space>[" + type ) + "]" ) ) ; } } }<BUG2FIX>if ( type == ( Short . class ) ) {
} class ScheduledNodeSampler implements Runnable { @ Override public void run ( ) { } } class SimpleNodeSampler extends TransportClientNodesService . NodeSampler { @ Override protected void doSample ( ) { HashSet < DiscoveryNode > newNodes = new HashSet < > ( ) ; HashSet < DiscoveryNode > newFilteredNodes = new HashSet < > ( ) ; for ( DiscoveryNode listedNode : listedNodes ) { if ( ! ( transportService . nodeConnected ( listedNode ) ) ) { try { logger . trace ( "connecting<seq2seq4repair_space>to<seq2seq4repair_space>listed<seq2seq4repair_space>node<seq2seq4repair_space>(light)<seq2seq4repair_space>[{}]" , listedNode ) ; transportService . connectToNodeLight ( listedNode ) ; } catch ( Throwable e ) { logger . debug ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>connect<seq2seq4repair_space>to<seq2seq4repair_space>node<seq2seq4repair_space>[{}],<seq2seq4repair_space>removed<seq2seq4repair_space>from<seq2seq4repair_space>nodes<seq2seq4repair_space>list" , e , listedNode ) ; continue ; } } try { NodesInfoResponse nodeInfo = transportService . submitRequest ( listedNode , NAME , Requests . nodesInfoRequest ( "_local" ) , TransportRequestOptions . options ( ) . withType ( STATE ) . withTimeout ( pingTimeout ) , new FutureTransportResponseHandler < NodesInfoResponse > ( ) { @ Override public NodesInfoResponse newInstance ( ) { return new NodesInfoResponse ( ) ; } } ) . txGet ( ) ; if ( ( ! ( ignoreClusterName ) ) && ( ! ( clusterName . equals ( nodeInfo . getClusterName ( ) ) ) ) ) { logger . warn ( "node<seq2seq4repair_space>{}<seq2seq4repair_space>not<seq2seq4repair_space>part<seq2seq4repair_space>of<seq2seq4repair_space>the<seq2seq4repair_space>cluster<seq2seq4repair_space>{},<seq2seq4repair_space>ignoring..." , listedNode , clusterName ) ; newFilteredNodes . add ( listedNode ) ; } else if ( ( nodeInfo . getNodes ( ) . length ) != 0 ) { DiscoveryNode nodeWithInfo = nodeInfo . getNodes ( ) [ 0 ] . getNode ( ) ; newNodes . add ( new DiscoveryNode ( nodeWithInfo . name ( ) , nodeWithInfo . id ( ) , nodeWithInfo . getHostName ( ) , nodeWithInfo . getHostAddress ( ) , listedNode . address ( ) , nodeWithInfo . attributes ( ) , nodeWithInfo . version ( ) ) ) ; } else { logger . debug ( "node<seq2seq4repair_space>{}<seq2seq4repair_space>didn't<seq2seq4repair_space>return<seq2seq4repair_space>any<seq2seq4repair_space>discovery<seq2seq4repair_space>info,<seq2seq4repair_space>temporarily<seq2seq4repair_space>using<seq2seq4repair_space>transport<seq2seq4repair_space>discovery<seq2seq4repair_space>node" , listedNode ) ; newNodes . add ( listedNode ) ; } } catch ( Throwable e ) { logger . info ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>get<seq2seq4repair_space>node<seq2seq4repair_space>info<seq2seq4repair_space>for<seq2seq4repair_space>{},<seq2seq4repair_space>disconnecting..." , e , listedNode ) ; transportService . disconnectFromNode ( listedNode ) ; } } nodes = validateNewNodes ( newNodes ) ; filteredNodes = ImmutableList . copyOf ( newFilteredNodes ) ; } } class SniffNodesSampler extends TransportClientNodesService . NodeSampler { @ Override protected void doSample ( ) { Set < DiscoveryNode > nodesToPing = Sets . newHashSet ( ) ; for ( DiscoveryNode node : listedNodes ) { nodesToPing . add ( node ) ; } for ( DiscoveryNode node : nodes ) { nodesToPing . add ( node ) ; } final CountDownLatch latch = new CountDownLatch ( nodesToPing . size ( ) ) ; final ConcurrentMap < DiscoveryNode , ClusterStateResponse > clusterStateResponses = ConcurrentCollections . newConcurrentMap ( ) ; for ( final DiscoveryNode listedNode : nodesToPing ) { threadPool . executor ( ThreadPool . Names . MANAGEMENT ) . execute ( new Runnable ( ) { @ Override public void run ( ) { try { if ( ! ( transportService . nodeConnected ( listedNode ) ) ) { try { if ( nodes . contains ( listedNode ) ) { logger . trace ( "connecting<seq2seq4repair_space>to<seq2seq4repair_space>cluster<seq2seq4repair_space>node<seq2seq4repair_space>[{}]" , listedNode ) ; transportService . connectToNode ( listedNode ) ; } else { logger . trace ( "connecting<seq2seq4repair_space>to<seq2seq4repair_space>listed<seq2seq4repair_space>node<seq2seq4repair_space>(light)<seq2seq4repair_space>[{}]" , listedNode ) ; transportService . connectToNodeLight ( listedNode ) ; } } catch ( Exception e ) { logger . debug ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>connect<seq2seq4repair_space>to<seq2seq4repair_space>node<seq2seq4repair_space>[{}],<seq2seq4repair_space>ignoring..." , e , listedNode ) ; latch . countDown ( ) ; return ; } } transportService . sendRequest ( listedNode , ClusterStateAction . NAME , Requests . clusterStateRequest ( ) . clear ( ) . nodes ( true ) . local ( true ) , TransportRequestOptions . options ( ) . withType ( STATE ) . withTimeout ( pingTimeout ) , new BaseTransportResponseHandler < ClusterStateResponse > ( ) { @ Override public ClusterStateResponse newInstance ( ) { return new ClusterStateResponse ( ) ; } @ Override public String executor ( ) { return ThreadPool . Names . SAME ; } @ Override public void handleResponse ( ClusterStateResponse response ) { clusterStateResponses . put ( listedNode , response ) ; latch . countDown ( ) ; } @ Override public void handleException ( TransportException e ) { logger . info ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>get<seq2seq4repair_space>local<seq2seq4repair_space>cluster<seq2seq4repair_space>state<seq2seq4repair_space>for<seq2seq4repair_space>{},<seq2seq4repair_space>disconnecting..." , e , listedNode ) ; transportService . disconnectFromNode ( listedNode ) ; latch . countDown ( ) ; } } ) ; } catch ( Throwable e ) { logger . info ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>get<seq2seq4repair_space>local<seq2seq4repair_space>cluster<seq2seq4repair_space>state<seq2seq4repair_space>info<seq2seq4repair_space>for<seq2seq4repair_space>{},<seq2seq4repair_space>disconnecting..." , e , listedNode ) ; transportService . disconnectFromNode ( listedNode ) ; latch . countDown ( ) ; } } } ) ; } try { latch . await ( ) ; } catch ( InterruptedException e ) { return ; } <START_BUG> HashSet < DiscoveryNode > newNodes = new HashSet ( listedNodes ) ; <END_BUG> HashSet < DiscoveryNode > newFilteredNodes = new HashSet < > ( ) ; for ( Map . Entry < DiscoveryNode , ClusterStateResponse > entry : clusterStateResponses . entrySet ( ) ) { if ( ( ! ( ignoreClusterName ) ) && ( ! ( clusterName . equals ( entry . getValue ( ) . getClusterName ( ) ) ) ) ) { logger . warn ( "node<seq2seq4repair_space>{}<seq2seq4repair_space>not<seq2seq4repair_space>part<seq2seq4repair_space>of<seq2seq4repair_space>the<seq2seq4repair_space>cluster<seq2seq4repair_space>{},<seq2seq4repair_space>ignoring..." , entry . getValue ( ) . getState ( ) . nodes ( ) . localNode ( ) , clusterName ) ; newFilteredNodes . add ( entry . getKey ( ) ) ; continue ; } for ( ObjectCursor < DiscoveryNode > cursor : entry . getValue ( ) . getState ( ) . nodes ( ) . dataNodes ( ) . values ( ) ) { newNodes . add ( cursor . value ) ; } } nodes = validateNewNodes ( newNodes ) ; filteredNodes = ImmutableList . copyOf ( newFilteredNodes ) ; } } public static interface NodeListenerCallback < Response > { void doWithNode ( DiscoveryNode node , ActionListener < Response > listener ) { } } }<BUG2FIX>HashSet < DiscoveryNode > newNodes = new HashSet < > ( ) ;
public class FloatArrayRef extends AbstractList < Float > implements RandomAccess { public static final FloatArrayRef EMPTY = new FloatArrayRef ( new float [ 0 ] ) ; public float [ ] values ; public int start ; public int end ; public FloatArrayRef ( float [ ] values ) { } public FloatArrayRef ( float [ ] values , int length ) { } public FloatArrayRef ( float [ ] values , int start , int end ) { } public void reset ( int newLength ) { } @ Override public int size ( ) { } @ Override public boolean isEmpty ( ) { <START_BUG> return ( size ( ) ) != 0 ; <END_BUG> } @ Override public Float get ( int index ) { } @ Override public boolean contains ( Object target ) { } @ Override public int indexOf ( Object target ) { } @ Override public int lastIndexOf ( Object target ) { } @ Override public Float set ( int index , Float element ) { } @ Override public boolean equals ( Object object ) { } @ Override public int hashCode ( ) { } @ Override public String toString ( ) { } private static int indexOf ( float [ ] array , float target , int start , int end ) { } private static int lastIndexOf ( float [ ] array , float target , int start , int end ) { } }<BUG2FIX>return ( size ( ) ) == 0 ;
public class NumericRangeFilterBuilder extends BaseFilterBuilder { private final String name ; private Object from ; private Object to ; private boolean includeLower = true ; private boolean includeUpper = true ; private Boolean cache ; private String cacheKey ; private String filterName ; public NumericRangeFilterBuilder ( String name ) { } public NumericRangeFilterBuilder from ( Object from ) { } public NumericRangeFilterBuilder from ( int from ) { } public NumericRangeFilterBuilder from ( long from ) { } public NumericRangeFilterBuilder from ( float from ) { } public NumericRangeFilterBuilder from ( double from ) { } public NumericRangeFilterBuilder gt ( Object from ) { } public NumericRangeFilterBuilder gt ( int from ) { } public NumericRangeFilterBuilder gt ( long from ) { } public NumericRangeFilterBuilder gt ( float from ) { } public NumericRangeFilterBuilder gt ( double from ) { } public NumericRangeFilterBuilder gte ( Object from ) { } public NumericRangeFilterBuilder gte ( int from ) { } public NumericRangeFilterBuilder gte ( long from ) { } public NumericRangeFilterBuilder gte ( float from ) { } public NumericRangeFilterBuilder gte ( double from ) { } public NumericRangeFilterBuilder to ( Object to ) { } public NumericRangeFilterBuilder to ( int to ) { } public NumericRangeFilterBuilder to ( long to ) { } public NumericRangeFilterBuilder to ( float to ) { } public NumericRangeFilterBuilder to ( double to ) { } public NumericRangeFilterBuilder lt ( Object to ) { } public NumericRangeFilterBuilder lt ( int to ) { } public NumericRangeFilterBuilder lt ( long to ) { } public NumericRangeFilterBuilder lt ( float to ) { } public NumericRangeFilterBuilder lt ( double to ) { } <START_BUG> public NumericRangeFilterBuilder lte ( String to ) { <END_BUG> this . to = to ; this . includeUpper = true ; return this ; } public NumericRangeFilterBuilder lte ( int to ) { } public NumericRangeFilterBuilder lte ( long to ) { } public NumericRangeFilterBuilder lte ( float to ) { } public NumericRangeFilterBuilder lte ( double to ) { } public NumericRangeFilterBuilder includeLower ( boolean includeLower ) { } public NumericRangeFilterBuilder includeUpper ( boolean includeUpper ) { } public NumericRangeFilterBuilder filterName ( String filterName ) { } public NumericRangeFilterBuilder cache ( boolean cache ) { } public NumericRangeFilterBuilder cacheKey ( String cacheKey ) { } @ Override protected void doXContent ( XContentBuilder builder , Params params ) throws IOException { } }<BUG2FIX>public NumericRangeFilterBuilder lte ( Object to ) {
public class BlitTest extends GdxTest { @ Override public boolean needsGL20 ( ) { <START_BUG> return false ; <END_BUG> } Texture rgb888 ; Texture rgba8888 ; Texture psRgb888 ; Texture psRgba8888 ; SpriteBatch batch ; public void create ( ) { } public void render ( ) { } }<BUG2FIX>return true ;
public class IndexBufferObjectSubData implements IndexData { static final IntBuffer tmpHandle = BufferUtils . newIntBuffer ( 1 ) ; ShortBuffer buffer ; ByteBuffer byteBuffer ; int bufferHandle ; final boolean isDirect ; boolean isDirty = true ; boolean isBound = false ; final int usage ; public IndexBufferObjectSubData ( boolean isStatic , int maxIndices ) { } public IndexBufferObjectSubData ( int maxIndices ) { } private int createBufferObject ( ) { } public int getNumIndices ( ) { } public int getNumMaxIndices ( ) { } public void setIndices ( short [ ] indices , int offset , int count ) { isDirty = true ; buffer . clear ( ) ; buffer . put ( indices , offset , count ) ; buffer . flip ( ) ; byteBuffer . position ( 0 ) ; byteBuffer . limit ( ( count << 1 ) ) ; if ( isBound ) { if ( ( Gdx . gl11 ) != null ) { GL11 gl = Gdx . gl11 ; gl . glBufferSubData ( GL_ELEMENT_ARRAY_BUFFER , 0 , byteBuffer . limit ( ) , byteBuffer ) ; } else <START_BUG> if ( ( Gdx . gl20 ) != null ) { <END_BUG> GL20 gl = Gdx . gl20 ; gl . glBufferSubData ( GL20 . GL_ELEMENT_ARRAY_BUFFER , 0 , byteBuffer . limit ( ) , byteBuffer ) ; } isDirty = false ; } } public ShortBuffer getBuffer ( ) { } public void bind ( ) { } public void unbind ( ) { } public void invalidate ( ) { } public void dispose ( ) { } }<BUG2FIX>if ( ( Gdx . gl11 ) != null ) {
public class SuggestSearchTests extends AbstractSharedClusterTest { @ Test public void testSuggestModes ( ) throws IOException { } @ Test public void testSizeOneShard ( ) throws Exception { } @ Test public void testUnmappedField ( ) throws IOException , InterruptedException , ExecutionException { } @ Test public void testSimple ( ) throws Exception { } @ Test public void testEmpty ( ) throws Exception { } @ Test public void testWithMultipleCommands ( ) throws Exception { } @ Test public void testSizeAndSort ( ) throws Exception { } @ Test public void testStopwordsOnlyPhraseSuggest ( ) throws IOException , ElasticSearchException { } @ Test public void testPrefixLength ( ) throws IOException , ElasticSearchException { } @ Test public void testMarvelHerosPhraseSuggest ( ) throws IOException , ElasticSearchException { } @ Test public void testSizePararm ( ) throws IOException { } @ Test public void testPhraseBoundaryCases ( ) throws IOException , ElasticSearchException { } protected Suggest searchSuggest ( Client client , SuggestionBuilder < ? > ... suggestion ) { } protected Suggest searchSuggest ( Client client , String suggestText , SuggestionBuilder < ? > ... suggestions ) { } protected Suggest searchSuggest ( Client client , String suggestText , int expectShardsFailed , SuggestionBuilder < ? > ... suggestions ) { } @ Test public void testDifferentShardSize ( ) throws Exception { } @ Test public void testShardFailures ( ) throws IOException , InterruptedException { Builder builder = ImmutableSettings . builder ( ) ; <START_BUG> builder . put ( "index.number_of_shards" , between ( 1 , 5 ) ) . put ( "index.number_of_replicas" , between ( 0 , 3 ) ) ; <END_BUG> builder . put ( "index.analysis.analyzer.suggest.tokenizer" , "standard" ) ; builder . putArray ( "index.analysis.analyzer.suggest.filter" , "standard" , "lowercase" , "shingler" ) ; builder . put ( "index.analysis.filter.shingler.type" , "shingle" ) ; builder . put ( "index.analysis.filter.shingler.min_shingle_size" , 2 ) ; builder . put ( "index.analysis.filter.shingler.max_shingle_size" , 5 ) ; builder . put ( "index.analysis.filter.shingler.output_unigrams" , true ) ; XContentBuilder mapping = XContentFactory . jsonBuilder ( ) . startObject ( ) . startObject ( "type1" ) . startObject ( "properties" ) . startObject ( "name" ) . field ( "type" , "multi_field" ) . field ( "path" , "just_name" ) . startObject ( "fields" ) . startObject ( "name" ) . field ( "type" , "string" ) . field ( "analyzer" , "suggest" ) . endObject ( ) . endObject ( ) . endObject ( ) . endObject ( ) . endObject ( ) . endObject ( ) ; client ( ) . admin ( ) . indices ( ) . prepareDelete ( ) . execute ( ) . actionGet ( ) ; client ( ) . admin ( ) . indices ( ) . prepareCreate ( "test" ) . setSettings ( builder . build ( ) ) . addMapping ( "type1" , mapping ) . execute ( ) . actionGet ( ) ; client ( ) . admin ( ) . cluster ( ) . prepareHealth ( "test" ) . setWaitForGreenStatus ( ) . execute ( ) . actionGet ( ) ; client ( ) . prepareIndex ( "test" , "type2" , "1" ) . setSource ( XContentFactory . jsonBuilder ( ) . startObject ( ) . field ( "foo" , "bar" ) . endObject ( ) ) . execute ( ) . actionGet ( ) ; client ( ) . prepareIndex ( "test" , "type2" , "2" ) . setSource ( XContentFactory . jsonBuilder ( ) . startObject ( ) . field ( "foo" , "bar" ) . endObject ( ) ) . execute ( ) . actionGet ( ) ; client ( ) . prepareIndex ( "test" , "type2" , "3" ) . setSource ( XContentFactory . jsonBuilder ( ) . startObject ( ) . field ( "foo" , "bar" ) . endObject ( ) ) . execute ( ) . actionGet ( ) ; client ( ) . prepareIndex ( "test" , "type2" , "4" ) . setSource ( XContentFactory . jsonBuilder ( ) . startObject ( ) . field ( "foo" , "bar" ) . endObject ( ) ) . execute ( ) . actionGet ( ) ; client ( ) . prepareIndex ( "test" , "type2" , "5" ) . setSource ( XContentFactory . jsonBuilder ( ) . startObject ( ) . field ( "foo" , "bar" ) . endObject ( ) ) . execute ( ) . actionGet ( ) ; client ( ) . prepareIndex ( "test" , "type1" , "1" ) . setSource ( XContentFactory . jsonBuilder ( ) . startObject ( ) . field ( "name" , "Just<seq2seq4repair_space>testing<seq2seq4repair_space>the<seq2seq4repair_space>suggestions<seq2seq4repair_space>api" ) . endObject ( ) ) . execute ( ) . actionGet ( ) ; client ( ) . prepareIndex ( "test" , "type1" , "2" ) . setSource ( XContentFactory . jsonBuilder ( ) . startObject ( ) . field ( "name" , "An<seq2seq4repair_space>other<seq2seq4repair_space>title" ) . endObject ( ) ) . execute ( ) . actionGet ( ) ; client ( ) . admin ( ) . indices ( ) . prepareRefresh ( ) . execute ( ) . actionGet ( ) ; SearchRequestBuilder suggestBuilder = client ( ) . prepareSearch ( ) . setSearchType ( COUNT ) ; suggestBuilder . setSuggestText ( "tetsting<seq2seq4repair_space>sugestion" ) ; suggestBuilder . addSuggestion ( phraseSuggestion ( "did_you_mean" ) . field ( "fielddoesnotexist" ) . maxErrors ( 5.0F ) ) ; assertThrows ( suggestBuilder , SearchPhaseExecutionException . class ) ; suggestBuilder = client ( ) . prepareSearch ( ) . setSearchType ( COUNT ) ; suggestBuilder . setSuggestText ( "tetsting<seq2seq4repair_space>sugestion" ) ; suggestBuilder . addSuggestion ( phraseSuggestion ( "did_you_mean" ) . field ( "name" ) . maxErrors ( 5.0F ) ) ; SearchResponse searchResponse = suggestBuilder . execute ( ) . actionGet ( ) ; ElasticsearchAssertions . assertNoFailures ( searchResponse ) ; ElasticsearchAssertions . assertSuggestion ( searchResponse . getSuggest ( ) , 0 , 0 , "did_you_mean" , "testing<seq2seq4repair_space>suggestions" ) ; } @ Test public void testEmptyShards ( ) throws IOException , InterruptedException { } }<BUG2FIX>builder . put ( "index.number_of_shards" , between ( 1 , 5 ) ) . put ( "index.number_of_replicas" , between ( 0 , 2 ) ) ;
public class WallElement extends FieldElement { Body wallBody ; Collection bodySet ; float x1 ; float y1 ; float x2 ; float y2 ; float kick ; boolean killBall ; boolean retractWhenHit ; @ Override public void finishCreate ( Map params , World world ) { } public boolean isRetracted ( ) { } public void setRetracted ( boolean retracted ) { } @ Override public Collection getBodies ( ) { } @ Override public boolean shouldCallTick ( ) { } Vector2 impulseForBall ( Body ball ) { } @ Override public void handleCollision ( Body ball , Body bodyHit , Field field ) { if ( retractWhenHit ) { this . setRetracted ( true ) ; } if ( killBall ) { field . removeBall ( ball ) ; } else { Vector2 impulse = this . impulseForBall ( ball ) ; if ( impulse != null ) { <START_BUG> ball . applyLinearImpulse ( impulse , ball . getWorldCenter ( ) ) ; <END_BUG> flashForFrames ( 3 ) ; } } } @ Override public void draw ( IFieldRenderer renderer ) { } }<BUG2FIX>ball . applyLinearImpulse ( impulse , ball . getWorldCenter ( ) , true ) ;
public class ConstantScoreQueryParser extends AbstractIndexComponent implements XContentQueryParser { public static final String NAME = "constant_score" ; @ Inject public ConstantScoreQueryParser ( Index index , @ IndexSettings Settings settings ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; Filter filter = null ; float boost = 1.0F ; <START_BUG> boolean cache = true ; <END_BUG> String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_OBJECT ) ) { if ( "filter" . equals ( currentFieldName ) ) { filter = parseContext . parseInnerFilter ( ) ; } } else if ( token . isValue ( ) ) { if ( "boost" . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } else if ( "_cache" . equals ( currentFieldName ) ) { cache = parser . booleanValue ( ) ; } } } if ( filter == null ) { throw new QueryParsingException ( index , "[constant_score]<seq2seq4repair_space>requires<seq2seq4repair_space>'filter'<seq2seq4repair_space>element" ) ; } if ( cache ) { filter = parseContext . cacheFilter ( filter ) ; } Query query = new org . apache . lucene . search . DeletionAwareConstantScoreQuery ( filter , true ) ; query . setBoost ( boost ) ; return query ; } }<BUG2FIX>boolean cache = false ;
public class DoubleFieldsFunctionDataComparator extends FieldComparator < Double > { public static ExtendedFieldComparatorSource comparatorSource ( SearchScript script ) { } private static class InnerSource extends FieldDataType . ExtendedFieldComparatorSource { private final SearchScript script ; private InnerSource ( SearchScript script ) { } @ Override public FieldComparator newComparator ( String fieldname , int numHits , int sortPos , boolean reversed ) throws IOException { } @ Override public Type reducedType ( ) { } } private final SearchScript script ; private final double [ ] values ; private double bottom ; public DoubleFieldsFunctionDataComparator ( int numHits , SearchScript script ) { } @ Override public FieldComparator < Double > setNextReader ( AtomicReaderContext context ) throws IOException { <START_BUG> script . setNextReader ( context . reader ( ) ) ; <END_BUG> return this ; } @ Override public void setScorer ( Scorer scorer ) { } @ Override public int compare ( int slot1 , int slot2 ) { } @ Override public int compareBottom ( int doc ) { } @ Override public int compareDocToValue ( int doc , Double val2 ) throws IOException { } @ Override public void copy ( int slot , int doc ) { } @ Override public void setBottom ( final int bottom ) { } @ Override public Double value ( int slot ) { } }<BUG2FIX>script . setNextReader ( context ) ;
public class PlainHighlighter implements Highlighter { private static final String CACHE_KEY = "highlight-plain" ; @ Override public String [ ] names ( ) { } public HighlightField highlight ( HighlighterContext highlighterContext ) { SearchContextHighlight . Field field = highlighterContext . field ; SearchContext context = highlighterContext . context ; FetchSubPhase . HitContext hitContext = highlighterContext . hitContext ; FieldMapper < ? > mapper = highlighterContext . mapper ; Encoder encoder = ( field . encoder ( ) . equals ( "html" ) ) ? Encoders . HTML : Encoders . DEFAULT ; if ( ! ( hitContext . cache ( ) . containsKey ( PlainHighlighter . CACHE_KEY ) ) ) { Map < FieldMapper < ? > , org . apache . lucene . search . highlight . Highlighter > mappers = Maps . newHashMap ( ) ; hitContext . cache ( ) . put ( PlainHighlighter . CACHE_KEY , mappers ) ; } Map < FieldMapper < ? > , org . apache . lucene . search . highlight . Highlighter > cache = ( ( Map < FieldMapper < ? > , org . apache . lucene . search . highlight . Highlighter > ) ( hitContext . cache ( ) . get ( PlainHighlighter . CACHE_KEY ) ) ) ; org . apache . lucene . search . highlight . Highlighter entry = cache . get ( mapper ) ; if ( entry == null ) { Query query = highlighterContext . query . originalQuery ( ) ; QueryScorer queryScorer = new CustomQueryScorer ( query , ( field . requireFieldMatch ( ) ? mapper . names ( ) . indexName ( ) : null ) ) ; queryScorer . setExpandMultiTermQuery ( true ) ; Fragmenter fragmenter ; if ( ( field . numberOfFragments ( ) ) == 0 ) { fragmenter = new NullFragmenter ( ) ; } else if ( ( field . fragmenter ( ) ) == null ) { fragmenter = new SimpleSpanFragmenter ( queryScorer , field . fragmentCharSize ( ) ) ; } else if ( "simple" . equals ( field . fragmenter ( ) ) ) { fragmenter = new SimpleFragmenter ( field . fragmentCharSize ( ) ) ; } else if ( "span" . equals ( field . fragmenter ( ) ) ) { fragmenter = new SimpleSpanFragmenter ( queryScorer , field . fragmentCharSize ( ) ) ; } else { throw new org . elasticsearch . ElasticSearchIllegalArgumentException ( ( ( ( ( "unknown<seq2seq4repair_space>fragmenter<seq2seq4repair_space>option<seq2seq4repair_space>[" + ( field . fragmenter ( ) ) ) + "]<seq2seq4repair_space>for<seq2seq4repair_space>the<seq2seq4repair_space>field<seq2seq4repair_space>[" ) + ( highlighterContext . fieldName ) ) + "]" ) ) ; } Formatter formatter = new SimpleHTMLFormatter ( field . preTags ( ) [ 0 ] , field . postTags ( ) [ 0 ] ) ; entry = new org . apache . lucene . search . highlight . Highlighter ( formatter , encoder , queryScorer ) ; entry . setTextFragmenter ( fragmenter ) ; entry . setMaxDocCharsToAnalyze ( Integer . MAX_VALUE ) ; cache . put ( mapper , entry ) ; } int numberOfFragments = ( ( field . numberOfFragments ( ) ) == 0 ) ? 1 : field . numberOfFragments ( ) ; ArrayList < TextFragment > fragsList = new ArrayList < TextFragment > ( ) ; List < Object > textsToHighlight ; try { <START_BUG> textsToHighlight = HighlightUtils . loadFieldValues ( mapper , context , hitContext , field . forceSource ( ) ) ; <END_BUG> for ( Object textToHighlight : textsToHighlight ) { String text = textToHighlight . toString ( ) ; Analyzer analyzer = context . mapperService ( ) . documentMapper ( hitContext . hit ( ) . type ( ) ) . mappers ( ) . indexAnalyzer ( ) ; TokenStream tokenStream = analyzer . tokenStream ( mapper . names ( ) . indexName ( ) , text ) ; if ( ( ! ( tokenStream . hasAttribute ( CharTermAttribute . class ) ) ) || ( ! ( tokenStream . hasAttribute ( OffsetAttribute . class ) ) ) ) { continue ; } TextFragment [ ] bestTextFragments = entry . getBestTextFragments ( tokenStream , text , false , numberOfFragments ) ; for ( TextFragment bestTextFragment : bestTextFragments ) { if ( ( bestTextFragment != null ) && ( ( bestTextFragment . getScore ( ) ) > 0 ) ) { fragsList . add ( bestTextFragment ) ; } } } } catch ( Exception e ) { throw new org . elasticsearch . search . fetch . FetchPhaseExecutionException ( context , ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>highlight<seq2seq4repair_space>field<seq2seq4repair_space>[" + ( highlighterContext . fieldName ) ) + "]" ) , e ) ; } if ( field . scoreOrdered ( ) ) { CollectionUtil . introSort ( fragsList , new Comparator < TextFragment > ( ) { public int compare ( TextFragment o1 , TextFragment o2 ) { return Math . round ( ( ( o2 . getScore ( ) ) - ( o1 . getScore ( ) ) ) ) ; } } ) ; } String [ ] fragments ; if ( ( ( ( field . numberOfFragments ( ) ) == 0 ) && ( ( textsToHighlight . size ( ) ) > 1 ) ) && ( ( fragsList . size ( ) ) > 0 ) ) { fragments = new String [ fragsList . size ( ) ] ; for ( int i = 0 ; i < ( fragsList . size ( ) ) ; i ++ ) { fragments [ i ] = fragsList . get ( i ) . toString ( ) ; } } else { numberOfFragments = ( ( fragsList . size ( ) ) < numberOfFragments ) ? fragsList . size ( ) : numberOfFragments ; fragments = new String [ numberOfFragments ] ; for ( int i = 0 ; i < ( fragments . length ) ;<BUG2FIX>textsToHighlight = HighlightUtils . loadFieldValues ( mapper , context , hitContext ) ;
public class FilterListFragment extends ItemListFragment < IssueFilter > implements Comparator < IssueFilter > { @ Inject private AccountDataManager cache ; @ Inject private AvatarLoader avatars ; @ Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; <START_BUG> setEmptyText ( getString ( no_filters ) ) ; <END_BUG> } @ Override public Loader < List < IssueFilter > > onCreateLoader ( int id , Bundle args ) { } @ Override public void onListItemClick ( ListView l , View v , int position , long id ) { } @ Override public void onResume ( ) { } @ Override protected ItemListAdapter < IssueFilter , ? extends ItemView > createAdapter ( List < IssueFilter > items ) { } @ Override public int compare ( final IssueFilter lhs , final IssueFilter rhs ) { } }<BUG2FIX>setEmptyText ( no_filters ) ;
public abstract class GistsFragment extends PagedItemFragment < Gist > { @ Inject protected AvatarLoader avatarHelper ; @ Inject protected GistService service ; @ Inject protected GistStore store ; @ Override public void onListItemClick ( ListView l , View v , int position , long id ) { } @ Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; setEmptyText ( getString ( no_gists ) ) ; <START_BUG> ListViewUtils . configure ( getActivity ( ) , getListView ( ) , true ) ; <END_BUG> } @ Override public boolean onOptionsItemSelected ( MenuItem item ) { } @ Override public void onActivityResult ( int requestCode , int resultCode , Intent data ) { } @ Override public void onLoadFinished ( Loader < List < Gist > > loader , List < Gist > items ) { } @ Override protected int getLoadingMessage ( ) { } @ Override protected ItemListAdapter < Gist , ? extends ItemView > createAdapter ( List < Gist > items ) { } }<BUG2FIX>ListViewUtils . configure ( getActivity ( ) , getListView ( ) ) ;
public class IncludeNestedDocsQuery extends Query { private final Filter parentFilter ; private final Query parentQuery ; private final Query origParentQuery ; public IncludeNestedDocsQuery ( Query parentQuery , Filter parentFilter ) { } IncludeNestedDocsQuery ( Query rewrite , Query originalQuery , IncludeNestedDocsQuery previousInstance ) { } IncludeNestedDocsQuery ( Query originalQuery , IncludeNestedDocsQuery previousInstance ) { } @ Override public Weight createWeight ( IndexSearcher searcher ) throws IOException { } static class IncludeNestedDocsWeight extends Weight { private final Query parentQuery ; private final Weight parentWeight ; private final Filter parentsFilter ; IncludeNestedDocsWeight ( Query parentQuery , Weight parentWeight , Filter parentsFilter ) { } @ Override public Query getQuery ( ) { } @ Override public void normalize ( float norm , float topLevelBoost ) { } @ Override public float getValueForNormalization ( ) throws IOException { } @ Override public Scorer scorer ( AtomicReaderContext context , boolean scoreDocsInOrder , boolean topScorer , Bits acceptDocs ) throws IOException { } @ Override public Explanation explain ( AtomicReaderContext context , int doc ) throws IOException { } @ Override public boolean scoresDocsOutOfOrder ( ) { } } static class IncludeNestedDocsScorer extends Scorer { final Scorer parentScorer ; final FixedBitSet parentBits ; int currentChildPointer = - 1 ; int currentParentPointer = - 1 ; int currentDoc = - 1 ; IncludeNestedDocsScorer ( Weight weight , Scorer parentScorer , FixedBitSet parentBits , int currentParentPointer ) { } @ Override public Collection < ChildScorer > getChildren ( ) { } public int nextDoc ( ) throws IOException { } public int advance ( int target ) throws IOException { } public float score ( ) throws IOException { } <START_BUG> public float freq ( ) throws IOException { <END_BUG> return parentScorer . freq ( ) ; } public int docID ( ) { } } @ Override public void extractTerms ( Set < Term > terms ) { } @ Override public Query rewrite ( IndexReader reader ) throws IOException { } @ Override public String toString ( String field ) { } @ Override public boolean equals ( Object _other ) { } @ Override public int hashCode ( ) { } @ Override public Query clone ( ) { } }<BUG2FIX>public int freq ( ) throws IOException {
public class MipMapTest extends GdxTest { @ Override public boolean needsGL20 ( ) { } PerspectiveCamera camera ; PerspectiveCamController controller ; Mesh mesh ; Texture textureHW ; Texture textureSW ; Texture currTexture ; ShaderProgram shader ; Stage ui ; InputMultiplexer multiplexer ; ComboBox minFilter ; ComboBox magFilter ; CheckBox hwMipMap ; @ Override public void create ( ) { } private void createUI ( ) { Skin skin = new Skin ( files . internal ( "data/uiskin.json" ) , files . internal ( "data/uiskin.png" ) ) ; ui = new Stage ( graphics . getWidth ( ) , graphics . getHeight ( ) , false ) ; String [ ] filters = new String [ TextureFilter . values ( ) . length ] ; int idx = 0 ; for ( TextureFilter filter : TextureFilter . values ( ) ) { filters [ ( idx ++ ) ] = filter . toString ( ) ; } hwMipMap = new CheckBox ( "Hardware<seq2seq4repair_space>Mips" , skin . getStyle ( CheckBoxStyle . class ) , "hardware" ) ; minFilter = new ComboBox ( filters , ui , skin . getStyle ( ComboBoxStyle . class ) , "minfilter" ) ; magFilter = new ComboBox ( new String [ ] { "Nearest" , "Linear" } , ui , skin . getStyle ( ComboBoxStyle . class ) , "magfilter" ) ; <START_BUG> Table table = new Table ( "container" ) ; <END_BUG> table . width = ui . width ( ) ; table . height = 30 ; table . y = ( ui . height ( ) ) - 30 ; table . add ( hwMipMap ) . spaceRight ( 5 ) ; table . add ( new com . badlogic . gdx . scenes . scene2d . ui . Label ( "Min<seq2seq4repair_space>Filter" , skin . getStyle ( LabelStyle . class ) ) ) . spaceRight ( 5 ) ; table . add ( minFilter ) . spaceRight ( 5 ) ; table . add ( new com . badlogic . gdx . scenes . scene2d . ui . Label ( "Mag<seq2seq4repair_space>Filter" , skin . getStyle ( LabelStyle . class ) ) ) . spaceRight ( 5 ) ; table . add ( magFilter ) ; ui . addActor ( table ) ; } @ Override public void render ( ) { } }<BUG2FIX>Table table = new Table ( ) ;
public class MetaDataDeleteIndexService extends AbstractComponent { private final ThreadPool threadPool ; private final ClusterService clusterService ; private final AllocationService allocationService ; private final NodeIndexDeletedAction nodeIndexDeletedAction ; private final MetaDataService metaDataService ; @ Inject public MetaDataDeleteIndexService ( Settings settings , ThreadPool threadPool , ClusterService clusterService , AllocationService allocationService , NodeIndexDeletedAction nodeIndexDeletedAction , MetaDataService metaDataService ) { } public void deleteIndex ( final MetaDataDeleteIndexService . Request request , final MetaDataDeleteIndexService . Listener userListener ) { MetaDataService . MdLock mdLock = metaDataService . indexMetaDataLock ( request . index ) ; try { mdLock . lock ( ) ; } catch ( InterruptedException e ) { userListener . onFailure ( e ) ; return ; } final MetaDataDeleteIndexService . DeleteIndexListener listener = new MetaDataDeleteIndexService . DeleteIndexListener ( mdLock , request , userListener ) ; clusterService . submitStateUpdateTask ( ( ( "delete-index<seq2seq4repair_space>[" + ( request . index ) ) + "]" ) , new ClusterStateUpdateTask ( ) { @ Override public ClusterState execute ( ClusterState currentState ) { try { if ( ! ( currentState . metaData ( ) . hasConcreteIndex ( request . index ) ) ) { listener . onFailure ( new org . elasticsearch . indices . IndexMissingException ( new Index ( request . index ) ) ) ; return currentState ; } logger . info ( "[{}]<seq2seq4repair_space>deleting<seq2seq4repair_space>index" , request . index ) ; RoutingTable . Builder routingTableBuilder = RoutingTable . builder ( ) . routingTable ( currentState . routingTable ( ) ) ; routingTableBuilder . remove ( request . index ) ; MetaData newMetaData = MetaData . newMetaDataBuilder ( ) . metaData ( currentState . metaData ( ) ) . remove ( request . index ) . build ( ) ; RoutingAllocation . Result routingResult = allocationService . reroute ( ClusterState . newClusterStateBuilder ( ) . state ( currentState ) . routingTable ( routingTableBuilder ) . metaData ( newMetaData ) . build ( ) ) ; ClusterBlocks blocks = ClusterBlocks . builder ( ) . blocks ( currentState . blocks ( ) ) . removeIndexBlocks ( request . index ) . build ( ) ; final AtomicInteger counter = new AtomicInteger ( currentState . nodes ( ) . size ( ) ) ; final NodeIndexDeletedAction . Listener nodeIndexDeleteListener = new NodeIndexDeletedAction . Listener ( ) { @ Override public void onNodeIndexDeleted ( String index , String nodeId ) { if ( index . equals ( request . index ) ) { if ( ( counter . decrementAndGet ( ) ) == 0 ) { listener . onResponse ( new MetaDataDeleteIndexService . Response ( true ) ) ; nodeIndexDeletedAction . remove ( this ) ; } } } } ; nodeIndexDeletedAction . add ( nodeIndexDeleteListener ) ; listener . future = threadPool . schedule ( request . timeout , SAME , new Runnable ( ) { @ Override public void run ( ) { listener . onResponse ( new MetaDataDeleteIndexService . Response ( false ) ) ; nodeIndexDeletedAction . remove ( nodeIndexDeleteListener ) ; } } ) ; return ClusterState . newClusterStateBuilder ( ) . state ( currentState ) . routingResult ( routingResult ) . metaData ( newMetaData ) . blocks ( blocks ) . build ( ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> listener . onFailure ( e ) ; return currentState ; } } } ) ; } class DeleteIndexListener implements MetaDataDeleteIndexService . Listener { private final AtomicBoolean notified = new AtomicBoolean ( ) ; private final MdLock mdLock ; private final MetaDataDeleteIndexService . Request request ; private final MetaDataDeleteIndexService . Listener listener ; volatile ScheduledFuture future ; private DeleteIndexListener ( MetaDataService . MdLock mdLock , MetaDataDeleteIndexService . Request request , MetaDataDeleteIndexService . Listener listener ) { } @ Override public void onResponse ( final MetaDataDeleteIndexService . Response response ) { } @ Override public void onFailure ( Throwable t ) { } } public static interface Listener { void onResponse ( MetaDataDeleteIndexService . Response response ) { } void onFailure ( Throwable t ) { } } public static class Request { final String index ; TimeValue timeout = TimeValue . timeValueSeconds ( 10 ) ; public Request ( String index ) { } public MetaDataDeleteIndexService . Request timeout ( TimeValue timeout ) { } } public static class Response { private final boolean acknowledged ; public Response ( boolean acknowledged ) { } public boolean acknowledged ( ) { } } }<BUG2FIX>} catch ( Throwable e ) {
public class IdentityMap < K , V > { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; public int size ; K [ ] keyTable ; V [ ] valueTable ; int capacity ; int stashSize ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private IdentityMap . Entries entries1 ; private IdentityMap . Entries entries2 ; private IdentityMap . Values values1 ; private IdentityMap . Values values2 ; private IdentityMap . Keys keys1 ; private IdentityMap . Keys keys2 ; public IdentityMap ( ) { } public IdentityMap ( int initialCapacity ) { } public IdentityMap ( int initialCapacity , float loadFactor ) { } public IdentityMap ( IdentityMap map ) { } public V put ( K key , V value ) { } private void putResize ( K key , V value ) { } private void push ( K insertKey , V insertValue , int index1 , K key1 , int index2 , K key2 , int index3 , K key3 ) { } private void putStash ( K key , V value ) { } public V get ( K key ) { } public V get ( K key , V defaultValue ) { } private V getStash ( K key , V defaultValue ) { } public V remove ( K key ) { } V removeStash ( K key ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean containsValue ( Object value , boolean identity ) { } public boolean containsKey ( K key ) { } private boolean containsKeyStash ( K key ) { } public K findKey ( Object value , boolean identity ) { } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( int h ) { } private int hash3 ( int h ) { } public String toString ( ) { } public IdentityMap . Entries < K , V > entries ( ) { } public IdentityMap . Values < V > values ( ) { } public IdentityMap . Keys < K > keys ( ) { } public static class Entry < K , V > { public K key ; public V value ; public String toString ( ) { } } private static class MapIterator < K , V > { public boolean hasNext ; final IdentityMap < K , V > map ; int nextIndex ; int currentIndex ; boolean valid = true ; public MapIterator ( IdentityMap < K , V > map ) { } public void reset ( ) { } void findNextIndex ( ) { } public void remove ( ) { if ( ( currentIndex ) < 0 ) throw new IllegalStateException ( "next<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>called<seq2seq4repair_space>before<seq2seq4repair_space>remove." ) ; if ( ( currentIndex ) >= ( map . capacity ) ) { map . removeStashIndex ( currentIndex ) ; <START_BUG> nextIndex = currentIndex ; <END_BUG> findNextIndex ( ) ; } else { map . keyTable [ currentIndex ] = null ; map . valueTable [ currentIndex ] = null ; } currentIndex = - 1 ; ( map . size ) -- ; } } public static class Entries < K , V > extends IdentityMap . MapIterator < K , V > implements Iterable < IdentityMap . Entry < K , V > > , Iterator < IdentityMap . Entry < K , V > > { private IdentityMap . Entry < K , V > entry = new IdentityMap . Entry ( ) ; public Entries ( IdentityMap < K , V > map ) { } public IdentityMap . Entry < K , V > next ( ) { } public boolean hasNext ( ) { } public Iterator < IdentityMap . Entry < K , V > > iterator ( ) { } } public static class Values < V > extends IdentityMap . MapIterator < Object , V > implements Iterable < V > , Iterator < V > { public Values ( IdentityMap < ? , V > map ) { } public boolean hasNext ( ) { } public V next ( ) { } public Iterator < V > iterator ( ) { } public Array < V > toArray ( ) { } public void toArray ( Array < V > array ) { } } public static class Keys < K > extends IdentityMap . MapIterator < K , Object > implements Iterable < K > , Iterator < K > { public Keys ( IdentityMap < K , ? > map ) { } public boolean hasNext ( ) { } public K next ( ) { } public Iterator < K > iterator ( ) { } public Array < K > toArray ( ) { } } }<BUG2FIX>nextIndex = ( currentIndex ) - 1 ;
abstract class QueryCollector extends Collector { final IndexFieldData idFieldData ; final IndexSearcher searcher ; final ConcurrentMap < HashedBytesRef , Query > queries ; final ESLogger logger ; final ExistsCollector collector = new Lucene . ExistsCollector ( ) ; final HashedBytesRef spare = new HashedBytesRef ( new BytesRef ( ) ) ; BytesValues values ; final List < Collector > facetCollectors = new ArrayList < Collector > ( ) ; final Collector facetCollector ; QueryCollector ( ESLogger logger , PercolateContext context ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override public void setNextReader ( AtomicReaderContext context ) throws IOException { <START_BUG> values = idFieldData . load ( context ) . getBytesValues ( ) ; <END_BUG> if ( ( facetCollector ) != null ) { facetCollector . setNextReader ( context ) ; } } @ Override public boolean acceptsDocsOutOfOrder ( ) { } static QueryCollector . Match match ( ESLogger logger , PercolateContext context , HighlightPhase highlightPhase ) { } static QueryCollector . Count count ( ESLogger logger , PercolateContext context ) { } static QueryCollector . MatchAndScore matchAndScore ( ESLogger logger , PercolateContext context , HighlightPhase highlightPhase ) { } static QueryCollector . MatchAndSort matchAndSort ( ESLogger logger , PercolateContext context ) { } static final class Match extends QueryCollector { final PercolateContext context ; final HighlightPhase highlightPhase ; final List < BytesRef > matches = new ArrayList < BytesRef > ( ) ; final List < Map < String , HighlightField > > hls = new ArrayList < Map < String , HighlightField > > ( ) ; final boolean limit ; final int size ; long counter = 0 ; Match ( ESLogger logger , PercolateContext context , HighlightPhase highlightPhase ) { } @ Override public void collect ( int doc ) throws IOException { } long counter ( ) { } List < BytesRef > matches ( ) { } List < Map < String , HighlightField > > hls ( ) { } } static final class MatchAndSort extends QueryCollector { private final TopScoreDocCollector topDocsCollector ; MatchAndSort ( ESLogger logger , PercolateContext context ) { } @ Override public void collect ( int doc ) throws IOException { } @ Override public void setNextReader ( AtomicReaderContext context ) throws IOException { super . setNextReader ( context ) ; topDocsCollector . setNextReader ( context ) ; } @ Override public void setScorer ( Scorer scorer ) throws IOException { } TopDocs topDocs ( ) { } } static final class MatchAndScore extends QueryCollector { final PercolateContext context ; final HighlightPhase highlightPhase ; final List < BytesRef > matches = new ArrayList < BytesRef > ( ) ; final List < Map < String , HighlightField > > hls = new ArrayList < Map < String , HighlightField > > ( ) ; final FloatArrayList scores = new FloatArrayList ( ) ; final boolean limit ; final int size ; long counter = 0 ; private Scorer scorer ; MatchAndScore ( ESLogger logger , PercolateContext context , HighlightPhase highlightPhase ) { } @ Override public void collect ( int doc ) throws IOException { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } long counter ( ) { } List < BytesRef > matches ( ) { } FloatArrayList scores ( ) { } List < Map < String , HighlightField > > hls ( ) { } } static final class Count extends QueryCollector { private long counter = 0 ; Count ( ESLogger logger , PercolateContext context ) { } @ Override public void collect ( int doc ) throws IOException { } long counter ( ) { } } }<BUG2FIX>values = idFieldData . load ( context ) . getBytesValues ( true ) ;
public class MipMapTest extends GdxTest { PerspectiveCamera camera ; PerspectiveCamController controller ; Mesh mesh ; Texture textureHW ; Texture textureSW ; Texture currTexture ; ShaderProgram shader ; Stage ui ; Skin skin ; InputMultiplexer multiplexer ; SelectBox < String > minFilter ; SelectBox < String > magFilter ; CheckBox hwMipMap ; @ Override public void create ( ) { } private void createUI ( ) { skin = new Skin ( files . internal ( "data/uiskin.json" ) ) ; <START_BUG> ui = new Stage ( graphics . getWidth ( ) , graphics . getHeight ( ) , false ) ; <END_BUG> String [ ] filters = new String [ TextureFilter . values ( ) . length ] ; int idx = 0 ; for ( TextureFilter filter : TextureFilter . values ( ) ) { filters [ ( idx ++ ) ] = filter . toString ( ) ; } hwMipMap = new CheckBox ( "Hardware<seq2seq4repair_space>Mips" , skin ) ; minFilter = new SelectBox ( skin ) ; minFilter . setItems ( filters ) ; magFilter = new SelectBox ( skin . get ( SelectBoxStyle . class ) ) ; magFilter . setItems ( "Nearest" , "Linear" ) ; Table table = new Table ( ) ; table . setSize ( ui . getWidth ( ) , 30 ) ; table . setY ( ( ( ui . getHeight ( ) ) - 30 ) ) ; table . add ( hwMipMap ) . spaceRight ( 5 ) ; table . add ( new com . badlogic . gdx . scenes . scene2d . ui . Label ( "Min<seq2seq4repair_space>Filter" , skin ) ) . spaceRight ( 5 ) ; table . add ( minFilter ) . spaceRight ( 5 ) ; table . add ( new com . badlogic . gdx . scenes . scene2d . ui . Label ( "Mag<seq2seq4repair_space>Filter" , skin ) ) . spaceRight ( 5 ) ; table . add ( magFilter ) ; ui . addActor ( table ) ; } @ Override public void render ( ) { } @ Override public void dispose ( ) { } }<BUG2FIX>ui = new Stage ( ) ;
public class DragAndDropTest extends GdxTest { Stage stage ; public void create ( ) { } public void render ( ) { } public void resize ( int width , int height ) { <START_BUG> stage . getViewport ( ) . update ( width , height ) ; <END_BUG> } public void dispose ( ) { } }<BUG2FIX>stage . getViewport ( ) . update ( width , height , true ) ;
public class DiscoveryService extends AbstractLifecycleComponent < DiscoveryService > { private static class InitialStateListener implements InitialStateDiscoveryListener { private final CountDownLatch latch = new CountDownLatch ( 1 ) ; private volatile boolean initialStateReceived ; @ Override public void initialStateProcessed ( ) { } public boolean waitForInitialState ( TimeValue timeValue ) throws InterruptedException { } } private final TimeValue initialStateTimeout ; private final Discovery discovery ; private DiscoveryService . InitialStateListener initialStateListener ; @ Inject public DiscoveryService ( Settings settings , Discovery discovery ) { } @ Override protected void doStart ( ) throws ElasticsearchException { } public void waitForInitialState ( ) { } @ Override protected void doStop ( ) throws ElasticsearchException { } @ Override protected void doClose ( ) throws ElasticsearchException { } public DiscoveryNode localNode ( ) { } public boolean initialStateReceived ( ) { } public String nodeDescription ( ) { } public void publish ( ClusterState clusterState , Discovery . AckListener ackListener ) { } public static String generateNodeId ( Settings settings ) { String seed = settings . get ( "discovery.id.seed" ) ; if ( seed != null ) { <START_BUG> Strings . randomBase64UUID ( new Random ( Long . parseLong ( seed ) ) ) ; <END_BUG> } return Strings . randomBase64UUID ( ) ; } }<BUG2FIX>return Strings . randomBase64UUID ( new Random ( Long . parseLong ( seed ) ) ) ;
public class Method { final String name ; final Class enclosingType ; final Class returnType ; final boolean isAbstract ; final boolean isFinal ; final boolean isStatic ; final boolean isNative ; final boolean isDefaultAccess ; final boolean isPrivate ; final boolean isProtected ; final boolean isPublic ; final boolean isVarArgs ; final boolean isMethod ; final boolean isConstructor ; final Parameter [ ] parameters ; final String methodId ; boolean accessible ; public Method ( String name , Class enclosingType , Class returnType , Parameter [ ] parameters , boolean isAbstract , boolean isFinal , boolean isStatic , boolean isDefaultAccess , boolean isPrivate , boolean isProtected , boolean isPublic , boolean isNative , boolean isVarArgs , boolean isMethod , boolean isConstructor , String methodId ) { } public boolean isAccessible ( ) { } public void setAccessible ( boolean accessible ) { } public Class getEnclosingType ( ) { } public Class getReturnType ( ) { } public Parameter [ ] getParameters ( ) { } public String getName ( ) { } public boolean isAbstract ( ) { } public boolean isFinal ( ) { } public boolean isDefaultAccess ( ) { } public boolean isPrivate ( ) { } public boolean isProtected ( ) { } public boolean isPublic ( ) { } public boolean isNative ( ) { } public boolean isVarArgs ( ) { } public boolean isStatic ( ) { } public boolean isMethod ( ) { } public boolean isConstructor ( ) { } public Object invoke ( Object obj , Object ... params ) { } boolean match ( String name , Class ... types ) { <START_BUG> if ( ! ( this . name . equals ( name ) ) ) <END_BUG> return false ; if ( ( types . length ) != ( parameters . length ) ) return false ; for ( int i = 0 ; i < ( types . length ) ; i ++ ) { Type t1 = instance . forName ( parameters [ i ] . getType ( ) . getName ( ) ) ; Type t2 = instance . forName ( types [ i ] . getName ( ) ) ; if ( ( t1 != t2 ) && ( ! ( t1 . isAssignableFrom ( t2 ) ) ) ) return false ; } return true ; } @ Override public String toString ( ) { } }<BUG2FIX>if ( ! ( name . equals ( name ) ) )
public class IdentityMap < K , V > { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; public int size ; K [ ] keyTable ; V [ ] valueTable ; int capacity ; int stashSize ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private IdentityMap . Entries entries1 ; private IdentityMap . Entries entries2 ; private IdentityMap . Values values1 ; private IdentityMap . Values values2 ; private IdentityMap . Keys keys1 ; private IdentityMap . Keys keys2 ; public IdentityMap ( ) { } public IdentityMap ( int initialCapacity ) { } public IdentityMap ( int initialCapacity , float loadFactor ) { } public IdentityMap ( IdentityMap map ) { } public V put ( K key , V value ) { } private void putResize ( K key , V value ) { } private void push ( K insertKey , V insertValue , int index1 , K key1 , int index2 , K key2 , int index3 , K key3 ) { } private void putStash ( K key , V value ) { } public V get ( K key ) { } public V get ( K key , V defaultValue ) { } private V getStash ( K key , V defaultValue ) { } public V remove ( K key ) { } V removeStash ( K key ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean containsValue ( Object value , boolean identity ) { } public boolean containsKey ( K key ) { } private boolean containsKeyStash ( K key ) { } public K findKey ( Object value , boolean identity ) { } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( int h ) { } private int hash3 ( int h ) { } public String toString ( ) { } public IdentityMap . Entries < K , V > entries ( ) { } public IdentityMap . Values < V > values ( ) { } public IdentityMap . Keys < K > keys ( ) { } public static class Entry < K , V > { public K key ; public V value ; public String toString ( ) { } } private static class MapIterator < K , V > { public boolean hasNext ; final IdentityMap < K , V > map ; int nextIndex ; int currentIndex ; boolean valid = true ; public MapIterator ( IdentityMap < K , V > map ) { } public void reset ( ) { } void findNextIndex ( ) { } public void remove ( ) { if ( ( currentIndex ) < 0 ) throw new IllegalStateException ( "next<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>called<seq2seq4repair_space>before<seq2seq4repair_space>remove." ) ; if ( ( currentIndex ) >= ( map . capacity ) ) { map . removeStashIndex ( currentIndex ) ; <START_BUG> nextIndex = ( currentIndex ) - 1 ; <END_BUG> findNextIndex ( ) ; } else { map . keyTable [ currentIndex ] = null ; map . valueTable [ currentIndex ] = null ; } currentIndex = - 1 ; ( map . size ) -- ; } } public static class Entries < K , V > extends IdentityMap . MapIterator < K , V > implements Iterable < IdentityMap . Entry < K , V > > , Iterator < IdentityMap . Entry < K , V > > { private IdentityMap . Entry < K , V > entry = new IdentityMap . Entry ( ) ; public Entries ( IdentityMap < K , V > map ) { } public IdentityMap . Entry < K , V > next ( ) { } public boolean hasNext ( ) { } public Iterator < IdentityMap . Entry < K , V > > iterator ( ) { } } public static class Values < V > extends IdentityMap . MapIterator < Object , V > implements Iterable < V > , Iterator < V > { public Values ( IdentityMap < ? , V > map ) { } public boolean hasNext ( ) { } public V next ( ) { } public Iterator < V > iterator ( ) { } public Array < V > toArray ( ) { } public void toArray ( Array < V > array ) { } } public static class Keys < K > extends IdentityMap . MapIterator < K , Object > implements Iterable < K > , Iterator < K > { public Keys ( IdentityMap < K , ? > map ) { } public boolean hasNext ( ) { } public K next ( ) { } public Iterator < K > iterator ( ) { } public Array < K > toArray ( ) { } } }<BUG2FIX>nextIndex = currentIndex ;
public class BoundingBox implements Serializable { private static final long serialVersionUID = - 1286036817192127343L ; private static final Vector3 tmpVector = new Vector3 ( ) ; public final Vector3 min = new Vector3 ( ) ; public final Vector3 max = new Vector3 ( ) ; private final Vector3 cnt = new Vector3 ( ) ; private final Vector3 dim = new Vector3 ( ) ; @ Deprecated private Vector3 [ ] corners ; @ Deprecated public Vector3 getCenter ( ) { } public Vector3 getCenter ( Vector3 out ) { <START_BUG> return out . set ( cnt ) ; <END_BUG> } public float getCenterX ( ) { } public float getCenterY ( ) { } public float getCenterZ ( ) { } @ Deprecated protected void updateCorners ( ) { } @ Deprecated public Vector3 [ ] getCorners ( ) { } public Vector3 getCorner000 ( final Vector3 out ) { } public Vector3 getCorner001 ( final Vector3 out ) { } public Vector3 getCorner010 ( final Vector3 out ) { } public Vector3 getCorner011 ( final Vector3 out ) { } public Vector3 getCorner100 ( final Vector3 out ) { } public Vector3 getCorner101 ( final Vector3 out ) { } public Vector3 getCorner110 ( final Vector3 out ) { } public Vector3 getCorner111 ( final Vector3 out ) { } @ Deprecated public Vector3 getDimensions ( ) { } public Vector3 getDimensions ( final Vector3 out ) { } public float getWidth ( ) { } public float getHeight ( ) { } public float getDepth ( ) { } @ Deprecated public Vector3 getMin ( ) { } public Vector3 getMin ( final Vector3 out ) { } @ Deprecated public Vector3 getMax ( ) { } public Vector3 getMax ( final Vector3 out ) { } public BoundingBox ( ) { } public BoundingBox ( BoundingBox bounds ) { } public BoundingBox ( Vector3 minimum , Vector3 maximum ) { } public BoundingBox set ( BoundingBox bounds ) { } public BoundingBox set ( Vector3 minimum , Vector3 maximum ) { } public BoundingBox set ( Vector3 [ ] points ) { } public BoundingBox set ( List < Vector3 > points ) { } public BoundingBox inf ( ) { } public BoundingBox ext ( Vector3 point ) { } public BoundingBox clr ( ) { } public boolean isValid ( ) { } public BoundingBox ext ( BoundingBox a_bounds ) { } public BoundingBox ext ( BoundingBox bounds , Matrix4 transform ) { } public BoundingBox mul ( Matrix4 transform ) { } public boolean contains ( BoundingBox b ) { } public boolean intersects ( BoundingBox b ) { } public boolean contains ( Vector3 v ) { } @ Override public String toString ( ) { } public BoundingBox ext ( float x , float y , float z ) { } static final float min ( final float a , final float b ) { } static final float max ( final float a , final float b ) { } }<BUG2FIX>return cnt ;
public class LittleEndianInputStream extends FilterInputStream { public LittleEndianInputStream ( InputStream in ) { } public boolean readBoolean ( ) throws IOException { } <START_BUG> public byte readByte ( int b ) throws IOException { <END_BUG> int temp = in . read ( ) ; if ( temp == ( - 1 ) ) throw new EOFException ( ) ; return ( ( byte ) ( temp ) ) ; } public int readUnsignedByte ( ) throws IOException { } public short readShort ( ) throws IOException { } public int readUnsignedShort ( ) throws IOException { } public char readChar ( ) throws IOException { } public int readInt ( ) throws IOException { } public long readLong ( ) throws IOException { } public String readUTF ( ) throws IOException { } public final double readDouble ( ) throws IOException { } public final float readFloat ( ) throws IOException { } public final int skipBytes ( int n ) throws IOException { } }<BUG2FIX>public byte readByte ( ) throws IOException {
public class IndexBufferObjectSubData implements IndexData { static final IntBuffer tmpHandle = BufferUtils . newIntBuffer ( 1 ) ; ShortBuffer buffer ; ByteBuffer byteBuffer ; int bufferHandle ; final boolean isDirect ; boolean isDirty = true ; boolean isBound = false ; final int usage ; public IndexBufferObjectSubData ( boolean isStatic , int maxIndices ) { } public IndexBufferObjectSubData ( int maxIndices ) { } private int createBufferObject ( ) { } public int getNumIndices ( ) { } public int getNumMaxIndices ( ) { } public void setIndices ( short [ ] indices , int offset , int count ) { isDirty = true ; buffer . clear ( ) ; buffer . put ( indices , offset , count ) ; buffer . flip ( ) ; byteBuffer . position ( 0 ) ; byteBuffer . limit ( ( count << 1 ) ) ; if ( isBound ) { if ( ( Gdx . gl11 ) != null ) { GL11 gl = Gdx . gl11 ; gl . glBufferSubData ( GL_ELEMENT_ARRAY_BUFFER , 0 , byteBuffer . limit ( ) , byteBuffer ) ; } else <START_BUG> if ( ( Gdx . gl11 ) != null ) { <END_BUG> GL20 gl = Gdx . gl20 ; gl . glBufferSubData ( GL20 . GL_ELEMENT_ARRAY_BUFFER , 0 , byteBuffer . limit ( ) , byteBuffer ) ; } isDirty = false ; } } public ShortBuffer getBuffer ( ) { } public void bind ( ) { } public void unbind ( ) { } public void invalidate ( ) { } public void dispose ( ) { } }<BUG2FIX>if ( ( Gdx . gl20 ) != null ) {
public class GroupCullingTest extends GdxTest { private static final int count = 100 ; private Stage stage ; private Skin skin ; private Table root ; private Label drawnLabel ; int drawn ; public void create ( ) { } @ Override public void dispose ( ) { } public void resize ( int width , int height ) { <START_BUG> stage . getViewport ( ) . update ( width , height ) ; <END_BUG> root . invalidate ( ) ; } public void render ( ) { } public boolean needsGL20 ( ) { } }<BUG2FIX>stage . getViewport ( ) . update ( width , height , true ) ;
public interface Application { public enum ApplicationType { Android , Desktop , Applet , WebGL , iOS ; } public static final int LOG_NONE = 0 ; public static final int LOG_DEBUG = 3 ; public static final int LOG_INFO = 2 ; public static final int LOG_ERROR = 1 ; public ApplicationListener getApplicationListener ( ) { } public Graphics getGraphics ( ) { } public Audio getAudio ( ) { } public Input getInput ( ) { } public Files getFiles ( ) { } public Net getNet ( ) { } public void log ( String tag , String message ) { } <START_BUG> public void log ( String tag , String message , Throwable exception ) ; <END_BUG> public void error ( String tag , String message ) { } public void error ( String tag , String message , Throwable exception ) { } public void debug ( String tag , String message ) { } public void debug ( String tag , String message , Throwable exception ) { } public void setLogLevel ( int logLevel ) { } public int getLogLevel ( ) { } public Application . ApplicationType getType ( ) { } public int getVersion ( ) { } public long getJavaHeap ( ) { } public long getNativeHeap ( ) { } public Preferences getPreferences ( String name ) { } public Clipboard getClipboard ( ) { } public void postRunnable ( Runnable runnable ) { } public void exit ( ) { } public void addLifecycleListener ( LifecycleListener listener ) { } public void removeLifecycleListener ( LifecycleListener listener ) { } }<BUG2FIX>public void log ( String tag , String message , Exception exception ) ;
@ Override public String getIndex ( ) { } @ Override public String id ( ) { } @ Override public String getId ( ) { } @ Override public String type ( ) { } @ Override public String getType ( ) { } public BytesReference sourceRef ( ) { } @ Override public BytesReference getSourceRef ( ) { } public BytesReference internalSourceRef ( ) { } @ Override public byte [ ] source ( ) { } @ Override public boolean isSourceEmpty ( ) { } @ Override public Map < String , Object > getSource ( ) { } @ Override public String sourceAsString ( ) { } @ Override public String getSourceAsString ( ) { } @ SuppressWarnings ( { "unchecked" } ) @ Override public Map < String , Object > sourceAsMap ( ) throws ElasticSearchParseException { } @ Override public Iterator < SearchHitField > iterator ( ) { } @ Override public SearchHitField field ( String fieldName ) { } @ Override public Map < String , SearchHitField > fields ( ) { } public Map < String , SearchHitField > fieldsOrNull ( ) { } @ Override public Map < String , SearchHitField > getFields ( ) { } public void fields ( Map < String , SearchHitField > fields ) { } public Map < String , HighlightField > internalHighlightFields ( ) { } @ Override public Map < String , HighlightField > highlightFields ( ) { } @ Override public Map < String , HighlightField > getHighlightFields ( ) { } public void highlightFields ( Map < String , HighlightField > highlightFields ) { } public void sortValues ( Object [ ] sortValues ) { } @ Override public Object [ ] sortValues ( ) { } @ Override public Object [ ] getSortValues ( ) { } @ Override public Explanation explanation ( ) { } @ Override public Explanation getExplanation ( ) { } public void explanation ( Explanation explanation ) { } @ Override public SearchShardTarget shard ( ) { } @ Override public SearchShardTarget getShard ( ) { } public void shard ( SearchShardTarget target ) { } public void matchedFilters ( String [ ] matchedFilters ) { } public String [ ] matchedFilters ( ) { } @ Override public String [ ] getMatchedFilters ( ) { } public static class Fields { static final XContentBuilderString _INDEX = new XContentBuilderString ( "_index" ) ; static final XContentBuilderString _TYPE = new XContentBuilderString ( "_type" ) ; static final XContentBuilderString _ID = new XContentBuilderString ( "_id" ) ; static final XContentBuilderString _VERSION = new XContentBuilderString ( "_version" ) ; static final XContentBuilderString _SCORE = new XContentBuilderString ( "_score" ) ; static final XContentBuilderString FIELDS = new XContentBuilderString ( "fields" ) ; static final XContentBuilderString HIGHLIGHT = new XContentBuilderString ( "highlight" ) ; static final XContentBuilderString SORT = new XContentBuilderString ( "sort" ) ; static final XContentBuilderString MATCH_FILTERS = new XContentBuilderString ( "matched_filters" ) ; static final XContentBuilderString _EXPLANATION = new XContentBuilderString ( "_explanation" ) ; static final XContentBuilderString VALUE = new XContentBuilderString ( "value" ) ; static final XContentBuilderString DESCRIPTION = new XContentBuilderString ( "description" ) ; static final XContentBuilderString DETAILS = new XContentBuilderString ( "details" ) ; } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } private void buildExplanation ( XContentBuilder builder , Explanation explanation ) throws IOException { } public static InternalSearchHit readSearchHit ( StreamInput in , InternalSearchHits . StreamContext context ) throws IOException { } @ Override public void readFrom ( StreamInput in ) throws IOException { } public void readFrom ( StreamInput in , InternalSearchHits . StreamContext context ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } public void writeTo ( StreamOutput out , InternalSearchHits . StreamContext context ) throws IOException { out . writeFloat ( score ) ; out . writeUTF ( id ) ; out . writeUTF ( type ) ; out . writeLong ( version ) ; <START_BUG> out . writeBytesReference ( source , true ) ; <END_BUG> if ( ( explanation ) == null ) { out . writeBoolean ( false ) ; } else { out . writeBoolean ( true ) ; writeExplanation ( out , explanation ) ; } if ( ( fields ) == null ) { out . writeVInt ( 0 ) ; } else { out . writeVInt ( fields . size ( ) ) ; for ( SearchHitField hitField : fields ( ) . values ( ) ) { hitField . writeTo ( out ) ; } } if ( ( highlightFields ) == null ) { out . writeVInt ( 0 ) ; } else { out . writeVInt ( highlightFields . size ( ) ) ; for ( HighlightField highlightField : highlightFields . values ( ) ) { highlightField . writeTo ( out ) ; } } if ( ( sortValues . length ) == 0 ) { out . writeVInt ( 0 ) ; } else { out . writeVInt ( sortValues . length ) ; for ( Object sortValue : sortValues ) { if ( sortValue == null ) { out . writeByte ( ( ( byte ) ( 0 ) ) ) ; } else { Class type = sortValue . getClass ( ) ; if ( type == ( String . class ) ) { out . writeByte ( ( ( byte ) ( 1 ) ) ) ; out . writeUTF ( ( ( String ) ( sortValue ) ) ) ; } else if ( type == ( Integer . class ) ) { out . writeByte ( ( ( byte ) ( 2 ) ) ) ; out . writeInt ( ( ( Integer ) ( sortValue ) ) ) ; } else if ( type == ( Long . class ) ) { out . writeByte ( ( ( byte ) ( 3 ) ) ) ;<BUG2FIX>out . writeBytesReference ( source ) ;
public class ObjectMap < K , V > { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; public int size ; K [ ] keyTable ; V [ ] valueTable ; int capacity ; int stashSize ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private ObjectMap . Entries entries1 ; private ObjectMap . Entries entries2 ; private ObjectMap . Values values1 ; private ObjectMap . Values values2 ; private ObjectMap . Keys keys1 ; private ObjectMap . Keys keys2 ; public ObjectMap ( ) { } public ObjectMap ( int initialCapacity ) { } public ObjectMap ( int initialCapacity , float loadFactor ) { } public ObjectMap ( ObjectMap < ? extends K , ? extends V > map ) { } public V put ( K key , V value ) { } private V put_internal ( K key , V value ) { } public void putAll ( ObjectMap < K , V > map ) { } private void putResize ( K key , V value ) { } private void push ( K insertKey , V insertValue , int index1 , K key1 , int index2 , K key2 , int index3 , K key3 ) { } private void putStash ( K key , V value ) { } public V get ( K key ) { } private V getStash ( K key ) { } public V get ( K key , V defaultValue ) { } private V getStash ( K key , V defaultValue ) { } public V remove ( K key ) { } V removeStash ( K key ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean containsValue ( Object value , boolean identity ) { } public boolean containsKey ( K key ) { } private boolean containsKeyStash ( K key ) { } public K findKey ( Object value , boolean identity ) { } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( int h ) { } private int hash3 ( int h ) { } public String toString ( ) { } public ObjectMap . Entries < K , V > entries ( ) { } public ObjectMap . Values < V > values ( ) { } public ObjectMap . Keys < K > keys ( ) { } public static class Entry < K , V > { public K key ; public V value ; public String toString ( ) { } } private static class MapIterator < K , V > { public boolean hasNext ; final ObjectMap < K , V > map ; int nextIndex ; int currentIndex ; boolean valid = true ; public MapIterator ( ObjectMap < K , V > map ) { } public void reset ( ) { } void advance ( ) { } public void remove ( ) { if ( ( currentIndex ) < 0 ) throw new IllegalStateException ( "next<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>called<seq2seq4repair_space>before<seq2seq4repair_space>remove." ) ; if ( ( currentIndex ) >= ( map . capacity ) ) { map . removeStashIndex ( currentIndex ) ; <START_BUG> nextIndex = currentIndex ; <END_BUG> advance ( ) ; } else { map . keyTable [ currentIndex ] = null ; map . valueTable [ currentIndex ] = null ; } currentIndex = - 1 ; ( map . size ) -- ; } } public static class Entries < K , V > extends ObjectMap . MapIterator < K , V > implements Iterable < ObjectMap . Entry < K , V > > , Iterator < ObjectMap . Entry < K , V > > { ObjectMap . Entry < K , V > entry = new ObjectMap . Entry ( ) ; public Entries ( ObjectMap < K , V > map ) { } public ObjectMap . Entry < K , V > next ( ) { } public boolean hasNext ( ) { } public Iterator < ObjectMap . Entry < K , V > > iterator ( ) { } } public static class Values < V > extends ObjectMap . MapIterator < Object , V > implements Iterable < V > , Iterator < V > { public Values ( ObjectMap < ? , V > map ) { } public boolean hasNext ( ) { } public V next ( ) { } public Iterator < V > iterator ( ) { } public Array < V > toArray ( ) { } public void toArray ( Array < V > array ) { } } public static class Keys < K > extends ObjectMap . MapIterator < K , Object > implements Iterable < K > , Iterator < K > { public Keys ( ObjectMap < K , ? > map ) { } public boolean hasNext ( ) { } public K next ( ) { } public Iterator < K > iterator ( ) { } public Array < K > toArray ( ) { } } }<BUG2FIX>nextIndex = ( currentIndex ) - 1 ;
public class DocIdOrdinals implements Ordinals { private final int numDocs ; public DocIdOrdinals ( int numDocs ) { } @ Override public boolean hasSingleArrayBackingStorage ( ) { } @ Override public Object getBackingStorage ( ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override public boolean isMultiValued ( ) { } @ Override public int getNumDocs ( ) { } @ Override public int getNumOrds ( ) { <START_BUG> return ( numDocs ) + 1 ; <END_BUG> } @ Override public Ordinals . Docs ordinals ( ) { } public static class Docs implements Ordinals . Docs { private final DocIdOrdinals parent ; private final IntArrayRef intsScratch = new IntArrayRef ( new int [ 1 ] ) ; private final SingleValueIter iter = new SingleValueIter ( ) ; public Docs ( DocIdOrdinals parent ) { } @ Override public Ordinals ordinals ( ) { } @ Override public int getNumDocs ( ) { } @ Override public int getNumOrds ( ) { return parent . getNumOrds ( ) ; } @ Override public boolean isMultiValued ( ) { } @ Override public int getOrd ( int docId ) { } @ Override public IntArrayRef getOrds ( int docId ) { } @ Override public Iter getIter ( int docId ) { } @ Override public void forEachOrdinalInDoc ( int docId , OrdinalInDocProc proc ) { } } }<BUG2FIX>return numDocs ;
public class TransportNodesListGatewayMetaState extends TransportNodesOperationAction < TransportNodesListGatewayMetaState . Request , TransportNodesListGatewayMetaState . NodesLocalGatewayMetaState , TransportNodesListGatewayMetaState . NodeRequest , TransportNodesListGatewayMetaState . NodeLocalGatewayMetaState > { private LocalGateway gateway ; @ Inject public TransportNodesListGatewayMetaState ( Settings settings , ClusterName clusterName , ThreadPool threadPool , ClusterService clusterService , TransportService transportService ) { } TransportNodesListGatewayMetaState initGateway ( LocalGateway gateway ) { } public ActionFuture < TransportNodesListGatewayMetaState . NodesLocalGatewayMetaState > list ( Set < String > nodesIds , @ Nullable TimeValue timeout ) { } @ Override protected String transportAction ( ) { } @ Override protected String transportNodeAction ( ) { } @ Override protected TransportNodesListGatewayMetaState . Request newRequest ( ) { } @ Override protected TransportNodesListGatewayMetaState . NodeRequest newNodeRequest ( ) { } @ Override protected TransportNodesListGatewayMetaState . NodeRequest newNodeRequest ( String nodeId , TransportNodesListGatewayMetaState . Request request ) { } @ Override protected TransportNodesListGatewayMetaState . NodeLocalGatewayMetaState newNodeResponse ( ) { } @ Override protected TransportNodesListGatewayMetaState . NodesLocalGatewayMetaState newResponse ( TransportNodesListGatewayMetaState . Request request , AtomicReferenceArray responses ) { } @ Override protected TransportNodesListGatewayMetaState . NodeLocalGatewayMetaState nodeOperation ( TransportNodesListGatewayMetaState . NodeRequest request ) throws ElasticSearchException { } @ Override protected boolean accumulateExceptions ( ) { } static class Request extends NodesOperationRequest { public Request ( ) { } public Request ( Set < String > nodesIds ) { } @ Override public TransportNodesListGatewayMetaState . Request timeout ( TimeValue timeout ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { super . readFrom ( in ) ; } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } public static class NodesLocalGatewayMetaState extends NodesOperationResponse < TransportNodesListGatewayMetaState . NodeLocalGatewayMetaState > { private FailedNodeException [ ] failures ; NodesLocalGatewayMetaState ( ) { } public NodesLocalGatewayMetaState ( ClusterName clusterName , TransportNodesListGatewayMetaState . NodeLocalGatewayMetaState [ ] nodes , FailedNodeException [ ] failures ) { } public FailedNodeException [ ] failures ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { super . readFrom ( in ) ; nodes = new TransportNodesListGatewayMetaState . NodeLocalGatewayMetaState [ in . readVInt ( ) ] ; for ( int i = 0 ; i < ( nodes . length ) ; i ++ ) { nodes [ i ] = new TransportNodesListGatewayMetaState . NodeLocalGatewayMetaState ( ) ; nodes [ i ] . readFrom ( in ) ; } } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } static class NodeRequest extends NodeOperationRequest { NodeRequest ( ) { } NodeRequest ( String nodeId ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { super . readFrom ( in ) ; } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } public static class NodeLocalGatewayMetaState extends NodeOperationResponse { private LocalGatewayMetaState state ; NodeLocalGatewayMetaState ( ) { } public NodeLocalGatewayMetaState ( DiscoveryNode node , LocalGatewayMetaState state ) { } public LocalGatewayMetaState state ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { super . readFrom ( in ) ; if ( in . readBoolean ( ) ) { <START_BUG> state = Builder . readFrom ( in , null ) ; <END_BUG> } } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } }<BUG2FIX>state = Builder . readFrom ( in ) ;
public class SuperJumperAndroid extends AndroidApplication { @ Override public void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; <START_BUG> initialize ( new SuperJumper ( ) , false ) ; <END_BUG> } }<BUG2FIX>initialize ( new SuperJumper ( ) ) ;
public abstract class Actor { public Group parent ; public final String name ; public boolean touchable = true ; public boolean visible = true ; public float x ; public float y ; public float width ; public float height ; public float originX ; public float originY ; public float scaleX = 1 ; public float scaleY = 1 ; public float rotation ; public final Color color = new Color ( 1 , 1 , 1 , 1 ) ; protected PooledLinkedList < Action > actions = new PooledLinkedList < Action > ( 10 ) ; private boolean toRemove ; protected Stage stage ; public Actor ( ) { } public Actor ( String name ) { } public abstract void draw ( SpriteBatch batch , float parentAlpha ) { } public boolean touchDown ( float x , float y , int pointer ) { } public void touchUp ( float x , float y , int pointer ) { } public void touchDragged ( float x , float y , int pointer ) { } public boolean touchMoved ( float x , float y ) { } public boolean scrolled ( int amount ) { } public boolean keyDown ( int keycode ) { } public boolean keyUp ( int keycode ) { } public boolean keyTyped ( char character ) { } public abstract Actor hit ( float x , float y ) { } public void toLocalCoordinates ( Vector2 point ) { } public void remove ( ) { } public void act ( float delta ) { } public void action ( Action action ) { } public void clearActions ( ) { } @ Override public String toString ( ) { <START_BUG> String name = ( ( this . name ) != null ) ? this . name : getClass ( ) . getSimpleName ( ) ; <END_BUG> if ( name . equals ( "" ) ) name = getClass ( ) . getName ( ) ; return ( ( ( ( ( ( ( ( ( ( ( name + "<seq2seq4repair_space>pos=" ) + ( x ) ) + "," ) + ( y ) ) + "<seq2seq4repair_space>origin=" ) + ( originX ) ) + "," ) + ( originY ) ) + "<seq2seq4repair_space>size=" ) + ( width ) ) + "," ) + ( height ) ; } public void markToRemove ( final boolean remove ) { } public boolean isMarkedToRemove ( ) { } public Stage getStage ( ) { } }<BUG2FIX>String name = ( ( this . name ) != null ) ? this . name : getClass ( ) . getName ( ) ;
while ( ( token = parser . nextToken ( ) ) != ( Token . END_ARRAY ) ) { builder . add ( parser . text ( ) ) ; } excluded = builder . build ( ) ; } else if ( "fields" . equals ( currentFieldName ) ) { List < String > fields = Lists . newArrayListWithCapacity ( 4 ) ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_ARRAY ) ) { fields . add ( parser . text ( ) ) ; } fieldsNames = fields . toArray ( new String [ fields . size ( ) ] ) ; } } else if ( token . isValue ( ) ) { if ( "field" . equals ( currentFieldName ) ) { field = parser . text ( ) ; } else if ( "script_field" . equals ( currentFieldName ) ) { script = parser . text ( ) ; } else if ( "size" . equals ( currentFieldName ) ) { size = parser . intValue ( ) ; } else if ( ( "all_terms" . equals ( currentFieldName ) ) || ( "allTerms" . equals ( currentFieldName ) ) ) { allTerms = parser . booleanValue ( ) ; } else if ( "regex" . equals ( currentFieldName ) ) { regex = parser . text ( ) ; } else if ( ( "regex_flags" . equals ( currentFieldName ) ) || ( "regexFlags" . equals ( currentFieldName ) ) ) { regexFlags = parser . text ( ) ; } else if ( ( "order" . equals ( currentFieldName ) ) || ( "comparator" . equals ( currentFieldName ) ) ) { comparatorType = ComparatorType . fromString ( parser . text ( ) ) ; } else if ( "script" . equals ( currentFieldName ) ) { script = parser . text ( ) ; } else if ( "lang" . equals ( currentFieldName ) ) { scriptLang = parser . text ( ) ; } else if ( ( "execution_hint" . equals ( currentFieldName ) ) || ( "executionHint" . equals ( currentFieldName ) ) ) { executionHint = parser . textOrNull ( ) ; } } } if ( "_index" . equals ( field ) ) { return new org . elasticsearch . search . facet . terms . index . IndexNameFacetCollector ( facetName , context . shardTarget ( ) . index ( ) , comparatorType , size ) ; } Pattern pattern = null ; if ( regex != null ) { pattern = Regex . compile ( regex , regexFlags ) ; } if ( fieldsNames != null ) { return new org . elasticsearch . search . facet . terms . strings . FieldsTermsStringFacetCollector ( facetName , fieldsNames , size , comparatorType , allTerms , context , excluded , pattern , scriptLang , script , params ) ; } if ( ( ( field == null ) && ( fieldsNames == null ) ) && ( script != null ) ) { return new org . elasticsearch . search . facet . terms . strings . ScriptTermsStringFieldFacetCollector ( facetName , size , comparatorType , context , excluded , pattern , scriptLang , script , params ) ; } <START_BUG> FieldMapper fieldMapper = context . mapperService ( ) . smartNameFieldMapper ( field ) ; <END_BUG> if ( fieldMapper != null ) { if ( fieldMapper instanceof IpFieldMapper ) { if ( ( script != null ) || ( "map" . equals ( executionHint ) ) ) { return new org . elasticsearch . search . facet . terms . ip . TermsIpFacetCollector ( facetName , field , size , comparatorType , allTerms , context , scriptLang , script , params ) ; } else { return new org . elasticsearch . search . facet . terms . ip . TermsIpOrdinalsFacetCollector ( facetName , field , size , comparatorType , allTerms , context , null ) ; } } else if ( ( fieldMapper . fieldDataType ( ) ) == ( DefaultTypes . LONG ) ) { if ( ( script != null ) || ( "map" . equals ( executionHint ) ) ) { return new org . elasticsearch . search . facet . terms . longs . TermsLongFacetCollector ( facetName , field , size , comparatorType , allTerms , context , excluded , scriptLang , script , params ) ; } else { return new org . elasticsearch . search . facet . terms . longs . TermsLongOrdinalsFacetCollector ( facetName , field , size , comparatorType , allTerms , context , excluded ) ; } } else if ( ( fieldMapper . fieldDataType ( ) ) == ( DefaultTypes . DOUBLE ) ) { if ( script != null ) { return new org . elasticsearch . search . facet . terms . doubles . TermsDoubleFacetCollector ( facetName , field , size , comparatorType , allTerms , context , excluded , scriptLang , script , params ) ; } else { return new org . elasticsearch . search . facet . terms . doubles . TermsDoubleOrdinalsFacetCollector ( facetName , field , size , comparatorType , allTerms , context , excluded ) ; } } else if ( ( fieldMapper . fieldDataType ( ) ) == ( DefaultTypes . INT ) ) { if ( ( script != null ) || ( "map" . equals ( executionHint ) ) ) { return new org . elasticsearch . search . facet . terms . ints . TermsIntFacetCollector ( facetName , field , size , comparatorType , allTerms , context , excluded , scriptLang , script , params ) ; } else { return new org . elasticsearch . search . facet . terms . ints . TermsIntOrdinalsFacetCollector ( facetName , field , size , comparatorType , allTerms , context , excluded ) ; } }<BUG2FIX>FieldMapper fieldMapper = context . smartNameFieldMapper ( field ) ;
public class TransportNodesShutdownAction extends TransportMasterNodeOperationAction < NodesShutdownRequest , NodesShutdownResponse > { private final Node node ; private final ClusterName clusterName ; private final boolean disabled ; private final TimeValue delay ; @ Inject public TransportNodesShutdownAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool , Node node , ClusterName clusterName ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected NodesShutdownRequest newRequest ( ) { } @ Override protected NodesShutdownResponse newResponse ( ) { } @ Override protected void processBeforeDelegationToMaster ( NodesShutdownRequest request , ClusterState state ) { } @ Override protected void masterOperation ( final NodesShutdownRequest request , final ClusterState state , final ActionListener < NodesShutdownResponse > listener ) throws ElasticsearchException { if ( disabled ) { throw new ElasticsearchIllegalStateException ( "Shutdown<seq2seq4repair_space>is<seq2seq4repair_space>disabled" ) ; } <START_BUG> final ObjectOpenHashSet < DiscoveryNode > nodes = new ObjectOpenHashSet < DiscoveryNode > ( ) ; <END_BUG> if ( state . nodes ( ) . isAllNodes ( request . nodesIds ) ) { logger . info ( "[cluster_shutdown]:<seq2seq4repair_space>requested,<seq2seq4repair_space>shutting<seq2seq4repair_space>down<seq2seq4repair_space>in<seq2seq4repair_space>[{}]" , request . delay ) ; nodes . addAll ( state . nodes ( ) . dataNodes ( ) . values ( ) ) ; nodes . addAll ( state . nodes ( ) . masterNodes ( ) . values ( ) ) ; Thread t = new Thread ( new Runnable ( ) { @ Override public void run ( ) { try { Thread . sleep ( request . delay . millis ( ) ) ; } catch ( InterruptedException e ) { } logger . trace ( "[cluster_shutdown]:<seq2seq4repair_space>stopping<seq2seq4repair_space>the<seq2seq4repair_space>cluster<seq2seq4repair_space>service<seq2seq4repair_space>so<seq2seq4repair_space>no<seq2seq4repair_space>re-routing<seq2seq4repair_space>will<seq2seq4repair_space>occur" ) ; clusterService . stop ( ) ; final CountDownLatch latch = new CountDownLatch ( nodes . size ( ) ) ; for ( ObjectCursor < DiscoveryNode > cursor : nodes ) { final DiscoveryNode node = cursor . value ; if ( node . id ( ) . equals ( state . nodes ( ) . masterNodeId ( ) ) ) { latch . countDown ( ) ; } else { logger . trace ( "[cluster_shutdown]:<seq2seq4repair_space>sending<seq2seq4repair_space>shutdown<seq2seq4repair_space>request<seq2seq4repair_space>to<seq2seq4repair_space>[{}]" , node ) ; transportService . sendRequest ( node , TransportNodesShutdownAction . NodeShutdownRequestHandler . ACTION , new TransportNodesShutdownAction . NodeShutdownRequest ( request ) , new EmptyTransportResponseHandler ( Names . SAME ) { @ Override public void handleResponse ( TransportResponse . Empty response ) { logger . trace ( "[cluster_shutdown]:<seq2seq4repair_space>received<seq2seq4repair_space>shutdown<seq2seq4repair_space>response<seq2seq4repair_space>from<seq2seq4repair_space>[{}]" , node ) ; latch . countDown ( ) ; } @ Override public void handleException ( TransportException exp ) { logger . warn ( "[cluster_shutdown]:<seq2seq4repair_space>received<seq2seq4repair_space>failed<seq2seq4repair_space>shutdown<seq2seq4repair_space>response<seq2seq4repair_space>from<seq2seq4repair_space>[{}]" , exp , node ) ; latch . countDown ( ) ; } } ) ; } } try { latch . await ( ) ; } catch ( InterruptedException e ) { } logger . info ( "[cluster_shutdown]:<seq2seq4repair_space>done<seq2seq4repair_space>shutting<seq2seq4repair_space>down<seq2seq4repair_space>all<seq2seq4repair_space>nodes<seq2seq4repair_space>except<seq2seq4repair_space>master,<seq2seq4repair_space>proceeding<seq2seq4repair_space>to<seq2seq4repair_space>master" ) ; logger . trace ( "[cluster_shutdown]:<seq2seq4repair_space>shutting<seq2seq4repair_space>down<seq2seq4repair_space>the<seq2seq4repair_space>master<seq2seq4repair_space>[{}]" , state . nodes ( ) . masterNode ( ) ) ; transportService . sendRequest ( state . nodes ( ) . masterNode ( ) , TransportNodesShutdownAction . NodeShutdownRequestHandler . ACTION , new TransportNodesShutdownAction . NodeShutdownRequest ( request ) , new EmptyTransportResponseHandler ( Names . SAME ) { @ Override public void handleResponse ( TransportResponse . Empty response ) { logger . trace ( "[cluster_shutdown]:<seq2seq4repair_space>received<seq2seq4repair_space>shutdown<seq2seq4repair_space>response<seq2seq4repair_space>from<seq2seq4repair_space>master" ) ; } @ Override public void handleException ( TransportException exp ) { logger . warn ( "[cluster_shutdown]:<seq2seq4repair_space>received<seq2seq4repair_space>failed<seq2seq4repair_space>shutdown<seq2seq4repair_space>response<seq2seq4repair_space>master" , exp ) ; } } ) ; } } ) ; t . start ( ) ; } else { final String [ ] nodesIds = state . nodes ( ) . resolveNodesIds ( request . nodesIds ) ; logger . info ( "[partial_cluster_shutdown]:<seq2seq4repair_space>requested,<seq2seq4repair_space>shutting<seq2seq4repair_space>down<seq2seq4repair_space>[{}]<seq2seq4repair_space>in<seq2seq4repair_space>[{}]" , nodesIds , request . delay ) ; for ( String nodeId : nodesIds ) { final DiscoveryNode node = state . nodes ( ) . get ( nodeId ) ; if ( node != null ) { nodes . add ( node ) ; } } Thread t = new Thread ( new Runnable ( ) { @ Override public void run ( ) { try { Thread . sleep ( request . delay . millis ( ) ) ; } catch ( InterruptedException e ) { } final CountDownLatch latch = new CountDownLatch ( nodesIds . length ) ; for ( String nodeId : nodesIds ) { final DiscoveryNode node = state . nodes ( ) . get ( nodeId ) ; if ( node == null ) { logger . warn ( "[partial_cluster_shutdown]:<seq2seq4repair_space>no<seq2seq4repair_space>node<seq2seq4repair_space>to<seq2seq4repair_space>shutdown<seq2seq4repair_space>for<seq2seq4repair_space>node_id<seq2seq4repair_space>[{}]" , nodeId ) ; latch . countDown ( ) ; continue ; } logger . trace ( "[partial_cluster_shutdown]:<seq2seq4repair_space>sending<seq2seq4repair_space>shutdown<seq2seq4repair_space>request<seq2seq4repair_space>to<seq2seq4repair_space>[{}]" , node ) ; transportService . sendRequest ( node , TransportNodesShutdownAction . NodeShutdownRequestHandler . ACTION , new TransportNodesShutdownAction . NodeShutdownRequest ( request ) , new EmptyTransportResponseHandler ( Names . SAME ) { @ Override public void handleResponse ( TransportResponse . Empty response ) { logger . trace ( "[partial_cluster_shutdown]:<seq2seq4repair_space>received<seq2seq4repair_space>shutdown<seq2seq4repair_space>response<seq2seq4repair_space>from<seq2seq4repair_space>[{}]" , node ) ; latch . countDown ( ) ; } @ Override public void handleException ( TransportException exp ) { logger . warn ( "[partial_cluster_shutdown]:<seq2seq4repair_space>received<seq2seq4repair_space>failed<seq2seq4repair_space>shutdown<seq2seq4repair_space>response<seq2seq4repair_space>from<seq2seq4repair_space>[{}]" , exp , node ) ; latch . countDown ( ) ; } } ) ; } try { latch . await ( ) ; } catch ( InterruptedException e ) { } logger . info ( "[partial_cluster_shutdown]:<seq2seq4repair_space>done<seq2seq4repair_space>shutting<seq2seq4repair_space>down<seq2seq4repair_space>[{}]" , ( ( Object ) ( nodesIds ) ) ) ; } } ) ; t . start ( ) ; } listener . onResponse ( new NodesShutdownResponse ( clusterName , nodes . toArray ( DiscoveryNode . class ) ) ) ; } private class NodeShutdownRequestHandler extends BaseTransportRequestHandler < TransportNodesShutdownAction . NodeShutdownRequest > { static final String ACTION = "/cluster/nodes/shutdown/node" ; @ Override public TransportNodesShutdownAction . NodeShutdownRequest newInstance ( ) { } @ Override public String executor ( ) { } @ Override public void messageReceived ( final TransportNodesShutdownAction . NodeShutdownRequest request , TransportChannel channel ) throws Exception { } } static class NodeShutdownRequest extends TransportRequest { boolean exit ; NodeShutdownRequest ( ) { } NodeShutdownRequest ( NodesShutdownRequest request ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { }<BUG2FIX>final ObjectOpenHashSet < DiscoveryNode > nodes = new ObjectOpenHashSet ( ) ;
public class GroupFadeTest extends GdxTest { Texture texture ; Stage stage ; @ Override public void create ( ) { texture = new Texture ( files . internal ( "data/badlogicsmall.jpg" ) ) ; <START_BUG> stage = new Stage ( 480 , 320 , true ) ; <END_BUG> for ( int i = 0 ; i < 100 ; i ++ ) { Image img = new Image ( new com . badlogic . gdx . graphics . g2d . TextureRegion ( texture ) ) ; img . setX ( ( ( ( float ) ( Math . random ( ) ) ) * 480 ) ) ; img . setY ( ( ( ( float ) ( Math . random ( ) ) ) * 320 ) ) ; img . getColor ( ) . a = ( ( ( float ) ( Math . random ( ) ) ) * 0.5F ) + 0.5F ; stage . addActor ( img ) ; } stage . getRoot ( ) . addAction ( forever ( sequence ( fadeOut ( 3 ) , fadeIn ( 3 ) ) ) ) ; } @ Override public void render ( ) { } @ Override public void dispose ( ) { } }<BUG2FIX>stage = new Stage ( ) ;
@ Override public ShardIdCache idCache ( ) { } @ Override public ShardFieldData fieldData ( ) { } @ Override public ShardRouting routingEntry ( ) { } public InternalIndexShard routingEntry ( ShardRouting newRouting ) { } public IndexShardState recovering ( String reason ) throws IndexShardClosedException , IndexShardRecoveringException , IndexShardRelocatedException , IndexShardStartedException { } public InternalIndexShard relocated ( String reason ) throws IndexShardNotStartedException { } @ Override public IndexShardState state ( ) { } @ Override public Create prepareCreate ( SourceToParse source ) throws ElasticSearchException { } @ Override public ParsedDocument create ( Engine . Create create ) throws ElasticSearchException { } @ Override public Index prepareIndex ( SourceToParse source ) throws ElasticSearchException { } @ Override public ParsedDocument index ( Engine . Index index ) throws ElasticSearchException { } @ Override public Delete prepareDelete ( String type , String id , long version ) throws ElasticSearchException { } @ Override public void delete ( Engine . Delete delete ) throws ElasticSearchException { } @ Override public DeleteByQuery prepareDeleteByQuery ( BytesReference querySource , @ Nullable String [ ] filteringAliases , String ... types ) throws ElasticSearchException { } @ Override public void deleteByQuery ( Engine . DeleteByQuery deleteByQuery ) throws ElasticSearchException { } @ Override public GetResult get ( Engine . Get get ) throws ElasticSearchException { } @ Override public void refresh ( Engine . Refresh refresh ) throws ElasticSearchException { } @ Override public RefreshStats refreshStats ( ) { } @ Override public FlushStats flushStats ( ) { } @ Override public DocsStats docStats ( ) { } @ Override public IndexingStats indexingStats ( String ... types ) { } @ Override public SearchStats searchStats ( String ... groups ) { } @ Override public GetStats getStats ( ) { } @ Override public StoreStats storeStats ( ) { } @ Override public MergeStats mergeStats ( ) { } @ Override public WarmerStats warmerStats ( ) { } @ Override public FilterCacheStats filterCacheStats ( ) { } @ Override public FieldDataStats fieldDataStats ( String ... fields ) { } @ Override public PercolatorQueriesRegistry percolateRegistry ( ) { } @ Override public ShardPercolateService shardPercolateService ( ) { } @ Override public IdCacheStats idCacheStats ( ) { } @ Override public CompletionStats completionStats ( String ... fields ) { } @ Override public void flush ( Engine . Flush flush ) throws ElasticSearchException { } @ Override public void optimize ( Engine . Optimize optimize ) throws ElasticSearchException { } @ Override public < T > T snapshot ( Engine . SnapshotHandler < T > snapshotHandler ) throws EngineException { } @ Override public void recover ( Engine . RecoveryHandler recoveryHandler ) throws EngineException { } @ Override public Searcher acquireSearcher ( String source ) { } public void close ( String reason ) { } public long checkIndexTook ( ) { } public InternalIndexShard postRecovery ( String reason ) throws IndexShardClosedException , IndexShardRelocatedException , IndexShardStartedException { } public void performRecoveryPrepareForTranslog ( ) throws ElasticSearchException { } public RecoveryStatus peerRecoveryStatus ( ) { } public void performRecoveryFinalization ( boolean withFlush , RecoveryStatus peerRecoveryStatus ) throws ElasticSearchException { } public void performRecoveryFinalization ( boolean withFlush ) throws ElasticSearchException { } public void performRecoveryOperation ( Translog . Operation operation ) throws ElasticSearchException { } public boolean ignoreRecoveryAttempt ( ) { } public void readAllowed ( ) throws IllegalIndexShardStateException { } private void writeAllowed ( Engine . Operation . Origin origin ) throws IllegalIndexShardStateException { } private void verifyStartedOrRecovering ( ) throws IllegalIndexShardStateException { } private void verifyNotClosed ( ) throws IllegalIndexShardStateException { } private void verifyStarted ( ) throws IllegalIndexShardStateException { } private void startScheduledTasksIfNeeded ( ) { } private Query filterQueryIfNeeded ( Query query , String [ ] types ) { } public static final String INDEX_REFRESH_INTERVAL = "index.refresh_interval" ; private class ApplyRefreshSettings implements IndexSettingsService . Listener { @ Override public void onRefreshSettings ( Settings settings ) { } } class EngineRefresher implements Runnable { @ Override public void run ( ) { } } class EngineMerger implements Runnable { @ Override public void run ( ) { } } private void checkIndex ( boolean throwException ) throws IndexShardException { try { checkIndexTook = 0 ; long time = System . currentTimeMillis ( ) ; if ( ! ( Lucene . indexExists ( store . directory ( ) ) ) ) { return ; } CheckIndex checkIndex = new CheckIndex ( store . directory ( ) ) ; BytesStreamOutput os = new BytesStreamOutput ( ) ; PrintStream out = new PrintStream ( os , false , Charsets . UTF_8 . name ( ) ) ; checkIndex . setInfoStream ( out ) ; out . flush ( ) ; CheckIndex . Status status = checkIndex . checkIndex ( ) ; if ( ! ( status . clean ) ) { if ( ( state ) == ( IndexShardState . CLOSED ) ) { return ; } logger . warn ( "check<seq2seq4repair_space>index<seq2seq4repair_space>[failure]\n{}" , new String ( os . bytes ( ) . toBytes ( ) , Charsets . UTF_8 ) ) ; if ( "fix" . equalsIgnoreCase ( checkIndexOnStartup ) ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "fixing<seq2seq4repair_space>index,<seq2seq4repair_space>writing<seq2seq4repair_space>new<seq2seq4repair_space>segments<seq2seq4repair_space>file<seq2seq4repair_space>..." ) ; } <START_BUG> checkIndex . fixIndex ( status , codecService . codec ( indexSettings . get ( INDEX_CODEC , "default" ) ) ) ; <END_BUG> if ( logger . isDebugEnabled ( ) ) { logger . debug ( "index<seq2seq4repair_space>fixed,<seq2seq4repair_space>wrote<seq2seq4repair_space>new<seq2seq4repair_space>segments<seq2seq4repair_space>file<seq2seq4repair_space>\"{}\"" , status . segmentsFileName ) ; } } else { if ( throwException ) { throw new IndexShardException ( shardId , "index<seq2seq4repair_space>check<seq2seq4repair_space>failure" ) ; } } } else { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "check<seq2seq4repair_space>index<seq2seq4repair_space>[success]\n{}" , new String ( os . bytes ( ) . toBytes ( ) , Charsets . UTF_8 ) ) ; } } checkIndexTook = ( System . currentTimeMillis ( ) ) - time ; } catch ( Exception e ) { logger . warn ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>check<seq2seq4repair_space>index" , e ) ; } } }<BUG2FIX>checkIndex . fixIndex ( status ) ;
public Matrix4 set ( float [ ] values ) { } public Matrix4 set ( Quaternion quaternion ) { } public Matrix4 set ( float x , float y , float z , float w ) { } public Matrix4 set ( Vector3 position , Quaternion orientation ) { } public Matrix4 set ( float translationX , float translationY , float translationZ , float quaternionX , float quaternionY , float quaternionZ , float quaternionW ) { } public Matrix4 set ( Vector3 xAxis , Vector3 yAxis , Vector3 zAxis , Vector3 pos ) { } public Matrix4 set ( Vector3 position , Quaternion orientation , Vector3 scale ) { } public Matrix4 cpy ( ) { } public Matrix4 trn ( Vector3 vector ) { } public Matrix4 trn ( float x , float y , float z ) { } public float [ ] getValues ( ) { } public Matrix4 mul ( Matrix4 matrix ) { } public Matrix4 mulLeft ( Matrix4 matrix ) { } public Matrix4 tra ( ) { } public Matrix4 idt ( ) { } public Matrix4 inv ( ) { } public float det ( ) { } public float det3x3 ( ) { } public Matrix4 setToProjection ( float near , float far , float fov , float aspectRatio ) { } public Matrix4 setToOrtho2D ( float x , float y , float width , float height ) { } public Matrix4 setToOrtho2D ( float x , float y , float width , float height , float near , float far ) { } public Matrix4 setToOrtho ( float left , float right , float bottom , float top , float near , float far ) { } public Matrix4 setTranslation ( Vector3 vector ) { } public Matrix4 setTranslation ( float x , float y , float z ) { } public Matrix4 setToTranslation ( Vector3 vector ) { } public Matrix4 setToTranslation ( float x , float y , float z ) { } public Matrix4 setToTranslationAndScaling ( Vector3 translation , Vector3 scaling ) { } public Matrix4 setToTranslationAndScaling ( float translationX , float translationY , float translationZ , float scalingX , float scalingY , float scalingZ ) { } static Quaternion quat = new Quaternion ( ) ; public Matrix4 setToRotation ( Vector3 axis , float degrees ) { } public Matrix4 setToRotationRad ( Vector3 axis , float radians ) { } public Matrix4 setToRotationRad ( float axisX , float axisY , float axisZ , float radians ) { } public Matrix4 setToRotation ( float axisX , float axisY , float axisZ , float angle ) { } public Matrix4 setToRotation ( final Vector3 v1 , final Vector3 v2 ) { } public Matrix4 setToRotation ( final float x1 , final float y1 , final float z1 , final float x2 , final float y2 , final float z2 ) { } public Matrix4 setFromEulerAngles ( float yaw , float pitch , float roll ) { } public Matrix4 setToScaling ( Vector3 vector ) { } public Matrix4 setToScaling ( float x , float y , float z ) { } static final Vector3 l_vez = new Vector3 ( ) ; static final Vector3 l_vex = new Vector3 ( ) ; static final Vector3 l_vey = new Vector3 ( ) ; public Matrix4 setToLookAt ( Vector3 direction , Vector3 up ) { } static final Vector3 tmpVec = new Vector3 ( ) ; static final Matrix4 tmpMat = new Matrix4 ( ) ; public Matrix4 setToLookAt ( Vector3 position , Vector3 target , Vector3 up ) { } static final Vector3 right = new Vector3 ( ) ; static final Vector3 tmpForward = new Vector3 ( ) ; static final Vector3 tmpUp = new Vector3 ( ) ; public Matrix4 setToWorld ( Vector3 position , Vector3 forward , Vector3 up ) { Matrix4 . tmpForward . set ( forward ) . nor ( ) ; Matrix4 . right . set ( Matrix4 . tmpForward ) . crs ( up ) . nor ( ) ; Matrix4 . tmpUp . set ( Matrix4 . right ) . crs ( Matrix4 . tmpForward ) . nor ( ) ; <START_BUG> this . set ( Matrix4 . right , Matrix4 . tmpUp , Matrix4 . tmpForward . scl ( ( - 1 ) ) , position ) ; <END_BUG> return this ; } public String toString ( ) { } public Matrix4 lerp ( Matrix4 matrix , float alpha ) { } public Matrix4 set ( Matrix3 mat ) { } public Matrix4 scl ( Vector3 scale ) { } public Matrix4 scl ( float x , float y , float z ) { } public Matrix4 scl ( float scale ) { } public Vector3 getTranslation ( Vector3 position ) { } public Quaternion getRotation ( Quaternion rotation , boolean normalizeAxes ) { } public Quaternion getRotation ( Quaternion rotation ) { } public float getScaleXSquared ( ) { } public float getScaleYSquared ( ) { } public float getScaleZSquared ( ) { } public float getScaleX ( ) { } public float getScaleY ( ) { } public float getScaleZ ( ) { } public Vector3 getScale ( Vector3 scale ) { } public Matrix4 toNormalMatrix ( ) { } static void matrix4_mul ( float [ ] mata , float [ ] matb ) { } static float matrix4_det ( float [ ] val ) { } static boolean matrix4_inv ( float [ ] val ) { } static void matrix4_mulVec ( float [ ] mat , float [ ] vec , int offset ) { } static void matrix4_proj ( float [ ] mat , float [ ] vec , int offset ) { } static void matrix4_rot ( float [ ] mat , float [ ] vec , int offset ) { } public static void mul ( float [ ] mata , float [ ] matb ) { }<BUG2FIX>this . set ( Matrix4 . right , Matrix4 . tmpUp , Matrix4 . tmpForward , position ) ;
public class RecentRepositories implements Serializable , Comparator < Repository > { public static final int MAX_SIZE = 5 ; private static final long serialVersionUID = 580345177644233739L ; private static final int VERSION = 2 ; private static File getFile ( final Context context , final User organization ) { } private LinkedHashSet < Long > ids ; private final File file ; private int id ; public RecentRepositories ( final Context context , final User organization ) { } private void load ( ) { } private void trim ( ) { } public RecentRepositories add ( final Repository repo ) { } <START_BUG> public RecentRepositories add ( final Long id ) { <END_BUG> if ( ( ids ) == null ) load ( ) ; ids . remove ( id ) ; ids . add ( id ) ; trim ( ) ; return this ; } public RecentRepositories saveAsync ( ) { } public RecentRepositories save ( ) { } public boolean contains ( Repository repository ) { } public boolean contains ( long id ) { } @ Override public int compare ( final Repository lhs , final Repository rhs ) { } }<BUG2FIX>public RecentRepositories add ( final long id ) {
public class BouncyDesktop { public static void main ( String [ ] argv ) { <START_BUG> new com . badlogic . gdx . backends . jogl . JoglApplication ( new Bouncy ( ) , "Bouncy" , 320 , 480 , false ) ; <END_BUG> } }<BUG2FIX>new com . badlogic . gdx . backends . jogl . JoglApplication ( new Bouncy ( ) , "Bouncy" , 320 , 480 , true ) ;
public class TransportExplainAction extends TransportShardSingleOperationAction < ExplainRequest , ExplainResponse > { private final IndicesService indicesService ; private final ScriptService scriptService ; private final CacheRecycler cacheRecycler ; private final PageCacheRecycler pageCacheRecycler ; private final BigArrays bigArrays ; @ Inject public TransportExplainAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportService transportService , IndicesService indicesService , ScriptService scriptService , CacheRecycler cacheRecycler , PageCacheRecycler pageCacheRecycler , BigArrays bigArrays ) { } @ Override protected void doExecute ( ExplainRequest request , ActionListener < ExplainResponse > listener ) { } protected String transportAction ( ) { } protected String executor ( ) { } @ Override protected void resolveRequest ( ClusterState state , ExplainRequest request ) { } protected ExplainResponse shardOperation ( ExplainRequest request , int shardId ) throws ElasticsearchException { IndexService indexService = indicesService . indexService ( request . index ( ) ) ; IndexShard indexShard = indexService . shardSafe ( shardId ) ; Term uidTerm = new Term ( UidFieldMapper . NAME , Uid . createUidAsBytes ( request . type ( ) , request . id ( ) ) ) ; Engine . GetResult result = indexShard . get ( new Engine . Get ( false , uidTerm ) ) ; if ( ! ( result . exists ( ) ) ) { return new ExplainResponse ( false ) ; } SearchContext context = new org . elasticsearch . search . internal . DefaultSearchContext ( 0 , new ShardSearchRequest ( ) . types ( new String [ ] { request . type ( ) } ) . filteringAliases ( request . filteringAlias ( ) ) . nowInMillis ( request . nowInMillis ) , null , result . searcher ( ) , indexService , indexShard , scriptService , cacheRecycler , pageCacheRecycler , bigArrays ) ; SearchContext . setCurrent ( context ) ; try { context . parsedQuery ( indexService . queryParserService ( ) . parseQuery ( request . source ( ) ) ) ; context . preProcess ( ) ; int topLevelDocId = ( result . docIdAndVersion ( ) . docId ) + ( result . docIdAndVersion ( ) . context . docBase ) ; Explanation explanation = context . searcher ( ) . explain ( context . query ( ) , topLevelDocId ) ; for ( RescoreSearchContext ctx : context . rescore ( ) ) { Rescorer rescorer = ctx . rescorer ( ) ; explanation = rescorer . explain ( topLevelDocId , context , ctx , explanation ) ; } if ( ( ( request . fields ( ) ) != null ) || ( ( ( request . fetchSourceContext ( ) ) != null ) && ( request . fetchSourceContext ( ) . fetchSource ( ) ) ) ) { GetResult getResult = indexShard . getService ( ) . get ( result , request . id ( ) , request . type ( ) , request . fields ( ) , request . fetchSourceContext ( ) ) ; return new ExplainResponse ( true , explanation , getResult ) ; } else { return new ExplainResponse ( true , explanation ) ; } } catch ( IOException e ) { throw new ElasticsearchException ( "Could<seq2seq4repair_space>not<seq2seq4repair_space>explain" , e ) ; } finally { <START_BUG> context . release ( ) ; <END_BUG> SearchContext . removeCurrent ( ) ; } } protected ExplainRequest newRequest ( ) { } protected ExplainResponse newResponse ( ) { } protected ClusterBlockException checkGlobalBlock ( ClusterState state , ExplainRequest request ) { } protected ClusterBlockException checkRequestBlock ( ClusterState state , ExplainRequest request ) { } protected ShardIterator shards ( ClusterState state , ExplainRequest request ) throws ElasticsearchException { } }<BUG2FIX>context . close ( ) ;
public final class Intersector { private static final Vector3 v0 = new Vector3 ( ) ; private static final Vector3 v1 = new Vector3 ( ) ; private static final Vector3 v2 = new Vector3 ( ) ; public static boolean isPointInTriangle ( Vector3 point , Vector3 t1 , Vector3 t2 , Vector3 t3 ) { } public static boolean isPointInTriangle ( Vector2 p , Vector2 a , Vector2 b , Vector2 c ) { } public static boolean isPointInTriangle ( float px , float py , float ax , float ay , float bx , float by , float cx , float cy ) { } public static boolean intersectSegmentPlane ( Vector3 start , Vector3 end , Plane plane , Vector3 intersection ) { } public static int pointLineSide ( Vector2 linePoint1 , Vector2 linePoint2 , Vector2 point ) { } public static int pointLineSide ( float linePoint1X , float linePoint1Y , float linePoint2X , float linePoint2Y , float pointX , float pointY ) { } public static boolean isPointInPolygon ( Array < Vector2 > polygon , Vector2 point ) { } public static boolean isPointInPolygon ( float [ ] polygon , int offset , int count , float x , float y ) { } public static float distanceLinePoint ( Vector2 start , Vector2 end , Vector2 point ) { } public static float distanceLinePoint ( float startX , float startY , float endX , float endY , float pointX , float pointY ) { } public static float distanceSegmentPoint ( float startX , float startY , float endX , float endY , float pointX , float pointY ) { } public static float distanceSegmentPoint ( Vector2 start , Vector2 end , Vector2 point ) { } public static Vector2 nearestSegmentPoint ( Vector2 start , Vector2 end , Vector2 point , Vector2 nearest ) { } public static Vector2 nearestSegmentPoint ( float startX , float startY , float endX , float endY , float pointX , float pointY , Vector2 nearest ) { } public static boolean intersectSegmentCircle ( Vector2 start , Vector2 end , Vector2 center , float squareRadius ) { } public static float intersectSegmentCircleDisplace ( Vector2 start , Vector2 end , Vector2 point , float radius , Vector2 displacement ) { } public static boolean intersectRayPlane ( Ray ray , Plane plane , Vector3 intersection ) { } public static float intersectLinePlane ( float x , float y , float z , float x2 , float y2 , float z2 , Plane plane , Vector3 intersection ) { Vector3 direction = Intersector . tmp . set ( x2 , y2 , z2 ) . sub ( x , y , z ) ; Vector3 origin = Intersector . tmp2 . set ( x , y , z ) ; float denom = direction . dot ( plane . getNormal ( ) ) ; if ( denom != 0 ) { float t = ( - ( ( origin . dot ( plane . getNormal ( ) ) ) + ( plane . getD ( ) ) ) ) / denom ; <START_BUG> if ( ( ( t >= 0 ) && ( t <= 1 ) ) && ( intersection != null ) ) <END_BUG> intersection . set ( origin ) . add ( direction . scl ( t ) ) ; return t ; } else if ( ( plane . testPoint ( origin ) ) == ( PlaneSide . OnPlane ) ) { if ( intersection != null ) intersection . set ( origin ) ; return 0 ; } return - 1 ; } private static final Plane p = new Plane ( new Vector3 ( ) , 0 ) ; private static final Vector3 i = new Vector3 ( ) ; public static boolean intersectRayTriangle ( Ray ray , Vector3 t1 , Vector3 t2 , Vector3 t3 , Vector3 intersection ) { } private static final Vector3 dir = new Vector3 ( ) ; private static final Vector3 start = new Vector3 ( ) ; public static boolean intersectRaySphere ( Ray ray , Vector3 center , float radius , Vector3 intersection ) { } public static boolean intersectRayBounds ( Ray ray , BoundingBox box , Vector3 intersection ) { } public static boolean intersectRayBoundsFast ( Ray ray , BoundingBox box ) { } public static boolean intersectRayBoundsFast ( Ray ray , Vector3 center , Vector3 dimensions ) { } static Vector3 best = new Vector3 ( ) ; static Vector3 tmp = new Vector3 ( ) ; static Vector3 tmp1 = new Vector3 ( ) ; static Vector3 tmp2 = new Vector3 ( ) ; static Vector3 tmp3 = new Vector3 ( ) ; static Vector2 v2tmp = new Vector2 ( ) ; public static boolean intersectRayTriangles ( Ray ray , float [ ] triangles , Vector3 intersection ) { } public static boolean intersectRayTriangles ( Ray ray , float [ ] vertices , short [ ] indices , int vertexSize , Vector3 intersection ) { } public static boolean intersectRayTriangles ( Ray ray , List < Vector3 > triangles , Vector3 intersection ) { } public static boolean intersectLines ( Vector2 p1 , Vector2 p2 , Vector2 p3 , Vector2 p4 , Vector2 intersection ) { } public static boolean intersectLines ( float x1 , float y1 , float x2 , float y2 , float x3 , float y3 , float x4 , float y4 , Vector2 intersection ) { } public static boolean intersectLinePolygon ( Vector2 p1 , Vector2 p2 , Polygon polygon ) { } public static boolean intersectRectangles ( Rectangle rectangle1 , Rectangle rectangle2 , Rectangle intersection ) { } public static boolean intersectSegmentPolygon ( Vector2 p1 , Vector2 p2 , Polygon polygon ) { } public static boolean intersectSegments ( Vector2 p1 , Vector2 p2 , Vector2 p3 , Vector2 p4 , Vector2 intersection ) { }<BUG2FIX>if ( intersection != null )
public class GdxSetup { public void build ( String outputDir , String appName , String packageName , String mainClass ) { Project project = new Project ( ) ; String packageDir = packageName . replace ( '.' , '/' ) ; project . files . add ( new ProjectFile ( "build.gradle" , true ) ) ; project . files . add ( new ProjectFile ( "settings.gradle" ) ) ; project . files . add ( new ProjectFile ( "gradlew" , false ) ) ; project . files . add ( new ProjectFile ( "gradlew.bat" , false ) ) ; project . files . add ( new ProjectFile ( "gradle/wrapper/gradle-wrapper.jar" , false ) ) ; project . files . add ( new ProjectFile ( "gradle/wrapper/gradle-wrapper.properties" , false ) ) ; project . files . add ( new ProjectFile ( "core/build.gradle" ) ) ; project . files . add ( new ProjectFile ( "core/src/MainClass" , ( ( ( ( "core/src/" + packageDir ) + "/" ) + mainClass ) + ".java" ) , true ) ) ; project . files . add ( new ProjectFile ( "core/CoreGdxDefinition" , ( ( ( ( "core/src/" + packageDir ) + "/" ) + mainClass ) + ".gwt.xml" ) , true ) ) ; project . files . add ( new ProjectFile ( "desktop/build.gradle" ) ) ; project . files . add ( new ProjectFile ( "desktop/src/DesktopLauncher" , ( ( "desktop/src/" + packageDir ) + "/desktop/DesktopLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "android/assets/badlogic.jpg" , false ) ) ; <START_BUG> project . files . add ( new ProjectFile ( "android/res/values/strings.xml" ) ) ; <END_BUG> project . files . add ( new ProjectFile ( "android/res/values/styles.xml" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-hdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-mdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-xhdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-xxhdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/src/AndroidLauncher" , ( ( "android/src/" + packageDir ) + "/android/AndroidLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "android/AndroidManifest.xml" ) ) ; project . files . add ( new ProjectFile ( "android/build.gradle" ) ) ; project . files . add ( new ProjectFile ( "android/ic_launcher-web.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/proguard-project.txt" , false ) ) ; project . files . add ( new ProjectFile ( "android/project.properties" , false ) ) ; project . files . add ( new ProjectFile ( "gwt/build.gradle" ) ) ; project . files . add ( new ProjectFile ( "gwt/src/GwtLauncher" , ( ( "gwt/src/" + packageDir ) + "/client/GwtLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "gwt/GdxDefinition" , ( ( "gwt/src/" + packageDir ) + "/GdxDefinition.gwt.xml" ) , true ) ) ; project . files . add ( new ProjectFile ( "gwt/war/index" , ( "gwt/webapp/" + "index.html" ) , true ) ) ; project . files . add ( new ProjectFile ( "gwt/war/WEB-INF/web.xml" , "gwt/webapp/WEB-INF/web.xml" , true ) ) ; project . files . add ( new ProjectFile ( "ios/src/IOSLauncher" , ( ( "ios/src/" + packageDir ) + "/IOSLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "ios/build.gradle" ) ) ; Map < String , String > values = new HashMap < String , String > ( ) ; values . put ( "%APP_NAME%" , appName ) ; values . put ( "%PACKAGE%" , packageName ) ; values . put ( "%MAIN_CLASS%" , mainClass ) ; copyAndReplace ( outputDir , project , values ) ; new File ( outputDir , "gradlew" ) . setExecutable ( true ) ; } private void copyAndReplace ( String outputDir , Project project , Map < String , String > values ) { } private byte [ ] readResource ( String resource ) { } private String readResourceAsString ( String resource ) { } private void writeFile ( File outFile , byte [ ] bytes ) { } private void writeFile ( File outFile , String text ) { } private void copyFile ( ProjectFile file , File out , Map < String , String > values ) { } private String replace ( String txt , Map < String , String > values ) { } private static void printHelp ( ) { } private static Map < String , String > parseArgs ( String [ ] args ) { } public static void main ( String [ ] args ) { } }<BUG2FIX>project . files . add ( new ProjectFile ( "android/res/values/strings.xml" , false ) ) ;
public class DataOutputStreamOutput extends StreamOutput { private final DataOutput out ; public DataOutputStreamOutput ( DataOutput out ) { } @ Override public void writeByte ( byte b ) throws IOException { <START_BUG> out . write ( b ) ; <END_BUG> } @ Override public void writeBytes ( byte [ ] b , int offset , int length ) throws IOException { } @ Override public void flush ( ) throws IOException { } @ Override public void reset ( ) throws IOException { } @ Override public void close ( ) throws IOException { } }<BUG2FIX>out . writeByte ( b ) ;
class ShardValidateQueryRequest extends BroadcastShardOperationRequest { private BytesReference querySource ; private String [ ] types = Strings . EMPTY_ARRAY ; private boolean explain ; @ Nullable private String [ ] filteringAliases ; ShardValidateQueryRequest ( ) { } public ShardValidateQueryRequest ( String index , int shardId , @ Nullable String [ ] filteringAliases , ValidateQueryRequest request ) { } public BytesReference querySource ( ) { } public String [ ] types ( ) { } public boolean explain ( ) { } public String [ ] filteringAliases ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { super . writeTo ( out ) ; <START_BUG> out . writeBytesReference ( querySource , true ) ; <END_BUG> out . writeVInt ( types . length ) ; for ( String type : types ) { out . writeUTF ( type ) ; } if ( ( filteringAliases ) != null ) { out . writeVInt ( filteringAliases . length ) ; for ( String alias : filteringAliases ) { out . writeUTF ( alias ) ; } } else { out . writeVInt ( 0 ) ; } out . writeBoolean ( explain ) ; } }<BUG2FIX>out . writeBytesReference ( querySource ) ;
public class IdsQueryParser implements QueryParser { public static final String NAME = "ids" ; @ Inject public IdsQueryParser ( ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; List < String > ids = new ArrayList < String > ( ) ; Collection < String > types = null ; String currentFieldName = null ; float boost = 1.0F ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_ARRAY ) ) { if ( "values" . equals ( currentFieldName ) ) { while ( ( token = parser . nextToken ( ) ) != ( Token . END_ARRAY ) ) { String value = parser . textOrNull ( ) ; if ( value == null ) { throw new QueryParsingException ( parseContext . index ( ) , "No<seq2seq4repair_space>value<seq2seq4repair_space>specified<seq2seq4repair_space>for<seq2seq4repair_space>term<seq2seq4repair_space>filter" ) ; } ids . add ( value ) ; } } else if ( ( "types" . equals ( currentFieldName ) ) || ( "type" . equals ( currentFieldName ) ) ) { types = new ArrayList < String > ( ) ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_ARRAY ) ) { String value = parser . textOrNull ( ) ; if ( value == null ) { throw new QueryParsingException ( parseContext . index ( ) , "No<seq2seq4repair_space>type<seq2seq4repair_space>specified<seq2seq4repair_space>for<seq2seq4repair_space>term<seq2seq4repair_space>filter" ) ; } types . add ( value ) ; } } else { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[ids]<seq2seq4repair_space>query<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>support<seq2seq4repair_space>[" + currentFieldName ) + "]" ) ) ; } } else if ( token . isValue ( ) ) { if ( ( "type" . equals ( currentFieldName ) ) || ( "_type" . equals ( currentFieldName ) ) ) { types = ImmutableList . of ( parser . text ( ) ) ; } else if ( "boost" . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } else { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[ids]<seq2seq4repair_space>query<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>support<seq2seq4repair_space>[" + currentFieldName ) + "]" ) ) ; } } } if ( ( ids . size ( ) ) == 0 ) { throw new QueryParsingException ( parseContext . index ( ) , "[ids]<seq2seq4repair_space>query,<seq2seq4repair_space>no<seq2seq4repair_space>ids<seq2seq4repair_space>values<seq2seq4repair_space>provided" ) ; } if ( ( types == null ) || ( types . isEmpty ( ) ) ) { types = parseContext . queryTypes ( ) ; } else if ( ( ( types . size ( ) ) == 1 ) && ( Iterables . getFirst ( types , null ) . equals ( "_all" ) ) ) { types = parseContext . mapperService ( ) . types ( ) ; } <START_BUG> UidFilter filter = new UidFilter ( types , ids , parseContext . indexCache ( ) . bloomCache ( ) ) ; <END_BUG> ConstantScoreQuery query = new ConstantScoreQuery ( filter ) ; query . setBoost ( boost ) ; return query ; } }<BUG2FIX>UidFilter filter = new UidFilter ( types , ids ) ;
public class IndicesTTLService extends AbstractLifecycleComponent < IndicesTTLService > { public static final String INDICES_TTL_INTERVAL = "indices.ttl.interval" ; public static final String INDEX_TTL_DISABLE_PURGE = "index.ttl.disable_purge" ; private final ClusterService clusterService ; private final IndicesService indicesService ; private final Client client ; private volatile TimeValue interval ; private final int bulkSize ; private IndicesTTLService . PurgerThread purgerThread ; @ Inject public IndicesTTLService ( Settings settings , ClusterService clusterService , IndicesService indicesService , NodeSettingsService nodeSettingsService , Client client ) { } @ Override protected void doStart ( ) throws ElasticsearchException { } @ Override protected void doStop ( ) throws ElasticsearchException { } @ Override protected void doClose ( ) throws ElasticsearchException { } private class PurgerThread extends Thread { volatile boolean running = true ; public PurgerThread ( String name ) { } public void doStop ( ) { } public void run ( ) { } private List < IndexShard > getShardsToPurge ( ) { } } private void purgeShards ( List < IndexShard > shardsToPurge ) { for ( IndexShard shardToPurge : shardsToPurge ) { Query query = NumericRangeQuery . newLongRange ( NAME , null , System . currentTimeMillis ( ) , false , true ) ; Engine . Searcher searcher = shardToPurge . acquireSearcher ( "indices_ttl" ) ; try { logger . debug ( "[{}][{}]<seq2seq4repair_space>purging<seq2seq4repair_space>shard" , shardToPurge . routingEntry ( ) . index ( ) , shardToPurge . routingEntry ( ) . id ( ) ) ; IndicesTTLService . ExpiredDocsCollector expiredDocsCollector = new IndicesTTLService . ExpiredDocsCollector ( shardToPurge . routingEntry ( ) . index ( ) ) ; searcher . searcher ( ) . search ( query , expiredDocsCollector ) ; List < IndicesTTLService . DocToPurge > docsToPurge = expiredDocsCollector . getDocsToPurge ( ) ; BulkRequestBuilder bulkRequest = client . prepareBulk ( ) ; for ( IndicesTTLService . DocToPurge docToPurge : docsToPurge ) { bulkRequest . add ( new DeleteRequest ( ) . index ( shardToPurge . routingEntry ( ) . index ( ) ) . type ( docToPurge . type ) . id ( docToPurge . id ) . version ( docToPurge . version ) . routing ( docToPurge . routing ) ) ; bulkRequest = processBulkIfNeeded ( bulkRequest , false ) ; } processBulkIfNeeded ( bulkRequest , true ) ; } catch ( Exception e ) { logger . warn ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>purge" , e ) ; } finally { <START_BUG> searcher . release ( ) ; <END_BUG> } } } private static class DocToPurge { public final String type ; public final String id ; public final long version ; public final String routing ; public DocToPurge ( String type , String id , long version , String routing ) { } } private class ExpiredDocsCollector extends Collector { private final MapperService mapperService ; private AtomicReaderContext context ; private List < IndicesTTLService . DocToPurge > docsToPurge = new ArrayList < > ( ) ; public ExpiredDocsCollector ( String index ) { } public void setScorer ( Scorer scorer ) { } public boolean acceptsDocsOutOfOrder ( ) { } public void collect ( int doc ) { } public void setNextReader ( AtomicReaderContext context ) throws IOException { } public List < IndicesTTLService . DocToPurge > getDocsToPurge ( ) { } } private BulkRequestBuilder processBulkIfNeeded ( BulkRequestBuilder bulkRequest , boolean force ) { } class ApplySettings implements NodeSettingsService . Listener { @ Override public void onRefreshSettings ( Settings settings ) { } } }<BUG2FIX>searcher . close ( ) ;
public class ProjectiveTextureTest extends GdxTest { @ Override public boolean needsGL20 ( ) { } PerspectiveCamera cam ; PerspectiveCamera projector ; Texture texture ; Mesh plane ; Mesh cube ; Matrix4 planeTrans = new Matrix4 ( ) ; Matrix4 cubeTrans = new Matrix4 ( ) ; Matrix4 modelNormal = new Matrix4 ( ) ; ShaderProgram projTexShader ; Stage ui ; InputMultiplexer multiplexer = new InputMultiplexer ( ) ; PerspectiveCamController controller ; ImmediateModeRenderer20 renderer ; float angle = 0 ; @ Override public void create ( ) { } public void setupScene ( ) { } public void setupUI ( ) { <START_BUG> ui = new Stage ( 480 , 320 , true ) ; <END_BUG> Skin skin = new Skin ( files . internal ( "data/uiskin.xml" ) , files . internal ( "data/uiskin.png" ) ) ; Button reload = skin . newButton ( "reload" , "Reload<seq2seq4repair_space>Shaders" ) ; ComboBox camera = skin . newComboBox ( "camera" , new String [ ] { "Camera" , "Light" } , ui ) ; Label fps = skin . newLabel ( "fps" , "fps:<seq2seq4repair_space>" ) ; Container container = new Container ( "container" , ( ( int ) ( ui . width ( ) ) ) , ( ( int ) ( ui . height ( ) ) ) ) ; container . add ( reload ) . spacingRight ( 5 ) ; container . add ( camera ) . spacingRight ( 5 ) ; container . add ( fps ) ; ui . addActor ( container ) ; reload . setClickListener ( new ClickListener ( ) { @ Override public void click ( Button button ) { ShaderProgram prog = new ShaderProgram ( files . internal ( "data/shaders/projtex-vert.glsl" ) . readString ( ) , files . internal ( "data/shaders/projtex-frag.glsl" ) . readString ( ) ) ; if ( ( prog . isCompiled ( ) ) == false ) { app . log ( "GLSL<seq2seq4repair_space>ERROR" , ( "Couldn\'t<seq2seq4repair_space>reload<seq2seq4repair_space>shaders:\n" + ( prog . getLog ( ) ) ) ) ; } else { projTexShader . dispose ( ) ; projTexShader = prog ; } } } ) ; } public void setupShaders ( ) { } @ Override public void render ( ) { } Vector3 position = new Vector3 ( ) ; private void renderMesh ( ShaderProgram shader , Matrix4 cam , Matrix4 projector , Matrix4 model , Mesh mesh , Color color ) { } }<BUG2FIX>ui = new Stage ( 480 , 320 , false ) ;
public class FloatValuesComparatorSource extends IndexFieldData . XFieldComparatorSource { private final IndexNumericFieldData indexFieldData ; private final Object missingValue ; public FloatValuesComparatorSource ( IndexNumericFieldData indexFieldData , @ Nullable Object missingValue ) { } @ Override public Type reducedType ( ) { } @ Override public FieldComparator < ? > newComparator ( String fieldname , int numHits , int sortPos , boolean reversed ) throws IOException { assert fieldname . equals ( indexFieldData . getFieldNames ( ) . indexName ( ) ) ; float dMissingValue ; if ( ( ( missingValue ) == null ) || ( "_last" . equals ( missingValue ) ) ) { dMissingValue = ( reversed ) ? Float . NEGATIVE_INFINITY : Float . POSITIVE_INFINITY ; } else if ( "_first" . equals ( missingValue ) ) { dMissingValue = ( reversed ) ? Float . POSITIVE_INFINITY : Float . NEGATIVE_INFINITY ; } else { dMissingValue = ( ( missingValue ) instanceof Number ) ? ( ( Number ) ( missingValue ) ) . floatValue ( ) : Float . parseFloat ( missingValue . toString ( ) ) ; } <START_BUG> return new FloatValuesComparator ( indexFieldData , dMissingValue , numHits ) ; <END_BUG> } }<BUG2FIX>return new FloatValuesComparator ( indexFieldData , dMissingValue , numHits , reversed ) ;
public class QueryStringQueryBuilder extends BaseQueryBuilder implements BoostableQueryBuilder < QueryStringQueryBuilder > { public static enum Operator { OR , AND ; } private final String queryString ; private String defaultField ; private QueryStringQueryBuilder . Operator defaultOperator ; private String analyzer ; private String quoteAnalyzer ; private String quoteFieldSuffix ; private Boolean autoGeneratePhraseQueries ; private Boolean allowLeadingWildcard ; private Boolean lowercaseExpandedTerms ; private Boolean enablePositionIncrements ; private Boolean analyzeWildcard ; private Locale locale ; private float boost = - 1 ; private Fuzziness fuzziness ; private int fuzzyPrefixLength = - 1 ; private int fuzzyMaxExpansions = - 1 ; private String fuzzyRewrite ; private int phraseSlop = - 1 ; private List < String > fields ; private ObjectFloatOpenHashMap < String > fieldsBoosts ; private Boolean useDisMax ; private float tieBreaker = - 1 ; private String rewrite = null ; private String minimumShouldMatch ; private Boolean lenient ; private String queryName ; public QueryStringQueryBuilder ( String queryString ) { } public QueryStringQueryBuilder defaultField ( String defaultField ) { } public QueryStringQueryBuilder field ( String field ) { } public QueryStringQueryBuilder field ( String field , float boost ) { if ( ( fields ) == null ) { fields = Lists . newArrayList ( ) ; } fields . add ( field ) ; if ( ( fieldsBoosts ) == null ) { <START_BUG> fieldsBoosts = new ObjectFloatOpenHashMap < String > ( ) ; <END_BUG> } fieldsBoosts . put ( field , boost ) ; return this ; } public QueryStringQueryBuilder useDisMax ( boolean useDisMax ) { } public QueryStringQueryBuilder tieBreaker ( float tieBreaker ) { } public QueryStringQueryBuilder defaultOperator ( QueryStringQueryBuilder . Operator defaultOperator ) { } public QueryStringQueryBuilder analyzer ( String analyzer ) { } public QueryStringQueryBuilder quoteAnalyzer ( String analyzer ) { } public QueryStringQueryBuilder autoGeneratePhraseQueries ( boolean autoGeneratePhraseQueries ) { } public QueryStringQueryBuilder allowLeadingWildcard ( boolean allowLeadingWildcard ) { } public QueryStringQueryBuilder lowercaseExpandedTerms ( boolean lowercaseExpandedTerms ) { } public QueryStringQueryBuilder enablePositionIncrements ( boolean enablePositionIncrements ) { } public QueryStringQueryBuilder fuzziness ( Fuzziness fuzziness ) { } public QueryStringQueryBuilder fuzzyPrefixLength ( int fuzzyPrefixLength ) { } public QueryStringQueryBuilder fuzzyMaxExpansions ( int fuzzyMaxExpansions ) { } public QueryStringQueryBuilder fuzzyRewrite ( String fuzzyRewrite ) { } public QueryStringQueryBuilder phraseSlop ( int phraseSlop ) { } public QueryStringQueryBuilder analyzeWildcard ( boolean analyzeWildcard ) { } public QueryStringQueryBuilder rewrite ( String rewrite ) { } public QueryStringQueryBuilder minimumShouldMatch ( String minimumShouldMatch ) { } public QueryStringQueryBuilder boost ( float boost ) { } public QueryStringQueryBuilder quoteFieldSuffix ( String quoteFieldSuffix ) { } public QueryStringQueryBuilder lenient ( Boolean lenient ) { } public QueryStringQueryBuilder queryName ( String queryName ) { } public QueryStringQueryBuilder locale ( Locale locale ) { } @ Override protected void doXContent ( XContentBuilder builder , Params params ) throws IOException { } }<BUG2FIX>fieldsBoosts = new ObjectFloatOpenHashMap ( ) ;
public class GdxInvadersDesktop { public static void main ( String [ ] argv ) { LwjglApplicationConfiguration config = new LwjglApplicationConfiguration ( ) ; config . title = "Gdx<seq2seq4repair_space>Invaders" ; config . vSyncEnabled = true ; <START_BUG> config . useGL20 = false ; <END_BUG> new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new GdxInvaders ( ) , config ) ; } }<BUG2FIX>config . useGL20 = true ;
public class FuzzyQueryParser implements QueryParser { public static final String NAME = "fuzzy" ; @ Inject public FuzzyQueryParser ( ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; XContentParser . Token token = parser . nextToken ( ) ; if ( token != ( Token . FIELD_NAME ) ) { throw new QueryParsingException ( parseContext . index ( ) , "[fuzzy]<seq2seq4repair_space>query<seq2seq4repair_space>malformed,<seq2seq4repair_space>no<seq2seq4repair_space>field" ) ; } String fieldName = parser . currentName ( ) ; String value = null ; float boost = 1.0F ; String minSimilarity = "0.5" ; int prefixLength = FuzzyQuery . defaultPrefixLength ; int maxExpansions = FuzzyQuery . defaultMaxExpansions ; <START_BUG> boolean transpositions = true ; <END_BUG> MultiTermQuery . RewriteMethod rewriteMethod = null ; token = parser . nextToken ( ) ; if ( token == ( Token . START_OBJECT ) ) { String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else { if ( "term" . equals ( currentFieldName ) ) { value = parser . text ( ) ; } else if ( "value" . equals ( currentFieldName ) ) { value = parser . text ( ) ; } else if ( "boost" . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } else if ( ( "min_similarity" . equals ( currentFieldName ) ) || ( "minSimilarity" . equals ( currentFieldName ) ) ) { minSimilarity = parser . text ( ) ; } else if ( ( "prefix_length" . equals ( currentFieldName ) ) || ( "prefixLength" . equals ( currentFieldName ) ) ) { prefixLength = parser . intValue ( ) ; } else if ( ( "max_expansions" . equals ( currentFieldName ) ) || ( "maxExpansions" . equals ( currentFieldName ) ) ) { maxExpansions = parser . intValue ( ) ; } else if ( "transpositions" . equals ( currentFieldName ) ) { transpositions = parser . booleanValue ( ) ; } else if ( "rewrite" . equals ( currentFieldName ) ) { rewriteMethod = QueryParsers . parseRewriteMethod ( parser . textOrNull ( ) , null ) ; } else { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[fuzzy]<seq2seq4repair_space>query<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>support<seq2seq4repair_space>[" + currentFieldName ) + "]" ) ) ; } } } parser . nextToken ( ) ; } else { value = parser . text ( ) ; parser . nextToken ( ) ; } if ( value == null ) { throw new QueryParsingException ( parseContext . index ( ) , "No<seq2seq4repair_space>value<seq2seq4repair_space>specified<seq2seq4repair_space>for<seq2seq4repair_space>fuzzy<seq2seq4repair_space>query" ) ; } Query query = null ; MapperService . SmartNameFieldMappers smartNameFieldMappers = parseContext . smartFieldMappers ( fieldName ) ; if ( smartNameFieldMappers != null ) { if ( smartNameFieldMappers . hasMapper ( ) ) { query = smartNameFieldMappers . mapper ( ) . fuzzyQuery ( value , minSimilarity , prefixLength , maxExpansions ) ; } } if ( query == null ) { int edits = FuzzyQuery . floatToEdits ( Float . parseFloat ( minSimilarity ) , value . codePointCount ( 0 , value . length ( ) ) ) ; query = new FuzzyQuery ( new Term ( fieldName , value ) , edits , prefixLength , maxExpansions , transpositions ) ; } if ( query instanceof MultiTermQuery ) { QueryParsers . setRewriteMethod ( ( ( MultiTermQuery ) ( query ) ) , rewriteMethod ) ; } query . setBoost ( boost ) ; return wrapSmartNameQuery ( query , smartNameFieldMappers , parseContext ) ; } }<BUG2FIX>boolean transpositions = false ;
public class BinaryFieldMapper extends AbstractFieldMapper < byte [ ] > { public static final String CONTENT_TYPE = "binary" ; public static class Builder extends AbstractFieldMapper . Builder < BinaryFieldMapper . Builder , BinaryFieldMapper > { public Builder ( String name ) { } @ Override public BinaryFieldMapper . Builder indexName ( String indexName ) { } @ Override public BinaryFieldMapper build ( BuilderContext context ) { } } public static class TypeParser implements XContentMapper . TypeParser { @ Override public XContentMapper . Builder parse ( String name , Map < String , Object > node , ParserContext parserContext ) throws MapperParsingException { } } protected BinaryFieldMapper ( Names names ) { } @ Override public byte [ ] value ( Fieldable field ) { } @ Override public byte [ ] valueFromString ( String value ) { } @ Override public String valueAsString ( Fieldable field ) { } @ Override public String indexedValue ( String value ) { } @ Override protected Field parseCreateField ( ParseContext context ) throws IOException { byte [ ] value ; if ( ( context . parser ( ) . currentToken ( ) ) == ( Token . VALUE_NULL ) ) { return null ; } else { value = context . parser ( ) . binaryValue ( ) ; } if ( value == null ) { return null ; } <START_BUG> return new Field ( names . indexName ( ) , value , Store . YES ) ; <END_BUG> } @ Override protected String contentType ( ) { } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } }<BUG2FIX>return new Field ( names . indexName ( ) , value ) ;
public class UserPagerAdapter extends FragmentPagerAdapter implements TitleProvider { private final boolean defaultUser ; private final FragmentManager fragmentManager ; private final Set < String > tags = new HashSet < String > ( ) ; public UserPagerAdapter ( final FragmentManager fm , final boolean defaultUser ) { } @ Override public Fragment getItem ( int position ) { } public UserPagerAdapter clearAdapter ( ) { } public Object instantiateItem ( ViewGroup container , int position ) { Object fragment = super . instantiateItem ( container , position ) ; <START_BUG> if ( ( position == 2 ) && ( fragment instanceof Fragment ) ) <END_BUG> tags . add ( ( ( Fragment ) ( fragment ) ) . getTag ( ) ) ; return fragment ; } @ Override public int getCount ( ) { } @ Override public String getTitle ( int position ) { } }<BUG2FIX>if ( fragment instanceof Fragment )
public class ExistsFieldQueryExtension implements FieldQueryExtension { public static final String NAME = "_exists_" ; @ Override public Query query ( QueryParseContext parseContext , String queryText ) { String fieldName = queryText ; Filter filter = null ; MapperService . SmartNameFieldMappers smartNameFieldMappers = parseContext . smartFieldMappers ( fieldName ) ; if ( smartNameFieldMappers != null ) { if ( smartNameFieldMappers . hasMapper ( ) ) { filter = smartNameFieldMappers . mapper ( ) . rangeFilter ( null , null , true , true ) ; } } if ( filter == null ) { filter = new TermRangeFilter ( fieldName , null , null , true , true ) ; } <START_BUG> filter = parseContext . cacheFilter ( filter ) ; <END_BUG> filter = wrapSmartNameFilter ( filter , smartNameFieldMappers , parseContext ) ; return new org . apache . lucene . search . DeletionAwareConstantScoreQuery ( filter ) ; } }<BUG2FIX>filter = parseContext . cacheFilter ( filter , null ) ;
public class RestBulkAction extends BaseRestHandler { @ Inject public RestBulkAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { BulkRequest bulkRequest = Requests . bulkRequest ( ) ; bulkRequest . listenerThreaded ( false ) ; String defaultIndex = request . param ( "index" ) ; String defaultType = request . param ( "type" ) ; String replicationType = request . param ( "replication" ) ; if ( replicationType != null ) { bulkRequest . replicationType ( ReplicationType . fromString ( replicationType ) ) ; } String consistencyLevel = request . param ( "consistency" ) ; if ( consistencyLevel != null ) { bulkRequest . consistencyLevel ( WriteConsistencyLevel . fromString ( consistencyLevel ) ) ; } bulkRequest . refresh ( request . paramAsBoolean ( "refresh" , bulkRequest . refresh ( ) ) ) ; try { bulkRequest . add ( request . content ( ) , request . contentUnsafe ( ) , defaultIndex , defaultType ) ; } catch ( Exception e ) { try { XContentBuilder builder = restContentBuilder ( request ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . BAD_REQUEST , builder . startObject ( ) . field ( "error" , e . getMessage ( ) ) . endObject ( ) ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } return ; } client . bulk ( bulkRequest , new org . elasticsearch . action . ActionListener < BulkResponse > ( ) { @ Override public void onResponse ( BulkResponse response ) { try { XContentBuilder builder = restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( RestBulkAction . Fields . TOOK , response . getTookInMillis ( ) ) ; builder . startArray ( RestBulkAction . Fields . ITEMS ) ; for ( BulkItemResponse itemResponse : response ) { builder . startObject ( ) ; builder . startObject ( itemResponse . getOpType ( ) ) ; builder . field ( RestBulkAction . Fields . _INDEX , itemResponse . getIndex ( ) ) ; builder . field ( RestBulkAction . Fields . _TYPE , itemResponse . getType ( ) ) ; builder . field ( RestBulkAction . Fields . _ID , itemResponse . getId ( ) ) ; long version = itemResponse . getVersion ( ) ; if ( version != ( - 1 ) ) { builder . field ( RestBulkAction . Fields . _VERSION , itemResponse . getVersion ( ) ) ; } if ( itemResponse . isFailed ( ) ) { builder . field ( RestBulkAction . Fields . ERROR , itemResponse . getFailure ( ) . getMessage ( ) ) ; } else { builder . field ( RestBulkAction . Fields . OK , true ) ; } if ( ( itemResponse . getResponse ( ) ) instanceof IndexResponse ) { IndexResponse indexResponse = itemResponse . getResponse ( ) ; if ( ( indexResponse . getMatches ( ) ) != null ) { builder . startArray ( RestBulkAction . Fields . MATCHES ) ; for ( String match : indexResponse . getMatches ( ) ) { builder . value ( match ) ; } builder . endArray ( ) ; } } builder . endObject ( ) ; builder . endObject ( ) ; } builder . endArray ( ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } static final class Fields { static final XContentBuilderString ITEMS = new XContentBuilderString ( "items" ) ; static final XContentBuilderString _INDEX = new XContentBuilderString ( "_index" ) ; static final XContentBuilderString _TYPE = new XContentBuilderString ( "_type" ) ; static final XContentBuilderString _ID = new XContentBuilderString ( "_id" ) ; static final XContentBuilderString ERROR = new XContentBuilderString ( "error" ) ; static final XContentBuilderString OK = new XContentBuilderString ( "ok" ) ; static final XContentBuilderString TOOK = new XContentBuilderString ( "took" ) ; static final XContentBuilderString _VERSION = new XContentBuilderString ( "_version" ) ; static final XContentBuilderString MATCHES = new XContentBuilderString ( "matches" ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class InterpolationTest extends GdxTest { private static final String [ ] interpolators = new String [ ] { "bounce" , "bounceIn" , "bounceOut" , "circle" , "circleIn" , "circleOut" , "elastic" , "elasticIn" , "elasticOut" , "exp10" , "exp10In" , "exp10Out" , "exp5" , "exp5In" , "exp5Out" , "fade" , "linear" , "pow2" , "pow2In" , "pow2Out" , "pow3" , "pow3In" , "pow3Out" , "pow4" , "pow4In" , "pow4Out" , "pow5" , "pow5In" , "pow5Out" , "sine" , "sineIn" , "sineOut" , "swing" , "swingIn" , "swingOut" } ; private Stage stage ; private Table root ; private List list ; private ShapeRenderer renderer ; Vector2 position = new Vector2 ( 300 , 20 ) ; Vector2 targetPosition = new Vector2 ( position ) ; Vector2 temp = new Vector2 ( ) ; float timer ; public void create ( ) { renderer = new ShapeRenderer ( ) ; stage = new Stage ( 0 , 0 , true ) ; input . setInputProcessor ( new com . badlogic . gdx . InputMultiplexer ( stage , new InputAdapter ( ) { public boolean touchDown ( int x , int y , int pointer , int button ) { Vector2 current = getCurrentPosition ( ) ; position . set ( current ) ; targetPosition . set ( ( x - 10 ) , ( ( ( graphics . getHeight ( ) ) - y ) - 10 ) ) ; timer = 0 ; return true ; } } ) ) ; root = new Table ( ) ; stage . addActor ( root ) ; root . pad ( 10 ) . top ( ) . left ( ) ; Skin skin = new Skin ( files . internal ( "data/uiskin.json" ) ) ; list = new List ( InterpolationTest . interpolators , skin ) ; ScrollPane scrollPane = new ScrollPane ( list , skin ) ; <START_BUG> scrollPane . setOverscroll ( false ) ; <END_BUG> scrollPane . setFadeScrollBars ( false ) ; root . add ( scrollPane ) . expandY ( ) . fillY ( ) . prefWidth ( 110 ) ; } public void resize ( int width , int height ) { } public void render ( ) { } Vector2 getCurrentPosition ( ) { } private Interpolation getInterpolation ( ) { } public boolean needsGL20 ( ) { } }<BUG2FIX>scrollPane . setOverscroll ( false , false ) ;
public class ShardFieldData extends AbstractIndexShardComponent implements IndexFieldDataCache . Listener { final CounterMetric evictionsMetric = new CounterMetric ( ) ; final CounterMetric totalMetric = new CounterMetric ( ) ; final ConcurrentMap < String , CounterMetric > perFieldTotals = ConcurrentCollections . newConcurrentMap ( ) ; private final CircuitBreakerService breakerService ; @ Inject public ShardFieldData ( ShardId shardId , @ IndexSettings Settings indexSettings , CircuitBreakerService breakerService ) { } public FieldDataStats stats ( String ... fields ) { ObjectLongOpenHashMap < String > fieldTotals = null ; if ( ( fields != null ) && ( ( fields . length ) > 0 ) ) { <START_BUG> fieldTotals = new ObjectLongOpenHashMap < String > ( ) ; <END_BUG> for ( Map . Entry < String , CounterMetric > entry : perFieldTotals . entrySet ( ) ) { for ( String field : fields ) { if ( Regex . simpleMatch ( field , entry . getKey ( ) ) ) { fieldTotals . put ( entry . getKey ( ) , entry . getValue ( ) . count ( ) ) ; } } } } long memorySize = totalMetric . count ( ) ; if ( perFieldTotals . containsKey ( NAME ) ) { memorySize -= perFieldTotals . get ( NAME ) . count ( ) ; } return new FieldDataStats ( memorySize , evictionsMetric . count ( ) , fieldTotals ) ; } @ Override public void onLoad ( FieldMapper . Names fieldNames , FieldDataType fieldDataType , AtomicFieldData fieldData ) { } @ Override public void onUnload ( FieldMapper . Names fieldNames , FieldDataType fieldDataType , boolean wasEvicted , long sizeInBytes , @ Nullable AtomicFieldData fieldData ) { } }<BUG2FIX>fieldTotals = new ObjectLongOpenHashMap ( ) ;
public class LocalDiscovery extends AbstractLifecycleComponent < Discovery > implements Discovery { private final TransportService transportService ; private final ClusterService clusterService ; private final ClusterName clusterName ; private DiscoveryNode localNode ; private volatile boolean master = false ; private final AtomicBoolean initialStateSent = new AtomicBoolean ( ) ; private final CopyOnWriteArrayList < InitialStateDiscoveryListener > initialStateListeners = new CopyOnWriteArrayList < InitialStateDiscoveryListener > ( ) ; private static final ConcurrentMap < ClusterName , LocalDiscovery . ClusterGroup > clusterGroups = new ConcurrentHashMap < ClusterName , LocalDiscovery . ClusterGroup > ( ) ; private static final AtomicLong nodeIdGenerator = new AtomicLong ( ) ; @ Inject public LocalDiscovery ( Settings settings , ClusterName clusterName , TransportService transportService , ClusterService clusterService ) { } @ Override protected void doStart ( ) throws ElasticSearchException { } @ Override protected void doStop ( ) throws ElasticSearchException { } @ Override protected void doClose ( ) throws ElasticSearchException { } @ Override public DiscoveryNode localNode ( ) { } @ Override public void addListener ( InitialStateDiscoveryListener listener ) { } @ Override public void removeListener ( InitialStateDiscoveryListener listener ) { } @ Override public String nodeDescription ( ) { } @ Override public void publish ( ClusterState clusterState ) { if ( ! ( master ) ) { throw new ElasticSearchIllegalStateException ( "Shouldn't<seq2seq4repair_space>publish<seq2seq4repair_space>state<seq2seq4repair_space>when<seq2seq4repair_space>not<seq2seq4repair_space>master" ) ; } LocalDiscovery . ClusterGroup clusterGroup = LocalDiscovery . clusterGroups . get ( clusterName ) ; if ( clusterGroup == null ) { return ; } try { final byte [ ] clusterStateBytes = Builder . toBytes ( clusterState ) ; for ( LocalDiscovery discovery : clusterGroup . members ( ) ) { if ( discovery . master ) { continue ; } <START_BUG> final ClusterState nodeSpecificClusterState = ClusterState . Builder . fromBytes ( clusterStateBytes , discovery . settings , discovery . localNode ) ; <END_BUG> if ( ( nodeSpecificClusterState . nodes ( ) . localNode ( ) ) != null ) { discovery . clusterService . submitStateUpdateTask ( "local-disco-receive(from<seq2seq4repair_space>master)" , new ProcessedClusterStateUpdateTask ( ) { @ Override public ClusterState execute ( ClusterState currentState ) { return nodeSpecificClusterState ; } @ Override public void clusterStateProcessed ( ClusterState clusterState ) { sendInitialStateEventIfNeeded ( ) ; } } ) ; } } } catch ( Exception e ) { throw new ElasticSearchIllegalStateException ( "Cluster<seq2seq4repair_space>state<seq2seq4repair_space>failed<seq2seq4repair_space>to<seq2seq4repair_space>serialize" , e ) ; } } private void sendInitialStateEventIfNeeded ( ) { } private class ClusterGroup { private Queue < LocalDiscovery > members = new org . elasticsearch . common . util . concurrent . jsr166y . LinkedTransferQueue < LocalDiscovery > ( ) ; Queue < LocalDiscovery > members ( ) { } } }<BUG2FIX>final ClusterState nodeSpecificClusterState = ClusterState . Builder . fromBytes ( clusterStateBytes , discovery . localNode ) ;
public abstract class BlobStoreGateway extends SharedStorageGateway { private BlobStore blobStore ; private ByteSizeValue chunkSize ; private BlobPath basePath ; private ImmutableBlobContainer metaDataBlobContainer ; private volatile int currentIndex ; protected BlobStoreGateway ( Settings settings , ClusterService clusterService , MetaDataCreateIndexService createIndexService ) { } protected void initialize ( BlobStore blobStore , ClusterName clusterName , @ Nullable ByteSizeValue defaultChunkSize ) throws IOException { } @ Override public String toString ( ) { } public BlobStore blobStore ( ) { } public BlobPath basePath ( ) { } public ByteSizeValue chunkSize ( ) { } @ Override public void reset ( ) throws Exception { } @ Override public MetaData read ( ) throws GatewayException { } public CommitPoint findCommitPoint ( String index , int shardId ) throws IOException { } @ Override public void write ( MetaData metaData ) throws GatewayException { } private int findLatestIndex ( ) throws IOException { } private MetaData readMetaData ( byte [ ] data ) throws IOException { XContentParser parser = null ; try { parser = XContentFactory . xContent ( JSON ) . createParser ( data ) ; <START_BUG> return Builder . fromXContent ( parser , settings ) ; <END_BUG> } finally { if ( parser != null ) { parser . close ( ) ; } } } }<BUG2FIX>return Builder . fromXContent ( parser ) ;
public class MultiValueLongFieldData extends LongFieldData { private static final int VALUE_CACHE_SIZE = 10 ; private ThreadLocal < ThreadLocals . CleanableValue < double [ ] [ ] > > doublesValuesCache = new ThreadLocal < ThreadLocals . CleanableValue < double [ ] [ ] > > ( ) { @ Override protected ThreadLocals . CleanableValue < double [ ] [ ] > initialValue ( ) { } } ; private ThreadLocal < ThreadLocals . CleanableValue < MutableDateTime [ ] [ ] > > dateTimesCache = new ThreadLocal < ThreadLocals . CleanableValue < MutableDateTime [ ] [ ] > > ( ) { @ Override protected ThreadLocals . CleanableValue < MutableDateTime [ ] [ ] > initialValue ( ) { } } ; private ThreadLocal < ThreadLocals . CleanableValue < long [ ] [ ] > > valuesCache = new ThreadLocal < ThreadLocals . CleanableValue < long [ ] [ ] > > ( ) { @ Override protected ThreadLocals . CleanableValue < long [ ] [ ] > initialValue ( ) { } } ; private final int [ ] [ ] ordinals ; public MultiValueLongFieldData ( String fieldName , int [ ] [ ] ordinals , long [ ] values ) { } @ Override protected long computeSizeInBytes ( ) { } @ Override public boolean multiValued ( ) { } @ Override public boolean hasValue ( int docId ) { } @ Override public void forEachValueInDoc ( int docId , StringValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , DoubleValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , LongValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , MissingDoubleValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , MissingLongValueInDocProc proc ) { } @ Override public void forEachOrdinalInDoc ( int docId , OrdinalInDocProc proc ) { boolean found = false ; for ( int [ ] ordinal : ordinals ) { int loc = ordinal [ docId ] ; if ( loc != 0 ) { found = true ; <START_BUG> proc . onOrdinal ( docId , ordinal [ docId ] ) ; <END_BUG> } } if ( ! found ) { proc . onOrdinal ( docId , 0 ) ; } } @ Override public void forEachValueInDoc ( int docId , ValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , DateValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , MutableDateTime dateTime , DateValueInDocProc proc ) { } @ Override public MutableDateTime [ ] dates ( int docId ) { } @ Override public double [ ] doubleValues ( int docId ) { } @ Override public long value ( int docId ) { } @ Override public long [ ] values ( int docId ) { } }<BUG2FIX>proc . onOrdinal ( docId , loc ) ;
public class SearchServiceTransportAction extends AbstractComponent { public static final String FREE_CONTEXT_ACTION_NAME = "indices:data/read/search[free_context]" ; public static final String CLEAR_SCROLL_CONTEXTS_ACTION_NAME = "indices:data/read/search[clear_scroll_contexts]" ; public static final String DFS_ACTION_NAME = "indices:data/read/search[phase/dfs]" ; public static final String QUERY_ACTION_NAME = "indices:data/read/search[phase/query]" ; public static final String QUERY_ID_ACTION_NAME = "indices:data/read/search[phase/query/id]" ; public static final String QUERY_SCROLL_ACTION_NAME = "indices:data/read/search[phase/query/scroll]" ; public static final String QUERY_FETCH_ACTION_NAME = "indices:data/read/search[phase/query+fetch]" ; public static final String QUERY_QUERY_FETCH_ACTION_NAME = "indices:data/read/search[phase/query/query+fetch]" ; public static final String QUERY_FETCH_SCROLL_ACTION_NAME = "indices:data/read/search[phase/query+fetch/scroll]" ; public static final String FETCH_ID_ACTION_NAME = "indices:data/read/search[phase/fetch/id]" ; public static final String SCAN_ACTION_NAME = "indices:data/read/search[phase/scan]" ; public static final String SCAN_SCROLL_ACTION_NAME = "indices:data/read/search[phase/scan/scroll]" ; static final class FreeContextResponseHandler implements TransportResponseHandler < SearchServiceTransportAction . SearchFreeContextResponse > { private final ActionListener < Boolean > listener ; FreeContextResponseHandler ( final ActionListener < Boolean > listener ) { } @ Override public SearchServiceTransportAction . SearchFreeContextResponse newInstance ( ) { } @ Override public void handleResponse ( SearchServiceTransportAction . SearchFreeContextResponse response ) { } @ Override public void handleException ( TransportException exp ) { } @ Override public String executor ( ) { } } private final ThreadPool threadPool ; private final TransportService transportService ; private final ClusterService clusterService ; private final SearchService searchService ; private final SearchServiceTransportAction . FreeContextResponseHandler freeContextResponseHandler = new SearchServiceTransportAction . FreeContextResponseHandler ( new ActionListener < Boolean > ( ) { @ Override public void onResponse ( Boolean aBoolean ) { } @ Override public void onFailure ( Throwable exp ) { } } ) ; @ Inject public SearchServiceTransportAction ( Settings settings , ThreadPool threadPool , TransportService transportService , ClusterService clusterService , SearchService searchService ) { } public void sendFreeContext ( DiscoveryNode node , final long contextId , SearchRequest request ) { } public void sendFreeContext ( DiscoveryNode node , long contextId , ClearScrollRequest request , final ActionListener < Boolean > actionListener ) { if ( clusterService . state ( ) . nodes ( ) . localNodeId ( ) . equals ( node . id ( ) ) ) { <START_BUG> boolean freed = searchService . freeContext ( contextId ) ; <END_BUG> actionListener . onResponse ( freed ) ; } else { transportService . sendRequest ( node , SearchServiceTransportAction . FREE_CONTEXT_ACTION_NAME , new SearchServiceTransportAction . SearchFreeContextRequest ( request , contextId ) , new SearchServiceTransportAction . FreeContextResponseHandler ( actionListener ) ) ; } } public void sendClearAllScrollContexts ( DiscoveryNode node , ClearScrollRequest request , final ActionListener < Boolean > actionListener ) { } public void sendExecuteDfs ( DiscoveryNode node , final ShardSearchRequest request , final SearchServiceListener < DfsSearchResult > listener ) { } public void sendExecuteQuery ( DiscoveryNode node , final ShardSearchRequest request , final SearchServiceListener < QuerySearchResultProvider > listener ) { } public void sendExecuteQuery ( DiscoveryNode node , final QuerySearchRequest request , final SearchServiceListener < QuerySearchResult > listener ) { } public void sendExecuteQuery ( DiscoveryNode node , final InternalScrollSearchRequest request , final SearchServiceListener < QuerySearchResult > listener ) { } public void sendExecuteFetch ( DiscoveryNode node , final ShardSearchRequest request , final SearchServiceListener < QueryFetchSearchResult > listener ) { } public void sendExecuteFetch ( DiscoveryNode node , final QuerySearchRequest request , final SearchServiceListener < QueryFetchSearchResult > listener ) { } public void sendExecuteFetch ( DiscoveryNode node , final InternalScrollSearchRequest request , final SearchServiceListener < QueryFetchSearchResult > listener ) { } public void sendExecuteFetch ( DiscoveryNode node , final FetchSearchRequest request , final SearchServiceListener < FetchSearchResult > listener ) { } public void sendExecuteScan ( DiscoveryNode node , final ShardSearchRequest request , final SearchServiceListener < QuerySearchResult > listener ) { } public void sendExecuteScan ( DiscoveryNode node , final InternalScrollSearchRequest request , final SearchServiceListener < QueryFetchSearchResult > listener ) { } private < T > void execute ( final Callable < ? extends T > callable , final SearchServiceListener < T > listener ) { } static class SearchFreeContextRequest extends TransportRequest implements IndicesRequest { private long id ; private OriginalIndices originalIndices ; SearchFreeContextRequest ( ) { } SearchFreeContextRequest ( SearchRequest request , long id ) { } SearchFreeContextRequest ( TransportRequest request , long id ) { } public long id ( ) { } @ Override public String [ ] indices ( ) { } @ Override public IndicesOptions indicesOptions ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } static class SearchFreeContextResponse extends TransportResponse { private boolean freed ; SearchFreeContextResponse ( ) { } SearchFreeContextResponse ( boolean freed ) { } public boolean isFreed ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } class SearchFreeContextTransportHandler extends BaseTransportRequestHandler < SearchServiceTransportAction . SearchFreeContextRequest > { @ Override public SearchServiceTransportAction . SearchFreeContextRequest newInstance ( ) { } @ Override public void messageReceived ( SearchServiceTransportAction . SearchFreeContextRequest request , TransportChannel channel ) throws Exception { } @ Override public String executor ( ) { } } static class ClearScrollContextsRequest extends TransportRequest { ClearScrollContextsRequest ( ) { } ClearScrollContextsRequest ( TransportRequest request ) { } } class ClearScrollContextsTransportHandler extends BaseTransportRequestHandler < SearchServiceTransportAction . ClearScrollContextsRequest > { @ Override public SearchServiceTransportAction . ClearScrollContextsRequest newInstance ( ) { } @ Override public void messageReceived ( SearchServiceTransportAction . ClearScrollContextsRequest request , TransportChannel channel ) throws Exception { } @ Override public String executor ( ) { } } private class SearchDfsTransportHandler extends BaseTransportRequestHandler < ShardSearchRequest > { @ Override public ShardSearchRequest newInstance ( ) { } @ Override public void messageReceived ( ShardSearchRequest request , TransportChannel channel ) throws Exception { } @ Override public String executor ( ) { } } private class SearchQueryTransportHandler extends BaseTransportRequestHandler < ShardSearchRequest > { @ Override public ShardSearchRequest newInstance ( ) { } @ Override public void messageReceived ( ShardSearchRequest request , TransportChannel channel ) throws Exception { } @ Override public String executor ( ) { } } private class SearchQueryByIdTransportHandler extends BaseTransportRequestHandler < QuerySearchRequest > { @ Override public QuerySearchRequest newInstance ( ) { }<BUG2FIX>final boolean freed = searchService . freeContext ( contextId ) ;
public class MatchAllDocsFilterTests { @ Test public void testMatchAllDocsFilter ( ) throws Exception { Directory dir = new RAMDirectory ( ) ; IndexWriter indexWriter = new IndexWriter ( dir , new org . apache . lucene . index . IndexWriterConfig ( Lucene . VERSION , Lucene . STANDARD_ANALYZER ) ) ; indexWriter . addDocument ( doc ( ) . add ( field ( "_id" , "1" ) ) . add ( field ( "text" , "lucene" ) ) . build ( ) ) ; indexWriter . addDocument ( doc ( ) . add ( field ( "_id" , "2" ) ) . add ( field ( "text" , "lucene<seq2seq4repair_space>release" ) ) . build ( ) ) ; IndexReader reader = IndexReader . open ( indexWriter , true ) ; IndexSearcher searcher = new IndexSearcher ( reader ) ; DeletionAwareConstantScoreQuery query = new DeletionAwareConstantScoreQuery ( Queries . MATCH_ALL_FILTER ) ; <START_BUG> long count = Lucene . count ( searcher , query , ( - 1 ) ) ; <END_BUG> assertThat ( count , equalTo ( 2L ) ) ; reader . close ( ) ; indexWriter . close ( ) ; } }<BUG2FIX>long count = Lucene . count ( searcher , query ) ;
public class Decal { private static final int VERTEX_SIZE = ( 3 + 1 ) + 2 ; public static final int SIZE = 4 * ( Decal . VERTEX_SIZE ) ; private static Vector3 tmp = new Vector3 ( ) ; private static Vector3 tmp2 = new Vector3 ( ) ; public int value ; protected float [ ] vertices = new float [ Decal . SIZE ] ; protected Vector3 position = new Vector3 ( ) ; protected Quaternion rotation = Quaternion . idt ( ) ; protected Vector2 scale = new Vector2 ( 1 , 1 ) ; public Vector2 transformationOffset = null ; protected Vector2 dimensions = new Vector2 ( ) ; protected DecalMaterial material = new DecalMaterial ( ) ; protected boolean updated = false ; protected Decal ( ) { } public void setColor ( float r , float g , float b , float a ) { } public void rotateX ( float angle ) { } public void rotateY ( float angle ) { } public void rotateZ ( float angle ) { } public void setRotation ( Vector3 dir , Vector3 up ) { } public Quaternion getRotation ( ) { } public void translateX ( float units ) { } public void setX ( float x ) { } public float getX ( ) { } public void translateY ( float units ) { } public void setY ( float y ) { } public float getY ( ) { } public void translateZ ( float units ) { } public void setZ ( float z ) { } public float getZ ( ) { } public void translate ( float x , float y , float z ) { } public void setPosition ( float x , float y , float z ) { } public Vector3 getPosition ( ) { } public void setScaleX ( float scale ) { } public float getScaleX ( ) { } public void setScaleY ( float scale ) { } public float getScaleY ( ) { } public void setScale ( float scaleX , float scaleY ) { } public void setScale ( float scale ) { } public void setWidth ( float width ) { } public float getWidth ( ) { } public void setHeight ( float height ) { } public float getHeight ( ) { } public void setDimensions ( float width , float height ) { } public float [ ] getVertices ( ) { } protected void update ( ) { } protected void transformVertices ( ) { } protected void resetVertices ( ) { } protected void updateUVs ( ) { } public void setTextureRegion ( TextureRegion textureRegion ) { } public TextureRegion getTextureRegion ( ) { } public void setBlending ( int srcBlendFactor , int dstBlendFactor ) { } public DecalMaterial getMaterial ( ) { } static final Vector3 dir = new Vector3 ( ) ; public void lookAt ( Vector3 position , Vector3 up ) { Decal . dir . set ( position ) . sub ( this . position ) . nor ( ) ; <START_BUG> setRotation ( Decal . dir , Y ) ; <END_BUG> } public static final int X1 = 0 ; public static final int Y1 = 1 ; public static final int Z1 = 2 ; public static final int C1 = 3 ; public static final int U1 = 4 ; public static final int V1 = 5 ; public static final int X2 = 6 ; public static final int Y2 = 7 ; public static final int Z2 = 8 ; public static final int C2 = 9 ; public static final int U2 = 10 ; public static final int V2 = 11 ; public static final int X3 = 12 ; public static final int Y3 = 13 ; public static final int Z3 = 14 ; public static final int C3 = 15 ; public static final int U3 = 16 ; public static final int V3 = 17 ; public static final int X4 = 18 ; public static final int Y4 = 19 ; public static final int Z4 = 20 ; public static final int C4 = 21 ; public static final int U4 = 22 ; public static final int V4 = 23 ; protected static Quaternion rotator = new Quaternion ( 0 , 0 , 0 , 0 ) ; protected static final Vector3 X_AXIS = new Vector3 ( 1 , 0 , 0 ) ; protected static final Vector3 Y_AXIS = new Vector3 ( 0 , 1 , 0 ) ; protected static final Vector3 Z_AXIS = new Vector3 ( 0 , 0 , 1 ) ; public static Decal newDecal ( TextureRegion textureRegion ) { } public static Decal newDecal ( TextureRegion textureRegion , boolean hasTransparency ) { } public static Decal newDecal ( float width , float height , TextureRegion textureRegion ) { } public static Decal newDecal ( float width , float height , TextureRegion textureRegion , boolean hasTransparency ) { } public static Decal newDecal ( float width , float height , TextureRegion textureRegion , int srcBlendFactor , int dstBlendFactor ) { } }<BUG2FIX>setRotation ( Decal . dir , up ) ;
public class TransportSearchAction extends TransportAction < SearchRequest , SearchResponse > { private final ClusterService clusterService ; private final TransportSearchDfsQueryThenFetchAction dfsQueryThenFetchAction ; private final TransportSearchQueryThenFetchAction queryThenFetchAction ; private final TransportSearchDfsQueryAndFetchAction dfsQueryAndFetchAction ; private final TransportSearchQueryAndFetchAction queryAndFetchAction ; private final TransportSearchScanAction scanAction ; private final TransportSearchCountAction countAction ; private final boolean optimizeSingleShard ; @ Inject public TransportSearchAction ( Settings settings , ThreadPool threadPool , TransportService transportService , ClusterService clusterService , TransportSearchDfsQueryThenFetchAction dfsQueryThenFetchAction , TransportSearchQueryThenFetchAction queryThenFetchAction , TransportSearchDfsQueryAndFetchAction dfsQueryAndFetchAction , TransportSearchQueryAndFetchAction queryAndFetchAction , TransportSearchScanAction scanAction , TransportSearchCountAction countAction ) { } @ Override protected void doExecute ( SearchRequest searchRequest , ActionListener < SearchResponse > listener ) { } private class TransportHandler extends BaseTransportRequestHandler < SearchRequest > { @ Override public SearchRequest newInstance ( ) { } @ Override public void messageReceived ( SearchRequest request , final TransportChannel channel ) throws Exception { request . listenerThreaded ( false ) ; if ( ( request . operationThreading ( ) ) == ( SearchOperationThreading . NO_THREADS ) ) { request . operationThreading ( SINGLE_THREAD ) ; } execute ( request , new ActionListener < SearchResponse > ( ) { @ Override public void onResponse ( SearchResponse result ) { try { channel . sendResponse ( result ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( e ) ; } catch ( Exception e1 ) { logger . warn ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>response<seq2seq4repair_space>for<seq2seq4repair_space>search" , e1 ) ; } } } ) ; } @ Override public String executor ( ) { } } }<BUG2FIX>} catch ( Throwable e ) {
public class IntValuesComparatorSource extends IndexFieldData . XFieldComparatorSource { private final IndexNumericFieldData indexFieldData ; private final Object missingValue ; public IntValuesComparatorSource ( IndexNumericFieldData indexFieldData , @ Nullable Object missingValue ) { } @ Override public Type reducedType ( ) { } @ Override public FieldComparator < ? > newComparator ( String fieldname , int numHits , int sortPos , boolean reversed ) throws IOException { assert fieldname . equals ( indexFieldData . getFieldNames ( ) . indexName ( ) ) ; int dMissingValue ; if ( ( ( missingValue ) == null ) || ( "_last" . equals ( missingValue ) ) ) { dMissingValue = ( reversed ) ? Integer . MIN_VALUE : Integer . MAX_VALUE ; } else if ( "_first" . equals ( missingValue ) ) { dMissingValue = ( reversed ) ? Integer . MAX_VALUE : Integer . MIN_VALUE ; } else { dMissingValue = ( ( missingValue ) instanceof Number ) ? ( ( Number ) ( missingValue ) ) . intValue ( ) : Integer . parseInt ( missingValue . toString ( ) ) ; } <START_BUG> return new IntValuesComparator ( indexFieldData , dMissingValue , numHits ) ; <END_BUG> } }<BUG2FIX>return new IntValuesComparator ( indexFieldData , dMissingValue , numHits , reversed ) ;
public class BenchmarkNettyClient { public static void main ( String [ ] args ) { final boolean waitForRequest = true ; final boolean spawn = true ; final ByteSizeValue payloadSize = new ByteSizeValue ( 100 , ByteSizeUnit . BYTES ) ; final int NUMBER_OF_CLIENTS = 1 ; final int NUMBER_OF_ITERATIONS = 100000 ; final byte [ ] payload = new byte [ ( ( int ) ( payloadSize . bytes ( ) ) ) ] ; final AtomicLong idGenerator = new AtomicLong ( ) ; Settings settings = ImmutableSettings . settingsBuilder ( ) . put ( "network.server" , false ) . put ( "network.tcp.blocking" , false ) . build ( ) ; final ThreadPool threadPool = new org . elasticsearch . threadpool . cached . CachedThreadPool ( settings ) ; final TimerService timerService = new TimerService ( settings , threadPool ) ; <START_BUG> final TransportService transportService = new TransportService ( new org . elasticsearch . transport . netty . NettyTransport ( settings , threadPool ) , threadPool , timerService ) . start ( ) ; <END_BUG> final DiscoveryNode node = new DiscoveryNode ( "server" , new InetSocketTransportAddress ( "localhost" , 9999 ) ) ; transportService . connectToNode ( node ) ; for ( int i = 0 ; i < 10000 ; i ++ ) { BenchmarkMessage message = new BenchmarkMessage ( 1 , payload ) ; transportService . submitRequest ( node , "benchmark" , message , new org . elasticsearch . transport . BaseTransportResponseHandler < BenchmarkMessage > ( ) { @ Override public BenchmarkMessage newInstance ( ) { return new BenchmarkMessage ( ) ; } @ Override public void handleResponse ( BenchmarkMessage response ) { } @ Override public void handleException ( TransportException exp ) { exp . printStackTrace ( ) ; } } ) . txGet ( ) ; } Thread [ ] clients = new Thread [ NUMBER_OF_CLIENTS ] ; final CountDownLatch latch = new CountDownLatch ( ( NUMBER_OF_CLIENTS * NUMBER_OF_ITERATIONS ) ) ; for ( int i = 0 ; i < NUMBER_OF_CLIENTS ; i ++ ) { clients [ i ] = new Thread ( new Runnable ( ) { @ Override public void run ( ) { for ( int j = 0 ; j < NUMBER_OF_ITERATIONS ; j ++ ) { final long id = idGenerator . incrementAndGet ( ) ; BenchmarkMessage message = new BenchmarkMessage ( id , payload ) ; org . elasticsearch . transport . BaseTransportResponseHandler < BenchmarkMessage > handler = new org . elasticsearch . transport . BaseTransportResponseHandler < BenchmarkMessage > ( ) { @ Override public BenchmarkMessage newInstance ( ) { return new BenchmarkMessage ( ) ; } @ Override public void handleResponse ( BenchmarkMessage response ) { if ( ( response . id ) != id ) { System . out . println ( ( ( ( ( "NO<seq2seq4repair_space>ID<seq2seq4repair_space>MATCH<seq2seq4repair_space>[" + ( response . id ) ) + "]<seq2seq4repair_space>and<seq2seq4repair_space>[" ) + id ) + "]" ) ) ; } latch . countDown ( ) ; } @ Override public void handleException ( TransportException exp ) { exp . printStackTrace ( ) ; latch . countDown ( ) ; } @ Override public boolean spawn ( ) { return spawn ; } } ; if ( waitForRequest ) { transportService . submitRequest ( node , "benchmark" , message , handler ) . txGet ( ) ; } else { transportService . sendRequest ( node , "benchmark" , message , handler ) ; } } } } ) ; } StopWatch stopWatch = new StopWatch ( ) . start ( ) ; for ( int i = 0 ; i < NUMBER_OF_CLIENTS ; i ++ ) { clients [ i ] . start ( ) ; } try { latch . await ( ) ; } catch ( InterruptedException e ) { e . printStackTrace ( ) ; } stopWatch . stop ( ) ; System . out . println ( ( ( ( ( ( ( ( ( ( "Ran<seq2seq4repair_space>[" + NUMBER_OF_CLIENTS ) + "],<seq2seq4repair_space>each<seq2seq4repair_space>with<seq2seq4repair_space>[" ) + NUMBER_OF_ITERATIONS ) + "]<seq2seq4repair_space>iterations,<seq2seq4repair_space>payload<seq2seq4repair_space>[" ) + payloadSize ) + "]:<seq2seq4repair_space>took<seq2seq4repair_space>[" ) + ( stopWatch . totalTime ( ) ) ) + "],<seq2seq4repair_space>TPS:<seq2seq4repair_space>" ) + ( ( NUMBER_OF_CLIENTS * NUMBER_OF_ITERATIONS ) / ( stopWatch . totalTime ( ) . secondsFrac ( ) ) ) ) ) ; transportService . close ( ) ; threadPool . shutdownNow ( ) ; } }<BUG2FIX>final TransportService transportService = new TransportService ( new org . elasticsearch . transport . netty . NettyTransport ( settings , threadPool ) , threadPool ) . start ( ) ;
public class GatewayService extends AbstractLifecycleComponent < GatewayService > implements ClusterStateListener { private final TimeValue initialStateTimeout ; private final Gateway gateway ; private final ThreadPool threadPool ; private volatile ExecutorService executor ; private final ClusterService clusterService ; private final DiscoveryService discoveryService ; private final MetaDataService metaDataService ; private final AtomicBoolean firstMasterRead = new AtomicBoolean ( ) ; @ Inject public GatewayService ( Settings settings , Gateway gateway , ClusterService clusterService , DiscoveryService discoveryService , ThreadPool threadPool , MetaDataService metaDataService ) { } @ Override protected void doStart ( ) throws ElasticSearchException { } @ Override protected void doStop ( ) throws ElasticSearchException { } @ Override protected void doClose ( ) throws ElasticSearchException { } @ Override public void clusterChanged ( final ClusterChangedEvent event ) { } private void writeToGateway ( final ClusterChangedEvent event ) { } private boolean readFromGateway ( @ Nullable TimeValue waitTimeout ) { logger . debug ( "First<seq2seq4repair_space>master<seq2seq4repair_space>in<seq2seq4repair_space>the<seq2seq4repair_space>cluster,<seq2seq4repair_space>reading<seq2seq4repair_space>state<seq2seq4repair_space>from<seq2seq4repair_space>gateway" ) ; MetaData metaData ; try { metaData = gateway . read ( ) ; } catch ( Exception e ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>read<seq2seq4repair_space>from<seq2seq4repair_space>gateway" , e ) ; return false ; } if ( metaData == null ) { logger . debug ( "No<seq2seq4repair_space>state<seq2seq4repair_space>read<seq2seq4repair_space>from<seq2seq4repair_space>gateway" ) ; <START_BUG> return false ; <END_BUG> } final MetaData fMetaData = metaData ; final CountDownLatch latch = new CountDownLatch ( fMetaData . indices ( ) . size ( ) ) ; clusterService . submitStateUpdateTask ( "gateway<seq2seq4repair_space>(recovered<seq2seq4repair_space>meta-data)" , new ClusterStateUpdateTask ( ) { @ Override public ClusterState execute ( ClusterState currentState ) { MetaData . Builder metaDataBuilder = newMetaDataBuilder ( ) . metaData ( currentState . metaData ( ) ) . maxNumberOfShardsPerNode ( fMetaData . maxNumberOfShardsPerNode ( ) ) ; for ( final IndexMetaData indexMetaData : fMetaData ) { threadPool . execute ( new Runnable ( ) { @ Override public void run ( ) { try { metaDataService . createIndex ( "gateway" , indexMetaData . index ( ) , indexMetaData . settings ( ) , indexMetaData . mappings ( ) , timeValueMillis ( ( ( initialStateTimeout . millis ( ) ) - 1000 ) ) ) ; } catch ( Exception e ) { logger . error ( ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>create<seq2seq4repair_space>index<seq2seq4repair_space>[" + ( indexMetaData . index ( ) ) ) + "]" ) , e ) ; } finally { latch . countDown ( ) ; } } } ) ; } return newClusterStateBuilder ( ) . state ( currentState ) . metaData ( metaDataBuilder ) . build ( ) ; } } ) ; if ( waitTimeout != null ) { try { return latch . await ( waitTimeout . millis ( ) , TimeUnit . MILLISECONDS ) ; } catch ( InterruptedException e ) { } } return false ; } }<BUG2FIX>return true ;
public class ShortArray { public short [ ] items ; public int size ; public boolean ordered ; public ShortArray ( ) { } public ShortArray ( int capacity ) { } public ShortArray ( boolean ordered , int capacity ) { } public ShortArray ( ShortArray array ) { } public ShortArray ( short [ ] array ) { } public ShortArray ( boolean ordered , short [ ] array , int startIndex , int count ) { } public void add ( short value ) { } public void addAll ( ShortArray array ) { } public void addAll ( ShortArray array , int offset , int length ) { } public void addAll ( short [ ] array ) { } public void addAll ( short [ ] array , int offset , int length ) { short [ ] items = this . items ; <START_BUG> int sizeNeeded = ( ( size ) + length ) - offset ; <END_BUG> if ( sizeNeeded >= ( items . length ) ) items = resize ( Math . max ( 8 , ( ( int ) ( sizeNeeded * 1.75F ) ) ) ) ; System . arraycopy ( array , offset , items , size , length ) ; size += length ; } public short get ( int index ) { } public void set ( int index , short value ) { } public void insert ( int index , short value ) { } public void swap ( int first , int second ) { } public boolean contains ( short value ) { } public int indexOf ( short value ) { } public int lastIndexOf ( char value ) { } public boolean removeValue ( short value ) { } public short removeIndex ( int index ) { } public boolean removeAll ( ShortArray array ) { } public short pop ( ) { } public short peek ( ) { } public short first ( ) { } public void clear ( ) { } public void shrink ( ) { } public short [ ] ensureCapacity ( int additionalCapacity ) { } protected short [ ] resize ( int newSize ) { } public void sort ( ) { } public void reverse ( ) { } public void shuffle ( ) { } public void truncate ( int newSize ) { } public short random ( ) { } public short [ ] toArray ( ) { } public boolean equals ( Object object ) { } public String toString ( ) { } public String toString ( String separator ) { } }<BUG2FIX>int sizeNeeded = ( size ) + length ;
public class MD2Loader implements KeyframedModelLoader { public KeyframedModel load ( FileHandle file , ModelLoaderHints hints ) { } public KeyframedModel load ( FileHandle fileHandle , float frameDuration ) { } public KeyframedModel load ( InputStream in , float frameDuration ) { } private KeyframedModel buildModel ( MD2Header header , MD2Triangle [ ] triangles , float [ ] texCoords , MD2Frame [ ] frames , float frameDuration ) { } private float [ ] buildTexCoords ( MD2Header header , MD2Triangle [ ] triangles , float [ ] texCoords ) { } private short [ ] buildIndices ( MD2Triangle [ ] triangles ) { } private MD2Frame [ ] loadFrames ( MD2Header header , byte [ ] bytes ) throws IOException { } private final byte [ ] charBuffer = new byte [ 16 ] ; private MD2Frame loadFrame ( MD2Header header , LittleEndianInputStream in ) throws IOException { MD2Frame frame = new MD2Frame ( ) ; frame . vertices = new float [ ( header . numVertices ) * 3 ] ; frame . normalIndices = new int [ header . numVertices ] ; float scaleX = in . readFloat ( ) ; float scaleY = in . readFloat ( ) ; float scaleZ = in . readFloat ( ) ; float transX = in . readFloat ( ) ; float transY = in . readFloat ( ) ; float transZ = in . readFloat ( ) ; in . read ( charBuffer ) ; int len = 0 ; for ( int i = 0 ; i < ( charBuffer . length ) ; i ++ ) if ( ( charBuffer [ i ] ) == 0 ) { <START_BUG> len = i - 1 ; <END_BUG> break ; } frame . name = new String ( charBuffer , 0 , len ) ; int vertIdx = 0 ; for ( int i = 0 ; i < ( header . numVertices ) ; i ++ ) { float x = ( ( in . read ( ) ) * scaleX ) + transX ; float y = ( ( in . read ( ) ) * scaleY ) + transY ; float z = ( ( in . read ( ) ) * scaleZ ) + transZ ; frame . vertices [ ( vertIdx ++ ) ] = y ; frame . vertices [ ( vertIdx ++ ) ] = z ; frame . vertices [ ( vertIdx ++ ) ] = x ; frame . normalIndices [ i ] = in . read ( ) ; } return frame ; } private MD2Triangle [ ] loadTriangles ( MD2Header header , byte [ ] bytes ) throws IOException { } private float [ ] loadTexCoords ( MD2Header header , byte [ ] bytes ) throws IOException { } private MD2Header loadHeader ( byte [ ] bytes ) throws IOException { } private byte [ ] loadBytes ( InputStream in ) throws IOException { } public class VertexIndices { public VertexIndices ( short vIdx , short tIdx , short nIdx ) { } @ Override public int hashCode ( ) { } @ Override public boolean equals ( Object obj ) { } public short vIdx ; public short tIdx ; public short nIdx ; } public static class MD2LoaderHints extends ModelLoaderHints { public final float frameDuration ; public MD2LoaderHints ( float frameDuration ) { } } }<BUG2FIX>len = i ;
public class G3DTLoader { public static KeyframedModel loadKeyframedModel ( FileHandle handle ) { } static int lineNum = 0 ; static String line = null ; public static KeyframedModel loadKeyframedModel ( InputStream stream ) { BufferedReader in = new BufferedReader ( new InputStreamReader ( stream ) ) ; G3DTLoader . lineNum = 1 ; try { String version = G3DTLoader . readString ( in ) ; if ( ! ( version . equals ( "g3dt-keyframed-1.0" ) ) ) throw new GdxRuntimeException ( "incorrect<seq2seq4repair_space>version" ) ; int numMeshes = G3DTLoader . readInt ( in ) ; KeyframedSubMesh [ ] subMeshes = new KeyframedSubMesh [ numMeshes ] ; for ( int i = 0 ; i < numMeshes ; i ++ ) { subMeshes [ i ] = G3DTLoader . readMesh ( in ) ; } KeyframedModel model = new KeyframedModel ( subMeshes ) ; <START_BUG> model . setAnimation ( model . getAnimations ( ) [ 0 ] . name , 0 ) ; <END_BUG> return model ; } catch ( Throwable e ) { throw new GdxRuntimeException ( ( ( ( ( ( "Couldn't<seq2seq4repair_space>read<seq2seq4repair_space>keyframed<seq2seq4repair_space>model,<seq2seq4repair_space>error<seq2seq4repair_space>in<seq2seq4repair_space>line<seq2seq4repair_space>" + ( G3DTLoader . lineNum ) ) + ",<seq2seq4repair_space>'" ) + ( G3DTLoader . line ) ) + "'<seq2seq4repair_space>:<seq2seq4repair_space>" ) + ( e . getMessage ( ) ) ) , e ) ; } } private static KeyframedSubMesh readMesh ( BufferedReader in ) throws IOException { } private static float [ ] buildVertices ( int numVertices , boolean hasNormals , Array < FloatArray > uvSets ) { } private static VertexAttribute [ ] createVertexAttributes ( boolean hasNormals , int uvs ) { } private static FloatArray readUVSet ( BufferedReader in , int numVertices ) throws IOException { } private static IntArray readFaces ( BufferedReader in ) throws IOException , NumberFormatException { } private static short [ ] convertToShortArray ( IntArray array ) { } private static float readFloat ( BufferedReader in ) throws IOException , NumberFormatException { } private static int readInt ( BufferedReader in ) throws IOException , NumberFormatException { } private static String readString ( BufferedReader in ) throws IOException { } private static void readFloatArray ( BufferedReader in , FloatArray array ) throws IOException { } private static int readFloatArray ( BufferedReader in , float [ ] array , int idx ) throws IOException { } private static void readIntArray ( BufferedReader in , IntArray array ) throws IOException { } private static String read ( BufferedReader in ) throws IOException { } public static void main ( String [ ] argv ) throws FileNotFoundException { } }<BUG2FIX>model . setAnimation ( model . getAnimations ( ) [ 0 ] . name , 0 , false ) ;
public class NewModelTest extends GdxTest { PerspectiveCamera cam ; ModelBatch modelBatch ; Model model ; ModelInstance instance ; ShapeRenderer shapeRenderer ; Light [ ] lights = new Light [ ] { new Light ( Color . WHITE , tmp . set ( ( - 10.0F ) , 10.0F , ( - 10.0F ) ) , 15.0F ) , new Light ( Color . BLUE , tmp . set ( 10.0F , 5.0F , 0.0F ) , 10.0F ) , new Light ( Color . GREEN , tmp . set ( 0.0F , 10.0F , 5.0F ) , 5.0F ) } ; float touchStartX = 0 ; float touchStartY = 0 ; @ Override public void create ( ) { } @ Override public void render ( ) { gl . glViewport ( 0 , 0 , graphics . getWidth ( ) , graphics . getHeight ( ) ) ; gl . glClear ( ( ( GL10 . GL_COLOR_BUFFER_BIT ) | ( GL10 . GL_DEPTH_BUFFER_BIT ) ) ) ; cam . update ( ) ; shapeRenderer . setProjectionMatrix ( cam . combined ) ; shapeRenderer . begin ( Line ) ; shapeRenderer . setColor ( RED ) ; shapeRenderer . line ( 0 , 0 , 0 , 100 , 0 , 0 ) ; shapeRenderer . setColor ( GREEN ) ; shapeRenderer . line ( 0 , 0 , 0 , 0 , 100 , 0 ) ; shapeRenderer . setColor ( BLUE ) ; shapeRenderer . line ( 0 , 0 , 0 , 0 , 0 , 100 ) ; shapeRenderer . end ( ) ; instance . transform . idt ( ) ; instance . transform . translate ( 0 , 0 , 3 ) ; modelBatch . begin ( cam ) ; <START_BUG> modelBatch . render ( lights , instance ) ; <END_BUG> modelBatch . end ( ) ; } @ Override public void dispose ( ) { } @ Override public boolean touchDown ( int x , int y , int pointer , int newParam ) { } @ Override public boolean touchDragged ( int x , int y , int pointer ) { } @ Override public boolean scrolled ( int amount ) { } @ Override public boolean needsGL20 ( ) { } }<BUG2FIX>modelBatch . render ( instance , lights ) ;
public abstract class AbstractIndexStore extends AbstractIndexComponent implements IndexStore { public static final String INDEX_STORE_THROTTLE_TYPE = "index.store.throttle.type" ; public static final String INDEX_STORE_THROTTLE_MAX_BYTES_PER_SEC = "index.store.throttle.max_bytes_per_sec" ; class ApplySettings implements IndexSettingsService . Listener { @ Override public void onRefreshSettings ( Settings settings ) { } } protected final IndexService indexService ; protected final IndicesStore indicesStore ; private volatile String rateLimitingType ; private volatile ByteSizeValue rateLimitingThrottle ; private volatile boolean nodeRateLimiting ; private final StoreRateLimiting rateLimiting = new StoreRateLimiting ( ) ; private final AbstractIndexStore . ApplySettings applySettings = new AbstractIndexStore . ApplySettings ( ) ; protected AbstractIndexStore ( Index index , @ IndexSettings Settings indexSettings , IndexService indexService , IndicesStore indicesStore ) { } @ Override <START_BUG> public void close ( boolean delete ) throws ElasticSearchException { <END_BUG> indexService . settingsService ( ) . removeListener ( applySettings ) ; } @ Override public boolean canDeleteUnallocated ( ShardId shardId ) { } @ Override public void deleteUnallocated ( ShardId shardId ) throws IOException { } @ Override public IndicesStore indicesStore ( ) { } @ Override public StoreRateLimiting rateLimiting ( ) { } }<BUG2FIX>public void close ( ) throws ElasticSearchException {
ensureYellow ( ) ; logger . info ( "--><seq2seq4repair_space>indexing" ) ; final int numDocs = randomIntBetween ( 10 , 100 ) ; IndexRequestBuilder [ ] builders = new IndexRequestBuilder [ numDocs ] ; for ( int i = 0 ; i < ( builders . length ) ; i ++ ) { builders [ i ] = client ( ) . prepareIndex ( "test" , "doc" , Integer . toString ( i ) ) . setSource ( "foo" , ( "bar" + i ) ) ; } indexRandom ( true , builders ) ; flushAndRefresh ( ) ; assertNoFailures ( client ( ) . admin ( ) . indices ( ) . prepareOptimize ( "test" ) . setForce ( true ) . setFlush ( true ) . setWaitForMerge ( true ) . setMaxNumSegments ( 1 ) . get ( ) ) ; CreateSnapshotResponse createSnapshotResponseFirst = client . admin ( ) . cluster ( ) . prepareCreateSnapshot ( "test-repo" , "test" ) . setWaitForCompletion ( true ) . setIndices ( "test" ) . get ( ) ; assertThat ( createSnapshotResponseFirst . getSnapshotInfo ( ) . successfulShards ( ) , greaterThan ( 0 ) ) ; assertThat ( createSnapshotResponseFirst . getSnapshotInfo ( ) . successfulShards ( ) , equalTo ( createSnapshotResponseFirst . getSnapshotInfo ( ) . totalShards ( ) ) ) ; assertThat ( client . admin ( ) . cluster ( ) . prepareGetSnapshots ( "test-repo" ) . setSnapshots ( "test" ) . get ( ) . getSnapshots ( ) . get ( 0 ) . state ( ) , equalTo ( SUCCESS ) ) ; { SnapshotStatus snapshotStatus = client . admin ( ) . cluster ( ) . prepareSnapshotStatus ( "test-repo" ) . setSnapshots ( "test" ) . get ( ) . getSnapshots ( ) . get ( 0 ) ; List < SnapshotIndexShardStatus > shards = snapshotStatus . getShards ( ) ; for ( SnapshotIndexShardStatus status : shards ) { assertThat ( status . getStats ( ) . getProcessedFiles ( ) , greaterThan ( 1 ) ) ; } } if ( frequently ( ) ) { logger . info ( "--><seq2seq4repair_space>upgrade" ) ; client ( ) . admin ( ) . indices ( ) . prepareUpdateSettings ( "test" ) . setSettings ( ImmutableSettings . builder ( ) . put ( INDEX_ROUTING_ALLOCATION_ENABLE , "none" ) ) . get ( ) ; backwardsCluster ( ) . allowOnAllNodes ( "test" ) ; logClusterState ( ) ; boolean upgraded ; do { logClusterState ( ) ; CountResponse countResponse = client ( ) . prepareCount ( ) . get ( ) ; assertHitCount ( countResponse , numDocs ) ; upgraded = backwardsCluster ( ) . upgradeOneNode ( ) ; ensureYellow ( ) ; countResponse = client ( ) . prepareCount ( ) . get ( ) ; assertHitCount ( countResponse , numDocs ) ; } while ( upgraded ) ; client ( ) . admin ( ) . indices ( ) . prepareUpdateSettings ( "test" ) . setSettings ( ImmutableSettings . builder ( ) . put ( INDEX_ROUTING_ALLOCATION_ENABLE , "all" ) ) . get ( ) ; } <START_BUG> if ( ( ( cluster ( ) . numDataNodes ( ) ) > 1 ) && ( randomBoolean ( ) ) ) { <END_BUG> client ( ) . admin ( ) . indices ( ) . prepareUpdateSettings ( "test" ) . setSettings ( ImmutableSettings . builder ( ) . put ( SETTING_NUMBER_OF_REPLICAS , randomIntBetween ( 1 , 2 ) ) ) . get ( ) ; } CreateSnapshotResponse createSnapshotResponseSecond = client . admin ( ) . cluster ( ) . prepareCreateSnapshot ( "test-repo" , "test-1" ) . setWaitForCompletion ( true ) . setIndices ( "test" ) . get ( ) ; assertThat ( createSnapshotResponseSecond . getSnapshotInfo ( ) . successfulShards ( ) , greaterThan ( 0 ) ) ; assertThat ( createSnapshotResponseSecond . getSnapshotInfo ( ) . successfulShards ( ) , equalTo ( createSnapshotResponseSecond . getSnapshotInfo ( ) . totalShards ( ) ) ) ; assertThat ( client . admin ( ) . cluster ( ) . prepareGetSnapshots ( "test-repo" ) . setSnapshots ( "test-1" ) . get ( ) . getSnapshots ( ) . get ( 0 ) . state ( ) , equalTo ( SUCCESS ) ) ; { SnapshotStatus snapshotStatus = client . admin ( ) . cluster ( ) . prepareSnapshotStatus ( "test-repo" ) . setSnapshots ( "test-1" ) . get ( ) . getSnapshots ( ) . get ( 0 ) ; List < SnapshotIndexShardStatus > shards = snapshotStatus . getShards ( ) ; for ( SnapshotIndexShardStatus status : shards ) { assertThat ( status . getStats ( ) . getProcessedFiles ( ) , equalTo ( 1 ) ) ; } } client ( ) . prepareDelete ( "test" , "doc" , "1" ) . get ( ) ; CreateSnapshotResponse createSnapshotResponseThird = client . admin ( ) . cluster ( ) . prepareCreateSnapshot ( "test-repo" , "test-2" ) . setWaitForCompletion ( true ) . setIndices ( "test" ) . get ( ) ; assertThat ( createSnapshotResponseThird . getSnapshotInfo ( ) . successfulShards ( ) , greaterThan ( 0 ) ) ; assertThat ( createSnapshotResponseThird . getSnapshotInfo ( ) . successfulShards ( ) , equalTo ( createSnapshotResponseThird . getSnapshotInfo ( ) . totalShards ( ) ) ) ; assertThat ( client . admin ( ) . cluster ( ) . prepareGetSnapshots ( "test-repo" ) . setSnapshots ( "test-2" ) . get ( ) . getSnapshots ( ) . get ( 0 ) . state ( ) , equalTo ( SUCCESS ) ) ; { SnapshotStatus snapshotStatus = client . admin ( ) . cluster ( ) . prepareSnapshotStatus ( "test-repo" ) . setSnapshots ( "test-2" ) . get ( ) . getSnapshots ( ) . get ( 0 ) ; List < SnapshotIndexShardStatus > shards = snapshotStatus . getShards ( ) ;<BUG2FIX>if ( randomBoolean ( ) ) {
public class HasChildQueryParser implements QueryParser { public static final String NAME = "has_child" ; @ Inject public HasChildQueryParser ( ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; Query query = null ; float boost = 1.0F ; String childType = null ; String scope = null ; String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_OBJECT ) ) { if ( "query" . equals ( currentFieldName ) ) { query = parseContext . parseInnerQuery ( ) ; } } else if ( token . isValue ( ) ) { if ( "type" . equals ( currentFieldName ) ) { childType = parser . text ( ) ; } else if ( "_scope" . equals ( currentFieldName ) ) { scope = parser . text ( ) ; } else if ( "boost" . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } } } if ( query == null ) { throw new QueryParsingException ( parseContext . index ( ) , "[has_child]<seq2seq4repair_space>requires<seq2seq4repair_space>'query'<seq2seq4repair_space>field" ) ; } if ( childType == null ) { throw new QueryParsingException ( parseContext . index ( ) , "[has_child]<seq2seq4repair_space>requires<seq2seq4repair_space>'type'<seq2seq4repair_space>field" ) ; } DocumentMapper childDocMapper = parseContext . mapperService ( ) . documentMapper ( childType ) ; if ( childDocMapper == null ) { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[has_child]<seq2seq4repair_space>No<seq2seq4repair_space>mapping<seq2seq4repair_space>for<seq2seq4repair_space>for<seq2seq4repair_space>type<seq2seq4repair_space>[" + childType ) + "]" ) ) ; } if ( ( childDocMapper . parentFieldMapper ( ) ) == null ) { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[has_child]<seq2seq4repair_space>Type<seq2seq4repair_space>[" + childType ) + "]<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>have<seq2seq4repair_space>parent<seq2seq4repair_space>mapping" ) ) ; } String parentType = childDocMapper . parentFieldMapper ( ) . type ( ) ; query . setBoost ( boost ) ; <START_BUG> query = new org . apache . lucene . search . FilteredQuery ( query , parseContext . cacheFilter ( childDocMapper . typeFilter ( ) ) ) ; <END_BUG> SearchContext searchContext = SearchContext . current ( ) ; HasChildFilter childFilter = new HasChildFilter ( query , scope , childType , parentType , searchContext ) ; ConstantScoreQuery childQuery = new ConstantScoreQuery ( childFilter ) ; childQuery . setBoost ( boost ) ; searchContext . addScopePhase ( childFilter ) ; return childQuery ; } }<BUG2FIX>query = new org . apache . lucene . search . FilteredQuery ( query , parseContext . cacheFilter ( childDocMapper . typeFilter ( ) , null ) ) ;
class ShardCountRequest extends BroadcastShardOperationRequest { private float minScore ; private BytesReference querySource ; private int querySourceOffset ; private int querySourceLength ; private String [ ] types = Strings . EMPTY_ARRAY ; @ Nullable private String [ ] filteringAliases ; ShardCountRequest ( ) { } public ShardCountRequest ( String index , int shardId , @ Nullable String [ ] filteringAliases , CountRequest request ) { } public float minScore ( ) { } public BytesReference querySource ( ) { } public String [ ] types ( ) { } public String [ ] filteringAliases ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { super . writeTo ( out ) ; out . writeFloat ( minScore ) ; <START_BUG> out . writeBytesReference ( querySource , true ) ; <END_BUG> out . writeVInt ( types . length ) ; for ( String type : types ) { out . writeUTF ( type ) ; } if ( ( filteringAliases ) != null ) { out . writeVInt ( filteringAliases . length ) ; for ( String alias : filteringAliases ) { out . writeUTF ( alias ) ; } } else { out . writeVInt ( 0 ) ; } } }<BUG2FIX>out . writeBytesReference ( querySource ) ;
@ Override public Terms terms ( String field ) throws IOException { if ( ! ( fieldMap . containsKey ( field ) ) ) { return null ; } long offset = fieldMap . lget ( ) ; final BytesStreamInput perFieldTermVectorInput = new BytesStreamInput ( this . termVectors ) ; perFieldTermVectorInput . reset ( ) ; perFieldTermVectorInput . skip ( offset ) ; final long numTerms = perFieldTermVectorInput . readVLong ( ) ; final boolean hasPositions = perFieldTermVectorInput . readBoolean ( ) ; final boolean hasOffsets = perFieldTermVectorInput . readBoolean ( ) ; final boolean hasPayloads = perFieldTermVectorInput . readBoolean ( ) ; final long sumTotalTermFreq = ( hasFieldStatistic ) ? readPotentiallyNegativeVLong ( perFieldTermVectorInput ) : - 1 ; final long sumDocFreq = ( hasFieldStatistic ) ? readPotentiallyNegativeVLong ( perFieldTermVectorInput ) : - 1 ; final int docCount = ( hasFieldStatistic ) ? readPotentiallyNegativeVInt ( perFieldTermVectorInput ) : - 1 ; return new Terms ( ) { @ Override public TermsEnum iterator ( TermsEnum reuse ) throws IOException { return new TermsEnum ( ) { int currentTerm = 0 ; int freq = 0 ; int docFreq = - 1 ; long totalTermFrequency = - 1 ; int [ ] positions = new int [ 1 ] ; int [ ] startOffsets = new int [ 1 ] ; int [ ] endOffsets = new int [ 1 ] ; BytesRef [ ] payloads = new BytesRef [ 1 ] ; final BytesRef spare = new BytesRef ( ) ; @ Override public BytesRef next ( ) throws IOException { if ( ( ( currentTerm ) ++ ) < numTerms ) { int termVectorSize = perFieldTermVectorInput . readVInt ( ) ; spare . grow ( termVectorSize ) ; perFieldTermVectorInput . readBytes ( spare . bytes , 0 , termVectorSize ) ; spare . length = termVectorSize ; if ( hasTermStatistic ) { docFreq = readPotentiallyNegativeVInt ( perFieldTermVectorInput ) ; totalTermFrequency = readPotentiallyNegativeVLong ( perFieldTermVectorInput ) ; } freq = readPotentiallyNegativeVInt ( perFieldTermVectorInput ) ; growBuffers ( ) ; writeInfos ( perFieldTermVectorInput ) ; return spare ; } else { return null ; } } private void writeInfos ( final BytesStreamInput input ) throws IOException { for ( int i = 0 ; i < ( freq ) ; i ++ ) { if ( hasPositions ) { positions [ i ] = input . readVInt ( ) ; } if ( hasOffsets ) { startOffsets [ i ] = input . readVInt ( ) ; endOffsets [ i ] = input . readVInt ( ) ; } if ( hasPayloads ) { int payloadLength = input . readVInt ( ) ; if ( payloadLength > 0 ) { if ( ( payloads [ i ] ) == null ) { payloads [ i ] = new BytesRef ( payloadLength ) ; } else { payloads [ i ] . grow ( payloadLength ) ; } input . readBytes ( payloads [ i ] . bytes , 0 , payloadLength ) ; payloads [ i ] . length = payloadLength ; payloads [ i ] . offset = 0 ; } } } } private void growBuffers ( ) { if ( hasPositions ) { positions = grow ( positions , freq ) ; } if ( hasOffsets ) { startOffsets = grow ( startOffsets , freq ) ; endOffsets = grow ( endOffsets , freq ) ; } if ( hasPayloads ) { if ( ( payloads . length ) < ( freq ) ) { final BytesRef [ ] newArray = new BytesRef [ ArrayUtil . oversize ( freq , NUM_BYTES_OBJECT_REF ) ] ; System . arraycopy ( payloads , 0 , newArray , 0 , payloads . length ) ; payloads = newArray ; } } } @ Override public Comparator < BytesRef > getComparator ( ) { return BytesRef . getUTF8SortedAsUnicodeComparator ( ) ; } @ Override <START_BUG> public SeekStatus seekCeil ( BytesRef text , boolean useCache ) throws IOException { <END_BUG> throw new UnsupportedOperationException ( ) ; } @ Override public void seekExact ( long ord ) throws IOException { throw new UnsupportedOperationException ( "Seek<seq2seq4repair_space>is<seq2seq4repair_space>not<seq2seq4repair_space>supported" ) ; } @ Override public BytesRef term ( ) throws IOException { return spare ; } @ Override public long ord ( ) throws IOException { throw new UnsupportedOperationException ( "ordinals<seq2seq4repair_space>are<seq2seq4repair_space>not<seq2seq4repair_space>supported" ) ; } @ Override public int docFreq ( ) throws IOException { return docFreq ; } @ Override public long totalTermFreq ( ) throws IOException { return totalTermFrequency ; } @ Override public DocsEnum docs ( Bits liveDocs , DocsEnum reuse , int flags ) throws IOException { return docsAndPositions ( liveDocs , ( reuse instanceof DocsAndPositionsEnum ? ( ( DocsAndPositionsEnum ) ( reuse ) ) : null ) , 0 ) ; } @ Override public DocsAndPositionsEnum docsAndPositions ( Bits liveDocs , DocsAndPositionsEnum reuse , int flags ) throws IOException { final TermVectorFields . TermVectorsDocsAndPosEnum retVal = ( reuse instanceof TermVectorFields . TermVectorsDocsAndPosEnum ) ? ( ( TermVectorFields . TermVectorsDocsAndPosEnum ) ( reuse ) ) : new TermVectorFields . TermVectorsDocsAndPosEnum ( ) ; return retVal . reset ( ( hasPositions ? positions : null ) , ( hasOffsets ? startOffsets : null ) , ( hasOffsets ? endOffsets : null ) , ( hasPayloads ? payloads : null ) , freq ) ; } } ; } @ Override public Comparator < BytesRef > getComparator ( ) { return BytesRef . getUTF8SortedAsUnicodeComparator ( ) ; } @ Override public long size ( ) throws IOException { return numTerms ; } @ Override public long getSumTotalTermFreq ( ) throws IOException { return sumTotalTermFreq ; } @ Override public long getSumDocFreq ( ) throws IOException { return sumDocFreq ; } @ Override public int getDocCount ( ) throws IOException { return docCount ; } @ Override public boolean hasOffsets ( ) { return hasOffsets ; } @ Override public boolean hasPositions ( ) { return hasPositions ; } @ Override public boolean hasPayloads ( ) { return hasPayloads ;<BUG2FIX>public SeekStatus seekCeil ( BytesRef text ) throws IOException {
public class JsonFloatFieldMapper extends JsonNumberFieldMapper < Float > { public static final String JSON_TYPE = "float" ; public static class Defaults extends JsonNumberFieldMapper . Defaults { public static final Float NULL_VALUE = null ; } public static class Builder extends JsonNumberFieldMapper . Builder < JsonFloatFieldMapper . Builder , JsonFloatFieldMapper > { protected Float nullValue = JsonFloatFieldMapper . Defaults . NULL_VALUE ; public Builder ( String name ) { } public JsonFloatFieldMapper . Builder nullValue ( float nullValue ) { } @ Override public JsonFloatFieldMapper build ( BuilderContext context ) { } } public static class TypeParser implements JsonTypeParser { @ Override public JsonMapper . Builder parse ( String name , JsonNode node , ParserContext parserContext ) throws MapperParsingException { } } private final Float nullValue ; private final String nullValueAsString ; protected JsonFloatFieldMapper ( Names names , int precisionStep , Field . Index index , Field . Store store , float boost , boolean omitNorms , boolean omitTermFreqAndPositions , Float nullValue ) { } @ Override protected int maxPrecisionStep ( ) { } @ Override public Float value ( Fieldable field ) { byte [ ] value = field . getBinaryValue ( ) ; if ( value == null ) { <START_BUG> return Float . NaN ; <END_BUG> } return Numbers . bytesToFloat ( value ) ; } @ Override public String indexedValue ( String value ) { } @ Override public String indexedValue ( Float value ) { } @ Override public Object valueFromTerm ( String term ) { } @ Override public Object valueFromString ( String text ) { } @ Override public Query rangeQuery ( String lowerTerm , String upperTerm , boolean includeLower , boolean includeUpper ) { } @ Override public Filter rangeFilter ( String lowerTerm , String upperTerm , boolean includeLower , boolean includeUpper ) { } @ Override protected Field parseCreateField ( JsonParseContext jsonContext ) throws IOException { } @ Override public int sortType ( ) { } @ Override protected String jsonType ( ) { } @ Override protected void doJsonBody ( JsonBuilder builder ) throws IOException { } }<BUG2FIX>return null ;
@ Test public class SimpleIndexQueryParserTests { private Injector injector ; private IndexQueryParserService queryParser ; @ BeforeClass public void setupQueryParser ( ) throws IOException { Settings settings = ImmutableSettings . settingsBuilder ( ) . put ( "index.cache.filter.type" , "none" ) . build ( ) ; Index index = new Index ( "test" ) ; injector = new ModulesBuilder ( ) . add ( new org . elasticsearch . common . settings . SettingsModule ( settings ) , new org . elasticsearch . threadpool . ThreadPoolModule ( settings ) , new IndicesQueriesModule ( ) , new org . elasticsearch . script . ScriptModule ( settings ) , new MapperServiceModule ( ) , new org . elasticsearch . index . settings . IndexSettingsModule ( index , settings ) , new org . elasticsearch . index . cache . IndexCacheModule ( settings ) , new org . elasticsearch . index . analysis . AnalysisModule ( settings ) , new org . elasticsearch . index . engine . IndexEngineModule ( settings ) , new org . elasticsearch . index . similarity . SimilarityModule ( settings ) , new org . elasticsearch . index . query . IndexQueryParserModule ( settings ) , new org . elasticsearch . index . IndexNameModule ( index ) , new AbstractModule ( ) { @ Override protected void configure ( ) { bind ( ClusterService . class ) . toProvider ( Providers . of ( ( ( ClusterService ) ( null ) ) ) ) ; } } ) . createInjector ( ) ; String mapping = copyToStringFromClasspath ( "/org/elasticsearch/test/unit/index/query/mapping.json" ) ; <START_BUG> injector . getInstance ( MapperService . class ) . add ( "person" , mapping ) ; <END_BUG> injector . getInstance ( MapperService . class ) . documentMapper ( "person" ) . parse ( new org . elasticsearch . common . bytes . BytesArray ( copyToBytesFromClasspath ( "/org/elasticsearch/test/unit/index/query/data.json" ) ) ) ; this . queryParser = injector . getInstance ( IndexQueryParserService . class ) ; } @ AfterClass public void close ( ) { } private IndexQueryParserService queryParser ( ) throws IOException { } @ Test public void testQueryStringBuilder ( ) throws Exception { } @ Test public void testQueryString ( ) throws Exception { } @ Test public void testQueryStringFields1Builder ( ) throws Exception { } @ Test public void testQueryStringFields1 ( ) throws Exception { } @ Test public void testQueryStringFieldsMatch ( ) throws Exception { } @ Test public void testQueryStringFields2Builder ( ) throws Exception { } @ Test public void testQueryStringFields2 ( ) throws Exception { } @ Test public void testQueryStringFields3Builder ( ) throws Exception { } @ Test public void testQueryStringFields3 ( ) throws Exception { } @ Test public void testMatchAllBuilder ( ) throws Exception { } @ Test public void testMatchAll ( ) throws Exception { } @ Test public void testDisMaxBuilder ( ) throws Exception { } @ Test public void testDisMax ( ) throws Exception { } @ Test public void testDisMax2 ( ) throws Exception { } @ Test public void testTermQueryBuilder ( ) throws IOException { } @ Test public void testTermQuery ( ) throws IOException { } @ Test public void testFuzzyQueryBuilder ( ) throws IOException { } @ Test public void testFuzzyQuery ( ) throws IOException { } @ Test public void testFuzzyQueryWithFieldsBuilder ( ) throws IOException { } @ Test public void testFuzzyQueryWithFields ( ) throws IOException { } @ Test public void testFuzzyQueryWithFields2 ( ) throws IOException { } @ Test public void testFieldQueryBuilder1 ( ) throws IOException { } @ Test public void testFieldQuery1 ( ) throws IOException { } @ Test public void testFieldQuery2 ( ) throws IOException { } @ Test public void testFieldQuery3 ( ) throws IOException { } @ Test public void testTextQuery1 ( ) throws IOException { } @ Test public void testTextQuery2 ( ) throws IOException { } @ Test public void testTextQuery3 ( ) throws IOException { } @ Test public void testTextQuery4 ( ) throws IOException { } @ Test public void testTextQuery4_2 ( ) throws IOException { } @ Test public void testTermWithBoostQueryBuilder ( ) throws IOException { } @ Test public void testTermWithBoostQuery ( ) throws IOException { } @ Test public void testPrefixQueryBuilder ( ) throws IOException { } @ Test public void testPrefixQuery ( ) throws IOException { } @ Test public void testPrefixBoostQuery ( ) throws IOException { } @ Test public void testPrefixFilteredQueryBuilder ( ) throws IOException { } @ Test public void testPrefixFilteredQuery ( ) throws IOException { } @ Test public void testPrefixNamedFilteredQuery ( ) throws IOException { } @ Test public void testPrefixQueryBoostQueryBuilder ( ) throws IOException { } @ Test public void testPrefixQueryBoostQuery ( ) throws IOException { } @ Test public void testWildcardQueryBuilder ( ) throws IOException { } @ Test public void testWildcardQuery ( ) throws IOException { } @ Test public void testWildcardBoostQuery ( ) throws IOException { } @ Test public void testRangeQueryBuilder ( ) throws IOException { } @ Test public void testRangeQuery ( ) throws IOException { } @ Test public void testRange2Query ( ) throws IOException { } @ Test public void testRangeFilteredQueryBuilder ( ) throws IOException { } @ Test public void testRangeFilteredQuery ( ) throws IOException { } @ Test public void testRangeNamedFilteredQuery ( ) throws IOException { } @ Test public void testNumericRangeFilteredQueryBuilder ( ) throws IOException { } @ Test public void testNumericRangeFilteredQuery ( ) throws IOException { } @ Test public void testBoolFilteredQuery ( ) throws IOException { } @ Test public void testAndFilteredQueryBuilder ( ) throws IOException { } @ Test public void testAndFilteredQuery ( ) throws IOException { } @ Test public void testAndNamedFilteredQuery ( ) throws IOException { } @ Test public void testAndFilteredQuery2 ( ) throws IOException { } @ Test public void testOrFilteredQueryBuilder ( ) throws IOException { } @ Test public void testOrFilteredQuery ( ) throws IOException { } @ Test public void testOrFilteredQuery2 ( ) throws IOException { }<BUG2FIX>injector . getInstance ( MapperService . class ) . add ( "person" , mapping , true ) ;
public interface ScoreFunction { void setNextReader ( AtomicReaderContext context ) { } float score ( int docId , float subQueryScore ) { } <START_BUG> float factor ( int docId ) ; <END_BUG> Explanation explainScore ( int docId , Explanation subQueryExpl ) { } Explanation explainFactor ( int docId ) { } }<BUG2FIX>double factor ( int docId ) ;
public class SingleArrayOrdinals implements Ordinals { private final int [ ] ordinals ; private final int numOrds ; private long size = - 1 ; public SingleArrayOrdinals ( int [ ] ordinals , int numOrds ) { } @ Override public Object getBackingStorage ( ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override public boolean isMultiValued ( ) { } @ Override public int getNumDocs ( ) { } @ Override public int getNumOrds ( ) { } @ Override public SingleArrayOrdinals . Docs ordinals ( ) { } public static class Docs implements Ordinals . Docs { private final SingleArrayOrdinals parent ; private final int [ ] ordinals ; private final IntArrayRef intsScratch = new IntArrayRef ( new int [ 1 ] ) ; private final SingleValueIter iter = new SingleValueIter ( ) ; public Docs ( SingleArrayOrdinals parent , int [ ] ordinals ) { } @ Override public Ordinals ordinals ( ) { } @ Override public int getNumDocs ( ) { } @ Override public int getNumOrds ( ) { } @ Override public boolean isMultiValued ( ) { } @ Override public int getOrd ( int docId ) { } @ Override public IntArrayRef getOrds ( int docId ) { int ordinal = ordinals [ docId ] ; if ( ordinal == 0 ) return IntArrayRef . EMPTY ; <START_BUG> intsScratch . values [ 0 ] = docId ; <END_BUG> return intsScratch ; } @ Override public Iter getIter ( int docId ) { } @ Override public void forEachOrdinalInDoc ( int docId , OrdinalInDocProc proc ) { } } }<BUG2FIX>intsScratch . values [ 0 ] = ordinal ;
public class GdxInvadersDesktop { public static void main ( String [ ] argv ) { LwjglApplicationConfiguration config = new LwjglApplicationConfiguration ( ) ; config . title = "Gdx<seq2seq4repair_space>Invaders" ; config . vSyncEnabled = true ; <START_BUG> config . useGL20 = true ; <END_BUG> new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new GdxInvaders ( ) , config ) ; } }<BUG2FIX>config . useGL20 = false ;
public abstract class BlobStoreIndexShardGateway extends AbstractIndexShardComponent implements IndexShardGateway { protected final ThreadPool threadPool ; protected final InternalIndexShard indexShard ; protected final Store store ; protected final ByteSizeValue chunkSize ; protected final BlobStore blobStore ; protected final BlobPath shardPath ; protected final ImmutableBlobContainer blobContainer ; private volatile RecoveryStatus recoveryStatus ; private volatile SnapshotStatus lastSnapshotStatus ; private volatile SnapshotStatus currentSnapshotStatus ; protected BlobStoreIndexShardGateway ( ShardId shardId , @ IndexSettings Settings indexSettings , ThreadPool threadPool , IndexGateway indexGateway , IndexShard indexShard , Store store ) { } @ Override public RecoveryStatus recoveryStatus ( ) { } @ Override public String toString ( ) { } @ Override public boolean requiresSnapshot ( ) { } @ Override public boolean requiresSnapshotScheduling ( ) { } @ Override public SnapshotLock obtainSnapshotLock ( ) throws Exception { } @ Override public void close ( boolean delete ) throws ElasticSearchException { } @ Override public SnapshotStatus lastSnapshotStatus ( ) { } @ Override public SnapshotStatus currentSnapshotStatus ( ) { } @ Override public SnapshotStatus snapshot ( final Snapshot snapshot ) throws IndexShardGatewaySnapshotFailedException { } private void doSnapshot ( final Snapshot snapshot ) throws IndexShardGatewaySnapshotFailedException { } @ Override public void recover ( boolean indexShouldExists , RecoveryStatus recoveryStatus ) throws IndexShardGatewayRecoveryException { } private void recoverTranslog ( CommitPoint commitPoint , ImmutableMap < String , BlobMetaData > blobs ) throws IndexShardGatewayRecoveryException { if ( commitPoint . translogFiles ( ) . isEmpty ( ) ) { indexShard . start ( "post<seq2seq4repair_space>recovery<seq2seq4repair_space>from<seq2seq4repair_space>gateway,<seq2seq4repair_space>no<seq2seq4repair_space>translog" ) ; return ; } try { indexShard . performRecoveryPrepareForTranslog ( ) ; final AtomicReference < Throwable > failure = new AtomicReference < Throwable > ( ) ; final CountDownLatch latch = new CountDownLatch ( 1 ) ; final Iterator < CommitPoint . FileInfo > transIt = commitPoint . translogFiles ( ) . iterator ( ) ; blobContainer . readBlob ( transIt . next ( ) . name ( ) , new BlobContainer . ReadBlobListener ( ) { FastByteArrayOutputStream bos = new FastByteArrayOutputStream ( ) ; boolean ignore = false ; @ Override public synchronized void onPartial ( byte [ ] data , int offset , int size ) throws IOException { if ( ignore ) { return ; } bos . write ( data , offset , size ) ; if ( ( bos . size ( ) ) < 4 ) { return ; } <START_BUG> BytesStreamInput si = new BytesStreamInput ( bos . underlyingBytes ( ) , 0 , bos . size ( ) ) ; <END_BUG> int position ; while ( true ) { try { position = si . position ( ) ; if ( ( position + 4 ) > ( bos . size ( ) ) ) { break ; } int opSize = si . readInt ( ) ; int curPos = si . position ( ) ; if ( ( ( si . position ( ) ) + opSize ) > ( bos . size ( ) ) ) { break ; } Translog . Operation operation = TranslogStreams . readTranslogOperation ( si ) ; if ( ( ( si . position ( ) ) - curPos ) != opSize ) { logger . warn ( "mismatch<seq2seq4repair_space>in<seq2seq4repair_space>size,<seq2seq4repair_space>expected<seq2seq4repair_space>[{}],<seq2seq4repair_space>got<seq2seq4repair_space>[{}]" , opSize , ( ( si . position ( ) ) - curPos ) ) ; } recoveryStatus . translog ( ) . addTranslogOperations ( 1 ) ; indexShard . performRecoveryOperation ( operation ) ; if ( ( si . position ( ) ) >= ( bos . size ( ) ) ) { position = si . position ( ) ; break ; } } catch ( Exception e ) { logger . warn ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>retrieve<seq2seq4repair_space>translog<seq2seq4repair_space>after<seq2seq4repair_space>[{}]<seq2seq4repair_space>operations,<seq2seq4repair_space>ignoring<seq2seq4repair_space>the<seq2seq4repair_space>rest,<seq2seq4repair_space>considered<seq2seq4repair_space>corrupted" , e , recoveryStatus . translog ( ) . currentTranslogOperations ( ) ) ; ignore = true ; latch . countDown ( ) ; return ; } } FastByteArrayOutputStream newBos = new FastByteArrayOutputStream ( ) ; int leftOver = ( bos . size ( ) ) - position ; if ( leftOver > 0 ) { newBos . write ( bos . underlyingBytes ( ) , position , leftOver ) ; } bos = newBos ; } @ Override public synchronized void onCompleted ( ) { if ( ignore ) { return ; } if ( ! ( transIt . hasNext ( ) ) ) { latch . countDown ( ) ; return ; } blobContainer . readBlob ( transIt . next ( ) . name ( ) , this ) ; } @ Override public void onFailure ( Throwable t ) { failure . set ( t ) ; latch . countDown ( ) ; } } ) ; latch . await ( ) ; if ( ( failure . get ( ) ) != null ) { throw failure . get ( ) ; } indexShard . performRecoveryFinalization ( true ) ; } catch ( Throwable e ) { throw new IndexShardGatewayRecoveryException ( shardId , "Failed<seq2seq4repair_space>to<seq2seq4repair_space>recover<seq2seq4repair_space>translog" , e ) ; } } private void recoverIndex ( CommitPoint commitPoint , ImmutableMap < String , BlobMetaData > blobs ) throws Exception { } private void recoverFile ( final CommitPoint . FileInfo fileInfo , final ImmutableMap < String , BlobMetaData > blobs , final CountDownLatch latch , final List < Throwable > failures ) { } private void snapshotTranslog ( Translog . Snapshot snapshot , CommitPoint . FileInfo fileInfo ) throws IOException { } private void snapshotFile ( Directory dir , final CommitPoint . FileInfo fileInfo , final CountDownLatch latch , final List < Throwable > failures ) throws IOException { } private boolean commitPointExistsInBlobs ( CommitPoint commitPoint , ImmutableMap < String , BlobMetaData > blobs ) { } private boolean commitPointFileExistsInBlobs ( CommitPoint . FileInfo fileInfo , ImmutableMap < String , BlobMetaData > blobs ) { } private CommitPoints buildCommitPoints ( ImmutableMap < String , BlobMetaData > blobs ) { } private String fileNameFromGeneration ( long generation ) { } private long findLatestFileNameGeneration ( ImmutableMap < String , BlobMetaData > blobs ) { } }<BUG2FIX>BytesStreamInput si = new BytesStreamInput ( bos . underlyingBytes ( ) , 0 , bos . size ( ) , false ) ;
public class RefreshRequestBuilder extends BroadcastOperationRequestBuilder < RefreshRequest , RefreshResponse , RefreshRequestBuilder > { public RefreshRequestBuilder ( IndicesAdminClient indicesClient ) { } public RefreshRequestBuilder setWaitForOperations ( boolean waitForOperations ) { <START_BUG> request . waitForOperations ( waitForOperations ) ; <END_BUG> return this ; } @ Override protected void doExecute ( ActionListener < RefreshResponse > listener ) { } }<BUG2FIX>request . setWaitForOperations ( waitForOperations ) ;
public class BulletBuild { public static void main ( String [ ] args ) throws Exception { new NativeCodeGenerator ( ) . generate ( "src" , "bin" , "jni" ) ; String cppFlags = "" ; cppFlags += "<seq2seq4repair_space>-fno-strict-aliasing" ; cppFlags += "<seq2seq4repair_space>-fno-rtti" ; cppFlags += "<seq2seq4repair_space>-DBT_NO_PROFILE" ; String [ ] excludes = new String [ ] { "src/bullet/BulletMultiThreaded/GpuSoftBodySolvers/**" } ; <START_BUG> String [ ] headers = new String [ ] { "src/bullet/" , "src/custom/" , "src/extras/serialize" } ; <END_BUG> BuildTarget win32home = BuildTarget . newDefaultTarget ( Windows , false ) ; win32home . compilerPrefix = "" ; win32home . buildFileName = "build-windows32home.xml" ; win32home . excludeFromMasterBuildFile = true ; win32home . cExcludes = win32home . cppExcludes = excludes ; win32home . headerDirs = headers ; win32home . cppFlags += cppFlags ; BuildTarget win32 = BuildTarget . newDefaultTarget ( Windows , false ) ; win32 . cExcludes = win32 . cppExcludes = excludes ; win32 . headerDirs = headers ; win32 . cppFlags += cppFlags ; BuildTarget win64 = BuildTarget . newDefaultTarget ( Windows , true ) ; win64 . cExcludes = win64 . cppExcludes = excludes ; win64 . headerDirs = headers ; win64 . cppFlags += cppFlags ; BuildTarget lin32 = BuildTarget . newDefaultTarget ( Linux , false ) ; lin32 . cExcludes = lin32 . cppExcludes = excludes ; lin32 . headerDirs = headers ; lin32 . cppFlags += cppFlags ; BuildTarget lin64 = BuildTarget . newDefaultTarget ( Linux , true ) ; lin64 . cExcludes = lin64 . cppExcludes = excludes ; lin64 . headerDirs = headers ; lin64 . cppFlags += cppFlags ; BuildTarget mac = BuildTarget . newDefaultTarget ( MacOsX , false ) ; mac . cExcludes = mac . cppExcludes = excludes ; mac . headerDirs = headers ; mac . cppFlags += cppFlags ; BuildTarget android = BuildTarget . newDefaultTarget ( Android , false ) ; android . cExcludes = android . cppExcludes = excludes ; android . headerDirs = headers ; android . cppFlags += cppFlags ; BuildTarget ios = BuildTarget . newDefaultTarget ( IOS , false ) ; ios . cExcludes = ios . cppExcludes = excludes ; ios . headerDirs = headers ; ios . cppFlags += cppFlags ; new AntScriptGenerator ( ) . generate ( new BuildConfig ( "gdx-bullet" ) , win32home , win32 , win64 , lin32 , lin64 , mac , android , ios ) ; } }<BUG2FIX>String [ ] headers = new String [ ] { "src/bullet/" , "src/custom/" } ;
public class AssetManager implements Disposable { final ObjectMap < Class , ObjectMap < String , RefCountedContainer > > assets = new ObjectMap < Class , ObjectMap < String , RefCountedContainer > > ( ) ; final ObjectMap < String , Class > assetTypes = new ObjectMap < String , Class > ( ) ; final ObjectMap < String , Array < String > > assetDependencies = new ObjectMap < String , Array < String > > ( ) ; final ObjectMap < Class , ObjectMap < String , AssetLoader > > loaders = new ObjectMap < Class , ObjectMap < String , AssetLoader > > ( ) ; final Array < AssetDescriptor > loadQueue = new Array < AssetDescriptor > ( ) ; final AsyncExecutor executor ; Stack < AssetLoadingTask > tasks = new Stack < AssetLoadingTask > ( ) ; AssetErrorListener listener = null ; int loaded = 0 ; int toLoad = 0 ; Logger log = new Logger ( "AssetManager" , Application . LOG_NONE ) ; public AssetManager ( ) { } public AssetManager ( FileHandleResolver resolver ) { } public synchronized < T > T get ( String fileName ) { } public synchronized < T > T get ( String fileName , Class < T > type ) { } public synchronized void unload ( String fileName ) { } public synchronized < T > boolean containsAsset ( T asset ) { } public synchronized < T > String getAssetFileName ( T asset ) { } public synchronized boolean isLoaded ( String fileName ) { } public synchronized boolean isLoaded ( String fileName , Class type ) { } public < T > AssetLoader getLoader ( final Class < T > type ) { } public < T > AssetLoader getLoader ( final Class < T > type , final String fileName ) { } public synchronized < T > void load ( String fileName , Class < T > type ) { } public synchronized < T > void load ( String fileName , Class < T > type , AssetLoaderParameters < T > parameter ) { } public synchronized void load ( AssetDescriptor desc ) { } private void disposeDependencies ( String fileName ) { } public synchronized boolean update ( ) { } public synchronized boolean update ( int millis ) { } public void finishLoading ( ) { } synchronized void injectDependencies ( String parentAssetFilename , Array < AssetDescriptor > dependendAssetDescs ) { } private synchronized void injectDependency ( String parentAssetFilename , AssetDescriptor dependendAssetDesc ) { } private void nextTask ( ) { } private void addTask ( AssetDescriptor assetDesc ) { } protected < T > void addAsset ( final String fileName , Class < T > type , T asset ) { } private boolean updateTask ( ) { } private void incrementRefCountedDependencies ( String parent ) { } private void handleTaskError ( Throwable t ) { log . error ( "Error<seq2seq4repair_space>loading<seq2seq4repair_space>asset." , t ) ; if ( tasks . isEmpty ( ) ) throw new GdxRuntimeException ( t ) ; AssetLoadingTask task = tasks . pop ( ) ; AssetDescriptor assetDesc = task . assetDesc ; if ( ( task . dependenciesLoaded ) && ( ( task . dependencies ) != null ) ) { for ( AssetDescriptor desc : task . dependencies ) { unload ( desc . fileName ) ; } } tasks . clear ( ) ; if ( ( listener ) != null ) { <START_BUG> listener . error ( assetDesc . fileName , assetDesc . type , t ) ; <END_BUG> } else { throw new GdxRuntimeException ( t ) ; } } public synchronized < T , P extends AssetLoaderParameters < T > > void setLoader ( Class < T > type , AssetLoader < T , P > loader ) { } public synchronized < T , P extends AssetLoaderParameters < T > > void setLoader ( Class < T > type , String suffix , AssetLoader < T , P > loader ) { } public synchronized int getLoadedAssets ( ) { } public synchronized int getQueuedAssets ( ) { } public synchronized float getProgress ( ) { } public synchronized void setErrorListener ( AssetErrorListener listener ) { } public synchronized void dispose ( ) { } public synchronized void clear ( ) { } public Logger getLogger ( ) { } public synchronized int getReferenceCount ( String fileName ) { } public synchronized void setReferenceCount ( String fileName , int refCount ) { } public synchronized String getDiagnostics ( ) { } public synchronized Array < String > getAssetNames ( ) { } public synchronized Array < String > getDependencies ( String fileName ) { } public synchronized Class getAssetType ( String fileName ) { } }<BUG2FIX>listener . error ( assetDesc , t ) ;
public final class ElasticsearchThreadFilter implements ThreadFilter { private final Pattern nodePrefix = Pattern . compile ( ( ( ( ( ( ( ( ( ( ( ( ( "\\[(" + "(" ) + ( Pattern . quote ( TRANSPORT_CLIENT_PREFIX ) ) ) + ")?(" ) + ( Pattern . quote ( GLOBAL_CLUSTER_NODE_PREFIX ) ) ) + "|" ) + ( Pattern . quote ( SUITE_CLUSTER_NODE_PREFIX ) ) ) + "|" ) + ( Pattern . quote ( TEST_CLUSTER_NODE_PREFIX ) ) ) + "|" ) + ( Pattern . quote ( SECOND_CLUSTER_NODE_PREFIX ) ) ) + ")" ) + ")\\d+\\]" ) ) ; @ Override public boolean reject ( Thread t ) { String threadName = t . getName ( ) ; if ( ( ( threadName . contains ( ( ( "[" + ( MulticastChannel . SHARED_CHANNEL_NAME ) ) + "]" ) ) ) || ( threadName . contains ( ( ( "[" + ( ElasticsearchSingleNodeTest . nodeName ( ) ) ) + "]" ) ) ) ) || ( threadName . contains ( "Keep-Alive-Timer" ) ) ) { return true ; } <START_BUG> return ( nodePrefix . matcher ( t . getName ( ) ) . find ( ) ) || true ; <END_BUG> } }<BUG2FIX>return nodePrefix . matcher ( t . getName ( ) ) . find ( ) ;
public class ConcreteBytesRefAtomicFieldData implements AtomicOrdinalFieldData < ScriptDocValues . Strings > { private final BytesRef [ ] values ; private final Ordinals ordinals ; private int [ ] hashes ; private long size = - 1 ; public ConcreteBytesRefAtomicFieldData ( BytesRef [ ] values , Ordinals ordinals ) { } @ Override public boolean isMultiValued ( ) { } @ Override public int getNumDocs ( ) { } @ Override public boolean isValuesOrdered ( ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override public OrdinalsBytesValues getBytesValues ( ) { } @ Override public OrdinalsHashedBytesValues getHashedBytesValues ( ) { } @ Override public OrdinalsStringValues getStringValues ( ) { } @ Override public Strings getScriptValues ( ) { } static abstract class BytesValues implements org . elasticsearch . index . fielddata . OrdinalsBytesValues { protected final BytesRef [ ] values ; protected final Docs ordinals ; BytesValues ( BytesRef [ ] values , Ordinals . Docs ordinals ) { } @ Override public Docs ordinals ( ) { } @ Override public BytesRef getValueByOrd ( int ord ) { } @ Override public BytesRef getValueScratchByOrd ( int ord , BytesRef ret ) { BytesRef value = values [ ord ] ; if ( value == null ) { ret . length = 0 ; } else { ret . bytes = value . bytes ; ret . offset = value . offset ; <START_BUG> ret . length = value . offset ; <END_BUG> } return ret ; } @ Override public BytesRef getSafeValueByOrd ( int ord ) { } @ Override public boolean hasValue ( int docId ) { } @ Override public BytesRef makeSafe ( BytesRef bytes ) { } @ Override public BytesRef getValue ( int docId ) { } @ Override public BytesRef getValueScratch ( int docId , BytesRef ret ) { } @ Override public BytesRef getValueSafe ( int docId ) { } @ Override public void forEachSafeValueInDoc ( int docId , ValueInDocProc proc ) { } static class Single extends ConcreteBytesRefAtomicFieldData . BytesValues { private final BytesRefArrayRef arrayScratch = new BytesRefArrayRef ( new BytesRef [ 1 ] , 1 ) ; private final Iter . Single iter = new Iter . Single ( ) ; Single ( BytesRef [ ] values , Ordinals . Docs ordinals ) { } @ Override public boolean isMultiValued ( ) { } @ Override public BytesRefArrayRef getValues ( int docId ) { } @ Override public Iter getIter ( int docId ) { } @ Override public Iter getIterSafe ( int docId ) { } @ Override public void forEachValueInDoc ( int docId , ValueInDocProc proc ) { } } static class Multi extends ConcreteBytesRefAtomicFieldData . BytesValues { private final BytesRefArrayRef arrayScratch = new BytesRefArrayRef ( new BytesRef [ 10 ] , 0 ) ; private final ConcreteBytesRefAtomicFieldData . BytesValues . Multi . ValuesIter iter ; Multi ( BytesRef [ ] values , Ordinals . Docs ordinals ) { } @ Override public boolean isMultiValued ( ) { } @ Override public BytesRefArrayRef getValues ( int docId ) { } @ Override public Iter getIter ( int docId ) { } @ Override public Iter getIterSafe ( int docId ) { } @ Override public void forEachValueInDoc ( int docId , ValueInDocProc proc ) { } static class ValuesIter implements Iter { private final BytesRef [ ] values ; private Ordinals . Docs . Iter ordsIter ; private int ord ; ValuesIter ( BytesRef [ ] values ) { } public ConcreteBytesRefAtomicFieldData . BytesValues . Multi . ValuesIter reset ( Ordinals . Docs . Iter ordsIter ) { } @ Override public boolean hasNext ( ) { } @ Override public BytesRef next ( ) { } } } } static abstract class HashedBytesValues implements org . elasticsearch . index . fielddata . OrdinalsHashedBytesValues { protected final BytesRef [ ] values ; protected final int [ ] hashes ; protected final Docs ordinals ; protected final HashedBytesRef scratch = new HashedBytesRef ( ) ; HashedBytesValues ( BytesRef [ ] values , int [ ] hashes , Ordinals . Docs ordinals ) { } @ Override public Docs ordinals ( ) { } @ Override public HashedBytesRef getValueByOrd ( int ord ) { } @ Override public HashedBytesRef getSafeValueByOrd ( int ord ) { } @ Override public boolean hasValue ( int docId ) { } @ Override public HashedBytesRef makeSafe ( HashedBytesRef bytes ) { } @ Override public HashedBytesRef getValue ( int docId ) { } @ Override public HashedBytesRef getValueSafe ( int docId ) { } static class Single extends ConcreteBytesRefAtomicFieldData . HashedBytesValues { private final Iter . Single iter = new Iter . Single ( ) ; Single ( BytesRef [ ] values , int [ ] hashes , Ordinals . Docs ordinals ) { } @ Override public boolean isMultiValued ( ) { } @ Override public Iter getIter ( int docId ) { } @ Override public Iter getIterSafe ( int docId ) { } @ Override public void forEachValueInDoc ( int docId , ValueInDocProc proc ) { } @ Override public void forEachSafeValueInDoc ( int docId , ValueInDocProc proc ) { } } static class Multi extends ConcreteBytesRefAtomicFieldData . HashedBytesValues { private final ConcreteBytesRefAtomicFieldData . HashedBytesValues . Multi . ValuesIter iter ; private final ConcreteBytesRefAtomicFieldData . HashedBytesValues . Multi . SafeValuesIter safeIter ; Multi ( BytesRef [ ] values , int [ ] hashes , Ordinals . Docs ordinals ) { } @ Override public boolean isMultiValued ( ) { } @ Override public Iter getIter ( int docId ) { } @ Override public Iter getIterSafe ( int docId ) { } @ Override public void forEachValueInDoc ( int docId , ValueInDocProc proc ) { } @ Override public void forEachSafeValueInDoc ( int docId , ValueInDocProc proc ) { } static class ValuesIter implements Iter { private final BytesRef [ ] values ; private final int [ ] hashes ; private Ordinals . Docs . Iter ordsIter ;<BUG2FIX>ret . length = value . length ;
public class IOSApplication implements Application { @ Override public Graphics getGraphics ( ) { } @ Override public Audio getAudio ( ) { } @ Override public Input getInput ( ) { } @ Override public Files getFiles ( ) { } @ Override public void log ( String tag , String message ) { <START_BUG> System . out . println ( ( ( tag + ":<seq2seq4repair_space>" ) + message ) ) ; <END_BUG> } @ Override public void log ( String tag , String message , Exception exception ) { } @ Override public void error ( String tag , String message ) { } @ Override public void error ( String tag , String message , Throwable exception ) { } @ Override public void debug ( String tag , String message ) { } @ Override public void debug ( String tag , String message , Throwable exception ) { } @ Override public void setLogLevel ( int logLevel ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } @ Override public Preferences getPreferences ( String name ) { } @ Override public void postRunnable ( Runnable runnable ) { } @ Override public void exit ( ) { } }<BUG2FIX>System . out . println ( message ) ;
public class RangeFilterParser extends AbstractIndexComponent implements XContentFilterParser { public static final String NAME = "range" ; @ Inject public RangeFilterParser ( Index index , @ IndexSettings Settings settings ) { } @ Override public String [ ] names ( ) { } @ Override public Filter parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; <START_BUG> boolean cache = false ; <END_BUG> String fieldName = null ; String from = null ; String to = null ; boolean includeLower = true ; boolean includeUpper = true ; String filterName = null ; String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_OBJECT ) ) { fieldName = currentFieldName ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else { if ( "from" . equals ( currentFieldName ) ) { from = parser . textOrNull ( ) ; } else if ( "to" . equals ( currentFieldName ) ) { to = parser . textOrNull ( ) ; } else if ( ( "include_lower" . equals ( currentFieldName ) ) || ( "includeLower" . equals ( currentFieldName ) ) ) { includeLower = parser . booleanValue ( ) ; } else if ( ( "include_upper" . equals ( currentFieldName ) ) || ( "includeUpper" . equals ( currentFieldName ) ) ) { includeUpper = parser . booleanValue ( ) ; } else if ( "gt" . equals ( currentFieldName ) ) { from = parser . textOrNull ( ) ; includeLower = false ; } else if ( ( "gte" . equals ( currentFieldName ) ) || ( "ge" . equals ( currentFieldName ) ) ) { from = parser . textOrNull ( ) ; includeLower = true ; } else if ( "lt" . equals ( currentFieldName ) ) { to = parser . textOrNull ( ) ; includeUpper = false ; } else if ( ( "lte" . equals ( currentFieldName ) ) || ( "le" . equals ( currentFieldName ) ) ) { to = parser . textOrNull ( ) ; includeUpper = true ; } } } } else if ( token . isValue ( ) ) { if ( "_name" . equals ( currentFieldName ) ) { filterName = parser . text ( ) ; } else if ( "_cache" . equals ( currentFieldName ) ) { cache = parser . booleanValue ( ) ; } } } if ( fieldName == null ) { throw new QueryParsingException ( index , "No<seq2seq4repair_space>field<seq2seq4repair_space>specified<seq2seq4repair_space>for<seq2seq4repair_space>range<seq2seq4repair_space>filter" ) ; } Filter filter = null ; MapperService . SmartNameFieldMappers smartNameFieldMappers = parseContext . smartFieldMappers ( fieldName ) ; if ( smartNameFieldMappers != null ) { if ( smartNameFieldMappers . hasMapper ( ) ) { filter = smartNameFieldMappers . mapper ( ) . rangeFilter ( from , to , includeLower , includeUpper ) ; } } if ( filter == null ) { filter = new TermRangeFilter ( fieldName , from , to , includeLower , includeUpper ) ; } if ( cache ) { filter = parseContext . cacheFilter ( filter ) ; } else { filter = parseContext . cacheWeakFilter ( filter ) ; } filter = wrapSmartNameFilter ( filter , smartNameFieldMappers , parseContext ) ; if ( filterName != null ) { parseContext . addNamedFilter ( filterName , filter ) ; } return filter ; } }<BUG2FIX>boolean cache = true ;
public interface ScoreFunction { void setNextReader ( AtomicReaderContext context ) { } <START_BUG> float score ( int docId , float subQueryScore ) ; <END_BUG> double factor ( int docId ) { } Explanation explainScore ( int docId , Explanation subQueryExpl ) { } Explanation explainFactor ( int docId ) { } }<BUG2FIX>double score ( int docId , float subQueryScore ) ;
public class RestActions { public static long parseVersion ( RestRequest request ) { } public static void buildBroadcastShardsHeader ( XContentBuilder builder , BroadcastOperationResponse response ) throws IOException { } public static byte [ ] parseQuerySource ( RestRequest request ) { String queryString = request . param ( "q" ) ; if ( queryString == null ) { <START_BUG> throw new ElasticSearchIllegalArgumentException ( "No<seq2seq4repair_space>query<seq2seq4repair_space>to<seq2seq4repair_space>execute,<seq2seq4repair_space>not<seq2seq4repair_space>in<seq2seq4repair_space>body,<seq2seq4repair_space>and<seq2seq4repair_space>not<seq2seq4repair_space>bounded<seq2seq4repair_space>to<seq2seq4repair_space>'q'<seq2seq4repair_space>parameter" ) ; <END_BUG> } QueryStringQueryBuilder queryBuilder = QueryBuilders . queryString ( queryString ) ; queryBuilder . defaultField ( request . param ( "df" ) ) ; queryBuilder . analyzer ( request . param ( "analyzer" ) ) ; String defaultOperator = request . param ( "default_operator" ) ; if ( defaultOperator != null ) { if ( "OR" . equals ( defaultOperator ) ) { queryBuilder . defaultOperator ( OR ) ; } else if ( "AND" . equals ( defaultOperator ) ) { queryBuilder . defaultOperator ( AND ) ; } else { throw new ElasticSearchIllegalArgumentException ( ( ( "Unsupported<seq2seq4repair_space>defaultOperator<seq2seq4repair_space>[" + defaultOperator ) + "],<seq2seq4repair_space>can<seq2seq4repair_space>either<seq2seq4repair_space>be<seq2seq4repair_space>[OR]<seq2seq4repair_space>or<seq2seq4repair_space>[AND]" ) ) ; } } return queryBuilder . buildAsBytes ( ) ; } public static String [ ] splitIndices ( String indices ) { } public static String [ ] splitTypes ( String typeNames ) { } public static String [ ] splitNodes ( String nodes ) { } }<BUG2FIX>return null ;
public class RestIndicesSegmentsAction extends BaseRestHandler { @ Inject public RestIndicesSegmentsAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { IndicesSegmentsRequest indicesSegmentsRequest = new IndicesSegmentsRequest ( splitIndices ( request . param ( "index" ) ) ) ; indicesSegmentsRequest . listenerThreaded ( false ) ; if ( request . hasParam ( "ignore_indices" ) ) { indicesSegmentsRequest . ignoreIndices ( IgnoreIndices . fromString ( request . param ( "ignore_indices" ) ) ) ; } BroadcastOperationThreading operationThreading = BroadcastOperationThreading . fromString ( request . param ( "operation_threading" ) , SINGLE_THREAD ) ; if ( operationThreading == ( BroadcastOperationThreading . NO_THREADS ) ) { operationThreading = BroadcastOperationThreading . SINGLE_THREAD ; } indicesSegmentsRequest . operationThreading ( operationThreading ) ; client . admin ( ) . indices ( ) . segments ( indicesSegmentsRequest , new org . elasticsearch . action . ActionListener < IndicesSegmentResponse > ( ) { @ Override public void onResponse ( IndicesSegmentResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( "ok" , true ) ; buildBroadcastShardsHeader ( builder , response ) ; response . toXContent ( builder , request ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class GeolocationContextMapping extends ContextMapping { public static final String TYPE = "geo" ; public static final String FIELD_PRECISION = "precision" ; public static final String FIELD_NEIGHBORS = "neighbors" ; public static final String FIELD_FIELDNAME = "path" ; private final Collection < String > defaultLocations ; private final int [ ] precision ; private final boolean neighbors ; private final String fieldName ; private final GeolocationContextMapping . GeoConfig defaultConfig ; protected GeolocationContextMapping ( String name , int [ ] precision , boolean neighbors , Collection < String > defaultLocations , String fieldName ) { } protected static GeolocationContextMapping load ( String name , Map < String , Object > config ) { } @ Override protected XContentBuilder toInnerXContent ( XContentBuilder builder , Params params ) throws IOException { } protected static Collection < String > parseSinglePointOrList ( XContentParser parser ) throws IOException { } @ Override public ContextConfig defaultConfig ( ) { } @ Override public ContextConfig parseContext ( ParseContext parseContext , XContentParser parser ) throws IOException , ElasticsearchParseException { } public static GeolocationContextMapping . GeoQuery query ( String name , GeoPoint point ) { } public static GeolocationContextMapping . GeoQuery query ( String name , double lat , double lon ) { } public static GeolocationContextMapping . GeoQuery query ( String name , String geohash ) { } private static final int parsePrecision ( XContentParser parser ) throws IOException , ElasticsearchParseException { } @ Override public GeolocationContextMapping . GeoQuery parseQuery ( String name , XContentParser parser ) throws IOException , ElasticsearchParseException { } @ Override public int hashCode ( ) { } @ Override public boolean equals ( Object obj ) { } public static class Builder extends ContextBuilder < GeolocationContextMapping > { private IntOpenHashSet precisions = new IntOpenHashSet ( ) ; private boolean neighbors ; private HashSet < String > defaultLocations = new HashSet < > ( ) ; private String fieldName = null ; protected Builder ( String name ) { } protected Builder ( String name , boolean neighbors , int ... levels ) { } public GeolocationContextMapping . Builder precision ( String precision ) { } public GeolocationContextMapping . Builder precision ( double precision , DistanceUnit unit ) { } public GeolocationContextMapping . Builder precision ( double meters ) { } public GeolocationContextMapping . Builder precision ( int level ) { } public GeolocationContextMapping . Builder neighbors ( boolean neighbors ) { } public GeolocationContextMapping . Builder addDefaultLocation ( String geohash ) { } public GeolocationContextMapping . Builder addDefaultLocations ( Collection < String > geohashes ) { } public GeolocationContextMapping . Builder addDefaultLocation ( double lat , double lon ) { } public GeolocationContextMapping . Builder defaultLocation ( GeoPoint point ) { } public GeolocationContextMapping . Builder field ( String fieldName ) { } @ Override public GeolocationContextMapping build ( ) { } } private static class GeoConfig extends ContextConfig { private final GeolocationContextMapping mapping ; private final Collection < String > locations ; public GeoConfig ( GeolocationContextMapping mapping , Collection < String > locations ) { } @ Override protected TokenStream wrapTokenStream ( Document doc , TokenStream stream ) { Collection < String > geohashes ; <START_BUG> if ( ( ( locations ) == null ) | ( ( locations . size ( ) ) == 0 ) ) { <END_BUG> if ( ( mapping . fieldName ) != null ) { IndexableField [ ] fields = doc . getFields ( mapping . fieldName ) ; if ( ( fields . length ) > 0 ) { geohashes = new java . util . ArrayList ( fields . length ) ; GeoPoint spare = new GeoPoint ( ) ; for ( IndexableField field : fields ) { spare . resetFromString ( field . stringValue ( ) ) ; geohashes . add ( spare . geohash ( ) ) ; } } else { geohashes = mapping . defaultLocations ; } } else { geohashes = mapping . defaultLocations ; } } else { geohashes = locations ; } Collection < String > locations = new HashSet < > ( ) ; for ( String geohash : geohashes ) { for ( int p : mapping . precision ) { int precision = Math . min ( p , geohash . length ( ) ) ; geohash = geohash . substring ( 0 , precision ) ; if ( mapping . neighbors ) { GeoHashUtils . addNeighbors ( geohash , precision , locations ) ; } locations . add ( geohash ) ; } } return new org . apache . lucene . analysis . PrefixAnalyzer . PrefixTokenFilter ( stream , ContextMapping . SEPARATOR , locations ) ; } public String toString ( ) { } } private static class GeoQuery extends ContextQuery { private final String location ; private final int [ ] precisions ; public GeoQuery ( String name , String location , int ... precisions ) { } @ Override public Automaton toAutomaton ( ) { } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } } }<BUG2FIX>if ( ( ( locations ) == null ) || ( ( locations . size ( ) ) == 0 ) ) {
public class IntFloatMap { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; private static final int EMPTY = 0 ; public int size ; int [ ] keyTable ; float [ ] valueTable ; int capacity ; int stashSize ; float zeroValue ; boolean hasZeroValue ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private IntFloatMap . Entries entries1 ; private IntFloatMap . Entries entries2 ; private IntFloatMap . Values values1 ; private IntFloatMap . Values values2 ; private IntFloatMap . Keys keys1 ; private IntFloatMap . Keys keys2 ; public IntFloatMap ( ) { } public IntFloatMap ( int initialCapacity ) { } public IntFloatMap ( int initialCapacity , float loadFactor ) { } public IntFloatMap ( IntFloatMap map ) { } public void put ( int key , float value ) { } public void putAll ( IntFloatMap map ) { } private void putResize ( int key , float value ) { } private void push ( int insertKey , float insertValue , int index1 , int key1 , int index2 , int key2 , int index3 , int key3 ) { } private void putStash ( int key , float value ) { } public float get ( int key , float defaultValue ) { } private float getStash ( int key , float defaultValue ) { } public float getAndIncrement ( int key , float defaultValue , float increment ) { } private float getAndIncrementStash ( int key , float defaultValue , float increment ) { } public float remove ( int key , float defaultValue ) { } float removeStash ( int key , float defaultValue ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean containsValue ( float value ) { } public boolean containsValue ( float value , float epsilon ) { } public boolean containsKey ( int key ) { } private boolean containsKeyStash ( int key ) { } public int findKey ( float value , int notFound ) { } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( int h ) { } private int hash3 ( int h ) { } public String toString ( ) { } public IntFloatMap . Entries entries ( ) { } public IntFloatMap . Values values ( ) { } public IntFloatMap . Keys keys ( ) { } public static class Entry < K > { public int key ; public float value ; public String toString ( ) { } } private static class MapIterator < K > { static final int INDEX_ILLEGAL = - 2 ; static final int INDEX_ZERO = - 1 ; public boolean hasNext ; final IntFloatMap map ; int nextIndex ; int currentIndex ; boolean valid = true ; public MapIterator ( IntFloatMap map ) { } public void reset ( ) { } void findNextIndex ( ) { } public void remove ( ) { if ( ( ( currentIndex ) == ( IntFloatMap . MapIterator . INDEX_ZERO ) ) && ( map . hasZeroValue ) ) { map . hasZeroValue = false ; } else if ( ( currentIndex ) < 0 ) { throw new IllegalStateException ( "next<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>called<seq2seq4repair_space>before<seq2seq4repair_space>remove." ) ; } else if ( ( currentIndex ) >= ( map . capacity ) ) { map . removeStashIndex ( currentIndex ) ; <START_BUG> nextIndex = ( currentIndex ) - 1 ; <END_BUG> findNextIndex ( ) ; } else { map . keyTable [ currentIndex ] = IntFloatMap . EMPTY ; } currentIndex = IntFloatMap . MapIterator . INDEX_ILLEGAL ; ( map . size ) -- ; } } public static class Entries extends IntFloatMap . MapIterator implements Iterable < IntFloatMap . Entry > , Iterator < IntFloatMap . Entry > { private IntFloatMap . Entry entry = new IntFloatMap . Entry ( ) ; public Entries ( IntFloatMap map ) { } public IntFloatMap . Entry next ( ) { } public boolean hasNext ( ) { } public Iterator < IntFloatMap . Entry > iterator ( ) { } } public static class Values extends IntFloatMap . MapIterator < Object > { public Values ( IntFloatMap map ) { } public boolean hasNext ( ) { } public float next ( ) { } public FloatArray toArray ( ) { } } public static class Keys extends IntFloatMap . MapIterator { public Keys ( IntFloatMap map ) { } public boolean hasNext ( ) { } public int next ( ) { } public IntArray toArray ( ) { } } }<BUG2FIX>nextIndex = currentIndex ;
public class GetAliasesRequestBuilder extends BaseAliasesRequestBuilder < GetAliasesResponse , GetAliasesRequestBuilder > { public GetAliasesRequestBuilder ( IndicesAdminClient client , String ... aliases ) { } @ Override protected void doExecute ( ActionListener < GetAliasesResponse > listener ) { <START_BUG> ( ( IndicesAdminClient ) ( client ) ) . getAliases ( request , listener ) ; <END_BUG> } }<BUG2FIX>client . getAliases ( request , listener ) ;
public class SharedLibraryLoader { public static boolean isWindows = System . getProperty ( "os.name" ) . contains ( "Windows" ) ; public static boolean isLinux = System . getProperty ( "os.name" ) . contains ( "Linux" ) ; public static boolean isMac = System . getProperty ( "os.name" ) . contains ( "Mac" ) ; public static boolean isIos = false ; public static boolean isAndroid = false ; public static boolean isARM = System . getProperty ( "os.arch" ) . startsWith ( "arm" ) ; public static boolean is64Bit = System . getProperty ( "os.arch" ) . equals ( "amd64" ) ; public static String abi = ( ( System . getProperty ( "sun.arch.abi" ) ) != null ) ? System . getProperty ( "sun.arch.abi" ) : "" ; private static final HashSet < String > loadedLibraries = new HashSet ( ) ; private String nativesJar ; public SharedLibraryLoader ( ) { } public SharedLibraryLoader ( String nativesJar ) { } public String crc ( InputStream input ) { } public String mapLibraryName ( String libraryName ) { } public synchronized void load ( String libraryName ) { } private InputStream readFile ( String path ) { } public File extractFile ( String sourcePath , String dirName ) throws IOException { } private File getExtractedFile ( String dirName , String fileName ) { } private boolean canWrite ( File file ) { <START_BUG> if ( ( file . canWrite ( ) ) && ( file . canExecute ( ) ) ) <END_BUG> return true ; File parent = file . getParentFile ( ) ; parent . mkdirs ( ) ; if ( ! ( parent . isDirectory ( ) ) ) return false ; try { new FileOutputStream ( file ) . close ( ) ; file . delete ( ) ; return true ; } catch ( Throwable ex ) { return false ; } } private File extractFile ( String sourcePath , String sourceCrc , File extractedFile ) throws IOException { } private void loadFile ( String sourcePath ) { } private Throwable loadFile ( String sourcePath , String sourceCrc , File extractedFile ) { } }<BUG2FIX>if ( file . canWrite ( ) )
public class RenderedCommentFragment extends DialogFragment implements LoaderCallbacks < CharSequence > { private static final String ARG_TEXT = "text" ; private static final String ARG_REPO = "repo" ; private ProgressBar progress ; private TextView bodyText ; @ Inject private HttpImageGetter imageGetter ; @ Override public void onViewCreated ( View view , Bundle savedInstanceState ) { } public void setText ( final String raw , final IRepositoryIdProvider repo ) { } private void showLoading ( final boolean loading ) { } @ Override public View onCreateView ( LayoutInflater inflater , ViewGroup container , Bundle savedInstanceState ) { } @ Override public Loader < CharSequence > onCreateLoader ( int loader , Bundle args ) { final CharSequence raw = args . getCharSequence ( RenderedCommentFragment . ARG_TEXT ) ; final IRepositoryIdProvider repo = ( ( IRepositoryIdProvider ) ( args . getSerializable ( RenderedCommentFragment . ARG_REPO ) ) ) ; <START_BUG> return new com . github . mobile . ui . MarkdownLoader ( getActivity ( ) , repo , raw . toString ( ) , imageGetter ) ; <END_BUG> } @ Override public void onLoadFinished ( Loader < CharSequence > loader , CharSequence rendered ) { } @ Override public void onLoaderReset ( Loader < CharSequence > loader ) { } }<BUG2FIX>return new com . github . mobile . ui . MarkdownLoader ( getActivity ( ) , repo , raw . toString ( ) , imageGetter , true ) ;
@ Override public Number getTermAsNumber ( ) { } @ Override public int count ( ) { } @ Override public int getCount ( ) { } @ Override public double min ( ) { } @ Override public double getMin ( ) { } @ Override public double max ( ) { } @ Override public double getMax ( ) { } @ Override public double total ( ) { } @ Override public double getTotal ( ) { } @ Override public double mean ( ) { } @ Override public double getMean ( ) { } @ Override public int compareTo ( Entry o ) { } } private String name ; int requiredSize ; long missing ; Collection < InternalTermsStatsDoubleFacet . DoubleEntry > entries = ImmutableList . of ( ) ; ComparatorType comparatorType ; public InternalTermsStatsDoubleFacet ( String name , ComparatorType comparatorType , int requiredSize , Collection < InternalTermsStatsDoubleFacet . DoubleEntry > entries , long missing ) { } @ Override public String name ( ) { } @ Override public String getName ( ) { } @ Override public String type ( ) { } @ Override public String getType ( ) { } @ Override public List < InternalTermsStatsDoubleFacet . DoubleEntry > entries ( ) { } List < InternalTermsStatsDoubleFacet . DoubleEntry > mutableList ( ) { } @ Override public List < InternalTermsStatsDoubleFacet . DoubleEntry > getEntries ( ) { } @ SuppressWarnings ( { "unchecked" } ) @ Override public Iterator < Entry > iterator ( ) { } @ Override public long missingCount ( ) { } @ Override public long getMissingCount ( ) { } private static ThreadLocal < ThreadLocals . CleanableValue < ExtTDoubleObjectHashMap < InternalTermsStatsDoubleFacet . DoubleEntry > > > aggregateCache = new ThreadLocal < ThreadLocals . CleanableValue < ExtTDoubleObjectHashMap < InternalTermsStatsDoubleFacet . DoubleEntry > > > ( ) { @ Override protected ThreadLocals . CleanableValue < ExtTDoubleObjectHashMap < DoubleEntry > > initialValue ( ) { } } ; @ Override public Facet reduce ( String name , List < Facet > facets ) { if ( ( facets . size ( ) ) == 1 ) { if ( ( requiredSize ) == 0 ) { InternalTermsStatsDoubleFacet tsFacet = ( ( InternalTermsStatsDoubleFacet ) ( facets . get ( 0 ) ) ) ; if ( ! ( tsFacet . entries . isEmpty ( ) ) ) { List < InternalTermsStatsDoubleFacet . DoubleEntry > entries = tsFacet . mutableList ( ) ; Collections . sort ( entries , comparatorType . comparator ( ) ) ; } } return facets . get ( 0 ) ; } int missing = 0 ; ExtTDoubleObjectHashMap < InternalTermsStatsDoubleFacet . DoubleEntry > map = aggregateCache . get ( ) . get ( ) ; map . clear ( ) ; for ( Facet facet : facets ) { InternalTermsStatsDoubleFacet tsFacet = ( ( InternalTermsStatsDoubleFacet ) ( facet ) ) ; missing += tsFacet . missing ; for ( Entry entry : tsFacet ) { InternalTermsStatsDoubleFacet . DoubleEntry doubleEntry = ( ( InternalTermsStatsDoubleFacet . DoubleEntry ) ( entry ) ) ; InternalTermsStatsDoubleFacet . DoubleEntry current = map . get ( doubleEntry . term ) ; if ( current != null ) { current . count += doubleEntry . count ; current . total += doubleEntry . total ; if ( ( ( doubleEntry . min ) < ( current . min ) ) || ( Double . isNaN ( current . min ) ) ) { current . min = doubleEntry . min ; } if ( ( ( doubleEntry . max ) > ( current . max ) ) || ( Double . isNaN ( current . max ) ) ) { current . max = doubleEntry . max ; } } else { map . put ( doubleEntry . term , doubleEntry ) ; } } } if ( ( requiredSize ) == 0 ) { InternalTermsStatsDoubleFacet . DoubleEntry [ ] entries1 = map . values ( new InternalTermsStatsDoubleFacet . DoubleEntry [ map . size ( ) ] ) ; Arrays . sort ( entries1 , comparatorType . comparator ( ) ) ; return new InternalTermsStatsDoubleFacet ( name , comparatorType , requiredSize , Arrays . asList ( entries1 ) , missing ) ; } else { Object [ ] values = map . internalValues ( ) ; Arrays . sort ( values , ( ( Comparator ) ( comparatorType . comparator ( ) ) ) ) ; <START_BUG> List < InternalTermsStatsDoubleFacet . DoubleEntry > ordered = new ArrayList < InternalTermsStatsDoubleFacet . DoubleEntry > ( ) ; <END_BUG> for ( int i = 0 ; i < ( requiredSize ) ; i ++ ) { InternalTermsStatsDoubleFacet . DoubleEntry value = ( ( InternalTermsStatsDoubleFacet . DoubleEntry ) ( values [ i ] ) ) ; if ( value == null ) { break ; } ordered . add ( value ) ; } return new InternalTermsStatsDoubleFacet ( name , comparatorType , requiredSize , ordered , missing ) ; } } static final class Fields { static final XContentBuilderString _TYPE = new XContentBuilderString ( "_type" ) ; static final XContentBuilderString MISSING = new XContentBuilderString ( "missing" ) ; static final XContentBuilderString TERMS = new XContentBuilderString ( "terms" ) ; static final XContentBuilderString TERM = new XContentBuilderString ( "term" ) ; static final XContentBuilderString COUNT = new XContentBuilderString ( "count" ) ; static final XContentBuilderString MIN = new XContentBuilderString ( "min" ) ; static final XContentBuilderString MAX = new XContentBuilderString ( "max" ) ; static final XContentBuilderString TOTAL = new XContentBuilderString ( "total" ) ; static final XContentBuilderString MEAN = new XContentBuilderString ( "mean" ) ; } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } public static InternalTermsStatsDoubleFacet readTermsStatsFacet ( StreamInput in ) throws IOException { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } }<BUG2FIX>List < InternalTermsStatsDoubleFacet . DoubleEntry > ordered = new ArrayList < InternalTermsStatsDoubleFacet . DoubleEntry > ( map . size ( ) ) ;
public class RestIndicesStatusAction extends BaseRestHandler { private final SettingsFilter settingsFilter ; @ Inject public RestIndicesStatusAction ( Settings settings , Client client , RestController controller , SettingsFilter settingsFilter ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { IndicesStatusRequest indicesStatusRequest = new IndicesStatusRequest ( splitIndices ( request . param ( "index" ) ) ) ; indicesStatusRequest . listenerThreaded ( false ) ; if ( request . hasParam ( "ignore_indices" ) ) { indicesStatusRequest . ignoreIndices ( IgnoreIndices . fromString ( request . param ( "ignore_indices" ) ) ) ; } indicesStatusRequest . recovery ( request . paramAsBoolean ( "recovery" , indicesStatusRequest . recovery ( ) ) ) ; indicesStatusRequest . snapshot ( request . paramAsBoolean ( "snapshot" , indicesStatusRequest . snapshot ( ) ) ) ; BroadcastOperationThreading operationThreading = BroadcastOperationThreading . fromString ( request . param ( "operation_threading" ) , SINGLE_THREAD ) ; if ( operationThreading == ( BroadcastOperationThreading . NO_THREADS ) ) { operationThreading = BroadcastOperationThreading . SINGLE_THREAD ; } indicesStatusRequest . operationThreading ( operationThreading ) ; client . admin ( ) . indices ( ) . status ( indicesStatusRequest , new org . elasticsearch . action . ActionListener < IndicesStatusResponse > ( ) { @ Override public void onResponse ( IndicesStatusResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( "ok" , true ) ; buildBroadcastShardsHeader ( builder , response ) ; response . toXContent ( builder , request , settingsFilter ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class TransportMultiSearchAction extends TransportAction < MultiSearchRequest , MultiSearchResponse > { private final ClusterService clusterService ; private final TransportSearchAction searchAction ; @ Inject public TransportMultiSearchAction ( Settings settings , ThreadPool threadPool , TransportService transportService , ClusterService clusterService , TransportSearchAction searchAction ) { } @ Override protected void doExecute ( final MultiSearchRequest request , final ActionListener < MultiSearchResponse > listener ) { } class TransportHandler extends BaseTransportRequestHandler < MultiSearchRequest > { @ Override public MultiSearchRequest newInstance ( ) { } @ Override public void messageReceived ( final MultiSearchRequest request , final TransportChannel channel ) throws Exception { request . listenerThreaded ( false ) ; execute ( request , new ActionListener < MultiSearchResponse > ( ) { @ Override public void onResponse ( MultiSearchResponse response ) { try { channel . sendResponse ( response ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( e ) ; } catch ( Exception e1 ) { logger . warn ( ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>error<seq2seq4repair_space>response<seq2seq4repair_space>for<seq2seq4repair_space>action<seq2seq4repair_space>[msearch]<seq2seq4repair_space>and<seq2seq4repair_space>request<seq2seq4repair_space>[" + request ) + "]" ) , e1 ) ; } } } ) ; } @ Override public String executor ( ) { } } }<BUG2FIX>} catch ( Throwable e ) {
public class GdxSetup { public static boolean isSdkLocationValid ( String sdkLocation ) { } public void build ( String outputDir , String appName , String packageName , String mainClass , String sdkLocation ) { Project project = new Project ( ) ; String packageDir = packageName . replace ( '.' , '/' ) ; String sdkPath = sdkLocation . replace ( '\\' , '/' ) ; <START_BUG> if ( GdxSetup . isSdkLocationValid ( sdkLocation ) ) { <END_BUG> System . out . println ( ( ( "Android<seq2seq4repair_space>SDK<seq2seq4repair_space>location<seq2seq4repair_space>'" + sdkLocation ) + "'<seq2seq4repair_space>doesn't<seq2seq4repair_space>contain<seq2seq4repair_space>an<seq2seq4repair_space>SDK" ) ) ; } project . files . add ( new ProjectFile ( "gitignore" , ".gitignore" , false ) ) ; project . files . add ( new ProjectFile ( "build.gradle" , true ) ) ; project . files . add ( new ProjectFile ( "settings.gradle" ) ) ; project . files . add ( new ProjectFile ( "gradlew" , false ) ) ; project . files . add ( new ProjectFile ( "gradlew.bat" , false ) ) ; project . files . add ( new ProjectFile ( "gradle/wrapper/gradle-wrapper.jar" , false ) ) ; project . files . add ( new ProjectFile ( "gradle/wrapper/gradle-wrapper.properties" , false ) ) ; project . files . add ( new ProjectFile ( "local.properties" , true ) ) ; project . files . add ( new ProjectFile ( "core/build.gradle" ) ) ; project . files . add ( new ProjectFile ( "core/src/MainClass" , ( ( ( ( "core/src/" + packageDir ) + "/" ) + mainClass ) + ".java" ) , true ) ) ; project . files . add ( new ProjectFile ( "core/CoreGdxDefinition" , ( ( ( ( "core/src/" + packageDir ) + "/" ) + mainClass ) + ".gwt.xml" ) , true ) ) ; project . files . add ( new ProjectFile ( "desktop/build.gradle" ) ) ; project . files . add ( new ProjectFile ( "desktop/src/DesktopLauncher" , ( ( "desktop/src/" + packageDir ) + "/desktop/DesktopLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "android/assets/badlogic.jpg" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/values/strings.xml" ) ) ; project . files . add ( new ProjectFile ( "android/res/values/styles.xml" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-hdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-mdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-xhdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-xxhdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/src/AndroidLauncher" , ( ( "android/src/" + packageDir ) + "/android/AndroidLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "android/AndroidManifest.xml" ) ) ; project . files . add ( new ProjectFile ( "android/build.gradle" , true ) ) ; project . files . add ( new ProjectFile ( "android/ic_launcher-web.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/proguard-project.txt" , false ) ) ; project . files . add ( new ProjectFile ( "android/project.properties" , false ) ) ; project . files . add ( new ProjectFile ( "gwt/build.gradle" ) ) ; project . files . add ( new ProjectFile ( "gwt/src/GwtLauncher" , ( ( "gwt/src/" + packageDir ) + "/client/GwtLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "gwt/GdxDefinition" , ( ( "gwt/src/" + packageDir ) + "/GdxDefinition.gwt.xml" ) , true ) ) ; project . files . add ( new ProjectFile ( "gwt/GdxDefinitionSuperdev" , ( ( "gwt/src/" + packageDir ) + "/GdxDefinitionSuperdev.gwt.xml" ) , true ) ) ; project . files . add ( new ProjectFile ( "gwt/war/index" , "gwt/webapp/index.html" , true ) ) ; project . files . add ( new ProjectFile ( "gwt/war/soundmanager2-jsmin.js" , "gwt/webapp/soundmanager2-jsmin.js" , false ) ) ; project . files . add ( new ProjectFile ( "gwt/war/soundmanager2-setup.js" , "gwt/webapp/soundmanager2-setup.js" , false ) ) ; project . files . add ( new ProjectFile ( "gwt/war/WEB-INF/web.xml" , "gwt/webapp/WEB-INF/web.xml" , true ) ) ; project . files . add ( new ProjectFile ( "ios/src/IOSLauncher" , ( ( "ios/src/" + packageDir ) + "/IOSLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "ios/build.gradle" , true ) ) ; project . files . add ( new ProjectFile ( "ios/Info.plist.xml" , false ) ) ; project . files . add ( new ProjectFile ( "ios/robovm.properties" ) ) ; project . files . add ( new ProjectFile ( "ios/robovm.xml" , false ) ) ; Map < String , String > values = new HashMap < String , String > ( ) ; values . put ( "%APP_NAME%" , appName ) ; values . put ( "%PACKAGE%" , packageName ) ; values . put ( "%MAIN_CLASS%" , mainClass ) ; values . put ( "%ANDROID_SDK%" , sdkPath ) ; copyAndReplace ( outputDir , project , values ) ; new File ( outputDir , "gradlew" ) . setExecutable ( true ) ; } private void copyAndReplace ( String outputDir , Project project , Map < String , String > values ) { } private byte [ ] readResource ( String resource ) { } private String readResourceAsString ( String resource ) { } private void writeFile ( File outFile , byte [ ] bytes ) { } private void writeFile ( File outFile , String text ) { } private void copyFile ( ProjectFile file , File out , Map < String , String > values ) { } private String replace ( String txt , Map < String , String > values ) { } private static void printHelp ( ) { } private static Map < String , String > parseArgs ( String [ ] args ) { } public static void main ( String [ ] args ) { } }<BUG2FIX>if ( ! ( GdxSetup . isSdkLocationValid ( sdkLocation ) ) ) {
public class SoftBodyTest extends BaseBulletTest { btSoftBodyWorldInfo worldInfo ; btSoftBody softBody ; Texture texture ; Mesh mesh ; Model model ; ModelInstance instance ; Matrix4 tmpM = new Matrix4 ( ) ; @ Override public BulletWorld createWorld ( ) { } @ Override public void create ( ) { } @ Override public void dispose ( ) { } @ Override protected void renderWorld ( ) { softBody . getVertices ( mesh . getVerticesBuffer ( ) , softBody . getNodeCount ( ) , mesh . getVertexSize ( ) , 0 ) ; softBody . getWorldTransform ( instance . transform ) ; modelBatch . begin ( camera ) ; world . render ( modelBatch , lights ) ; <START_BUG> modelBatch . render ( lights , instance ) ; <END_BUG> modelBatch . end ( ) ; } @ Override public boolean tap ( float x , float y , int count , int button ) { } }<BUG2FIX>modelBatch . render ( instance , lights ) ;
public class IssueDashboardActivity extends RoboFragmentActivity { @ InjectView ( id . tpi_header ) private TitlePageIndicator indicator ; @ InjectView ( id . vp_pages ) private ViewPager pager ; @ Override protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; setContentView ( issue_dashboard ) ; <START_BUG> setTitle ( getString ( dashboard_issues_title ) ) ; <END_BUG> pager . setAdapter ( new IssueDashboardPagerAdapter ( getApplicationContext ( ) , getSupportFragmentManager ( ) ) ) ; indicator . setViewPager ( pager ) ; } }<BUG2FIX>setTitle ( dashboard_issues_title ) ;
public AllFieldMapper . Builder enabled ( boolean enabled ) { } @ Override public AllFieldMapper build ( BuilderContext context ) { } } public static class TypeParser implements Mapper . TypeParser { @ Override public Mapper . Builder parse ( String name , Map < String , Object > node , ParserContext parserContext ) throws MapperParsingException { } } private boolean enabled ; private volatile boolean autoBoost ; public AllFieldMapper ( ) { } protected AllFieldMapper ( String name , FieldType fieldType , NamedAnalyzer indexAnalyzer , NamedAnalyzer searchAnalyzer , boolean enabled , boolean autoBoost , PostingsFormatProvider postingsProvider , DocValuesFormatProvider docValuesProvider , SimilarityProvider similarity , @ Nullable Settings fieldDataSettings , Settings indexSettings ) { } public boolean enabled ( ) { } @ Override public FieldType defaultFieldType ( ) { } @ Override public FieldDataType defaultFieldDataType ( ) { } @ Override public Query queryStringTermQuery ( Term term ) { } @ Override public Query termQuery ( Object value , QueryParseContext context ) { } @ Override public void preParse ( ParseContext context ) throws IOException { } @ Override public void postParse ( ParseContext context ) throws IOException { } @ Override public void parse ( ParseContext context ) throws IOException { } @ Override public void validate ( ParseContext context ) throws MapperParsingException { } @ Override public boolean includeInObject ( ) { } @ Override protected void parseCreateField ( ParseContext context , List < Field > fields ) throws IOException { } private Analyzer findAnalyzer ( ParseContext context ) { } @ Override public Void value ( Object value ) { } @ Override public Object valueForSearch ( Object value ) { } @ Override protected String contentType ( ) { } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } private void innerToXContent ( XContentBuilder builder , boolean includeDefaults ) throws IOException { if ( includeDefaults || ( ( enabled ) != ( AllFieldMapper . Defaults . ENABLED ) ) ) { builder . field ( "enabled" , enabled ) ; } if ( includeDefaults || ( ( autoBoost ) != false ) ) { builder . field ( "auto_boost" , autoBoost ) ; } if ( includeDefaults || ( ( fieldType . stored ( ) ) != ( AllFieldMapper . Defaults . FIELD_TYPE . stored ( ) ) ) ) { builder . field ( "store" , fieldType . stored ( ) ) ; } if ( includeDefaults || ( ( fieldType . storeTermVectors ( ) ) != ( AllFieldMapper . Defaults . FIELD_TYPE . storeTermVectors ( ) ) ) ) { builder . field ( "store_term_vectors" , fieldType . storeTermVectors ( ) ) ; } if ( includeDefaults || ( ( fieldType . storeTermVectorOffsets ( ) ) != ( AllFieldMapper . Defaults . FIELD_TYPE . storeTermVectorOffsets ( ) ) ) ) { builder . field ( "store_term_vector_offsets" , fieldType . storeTermVectorOffsets ( ) ) ; } if ( includeDefaults || ( ( fieldType . storeTermVectorPositions ( ) ) != ( AllFieldMapper . Defaults . FIELD_TYPE . storeTermVectorPositions ( ) ) ) ) { builder . field ( "store_term_vector_positions" , fieldType . storeTermVectorPositions ( ) ) ; } if ( includeDefaults || ( ( fieldType . storeTermVectorPayloads ( ) ) != ( AllFieldMapper . Defaults . FIELD_TYPE . storeTermVectorPayloads ( ) ) ) ) { builder . field ( "store_term_vector_payloads" , fieldType . storeTermVectorPayloads ( ) ) ; } if ( includeDefaults || ( ( fieldType . omitNorms ( ) ) != ( AllFieldMapper . Defaults . FIELD_TYPE . omitNorms ( ) ) ) ) { builder . field ( "omit_norms" , fieldType . omitNorms ( ) ) ; } if ( ( ( indexAnalyzer ) == null ) && ( ( searchAnalyzer ) == null ) ) { if ( includeDefaults ) { builder . field ( "analyzer" , "default" ) ; } } else if ( ( indexAnalyzer ) == null ) { if ( includeDefaults || ( ! ( searchAnalyzer . name ( ) . startsWith ( "_" ) ) ) ) { builder . field ( "search_analyzer" , searchAnalyzer . name ( ) ) ; } } else if ( ( searchAnalyzer ) == null ) { if ( includeDefaults || ( ! ( indexAnalyzer . name ( ) . startsWith ( "_" ) ) ) ) { builder . field ( "index_analyzer" , indexAnalyzer . name ( ) ) ; } } else if ( indexAnalyzer . name ( ) . equals ( searchAnalyzer . name ( ) ) ) { if ( includeDefaults || ( ! ( indexAnalyzer . name ( ) . startsWith ( "_" ) ) ) ) { builder . field ( "analyzer" , indexAnalyzer . name ( ) ) ; } } else { if ( includeDefaults || ( ! ( indexAnalyzer . name ( ) . startsWith ( "_" ) ) ) ) { builder . field ( "index_analyzer" , indexAnalyzer . name ( ) ) ; } if ( includeDefaults || ( ! ( searchAnalyzer . name ( ) . startsWith ( "_" ) ) ) ) { builder . field ( "search_analyzer" , searchAnalyzer . name ( ) ) ; } } if ( ( similarity ( ) ) != null ) { builder . field ( "similarity" , similarity ( ) . name ( ) ) ; } else if ( includeDefaults ) { <START_BUG> builder . field ( "similariry" , DEFAULT_SIMILARITY ) ; <END_BUG> } if ( ( customFieldDataSettings ) != null ) { builder . field ( "fielddata" , ( ( Map ) ( customFieldDataSettings . getAsMap ( ) ) ) ) ; } else if ( includeDefaults ) { builder . field ( "fielddata" , ( ( Map ) ( fieldDataType . getSettings ( ) . getAsMap ( ) ) ) ) ; } } @ Override public void merge ( Mapper mergeWith , MergeContext mergeContext ) throws MergeMappingException { } @ Override public boolean hasDocValues ( ) { } }<BUG2FIX>builder . field ( "similarity" , DEFAULT_SIMILARITY ) ;
public final class SpriteBatch { private static final int MAX_VERTICES = 6 * 5000 ; private final Mesh mesh ; private final Graphics graphics ; private final Matrix transform = new Matrix ( ) ; private final Matrix viewMatrix = new Matrix ( ) ; private final float [ ] vertices = new float [ ( SpriteBatch . MAX_VERTICES ) * ( ( 2 + 4 ) + 2 ) ] ; private Texture lastTexture = null ; private int idx = 0 ; private boolean drawing = false ; private float invTexWidth = 0 ; private float invTexHeight = 0 ; private boolean useTextBlend = false ; private ShaderProgram shader ; public int renderCalls = 0 ; public SpriteBatch ( Graphics graphics ) { } private void createShader ( ) { String vertexShader = "attribute<seq2seq4repair_space>vec4<seq2seq4repair_space>a_position;<seq2seq4repair_space>\n" + ( ( ( ( ( ( ( ( ( ( ( "attribute<seq2seq4repair_space>vec4<seq2seq4repair_space>a_color;<seq2seq4repair_space>\n" + "attribute<seq2seq4repair_space>vec2<seq2seq4repair_space>a_texCoords;<seq2seq4repair_space>\n" ) + "uniform<seq2seq4repair_space>mat4<seq2seq4repair_space>u_projectionViewMatrix;<seq2seq4repair_space>\n" ) + "varying<seq2seq4repair_space>vec4<seq2seq4repair_space>v_color;<seq2seq4repair_space>\n" ) + "varying<seq2seq4repair_space>vec2<seq2seq4repair_space>v_texCoords;<seq2seq4repair_space>\n" ) + "<seq2seq4repair_space>\n" ) + "void<seq2seq4repair_space>main()<seq2seq4repair_space>\n" ) + "{<seq2seq4repair_space>\n" ) + "<seq2seq4repair_space>v_color<seq2seq4repair_space>=<seq2seq4repair_space>a_color;<seq2seq4repair_space>\n" ) + "<seq2seq4repair_space>v_texCoords<seq2seq4repair_space>=<seq2seq4repair_space>a_texCoords;<seq2seq4repair_space>\n" ) + "<seq2seq4repair_space>gl_Position<seq2seq4repair_space>=<seq2seq4repair_space>u_projectionViewMatrix<seq2seq4repair_space>*<seq2seq4repair_space>a_position;<seq2seq4repair_space>\n" ) + "}<seq2seq4repair_space>\n" ) ; String fragmentShader = "precision<seq2seq4repair_space>mediump<seq2seq4repair_space>float;\n" + ( ( ( ( ( ( "varying<seq2seq4repair_space>vec4<seq2seq4repair_space>v_color;\n" + "varying<seq2seq4repair_space>vec2<seq2seq4repair_space>v_texCoords;\n" ) + "uniform<seq2seq4repair_space>sampler2D<seq2seq4repair_space>u_texture;\n" ) + "void<seq2seq4repair_space>main()<seq2seq4repair_space>\n" ) + "{<seq2seq4repair_space>\n" ) + "<seq2seq4repair_space>gl_FragColor<seq2seq4repair_space>=<seq2seq4repair_space>v_color<seq2seq4repair_space>*<seq2seq4repair_space>texture2D(u_texture,<seq2seq4repair_space>v_texCoords);\n" ) + "}" ) ; <START_BUG> shader = new ShaderProgram ( graphics . getGL20 ( ) , vertexShader , fragmentShader ) ; <END_BUG> if ( ( shader . isCompiled ( ) ) == false ) throw new IllegalArgumentException ( ( "couldn't<seq2seq4repair_space>compile<seq2seq4repair_space>shader:<seq2seq4repair_space>" + ( shader . getLog ( ) ) ) ) ; } public void begin ( ) { } public void begin ( Matrix transform ) { } public void end ( ) { } public void draw ( Texture texture , int x , int y , int width , int height , int srcX , int srcY , int srcWidth , int srcHeight , Color tint ) { } public void draw ( Texture texture , int x , int y , int srcX , int srcY , int srcWidth , int srcHeight , Color tint ) { } public void draw ( Texture texture , int [ ] xy , int srcX , int srcY , int srcWidth , int srcHeight , Color tint ) { } private void renderMesh ( ) { } public void drawText ( Font font , String text , int x , int y , Color tint ) { } }<BUG2FIX>shader = new ShaderProgram ( graphics . getGL20 ( ) , vertexShader , fragmentShader , true ) ;
public class TieredMergePolicyProvider extends AbstractIndexShardComponent implements MergePolicyProvider < TieredMergePolicy > { private final IndexSettingsService indexSettingsService ; private final Set < TieredMergePolicyProvider . CustomTieredMergePolicyProvider > policies = new CopyOnWriteArraySet < TieredMergePolicyProvider . CustomTieredMergePolicyProvider > ( ) ; private volatile boolean compoundFormat ; private volatile double expungeDeletesPctAllowed ; private volatile ByteSizeValue floorSegment ; private volatile int maxMergeAtOnce ; private volatile int maxMergeAtOnceExplicit ; private volatile ByteSizeValue maxMergedSegment ; private volatile double segmentsPerTier ; private boolean asyncMerge ; private final TieredMergePolicyProvider . ApplySettings applySettings = new TieredMergePolicyProvider . ApplySettings ( ) ; @ Inject public TieredMergePolicyProvider ( Store store , IndexSettingsService indexSettingsService ) { } @ Override public TieredMergePolicy newMergePolicy ( ) { } @ Override public void close ( boolean delete ) throws ElasticSearchException { } class ApplySettings implements IndexSettingsService . Listener { @ Override public void onRefreshSettings ( Settings settings ) { double expungeDeletesPctAllowed = settings . getAsDouble ( "index.merge.policy.expunge_deletes_allowed" , TieredMergePolicyProvider . this . expungeDeletesPctAllowed ) ; if ( expungeDeletesPctAllowed != ( TieredMergePolicyProvider . this . expungeDeletesPctAllowed ) ) { logger . info ( "updating<seq2seq4repair_space>[expunge_deletes_allowed]<seq2seq4repair_space>from<seq2seq4repair_space>[{}]<seq2seq4repair_space>to<seq2seq4repair_space>[{}]" , TieredMergePolicyProvider . this . expungeDeletesPctAllowed , expungeDeletesPctAllowed ) ; TieredMergePolicyProvider . this . expungeDeletesPctAllowed = expungeDeletesPctAllowed ; for ( TieredMergePolicyProvider . CustomTieredMergePolicyProvider policy : policies ) { policy . setExpungeDeletesPctAllowed ( expungeDeletesPctAllowed ) ; } } ByteSizeValue floorSegment = settings . getAsBytesSize ( "index.merge.policy.floor_segment" , TieredMergePolicyProvider . this . floorSegment ) ; if ( ! ( floorSegment . equals ( TieredMergePolicyProvider . this . floorSegment ) ) ) { logger . info ( "updating<seq2seq4repair_space>[floor_segment]<seq2seq4repair_space>from<seq2seq4repair_space>[{}]<seq2seq4repair_space>to<seq2seq4repair_space>[{}]" , TieredMergePolicyProvider . this . floorSegment , floorSegment ) ; TieredMergePolicyProvider . this . floorSegment = floorSegment ; for ( TieredMergePolicyProvider . CustomTieredMergePolicyProvider policy : policies ) { policy . setFloorSegmentMB ( floorSegment . mbFrac ( ) ) ; } } int maxMergeAtOnce = settings . getAsInt ( "index.merge.policy.max_merge_at_once" , TieredMergePolicyProvider . this . maxMergeAtOnce ) ; if ( maxMergeAtOnce != ( TieredMergePolicyProvider . this . maxMergeAtOnce ) ) { logger . info ( "updating<seq2seq4repair_space>[max_merge_at_once]<seq2seq4repair_space>from<seq2seq4repair_space>[{}]<seq2seq4repair_space>to<seq2seq4repair_space>[{}]" , TieredMergePolicyProvider . this . maxMergeAtOnce , maxMergeAtOnce ) ; TieredMergePolicyProvider . this . maxMergeAtOnce = maxMergeAtOnce ; for ( TieredMergePolicyProvider . CustomTieredMergePolicyProvider policy : policies ) { policy . setMaxMergeAtOnce ( maxMergeAtOnce ) ; } } int maxMergeAtOnceExplicit = settings . getAsInt ( "index.merge.policy.max_merge_at_once_explicit" , TieredMergePolicyProvider . this . maxMergeAtOnceExplicit ) ; <START_BUG> if ( maxMergeAtOnce != ( TieredMergePolicyProvider . this . maxMergeAtOnceExplicit ) ) { <END_BUG> logger . info ( "updating<seq2seq4repair_space>[max_merge_at_once_explicit]<seq2seq4repair_space>from<seq2seq4repair_space>[{}]<seq2seq4repair_space>to<seq2seq4repair_space>[{}]" , TieredMergePolicyProvider . this . maxMergeAtOnceExplicit , maxMergeAtOnceExplicit ) ; TieredMergePolicyProvider . this . maxMergeAtOnceExplicit = maxMergeAtOnceExplicit ; for ( TieredMergePolicyProvider . CustomTieredMergePolicyProvider policy : policies ) { policy . setMaxMergeAtOnceExplicit ( maxMergeAtOnceExplicit ) ; } } ByteSizeValue maxMergedSegment = settings . getAsBytesSize ( "index.merge.policy.max_merged_segment" , TieredMergePolicyProvider . this . maxMergedSegment ) ; if ( ! ( maxMergedSegment . equals ( TieredMergePolicyProvider . this . maxMergedSegment ) ) ) { logger . info ( "updating<seq2seq4repair_space>[max_merged_segment]<seq2seq4repair_space>from<seq2seq4repair_space>[{}]<seq2seq4repair_space>to<seq2seq4repair_space>[{}]" , TieredMergePolicyProvider . this . maxMergedSegment , maxMergedSegment ) ; TieredMergePolicyProvider . this . maxMergedSegment = maxMergedSegment ; for ( TieredMergePolicyProvider . CustomTieredMergePolicyProvider policy : policies ) { policy . setFloorSegmentMB ( maxMergedSegment . mbFrac ( ) ) ; } } double segmentsPerTier = settings . getAsDouble ( "index.merge.policy.segments_per_tier" , TieredMergePolicyProvider . this . segmentsPerTier ) ; if ( segmentsPerTier != ( TieredMergePolicyProvider . this . segmentsPerTier ) ) { logger . info ( "updating<seq2seq4repair_space>[segments_per_tier]<seq2seq4repair_space>from<seq2seq4repair_space>[{}]<seq2seq4repair_space>to<seq2seq4repair_space>[{}]" , TieredMergePolicyProvider . this . segmentsPerTier , segmentsPerTier ) ; TieredMergePolicyProvider . this . segmentsPerTier = segmentsPerTier ; for ( TieredMergePolicyProvider . CustomTieredMergePolicyProvider policy : policies ) { policy . setSegmentsPerTier ( segmentsPerTier ) ; } } boolean compoundFormat = settings . getAsBoolean ( "index.compound_format" , TieredMergePolicyProvider . this . compoundFormat ) ; if ( compoundFormat != ( TieredMergePolicyProvider . this . compoundFormat ) ) { logger . info ( "updating<seq2seq4repair_space>index.compound_format<seq2seq4repair_space>from<seq2seq4repair_space>[{}]<seq2seq4repair_space>to<seq2seq4repair_space>[{}]" , TieredMergePolicyProvider . this . compoundFormat , compoundFormat ) ; TieredMergePolicyProvider . this . compoundFormat = compoundFormat ; for ( TieredMergePolicyProvider . CustomTieredMergePolicyProvider policy : policies ) { policy . setUseCompoundFile ( compoundFormat ) ; } } } } public static class CustomTieredMergePolicyProvider extends TieredMergePolicy { private final TieredMergePolicyProvider provider ; public CustomTieredMergePolicyProvider ( TieredMergePolicyProvider provider ) { } @ Override public void close ( ) { } } public static class EnableMergeTieredMergePolicyProvider extends TieredMergePolicyProvider . CustomTieredMergePolicyProvider implements EnableMergePolicy { private final ThreadLocal < Boolean > enableMerge = new ThreadLocal < Boolean > ( ) { @ Override protected Boolean initialValue ( ) { } } ; public EnableMergeTieredMergePolicyProvider ( TieredMergePolicyProvider provider ) { } @ Override public void enableMerge ( ) { } @ Override public void disableMerge ( ) { } @ Override public boolean isMergeEnabled ( ) { } @ Override public void close ( ) { } @ Override public MergeSpecification findMerges ( SegmentInfos infos ) throws IOException { } @ Override public MergeSpecification findMergesToExpungeDeletes ( SegmentInfos segmentInfos ) throws IOException , CorruptIndexException { } @ Override public MergeSpecification findMergesForOptimize ( SegmentInfos infos , int maxNumSegments , Set < SegmentInfo > segmentsToOptimize ) throws IOException { } } }<BUG2FIX>if ( maxMergeAtOnceExplicit != ( TieredMergePolicyProvider . this . maxMergeAtOnceExplicit ) ) {
public class NewModelTest extends GdxTest { PerspectiveCamera cam ; ModelBatch modelBatch ; Model model ; ModelInstance instance ; ShapeRenderer shapeRenderer ; Light [ ] lights = new Light [ ] { new Light ( Color . WHITE , tmp . set ( ( - 10.0F ) , 10.0F , ( - 10.0F ) ) , 15.0F ) , new Light ( Color . BLUE , tmp . set ( 10.0F , 5.0F , 0.0F ) , 10.0F ) , new Light ( Color . GREEN , tmp . set ( 0.0F , 10.0F , 5.0F ) , 5.0F ) } ; float touchStartX = 0 ; float touchStartY = 0 ; @ Override public void create ( ) { JsonModelLoader loader = new JsonModelLoader ( ) ; <START_BUG> model = new Model ( loader . parseModel ( files . internal ( "data/g3d/cubes.g3dj" ) , null ) ) ; <END_BUG> instance = new ModelInstance ( model ) ; modelBatch = new ModelBatch ( ) ; TestShader . ignoreUnimplemented = true ; shapeRenderer = new ShapeRenderer ( ) ; cam = new PerspectiveCamera ( 67 , graphics . getWidth ( ) , graphics . getHeight ( ) ) ; cam . position . set ( 10.0F , 10.0F , 10.0F ) ; cam . direction . set ( ( - 1 ) , ( - 1 ) , ( - 1 ) ) ; cam . near = 0.1F ; cam . far = 300.0F ; input . setInputProcessor ( this ) ; } @ Override public void render ( ) { } @ Override public void dispose ( ) { } @ Override public boolean touchDown ( int x , int y , int pointer , int newParam ) { } @ Override public boolean touchDragged ( int x , int y , int pointer ) { } @ Override public boolean scrolled ( int amount ) { } @ Override public boolean needsGL20 ( ) { } }<BUG2FIX>model = new Model ( loader . parseModel ( files . internal ( "data/g3d/cubes.g3dj" ) ) ) ;
private byte id ; OpType ( byte id ) { } public byte id ( ) { } public static IndexRequest . OpType fromId ( byte id ) { } } private String type ; private String id ; @ Nullable private String routing ; @ Nullable private String parent ; @ Nullable private String timestamp ; private long ttl = - 1 ; private BytesReference source ; private boolean sourceUnsafe ; private IndexRequest . OpType opType = IndexRequest . OpType . INDEX ; private boolean refresh = false ; private long version = 0 ; private VersionType versionType = VersionType . INTERNAL ; private String percolate ; private XContentType contentType = Requests . INDEX_CONTENT_TYPE ; public IndexRequest ( ) { } public IndexRequest ( String index ) { } public IndexRequest ( String index , String type , String id ) { } @ Override public ActionRequestValidationException validate ( ) { } @ Override public void beforeLocalFork ( ) { } @ Override public IndexRequest index ( String index ) { } public IndexRequest contentType ( XContentType contentType ) { } @ Override public IndexRequest listenerThreaded ( boolean threadedListener ) { } @ Override public IndexRequest operationThreaded ( boolean threadedOperation ) { } public String type ( ) { } @ Required public IndexRequest type ( String type ) { } public String id ( ) { } public IndexRequest id ( String id ) { } public IndexRequest routing ( String routing ) { } public String routing ( ) { } public IndexRequest parent ( String parent ) { } public String parent ( ) { } public IndexRequest timestamp ( String timestamp ) { } public String timestamp ( ) { } public IndexRequest ttl ( Long ttl ) throws ElasticSearchGenerationException { } public long ttl ( ) { } public BytesReference source ( ) { } public BytesReference safeSource ( ) { } public Map < String , Object > sourceAsMap ( ) { } @ Required public IndexRequest source ( Map source ) throws ElasticSearchGenerationException { } @ Required public IndexRequest source ( Map source , XContentType contentType ) throws ElasticSearchGenerationException { } @ Required public IndexRequest source ( String source ) { } @ Required public IndexRequest source ( XContentBuilder sourceBuilder ) { } @ Required public IndexRequest source ( String field1 , Object value1 ) { } @ Required public IndexRequest source ( String field1 , Object value1 , String field2 , Object value2 ) { } @ Required public IndexRequest source ( String field1 , Object value1 , String field2 , Object value2 , String field3 , Object value3 ) { } @ Required public IndexRequest source ( String field1 , Object value1 , String field2 , Object value2 , String field3 , Object value3 , String field4 , Object value4 ) { } public IndexRequest source ( BytesReference source , boolean unsafe ) { } public IndexRequest source ( byte [ ] source ) { } @ Required public IndexRequest source ( byte [ ] source , int offset , int length ) { } @ Required public IndexRequest source ( byte [ ] source , int offset , int length , boolean unsafe ) { } public IndexRequest timeout ( TimeValue timeout ) { } public IndexRequest timeout ( String timeout ) { } public IndexRequest opType ( IndexRequest . OpType opType ) { } public IndexRequest opType ( String opType ) throws ElasticSearchIllegalArgumentException { } @ Override public IndexRequest replicationType ( ReplicationType replicationType ) { } @ Override public IndexRequest consistencyLevel ( WriteConsistencyLevel consistencyLevel ) { } public IndexRequest replicationType ( String replicationType ) { } public IndexRequest create ( boolean create ) { } public IndexRequest . OpType opType ( ) { } public IndexRequest refresh ( boolean refresh ) { } public boolean refresh ( ) { } public IndexRequest version ( long version ) { } public long version ( ) { } public IndexRequest versionType ( VersionType versionType ) { } public VersionType versionType ( ) { } public IndexRequest percolate ( String percolate ) { } public String percolate ( ) { } public void process ( MetaData metaData , String aliasOrIndex , @ Nullable MappingMetaData mappingMd , boolean allowIdGeneration ) throws ElasticSearchException { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { super . writeTo ( out ) ; out . writeUTF ( type ) ; if ( ( id ) == null ) { out . writeBoolean ( false ) ; } else { out . writeBoolean ( true ) ; out . writeUTF ( id ) ; } if ( ( routing ) == null ) { out . writeBoolean ( false ) ; } else { out . writeBoolean ( true ) ; out . writeUTF ( routing ) ; } if ( ( parent ) == null ) { out . writeBoolean ( false ) ; } else { out . writeBoolean ( true ) ; out . writeUTF ( parent ) ; } if ( ( timestamp ) == null ) { out . writeBoolean ( false ) ; } else { out . writeBoolean ( true ) ; out . writeUTF ( timestamp ) ; } out . writeLong ( ttl ) ; <START_BUG> out . writeBytesReference ( source , true ) ; <END_BUG> out . writeByte ( opType . id ( ) ) ; out . writeBoolean ( refresh ) ; out . writeLong ( version ) ; if ( ( percolate ) == null ) { out . writeBoolean ( false ) ; } else { out . writeBoolean ( true ) ; out . writeUTF ( percolate ) ; } out . writeByte ( versionType . getValue ( ) ) ; } @ Override public String toString ( ) { } }<BUG2FIX>out . writeBytesReference ( source ) ;
public class BulletTestCollection extends GdxTest implements InputProcessor , GestureListener { protected final BulletTest [ ] tests = new BulletTest [ ] { new BasicBulletTest ( ) , new ShootTest ( ) , new BasicShapesTest ( ) , new KinematicTest ( ) , new ConstraintsTest ( ) , new MeshShapeTest ( ) , new ConvexHullTest ( ) , new ConvexHullDistanceTest ( ) , new RayCastTest ( ) , new RayPickRagdollTest ( ) , new InternalTickTest ( ) , new CollisionWorldTest ( ) , new CollisionTest ( ) , new FrustumCullingTest ( ) , new ContactCallbackTest ( ) , new ContactCallbackTest2 ( ) , new ContactCacheTest ( ) , new SoftBodyTest ( ) , new SoftMeshTest ( ) , new VehicleTest ( ) , new CharacterTest ( ) , new ImportTest ( ) } ; protected int testIndex = 0 ; private Application app = null ; private BitmapFont font ; private Stage hud ; private Label fpsLabel ; private Label titleLabel ; private Label instructLabel ; private int loading = 0 ; private CameraInputController cameraController ; @ Override public void render ( ) { } @ Override public void create ( ) { if ( ( app ) == null ) { app = Gdx . app ; tests [ testIndex ] . create ( ) ; } cameraController = new CameraInputController ( tests [ testIndex ] . camera ) ; cameraController . activateKey = Keys . CONTROL_LEFT ; cameraController . autoUpdate = false ; cameraController . forwardTarget = false ; cameraController . translateTarget = false ; input . setInputProcessor ( new com . badlogic . gdx . InputMultiplexer ( cameraController , this , new GestureDetector ( this ) ) ) ; font = new BitmapFont ( files . internal ( "data/arial-15.fnt" ) , false ) ; <START_BUG> hud = new Stage ( 480 , 320 , true ) ; <END_BUG> hud . addActor ( ( fpsLabel = new Label ( "<seq2seq4repair_space>" , new Label . LabelStyle ( font , Color . WHITE ) ) ) ) ; fpsLabel . setPosition ( 0 , 0 ) ; hud . addActor ( ( titleLabel = new Label ( tests [ testIndex ] . getClass ( ) . getSimpleName ( ) , new Label . LabelStyle ( font , Color . WHITE ) ) ) ) ; titleLabel . setY ( ( ( hud . getHeight ( ) ) - ( titleLabel . getHeight ( ) ) ) ) ; hud . addActor ( ( instructLabel = new Label ( "A\nB\nC\nD\nE\nF" , new Label . LabelStyle ( font , Color . WHITE ) ) ) ) ; instructLabel . setY ( ( ( titleLabel . getY ( ) ) - ( instructLabel . getHeight ( ) ) ) ) ; instructLabel . setAlignment ( ( ( Align . top ) | ( Align . left ) ) ) ; instructLabel . setText ( tests [ testIndex ] . instructions ) ; } @ Override public void dispose ( ) { } public void next ( ) { } public void loadnext ( ) { } @ Override public boolean keyDown ( int keycode ) { } @ Override public boolean keyTyped ( char character ) { } @ Override public boolean keyUp ( int keycode ) { } @ Override public boolean touchDown ( int x , int y , int pointer , int button ) { } @ Override public boolean touchDragged ( int x , int y , int pointer ) { } @ Override public boolean touchUp ( int x , int y , int pointer , int button ) { } @ Override public boolean mouseMoved ( int x , int y ) { } @ Override public boolean scrolled ( int amount ) { } @ Override public boolean touchDown ( float x , float y , int pointer , int button ) { } @ Override public boolean tap ( float x , float y , int count , int button ) { } @ Override public boolean longPress ( float x , float y ) { } @ Override public boolean fling ( float velocityX , float velocityY , int button ) { } @ Override public boolean pan ( float x , float y , float deltaX , float deltaY ) { } @ Override public boolean panStop ( float x , float y , int pointer , int button ) { } @ Override public boolean zoom ( float originalDistance , float currentDistance ) { } @ Override public boolean pinch ( Vector2 initialFirstPointer , Vector2 initialSecondPointer , Vector2 firstPointer , Vector2 secondPointer ) { } }<BUG2FIX>hud = new Stage ( ) ;
private int minTermFreq = - 1 ; private int maxQueryTerms = - 1 ; private String [ ] stopWords = null ; private int minDocFreq = - 1 ; private int maxDocFreq = - 1 ; private int minWordLen = - 1 ; private int maxWordLen = - 1 ; private float boostTerms = - 1 ; private SearchType searchType = SearchType . DEFAULT ; private int searchSize = 0 ; private int searchFrom = 0 ; private String searchQueryHint ; private String [ ] searchIndices ; private String [ ] searchTypes ; private Scroll searchScroll ; private BytesReference searchSource ; private boolean searchSourceUnsafe ; private boolean threadedListener = false ; MoreLikeThisRequest ( ) { } public MoreLikeThisRequest ( String index ) { } public String index ( ) { } public String type ( ) { } void index ( String index ) { } @ Required public MoreLikeThisRequest type ( String type ) { } public String id ( ) { } @ Required public MoreLikeThisRequest id ( String id ) { } public String [ ] fields ( ) { } public MoreLikeThisRequest fields ( String ... fields ) { } public MoreLikeThisRequest percentTermsToMatch ( float percentTermsToMatch ) { } public float percentTermsToMatch ( ) { } public MoreLikeThisRequest minTermFreq ( int minTermFreq ) { } public int minTermFreq ( ) { } public MoreLikeThisRequest maxQueryTerms ( int maxQueryTerms ) { } public int maxQueryTerms ( ) { } public MoreLikeThisRequest stopWords ( String ... stopWords ) { } public String [ ] stopWords ( ) { } public MoreLikeThisRequest minDocFreq ( int minDocFreq ) { } public int minDocFreq ( ) { } public MoreLikeThisRequest maxDocFreq ( int maxDocFreq ) { } public int maxDocFreq ( ) { } public MoreLikeThisRequest minWordLen ( int minWordLen ) { } public int minWordLen ( ) { } public MoreLikeThisRequest maxWordLen ( int maxWordLen ) { } public int maxWordLen ( ) { } public MoreLikeThisRequest boostTerms ( float boostTerms ) { } public float boostTerms ( ) { } void beforeLocalFork ( ) { } public MoreLikeThisRequest searchSource ( SearchSourceBuilder sourceBuilder ) { } public MoreLikeThisRequest searchSource ( String searchSource ) { } public MoreLikeThisRequest searchSource ( Map searchSource ) { } public MoreLikeThisRequest searchSource ( XContentBuilder builder ) { } public MoreLikeThisRequest searchSource ( byte [ ] searchSource ) { } public MoreLikeThisRequest searchSource ( byte [ ] searchSource , int offset , int length , boolean unsafe ) { } public MoreLikeThisRequest searchSource ( BytesReference searchSource , boolean unsafe ) { } public BytesReference searchSource ( ) { } public boolean searchSourceUnsafe ( ) { } public MoreLikeThisRequest searchType ( SearchType searchType ) { } public MoreLikeThisRequest searchType ( String searchType ) throws ElasticSearchIllegalArgumentException { } public SearchType searchType ( ) { } public MoreLikeThisRequest searchIndices ( String ... searchIndices ) { } public String [ ] searchIndices ( ) { } public MoreLikeThisRequest searchTypes ( String ... searchTypes ) { } public String [ ] searchTypes ( ) { } public MoreLikeThisRequest searchQueryHint ( String searchQueryHint ) { } public String searchQueryHint ( ) { } public MoreLikeThisRequest searchScroll ( Scroll searchScroll ) { } public Scroll searchScroll ( ) { } public MoreLikeThisRequest searchSize ( int size ) { } public int searchSize ( ) { } public MoreLikeThisRequest searchFrom ( int from ) { } public int searchFrom ( ) { } @ Override public ActionRequestValidationException validate ( ) { } @ Override public boolean listenerThreaded ( ) { } @ Override public ActionRequest listenerThreaded ( boolean listenerThreaded ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { out . writeUTF ( index ) ; out . writeUTF ( type ) ; out . writeUTF ( id ) ; if ( ( fields ) == null ) { out . writeVInt ( 0 ) ; } else { out . writeVInt ( fields . length ) ; for ( String field : fields ) { out . writeUTF ( field ) ; } } out . writeFloat ( percentTermsToMatch ) ; out . writeVInt ( minTermFreq ) ; out . writeVInt ( maxQueryTerms ) ; if ( ( stopWords ) == null ) { out . writeVInt ( 0 ) ; } else { out . writeVInt ( stopWords . length ) ; for ( String stopWord : stopWords ) { out . writeUTF ( stopWord ) ; } } out . writeVInt ( minDocFreq ) ; out . writeVInt ( maxDocFreq ) ; out . writeVInt ( minWordLen ) ; out . writeVInt ( maxWordLen ) ; out . writeFloat ( boostTerms ) ; out . writeByte ( searchType . id ( ) ) ; if ( ( searchQueryHint ) == null ) { out . writeBoolean ( false ) ; } else { out . writeBoolean ( true ) ; out . writeUTF ( searchQueryHint ) ; } if ( ( searchIndices ) == null ) { out . writeVInt ( 0 ) ; } else { out . writeVInt ( ( ( searchIndices . length ) + 1 ) ) ; for ( String index : searchIndices ) { out . writeUTF ( index ) ; } } if ( ( searchTypes ) == null ) { out . writeVInt ( 0 ) ; } else { out . writeVInt ( ( ( searchTypes . length ) + 1 ) ) ; for ( String type : searchTypes ) { out . writeUTF ( type ) ; } } if ( ( searchScroll ) == null ) { out . writeBoolean ( false ) ; } else { out . writeBoolean ( true ) ; searchScroll . writeTo ( out ) ; } <START_BUG> out . writeBytesReference ( searchSource , true ) ; <END_BUG> out . writeVInt ( searchSize ) ; out . writeVInt ( searchFrom ) ; } }<BUG2FIX>out . writeBytesReference ( searchSource ) ;
public class RestDeleteAction extends BaseRestHandler { @ Inject public RestDeleteAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { DeleteRequest deleteRequest = new DeleteRequest ( request . param ( "index" ) , request . param ( "type" ) , request . param ( "id" ) ) ; deleteRequest . listenerThreaded ( false ) ; deleteRequest . operationThreaded ( true ) ; deleteRequest . parent ( request . param ( "parent" ) ) ; deleteRequest . routing ( request . param ( "routing" ) ) ; deleteRequest . timeout ( request . paramAsTime ( "timeout" , DEFAULT_TIMEOUT ) ) ; deleteRequest . refresh ( request . paramAsBoolean ( "refresh" , deleteRequest . refresh ( ) ) ) ; deleteRequest . version ( RestActions . parseVersion ( request ) ) ; deleteRequest . versionType ( VersionType . fromString ( request . param ( "version_type" ) , deleteRequest . versionType ( ) ) ) ; String replicationType = request . param ( "replication" ) ; if ( replicationType != null ) { deleteRequest . replicationType ( ReplicationType . fromString ( replicationType ) ) ; } String consistencyLevel = request . param ( "consistency" ) ; if ( consistencyLevel != null ) { deleteRequest . consistencyLevel ( WriteConsistencyLevel . fromString ( consistencyLevel ) ) ; } client . delete ( deleteRequest , new org . elasticsearch . action . ActionListener < DeleteResponse > ( ) { @ Override public void onResponse ( DeleteResponse result ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) . field ( RestDeleteAction . Fields . OK , true ) . field ( RestDeleteAction . Fields . FOUND , ( ! ( result . isNotFound ( ) ) ) ) . field ( RestDeleteAction . Fields . _INDEX , result . getIndex ( ) ) . field ( RestDeleteAction . Fields . _TYPE , result . getType ( ) ) . field ( RestDeleteAction . Fields . _ID , result . getId ( ) ) . field ( RestDeleteAction . Fields . _VERSION , result . getVersion ( ) ) . endObject ( ) ; RestStatus status = org . elasticsearch . rest . RestStatus . OK ; if ( result . isNotFound ( ) ) { status = org . elasticsearch . rest . RestStatus . NOT_FOUND ; } channel . sendResponse ( new XContentRestResponse ( request , status , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } static final class Fields { static final XContentBuilderString OK = new XContentBuilderString ( "ok" ) ; static final XContentBuilderString FOUND = new XContentBuilderString ( "found" ) ; static final XContentBuilderString _INDEX = new XContentBuilderString ( "_index" ) ; static final XContentBuilderString _TYPE = new XContentBuilderString ( "_type" ) ; static final XContentBuilderString _ID = new XContentBuilderString ( "_id" ) ; static final XContentBuilderString _VERSION = new XContentBuilderString ( "_version" ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class StagePerformanceTest extends GdxTest { @ Override public boolean needsGL20 ( ) { <START_BUG> return false ; <END_BUG> } TextureRegion [ ] regions ; Stage stage ; SpriteBatch batch ; BitmapFont font ; Sprite [ ] sprites ; boolean useStage = true ; @ Override public void create ( ) { } @ Override public void render ( ) { } }<BUG2FIX>return true ;
public class MipMapTest extends GdxTest { @ Override public boolean needsGL20 ( ) { } PerspectiveCamera camera ; PerspectiveCamController controller ; Mesh mesh ; Texture textureHW ; Texture textureSW ; Texture currTexture ; ShaderProgram shader ; Stage ui ; InputMultiplexer multiplexer ; ComboBox minFilter ; ComboBox magFilter ; CheckBox hwMipMap ; @ Override public void create ( ) { } private void createUI ( ) { } @ Override public void render ( ) { gl . glClear ( GL_COLOR_BUFFER_BIT ) ; gl . glEnable ( GL_TEXTURE_2D ) ; camera . update ( ) ; <START_BUG> currTexture = ( hwMipMap . isChecked ) ? textureHW : textureSW ; <END_BUG> currTexture . bind ( ) ; currTexture . setFilter ( TextureFilter . valueOf ( minFilter . getSelection ( ) ) , TextureFilter . valueOf ( magFilter . getSelection ( ) ) ) ; shader . begin ( ) ; shader . setUniformMatrix ( "u_projTrans" , camera . combined ) ; shader . setUniformi ( "s_texture" , 0 ) ; mesh . render ( shader , GL_TRIANGLE_FAN ) ; shader . end ( ) ; ui . draw ( ) ; } }<BUG2FIX>currTexture = ( hwMipMap . isChecked ( ) ) ? textureHW : textureSW ;
public class FilesTest extends GdxTest { String message = "" ; boolean success ; BitmapFont font ; SpriteBatch batch ; @ Override public void create ( ) { } private void testClasspath ( ) throws IOException { } private void testInternal ( ) throws IOException { } private void testExternal ( ) throws IOException { } private void testAbsolute ( ) throws IOException { } private void testLocal ( ) throws IOException { String path = "meow" ; FileHandle handle = files . local ( path ) ; handle . delete ( ) ; if ( handle . exists ( ) ) fail ( ) ; if ( handle . isDirectory ( ) ) fail ( ) ; if ( handle . delete ( ) ) fail ( ) ; if ( ( handle . list ( ) . length ) != 0 ) fail ( ) ; if ( handle . child ( "meow" ) . exists ( ) ) fail ( ) ; <START_BUG> if ( ! ( handle . parent ( ) . exists ( ) ) ) <END_BUG> fail ( ) ; try { handle . read ( ) . close ( ) ; fail ( ) ; } catch ( Exception ignored ) { } handle . mkdirs ( ) ; if ( ! ( handle . exists ( ) ) ) fail ( ) ; if ( ! ( handle . isDirectory ( ) ) ) fail ( ) ; if ( ( handle . list ( ) . length ) != 0 ) fail ( ) ; handle . child ( "meow" ) . mkdirs ( ) ; if ( ( handle . list ( ) . length ) != 1 ) fail ( ) ; FileHandle child = handle . list ( ) [ 0 ] ; if ( ! ( child . name ( ) . equals ( "meow" ) ) ) fail ( ) ; if ( ! ( child . parent ( ) . exists ( ) ) ) fail ( ) ; if ( ! ( handle . deleteDirectory ( ) ) ) fail ( ) ; if ( handle . exists ( ) ) fail ( ) ; OutputStream output = handle . write ( false ) ; output . write ( "moo" . getBytes ( ) ) ; output . close ( ) ; if ( ! ( handle . exists ( ) ) ) fail ( ) ; if ( ( handle . length ( ) ) != 3 ) fail ( ) ; FileHandle copy = files . local ( ( path + "-copy" ) ) ; copy . delete ( ) ; if ( copy . exists ( ) ) fail ( ) ; handle . copyTo ( copy ) ; if ( ! ( copy . exists ( ) ) ) fail ( ) ; if ( ( copy . length ( ) ) != 3 ) fail ( ) ; FileHandle move = files . local ( ( path + "-move" ) ) ; move . delete ( ) ; if ( move . exists ( ) ) fail ( ) ; copy . moveTo ( move ) ; if ( ! ( move . exists ( ) ) ) fail ( ) ; if ( ( move . length ( ) ) != 3 ) fail ( ) ; move . deleteDirectory ( ) ; if ( move . exists ( ) ) fail ( ) ; InputStream input = handle . read ( ) ; byte [ ] bytes = new byte [ 6 ] ; if ( ( input . read ( bytes ) ) != 3 ) fail ( ) ; input . close ( ) ; if ( ! ( new String ( bytes , 0 , 3 ) . equals ( "moo" ) ) ) fail ( ) ; output = handle . write ( true ) ; output . write ( "cow" . getBytes ( ) ) ; output . close ( ) ; if ( ( handle . length ( ) ) != 6 ) fail ( ) ; input = handle . read ( ) ; if ( ( input . read ( bytes ) ) != 6 ) fail ( ) ; input . close ( ) ; if ( ! ( new String ( bytes , 0 , 6 ) . equals ( "moocow" ) ) ) fail ( ) ; if ( handle . isDirectory ( ) ) fail ( ) ; if ( ( handle . list ( ) . length ) != 0 ) fail ( ) ; if ( ! ( handle . name ( ) . equals ( "meow" ) ) ) fail ( ) ; if ( ! ( handle . nameWithoutExtension ( ) . equals ( "meow" ) ) ) fail ( ) ; if ( ! ( handle . extension ( ) . equals ( "" ) ) ) fail ( ) ; handle . deleteDirectory ( ) ; if ( handle . exists ( ) ) fail ( ) ; if ( handle . isDirectory ( ) ) fail ( ) ; handle . delete ( ) ; handle . deleteDirectory ( ) ; } private void fail ( ) { } private void fail ( String msg ) { } @ Override public void render ( ) { } @ Override public void dispose ( ) { } }<BUG2FIX>if ( handle . parent ( ) . exists ( ) )
public class AndroidFileHandle extends FileHandle { final AssetManager assets ; AndroidFileHandle ( AssetManager assets , String fileName , FileType type ) { } AndroidFileHandle ( AssetManager assets , File file , FileType type ) { } public FileHandle child ( String name ) { } public FileHandle sibling ( String name ) { } public FileHandle parent ( ) { } public InputStream read ( ) { } public FileHandle [ ] list ( ) { } public FileHandle [ ] list ( String suffix ) { if ( ( type ) == ( FileType . Internal ) ) { try { String [ ] relativePaths = assets . list ( file . getPath ( ) ) ; FileHandle [ ] handles = new FileHandle [ relativePaths . length ] ; int count = 0 ; for ( int i = 0 , n = handles . length ; i < n ; i ++ ) { String path = relativePaths [ i ] ; if ( ! ( path . endsWith ( suffix ) ) ) continue ; handles [ count ] = new AndroidFileHandle ( assets , new File ( file , path ) , type ) ; count ++ ; } if ( count < ( relativePaths . length ) ) { FileHandle [ ] newHandles = new FileHandle [ count ] ; System . arraycopy ( handles , 0 , newHandles , 0 , count ) ; handles = newHandles ; } return handles ; } catch ( Exception ex ) { throw new com . badlogic . gdx . utils . GdxRuntimeException ( ( ( ( ( "Error<seq2seq4repair_space>listing<seq2seq4repair_space>children:<seq2seq4repair_space>" + ( file ) ) + "<seq2seq4repair_space>(" ) + ( type ) ) + ")" ) , ex ) ; } } <START_BUG> return super . list ( suffix ) ; <END_BUG> } public boolean isDirectory ( ) { } public boolean exists ( ) { } public long length ( ) { } public long lastModified ( ) { } }<BUG2FIX>return super . list ( ) ;
public class IntIntMap { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; private static final int EMPTY = 0 ; public int size ; int [ ] keyTable ; int [ ] valueTable ; int capacity ; int stashSize ; int zeroValue ; boolean hasZeroValue ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private IntIntMap . Entries entries1 ; private IntIntMap . Entries entries2 ; private IntIntMap . Values values1 ; private IntIntMap . Values values2 ; private IntIntMap . Keys keys1 ; private IntIntMap . Keys keys2 ; public IntIntMap ( ) { } public IntIntMap ( int initialCapacity ) { } public IntIntMap ( int initialCapacity , float loadFactor ) { } public IntIntMap ( IntIntMap map ) { } public void put ( int key , int value ) { } public void putAll ( IntIntMap map ) { } private void putResize ( int key , int value ) { } private void push ( int insertKey , int insertValue , int index1 , int key1 , int index2 , int key2 , int index3 , int key3 ) { } private void putStash ( int key , int value ) { } public int get ( int key , int defaultValue ) { } private int getStash ( int key , int defaultValue ) { } public int getAndIncrement ( int key , int defaultValue , int increment ) { } private int getAndIncrementStash ( int key , int defaultValue , int increment ) { } public int remove ( int key , int defaultValue ) { } int removeStash ( int key , int defaultValue ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean containsValue ( int value ) { } public boolean containsKey ( int key ) { } private boolean containsKeyStash ( int key ) { } public int findKey ( int value , int notFound ) { } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( int h ) { } private int hash3 ( int h ) { } public String toString ( ) { } public IntIntMap . Entries entries ( ) { } public IntIntMap . Values values ( ) { } public IntIntMap . Keys keys ( ) { } public static class Entry < K > { public int key ; public int value ; public String toString ( ) { } } private static class MapIterator < K > { static final int INDEX_ILLEGAL = - 2 ; static final int INDEX_ZERO = - 1 ; public boolean hasNext ; final IntIntMap map ; int nextIndex ; int currentIndex ; boolean valid = true ; public MapIterator ( IntIntMap map ) { } public void reset ( ) { } void findNextIndex ( ) { } public void remove ( ) { if ( ( ( currentIndex ) == ( IntIntMap . MapIterator . INDEX_ZERO ) ) && ( map . hasZeroValue ) ) { map . hasZeroValue = false ; } else if ( ( currentIndex ) < 0 ) { throw new IllegalStateException ( "next<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>called<seq2seq4repair_space>before<seq2seq4repair_space>remove." ) ; } else if ( ( currentIndex ) >= ( map . capacity ) ) { map . removeStashIndex ( currentIndex ) ; <START_BUG> nextIndex = ( currentIndex ) - 1 ; <END_BUG> findNextIndex ( ) ; } else { map . keyTable [ currentIndex ] = IntIntMap . EMPTY ; } currentIndex = IntIntMap . MapIterator . INDEX_ILLEGAL ; ( map . size ) -- ; } } public static class Entries extends IntIntMap . MapIterator implements Iterable < IntIntMap . Entry > , Iterator < IntIntMap . Entry > { private IntIntMap . Entry entry = new IntIntMap . Entry ( ) ; public Entries ( IntIntMap map ) { } public IntIntMap . Entry next ( ) { } public boolean hasNext ( ) { } public Iterator < IntIntMap . Entry > iterator ( ) { } } public static class Values extends IntIntMap . MapIterator < Object > { public Values ( IntIntMap map ) { } public boolean hasNext ( ) { } public int next ( ) { } public IntArray toArray ( ) { } } public static class Keys extends IntIntMap . MapIterator { public Keys ( IntIntMap map ) { } public boolean hasNext ( ) { } public int next ( ) { } public IntArray toArray ( ) { } } }<BUG2FIX>nextIndex = currentIndex ;
public class TransportMoreLikeThisAction extends BaseAction < MoreLikeThisRequest , SearchResponse > { private final TransportSearchAction searchAction ; private final TransportGetAction getAction ; private final IndicesService indicesService ; private final ClusterService clusterService ; @ Inject public TransportMoreLikeThisAction ( Settings settings , TransportSearchAction searchAction , TransportGetAction getAction , ClusterService clusterService , IndicesService indicesService , TransportService transportService ) { } @ Override protected void doExecute ( final MoreLikeThisRequest request , final ActionListener < SearchResponse > listener ) { ClusterState clusterState = clusterService . state ( ) ; request . index ( clusterState . metaData ( ) . concreteIndex ( request . index ( ) ) ) ; Set < String > getFields = newHashSet ( ) ; if ( ( request . fields ( ) ) != null ) { Collections . addAll ( getFields , request . fields ( ) ) ; } getFields . add ( NAME ) ; <START_BUG> GetRequest getRequest = getRequest ( request . index ( ) ) . fields ( getFields . toArray ( new String [ getFields . size ( ) ] ) ) . type ( request . type ( ) ) . id ( request . id ( ) ) . listenerThreaded ( false ) . operationThreaded ( true ) ; <END_BUG> request . beforeLocalFork ( ) ; getAction . execute ( getRequest , new ActionListener < GetResponse > ( ) { @ Override public void onResponse ( GetResponse getResponse ) { if ( ! ( getResponse . exists ( ) ) ) { listener . onFailure ( new ElasticSearchException ( "document<seq2seq4repair_space>missing" ) ) ; return ; } final BoolQueryBuilder boolBuilder = boolQuery ( ) ; try { DocumentMapper docMapper = indicesService . indexServiceSafe ( request . index ( ) ) . mapperService ( ) . documentMapper ( request . type ( ) ) ; final Set < String > fields = newHashSet ( ) ; if ( ( request . fields ( ) ) != null ) { for ( String field : request . fields ( ) ) { FieldMappers fieldMappers = docMapper . mappers ( ) . smartName ( field ) ; if ( fieldMappers != null ) { fields . add ( fieldMappers . mapper ( ) . names ( ) . indexName ( ) ) ; } else { fields . add ( field ) ; } } } if ( ! ( fields . isEmpty ( ) ) ) { for ( Iterator < String > it = fields . iterator ( ) ; it . hasNext ( ) ; ) { String field = it . next ( ) ; GetField getField = getResponse . field ( field ) ; if ( getField != null ) { for ( Object value : getField . values ( ) ) { addMoreLikeThis ( request , boolBuilder , getField . name ( ) , value . toString ( ) ) ; } it . remove ( ) ; } } if ( ! ( fields . isEmpty ( ) ) ) { parseSource ( getResponse , boolBuilder , docMapper , fields , request ) ; } } else { parseSource ( getResponse , boolBuilder , docMapper , fields , request ) ; } if ( boolBuilder . clauses ( ) . isEmpty ( ) ) { listener . onFailure ( new ElasticSearchException ( "No<seq2seq4repair_space>fields<seq2seq4repair_space>found<seq2seq4repair_space>to<seq2seq4repair_space>fetch<seq2seq4repair_space>the<seq2seq4repair_space>'likeText'<seq2seq4repair_space>from" ) ) ; return ; } Term uidTerm = docMapper . uidMapper ( ) . term ( request . type ( ) , request . id ( ) ) ; boolBuilder . mustNot ( termQuery ( uidTerm . field ( ) , uidTerm . text ( ) ) ) ; } catch ( Exception e ) { listener . onFailure ( e ) ; return ; } String [ ] searchIndices = request . searchIndices ( ) ; if ( searchIndices == null ) { searchIndices = new String [ ] { request . index ( ) } ; } String [ ] searchTypes = request . searchTypes ( ) ; if ( searchTypes == null ) { searchTypes = new String [ ] { request . type ( ) } ; } SearchRequest searchRequest = searchRequest ( searchIndices ) . types ( searchTypes ) . searchType ( request . searchType ( ) ) . scroll ( request . searchScroll ( ) ) . extraSource ( searchSource ( ) . query ( boolBuilder ) ) . listenerThreaded ( request . listenerThreaded ( ) ) ; if ( ( request . searchSource ( ) ) != null ) { searchRequest . source ( request . searchSource ( ) , request . searchSourceOffset ( ) , request . searchSourceLength ( ) , request . searchSourceUnsafe ( ) ) ; } searchAction . execute ( searchRequest , new ActionListener < SearchResponse > ( ) { @ Override public void onResponse ( SearchResponse response ) { listener . onResponse ( response ) ; } @ Override public void onFailure ( Throwable e ) { listener . onFailure ( e ) ; } } ) ; } @ Override public void onFailure ( Throwable e ) { listener . onFailure ( e ) ; } } ) ; } private void parseSource ( GetResponse getResponse , final BoolQueryBuilder boolBuilder , DocumentMapper docMapper , final Set < String > fields , final MoreLikeThisRequest request ) { } private void addMoreLikeThis ( MoreLikeThisRequest request , BoolQueryBuilder boolBuilder , FieldMapper fieldMapper , Fieldable field ) { } private void addMoreLikeThis ( MoreLikeThisRequest request , BoolQueryBuilder boolBuilder , String fieldName , String likeText ) { } private class TransportHandler extends BaseTransportRequestHandler < MoreLikeThisRequest > { @ Override public MoreLikeThisRequest newInstance ( ) { } @ Override public void messageReceived ( MoreLikeThisRequest request , final TransportChannel channel ) throws Exception { } @ Override public boolean spawn ( ) { } } }<BUG2FIX>GetRequest getRequest = getRequest ( request . index ( ) ) . fields ( getFields . toArray ( new String [ getFields . size ( ) ] ) ) . type ( request . type ( ) ) . id ( request . id ( ) ) . listenerThreaded ( true ) . operationThreaded ( true ) ;
public class GistFilesViewActivity extends PagerActivity { public static Intent createIntent ( Gist gist , int position ) { } @ InjectExtra ( Intents . EXTRA_GIST_ID ) private String gistId ; @ InjectExtra ( Intents . EXTRA_POSITION ) private int initialPosition ; @ InjectView ( id . vp_pages ) private ViewPager pager ; @ InjectView ( id . pb_loading ) private ProgressBar loadingBar ; @ InjectView ( id . tpi_header ) private TitlePageIndicator indicator ; private Gist gist ; @ Inject private GistStore store ; @ Inject private AvatarLoader avatars ; @ Inject private HttpImageGetter imageGetter ; private GistFilesPagerAdapter adapter ; @ Override protected void onCreate ( Bundle savedInstanceState ) { } private void configurePager ( ) { ActionBar actionBar = getSupportActionBar ( ) ; actionBar . setDisplayHomeAsUpEnabled ( true ) ; User author = gist . getUser ( ) ; if ( author != null ) { actionBar . setSubtitle ( author . getLogin ( ) ) ; avatars . bind ( actionBar , author ) ; } else actionBar . setSubtitle ( anonymous ) ; ViewUtils . setGone ( loadingBar , true ) ; ViewUtils . setGone ( pager , false ) ; ViewUtils . setGone ( indicator , false ) ; adapter = new GistFilesPagerAdapter ( this , gist ) ; pager . setAdapter ( adapter ) ; indicator . setViewPager ( pager ) ; if ( ( initialPosition ) < ( adapter . getCount ( ) ) ) { <START_BUG> pager . scheduleSetItem ( initialPosition , null ) ; <END_BUG> onPageSelected ( initialPosition ) ; } } @ Override public boolean onOptionsItemSelected ( MenuItem item ) { } @ Override protected FragmentProvider getProvider ( ) { } }<BUG2FIX>pager . scheduleSetItem ( initialPosition ) ;
public class MD5Test extends GdxTest implements InputProcessor { PerspectiveCamera camera ; MD5Model model ; MD5Animation anim ; MD5AnimationInfo animInfo ; MD5Joints skeleton ; MD5Renderer renderer ; SpriteBatch batch ; BitmapFont font ; @ Override public void create ( ) { app . log ( "MD5<seq2seq4repair_space>Test" , "created" ) ; <START_BUG> model = MD5Loader . loadModel ( files . internal ( "data/zfat.md5mesh" ) . read ( ) , false ) ; <END_BUG> anim = MD5Loader . loadAnimation ( files . internal ( "data/walk1.md5anim" ) . read ( ) ) ; skeleton = new MD5Joints ( ) ; skeleton . joints = new float [ anim . frames [ 0 ] . joints . length ] ; animInfo = new MD5AnimationInfo ( anim . frames . length , anim . secondsPerFrame ) ; renderer = new MD5Renderer ( model , false , true ) ; renderer . setSkeleton ( model . baseSkeleton ) ; camera = new PerspectiveCamera ( ) ; camera . getPosition ( ) . set ( 0 , 25 , 100 ) ; camera . setFov ( 60 ) ; camera . setNear ( 1 ) ; camera . setFar ( 1000 ) ; camera . setViewport ( graphics . getWidth ( ) , graphics . getHeight ( ) ) ; batch = new SpriteBatch ( ) ; font = new BitmapFont ( ) ; graphics . getGL10 ( ) . glViewport ( 0 , 0 , graphics . getWidth ( ) , graphics . getHeight ( ) ) ; input . setInputProcessor ( this ) ; } float angle = 0 ; @ Override public void render ( ) { } @ Override public void dispose ( ) { } @ Override public boolean keyDown ( int keycode ) { } @ Override public boolean keyTyped ( char character ) { } @ Override public boolean keyUp ( int keycode ) { } @ Override public boolean touchDown ( int x , int y , int pointer ) { } @ Override public boolean touchDragged ( int x , int y , int pointer ) { } @ Override public boolean touchUp ( int x , int y , int pointer ) { } @ Override public boolean needsGL20 ( ) { } }<BUG2FIX>model = MD5Loader . loadModel ( files . internal ( "data/zfat.md5mesh" ) . read ( ) , true ) ;
public class IntArray { public int [ ] items ; public int size ; public boolean ordered ; public IntArray ( ) { } public IntArray ( int capacity ) { } public IntArray ( boolean ordered , int capacity ) { } public IntArray ( IntArray array ) { } public IntArray ( int [ ] array ) { } public IntArray ( boolean ordered , int [ ] array , int startIndex , int count ) { } public void add ( int value ) { } public void addAll ( IntArray array ) { } public void addAll ( IntArray array , int offset , int length ) { } public void addAll ( int [ ] array ) { } public void addAll ( int [ ] array , int offset , int length ) { int [ ] items = this . items ; <START_BUG> int sizeNeeded = ( ( size ) + length ) - offset ; <END_BUG> if ( sizeNeeded >= ( items . length ) ) items = resize ( Math . max ( 8 , ( ( int ) ( sizeNeeded * 1.75F ) ) ) ) ; System . arraycopy ( array , offset , items , size , length ) ; size += length ; } public int get ( int index ) { } public void set ( int index , int value ) { } public void insert ( int index , int value ) { } public void swap ( int first , int second ) { } public boolean contains ( int value ) { } public int indexOf ( int value ) { } public int lastIndexOf ( int value ) { } public boolean removeValue ( int value ) { } public int removeIndex ( int index ) { } public boolean removeAll ( IntArray array ) { } public int pop ( ) { } public int peek ( ) { } public int first ( ) { } public void clear ( ) { } public void shrink ( ) { } public int [ ] ensureCapacity ( int additionalCapacity ) { } protected int [ ] resize ( int newSize ) { } public void sort ( ) { } public void reverse ( ) { } public void shuffle ( ) { } public void truncate ( int newSize ) { } public int random ( ) { } public int [ ] toArray ( ) { } public boolean equals ( Object object ) { } public String toString ( ) { } public String toString ( String separator ) { } }<BUG2FIX>int sizeNeeded = ( size ) + length ;
public class NinePatch { public static final int TOP_LEFT = 0 ; public static final int TOP_CENTER = 1 ; public static final int TOP_RIGHT = 2 ; public static final int MIDDLE_LEFT = 3 ; public static final int MIDDLE_CENTER = 4 ; public static final int MIDDLE_RIGHT = 5 ; public static final int BOTTOM_LEFT = 6 ; public static final int BOTTOM_CENTER = 7 ; public static final int BOTTOM_RIGHT = 8 ; TextureRegion [ ] patches ; private NinePatch ( ) { } public NinePatch ( Texture texture , int left , int right , int top , int bottom ) { } public NinePatch ( TextureRegion region , int left , int right , int top , int bottom ) { } public NinePatch ( TextureRegion ... patches ) { } private void checkValidity ( ) { } public void draw ( SpriteBatch batch , float x , float y , float width , float height ) { } public float getLeftWidth ( ) { } public float getRightWidth ( ) { } public float getTopHeight ( ) { } public float getBottomHeight ( ) { } public float getTotalHeight ( ) { <START_BUG> return ( ( getTopHeight ( ) ) + ( getBottomHeight ( ) ) ) + ( patches [ NinePatch . MIDDLE_LEFT ] . getRegionHeight ( ) ) ; <END_BUG> } public float getTotalWidth ( ) { } public TextureRegion [ ] getPatches ( ) { } }<BUG2FIX>return ( ( getTopHeight ( ) ) + ( getBottomHeight ( ) ) ) + ( patches [ NinePatch . MIDDLE_CENTER ] . getRegionHeight ( ) ) ;
public class ScriptTermsStringFieldFacetCollector extends AbstractFacetCollector { private final ComparatorType comparatorType ; private final int size ; private final int numberOfShards ; private final String sScript ; private final SearchScript script ; private final Matcher matcher ; private final ImmutableSet < String > excluded ; private final TObjectIntHashMap < String > facets ; public ScriptTermsStringFieldFacetCollector ( String facetName , int size , InternalStringTermsFacet . ComparatorType comparatorType , SearchContext context , ImmutableSet < String > excluded , Pattern pattern , String scriptLang , String script , Map < String , Object > params ) { } @ Override protected void doSetNextReader ( IndexReader reader , int docBase ) throws IOException { } @ Override protected void doCollect ( int doc ) throws IOException { } private boolean match ( String value ) { } @ Override public Facet facet ( ) { if ( facets . isEmpty ( ) ) { TermsStringFacetCollector . pushFacets ( facets ) ; return new InternalStringTermsFacet ( facetName , sScript , comparatorType , size , ImmutableList . < InternalStringTermsFacet . StringEntry > of ( ) ) ; } else { <START_BUG> BoundedTreeSet < InternalStringTermsFacet . StringEntry > ordered = new BoundedTreeSet < InternalStringTermsFacet . StringEntry > ( COUNT . comparator ( ) , ( ( size ) * ( numberOfShards ) ) ) ; <END_BUG> for ( TObjectIntIterator < String > it = facets . iterator ( ) ; it . hasNext ( ) ; ) { it . advance ( ) ; ordered . add ( new InternalStringTermsFacet . StringEntry ( it . key ( ) , it . value ( ) ) ) ; } TermsStringFacetCollector . pushFacets ( facets ) ; return new InternalStringTermsFacet ( facetName , sScript , comparatorType , size , ordered ) ; } } }<BUG2FIX>BoundedTreeSet < InternalStringTermsFacet . StringEntry > ordered = new BoundedTreeSet < InternalStringTermsFacet . StringEntry > ( comparatorType . comparator ( ) , ( ( size ) * ( numberOfShards ) ) ) ;
public class TransportService extends AbstractLifecycleComponent < TransportService > { private final Transport transport ; private final ThreadPool threadPool ; volatile ImmutableMap < String , TransportRequestHandler > serverHandlers = ImmutableMap . of ( ) ; final Object serverHandlersMutex = new Object ( ) ; final ConcurrentMapLong < TransportService . RequestHolder > clientHandlers = ConcurrentCollections . newConcurrentMapLongWithAggressiveConcurrency ( ) ; final AtomicLong requestIds = new AtomicLong ( ) ; final CopyOnWriteArrayList < TransportConnectionListener > connectionListeners = new CopyOnWriteArrayList < TransportConnectionListener > ( ) ; final Map < Long , TransportService . TimeoutInfoHolder > timeoutInfoHandlers = Collections . synchronizedMap ( new LinkedHashMap < Long , TransportService . TimeoutInfoHolder > ( 100 , 0.75F , true ) { protected boolean removeEldestEntry ( Map . Entry eldest ) { } } ) ; private boolean throwConnectException = false ; private final TransportService . Adapter adapter = new TransportService . Adapter ( ) ; public TransportService ( Transport transport , ThreadPool threadPool ) { } @ Inject public TransportService ( Settings settings , Transport transport , ThreadPool threadPool ) { } @ Override protected void doStart ( ) throws ElasticSearchException { } @ Override protected void doStop ( ) throws ElasticSearchException { } @ Override protected void doClose ( ) throws ElasticSearchException { } public boolean addressSupported ( Class < ? extends TransportAddress > address ) { } public TransportInfo info ( ) { } public TransportStats stats ( ) { } public BoundTransportAddress boundAddress ( ) { } public boolean nodeConnected ( DiscoveryNode node ) { } public void connectToNode ( DiscoveryNode node ) throws ConnectTransportException { } public void connectToNodeLight ( DiscoveryNode node ) throws ConnectTransportException { } public void disconnectFromNode ( DiscoveryNode node ) { } public void addConnectionListener ( TransportConnectionListener listener ) { } public void removeConnectionListener ( TransportConnectionListener listener ) { } public void throwConnectException ( boolean throwConnectException ) { } public < T extends TransportResponse > TransportFuture < T > submitRequest ( DiscoveryNode node , String action , TransportRequest request , TransportResponseHandler < T > handler ) throws TransportException { } public < T extends TransportResponse > TransportFuture < T > submitRequest ( DiscoveryNode node , String action , TransportRequest request , TransportRequestOptions options , TransportResponseHandler < T > handler ) throws TransportException { } public < T extends TransportResponse > void sendRequest ( final DiscoveryNode node , final String action , final TransportRequest request , final TransportResponseHandler < T > handler ) throws TransportException { } public < T extends TransportResponse > void sendRequest ( final DiscoveryNode node , final String action , final TransportRequest request , final TransportRequestOptions options , final TransportResponseHandler < T > handler ) throws TransportException { final long requestId = newRequestId ( ) ; TransportService . TimeoutHandler timeoutHandler = null ; try { if ( ( options . timeout ( ) ) != null ) { timeoutHandler = new TransportService . TimeoutHandler ( requestId ) ; timeoutHandler . future = threadPool . schedule ( options . timeout ( ) , GENERIC , timeoutHandler ) ; } clientHandlers . put ( requestId , new TransportService . RequestHolder < T > ( handler , node , action , timeoutHandler ) ) ; transport . sendRequest ( node , requestId , action , request , options ) ; <START_BUG> } catch ( final Exception e ) { <END_BUG> clientHandlers . remove ( requestId ) ; if ( timeoutHandler != null ) { timeoutHandler . future . cancel ( false ) ; } if ( throwConnectException ) { if ( e instanceof ConnectTransportException ) { throw ( ( ConnectTransportException ) ( e ) ) ; } } final SendRequestTransportException sendRequestException = new SendRequestTransportException ( node , action , e ) ; threadPool . executor ( GENERIC ) . execute ( new Runnable ( ) { @ Override public void run ( ) { handler . handleException ( sendRequestException ) ; } } ) ; } } private long newRequestId ( ) { } public TransportAddress [ ] addressesFromString ( String address ) throws Exception { } public void registerHandler ( String action , TransportRequestHandler handler ) { } public void removeHandler ( String action ) { } class Adapter implements TransportServiceAdapter { final MeanMetric rxMetric = new MeanMetric ( ) ; final MeanMetric txMetric = new MeanMetric ( ) ; @ Override public void received ( long size ) { } @ Override public void sent ( long size ) { } @ Override public TransportRequestHandler handler ( String action ) { } @ Override public TransportResponseHandler remove ( long requestId ) { } @ Override public void raiseNodeConnected ( final DiscoveryNode node ) { } @ Override public void raiseNodeDisconnected ( final DiscoveryNode node ) { } } class TimeoutHandler implements Runnable { private final long requestId ; private final long sentTime = System . currentTimeMillis ( ) ; ScheduledFuture future ; TimeoutHandler ( long requestId ) { } public long sentTime ( ) { } @ Override public void run ( ) { } } static class TimeoutInfoHolder { private final DiscoveryNode node ; private final String action ; private final long sentTime ; private final long timeoutTime ; TimeoutInfoHolder ( DiscoveryNode node , String action , long sentTime , long timeoutTime ) { } public DiscoveryNode node ( ) { } public String action ( ) { } public long sentTime ( ) { } public long timeoutTime ( ) { } } static class RequestHolder < T extends TransportResponse > { private final TransportResponseHandler < T > handler ; private final DiscoveryNode node ; private final String action ; private final TransportService . TimeoutHandler timeout ; RequestHolder ( TransportResponseHandler < T > handler , DiscoveryNode node , String action , TransportService . TimeoutHandler timeout ) { } public TransportResponseHandler < T > handler ( ) { } public DiscoveryNode node ( ) { } public String action ( ) { } public void cancel ( ) { } } }<BUG2FIX>} catch ( final Throwable e ) {
public class RestAnalyzeAction extends BaseRestHandler { @ Inject public RestAnalyzeAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { String text = request . param ( "text" ) ; if ( ( text == null ) && ( request . hasContent ( ) ) ) { text = request . content ( ) . toUtf8 ( ) ; } if ( text == null ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , new ElasticSearchIllegalArgumentException ( "text<seq2seq4repair_space>is<seq2seq4repair_space>missing" ) ) ) ; } catch ( IOException e1 ) { logger . warn ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>response" , e1 ) ; } return ; } AnalyzeRequest analyzeRequest = new AnalyzeRequest ( request . param ( "index" ) , text ) ; analyzeRequest . listenerThreaded ( false ) ; analyzeRequest . preferLocal ( request . paramAsBoolean ( "prefer_local" , analyzeRequest . preferLocalShard ( ) ) ) ; analyzeRequest . analyzer ( request . param ( "analyzer" ) ) ; analyzeRequest . field ( request . param ( "field" ) ) ; analyzeRequest . tokenizer ( request . param ( "tokenizer" ) ) ; analyzeRequest . tokenFilters ( request . paramAsStringArray ( "token_filters" , request . paramAsStringArray ( "filters" , null ) ) ) ; client . admin ( ) . indices ( ) . analyze ( analyzeRequest , new org . elasticsearch . action . ActionListener < AnalyzeResponse > ( ) { @ Override public void onResponse ( AnalyzeResponse response ) { try { <START_BUG> XContentBuilder builder = restContentBuilder ( request ) ; <END_BUG> builder . startObject ( ) ; response . toXContent ( builder , request ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; } catch ( Exception e ) { onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>XContentBuilder builder = restContentBuilder ( request , false ) ;
public class AndroidApplication extends Activity implements Application { protected AndroidGraphics graphics ; protected AndroidInput input ; protected AndroidAudio audio ; protected AndroidFiles files ; protected AndroidNet net ; protected ApplicationListener listener ; protected Handler handler ; protected boolean firstResume = true ; protected final Array < Runnable > runnables = new Array < Runnable > ( ) ; protected final Array < Runnable > executedRunnables = new Array < Runnable > ( ) ; protected WakeLock wakeLock = null ; protected int logLevel = LOG_INFO ; public void initialize ( ApplicationListener listener , boolean useGL2IfAvailable ) { } public void initialize ( ApplicationListener listener , AndroidApplicationConfiguration config ) { graphics = new AndroidGraphics ( this , config , ( ( config . resolutionStrategy ) == null ? new FillResolutionStrategy ( ) : config . resolutionStrategy ) ) ; input = new AndroidInput ( this , graphics . view , config ) ; audio = new AndroidAudio ( this , config ) ; files = new AndroidFiles ( this . getAssets ( ) , this . getFilesDir ( ) . getAbsolutePath ( ) ) ; <START_BUG> net = new AndroidNet ( ) ; <END_BUG> this . listener = listener ; this . handler = new Handler ( ) ; Gdx . app = this ; Gdx . input = this . getInput ( ) ; Gdx . audio = this . getAudio ( ) ; Gdx . files = this . getFiles ( ) ; Gdx . graphics = this . getGraphics ( ) ; Gdx . net = this . getNet ( ) ; try { requestWindowFeature ( FEATURE_NO_TITLE ) ; } catch ( Exception ex ) { log ( "AndroidApplication" , "Content<seq2seq4repair_space>already<seq2seq4repair_space>displayed,<seq2seq4repair_space>cannot<seq2seq4repair_space>request<seq2seq4repair_space>FEATURE_NO_TITLE" , ex ) ; } getWindow ( ) . setFlags ( FLAG_FULLSCREEN , FLAG_FULLSCREEN ) ; getWindow ( ) . clearFlags ( FLAG_FORCE_NOT_FULLSCREEN ) ; setContentView ( graphics . getView ( ) , createLayoutParams ( ) ) ; createWakeLock ( config ) ; } protected LayoutParams createLayoutParams ( ) { } protected void createWakeLock ( AndroidApplicationConfiguration config ) { } public View initializeForView ( ApplicationListener listener , boolean useGL2IfAvailable ) { } public View initializeForView ( ApplicationListener listener , AndroidApplicationConfiguration config ) { } @ Override protected void onPause ( ) { } @ Override protected void onResume ( ) { } @ Override protected void onDestroy ( ) { } @ Override public Audio getAudio ( ) { } @ Override public Files getFiles ( ) { } @ Override public Graphics getGraphics ( ) { } @ Override public Input getInput ( ) { } @ Override public Net getNet ( ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } @ Override public Preferences getPreferences ( String name ) { } AndroidClipboard clipboard ; @ Override public Clipboard getClipboard ( ) { } @ Override public void postRunnable ( Runnable runnable ) { } @ Override public void onConfigurationChanged ( Configuration config ) { } @ Override public void exit ( ) { } @ Override public void debug ( String tag , String message ) { } @ Override public void debug ( String tag , String message , Throwable exception ) { } @ Override public void log ( String tag , String message ) { } @ Override public void log ( String tag , String message , Exception exception ) { } @ Override public void error ( String tag , String message ) { } @ Override public void error ( String tag , String message , Throwable exception ) { } @ Override public void setLogLevel ( int logLevel ) { } }<BUG2FIX>net = new AndroidNet ( this ) ;
public class GeoHashGridParser implements Aggregator . Parser { @ Override public String type ( ) { } public static final int DEFAULT_PRECISION = 5 ; public static final int DEFAULT_MAX_NUM_CELLS = 10000 ; @ Override public AggregatorFactory parse ( String aggregationName , XContentParser parser , SearchContext context ) throws IOException { String field = null ; int precision = GeoHashGridParser . DEFAULT_PRECISION ; int requiredSize = GeoHashGridParser . DEFAULT_MAX_NUM_CELLS ; int shardSize = - 1 ; XContentParser . Token token ; String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . VALUE_STRING ) ) { if ( "field" . equals ( currentFieldName ) ) { field = parser . text ( ) ; } } else if ( token == ( Token . VALUE_NUMBER ) ) { if ( "precision" . equals ( currentFieldName ) ) { precision = parser . intValue ( ) ; } else if ( "size" . equals ( currentFieldName ) ) { requiredSize = parser . intValue ( ) ; } else if ( ( "shard_size" . equals ( currentFieldName ) ) || ( "shardSize" . equals ( currentFieldName ) ) ) { shardSize = parser . intValue ( ) ; } } } if ( shardSize == 0 ) { shardSize = Integer . MAX_VALUE ; } if ( requiredSize == 0 ) { requiredSize = Integer . MAX_VALUE ; } if ( shardSize < 0 ) { shardSize = BucketUtils . suggestShardSideQueueSize ( requiredSize , context . numberOfShards ( ) ) ; } if ( shardSize < requiredSize ) { shardSize = requiredSize ; } <START_BUG> ValuesSourceConfig < GeoPointValuesSource > config = new ValuesSourceConfig < GeoPointValuesSource > ( GeoPointValuesSource . class ) ; <END_BUG> if ( field == null ) { return new GeoHashGridParser . GeoGridFactory ( aggregationName , config , precision , requiredSize , shardSize ) ; } FieldMapper < ? > mapper = context . smartNameFieldMapper ( field ) ; if ( mapper == null ) { config . unmapped ( true ) ; return new GeoHashGridParser . GeoGridFactory ( aggregationName , config , precision , requiredSize , shardSize ) ; } IndexFieldData < ? > indexFieldData = context . fieldData ( ) . getForField ( mapper ) ; config . fieldContext ( new FieldContext ( field , indexFieldData ) ) ; return new GeoHashGridParser . GeoGridFactory ( aggregationName , config , precision , requiredSize , shardSize ) ; } private static class GeoGridFactory extends ValueSourceAggregatorFactory < GeoPointValuesSource > { private int precision ; private int requiredSize ; private int shardSize ; public GeoGridFactory ( String name , ValuesSourceConfig < GeoPointValuesSource > valueSourceConfig , int precision , int requiredSize , int shardSize ) { } @ Override protected Aggregator createUnmapped ( AggregationContext aggregationContext , Aggregator parent ) { } @ Override protected Aggregator create ( final GeoPointValuesSource valuesSource , long expectedBucketsCount , AggregationContext aggregationContext , Aggregator parent ) { } private static class CellValues extends LongValues { private GeoPointValuesSource geoPointValues ; private GeoPointValues geoValues ; private int precision ; protected CellValues ( GeoPointValuesSource geoPointValues , int precision ) { } @ Override public int setDocument ( int docId ) { } @ Override public long nextValue ( ) { } } private static class CellIdSource extends FieldDataSource . Numeric { private final LongValues values ; private MetaData metaData ; public CellIdSource ( LongValues values , MetaData delegate ) { } @ Override public boolean isFloatingPoint ( ) { } @ Override public LongValues longValues ( ) { } @ Override public DoubleValues doubleValues ( ) { } @ Override public BytesValues bytesValues ( ) { } @ Override public MetaData metaData ( ) { } } } }<BUG2FIX>ValuesSourceConfig < GeoPointValuesSource > config = new ValuesSourceConfig ( GeoPointValuesSource . class ) ;
public class Xml { private final Array < Xml . Element > elements = new Array ( 8 ) ; private Xml . Element root ; private Xml . Element current ; private final StringBuilder textBuffer = new StringBuilder ( 64 ) ; public Xml . Element parse ( String xml ) { } public Xml . Element parse ( Reader reader ) throws IOException { } public Xml . Element parse ( InputStream input ) throws IOException { } public Xml . Element parse ( FileHandle file ) throws IOException { } public Xml . Element parse ( char [ ] data , int offset , int length ) { } private static byte [ ] init__xml_actions_0 ( ) { } private static final byte [ ] _xml_actions = Xml . init__xml_actions_0 ( ) ; private static byte [ ] init__xml_key_offsets_0 ( ) { } private static final byte [ ] _xml_key_offsets = Xml . init__xml_key_offsets_0 ( ) ; private static char [ ] init__xml_trans_keys_0 ( ) { } private static final char [ ] _xml_trans_keys = Xml . init__xml_trans_keys_0 ( ) ; private static byte [ ] init__xml_single_lengths_0 ( ) { } private static final byte [ ] _xml_single_lengths = Xml . init__xml_single_lengths_0 ( ) ; private static byte [ ] init__xml_range_lengths_0 ( ) { } private static final byte [ ] _xml_range_lengths = Xml . init__xml_range_lengths_0 ( ) ; private static short [ ] init__xml_index_offsets_0 ( ) { } private static final short [ ] _xml_index_offsets = Xml . init__xml_index_offsets_0 ( ) ; private static byte [ ] init__xml_indicies_0 ( ) { } private static final byte [ ] _xml_indicies = Xml . init__xml_indicies_0 ( ) ; private static byte [ ] init__xml_trans_targs_0 ( ) { } private static final byte [ ] _xml_trans_targs = Xml . init__xml_trans_targs_0 ( ) ; private static byte [ ] init__xml_trans_actions_0 ( ) { } private static final byte [ ] _xml_trans_actions = Xml . init__xml_trans_actions_0 ( ) ; static final int xml_start = 1 ; static final int xml_first_final = 34 ; static final int xml_error = 0 ; static final int xml_en_elementBody = 15 ; static final int xml_en_main = 1 ; protected void open ( String name ) { } protected void attribute ( String name , String value ) { } protected String entity ( String name ) { } protected void text ( String text ) { } protected void close ( ) { } public static class Element { private final String name ; private ObjectMap < String , String > attributes ; private Array < Xml . Element > children ; private String text ; public Element ( String name ) { } public String getName ( ) { } public String getAttribute ( String name ) { } public void setAttribute ( String name , String value ) { } public int getChildCount ( ) { } public Xml . Element getChild ( int i ) { } public void addChild ( Xml . Element element ) { } public String getText ( ) { } public void setText ( String text ) { } public String toString ( ) { } public String toString ( String indent ) { } public Xml . Element getChildByName ( String name ) { } public Xml . Element getChildByNameRecursive ( String name ) { } public Array < Xml . Element > getChildrenByName ( String name ) { Array < Xml . Element > children = new Array < Xml . Element > ( ) ; if ( ( this . children ) == null ) return children ; for ( int i = 0 ; i < ( this . children . size ) ; i ++ ) { <START_BUG> Xml . Element child = children . get ( i ) ; <END_BUG> if ( child . name . equals ( name ) ) children . add ( child ) ; } return children ; } } }<BUG2FIX>Xml . Element child = this . children . get ( i ) ;
public class BulletTestCollection extends GdxTest implements InputProcessor , GestureListener { protected final BulletTest [ ] tests = new BulletTest [ ] { new ShootTest ( ) , new BasicShapesTest ( ) , new KinematicTest ( ) , new ConstraintsTest ( ) , new MeshShapeTest ( ) , new ConvexHullTest ( ) , new RayCastTest ( ) , new RayPickRagdollTest ( ) , new InternalTickTest ( ) , new CollisionWorldTest ( ) , new CollisionTest ( ) , new FrustumCullingTest ( ) , new ContactCallbackTest ( ) , new SoftBodyTest ( ) } ; protected int testIndex = 0 ; private Application app = null ; private BitmapFont font ; private Stage hud ; private Label fpsLabel ; private Label titleLabel ; private Label instructLabel ; private int loading = 0 ; @ Override public void render ( ) { } @ Override public void create ( ) { } @ Override public void dispose ( ) { } public void next ( ) { } public void loadnext ( ) { } @ Override public boolean keyDown ( int keycode ) { } @ Override public boolean keyTyped ( char character ) { } @ Override public boolean keyUp ( int keycode ) { } @ Override public boolean touchDown ( int x , int y , int pointer , int button ) { } @ Override public boolean touchDragged ( int x , int y , int pointer ) { } @ Override public boolean touchUp ( int x , int y , int pointer , int button ) { } @ Override public boolean needsGL20 ( ) { <START_BUG> return false ; <END_BUG> } @ Override public boolean mouseMoved ( int x , int y ) { } @ Override public boolean scrolled ( int amount ) { } @ Override public boolean touchDown ( float x , float y , int pointer , int button ) { } @ Override public boolean tap ( float x , float y , int count , int button ) { } @ Override public boolean longPress ( float x , float y ) { } @ Override public boolean fling ( float velocityX , float velocityY , int button ) { } @ Override public boolean pan ( float x , float y , float deltaX , float deltaY ) { } @ Override public boolean zoom ( float originalDistance , float currentDistance ) { } @ Override public boolean pinch ( Vector2 initialFirstPointer , Vector2 initialSecondPointer , Vector2 firstPointer , Vector2 secondPointer ) { } }<BUG2FIX>return true ;
public class BenchmarkNettyLargeMessages { public static void main ( String [ ] args ) throws InterruptedException { final ByteSizeValue payloadSize = new ByteSizeValue ( 10 , ByteSizeUnit . MB ) ; final int NUMBER_OF_ITERATIONS = 100000 ; final int NUMBER_OF_CLIENTS = 5 ; final byte [ ] payload = new byte [ ( ( int ) ( payloadSize . bytes ( ) ) ) ] ; Settings settings = ImmutableSettings . settingsBuilder ( ) . build ( ) ; final ThreadPool threadPool = new ThreadPool ( ) ; final TransportService transportServiceServer = new TransportService ( new org . elasticsearch . transport . netty . NettyTransport ( settings , threadPool ) , threadPool ) . start ( ) ; final TransportService transportServiceClient = new TransportService ( new org . elasticsearch . transport . netty . NettyTransport ( settings , threadPool ) , threadPool ) . start ( ) ; final DiscoveryNode bigNode = new DiscoveryNode ( "big" , new InetSocketTransportAddress ( "localhost" , 9300 ) ) ; final DiscoveryNode smallNode = bigNode ; transportServiceClient . connectToNode ( bigNode ) ; transportServiceClient . connectToNode ( smallNode ) ; transportServiceServer . registerHandler ( "benchmark" , new BaseTransportRequestHandler < BenchmarkMessage > ( ) { @ Override public BenchmarkMessage newInstance ( ) { return new BenchmarkMessage ( ) ; } @ Override public String executor ( ) { return Names . GENERIC ; } @ Override public void messageReceived ( BenchmarkMessage request , TransportChannel channel ) throws Exception { channel . sendResponse ( request ) ; } } ) ; final CountDownLatch latch = new CountDownLatch ( NUMBER_OF_CLIENTS ) ; for ( int i = 0 ; i < NUMBER_OF_CLIENTS ; i ++ ) { new Thread ( new Runnable ( ) { @ Override public void run ( ) { for ( int i = 0 ; i < NUMBER_OF_ITERATIONS ; i ++ ) { BenchmarkMessage message = new BenchmarkMessage ( 1 , payload ) ; transportServiceClient . submitRequest ( bigNode , "benchmark" , message , options ( ) . withLowType ( ) , new BaseTransportResponseHandler < BenchmarkMessage > ( ) { @ Override public BenchmarkMessage newInstance ( ) { return new BenchmarkMessage ( ) ; } @ Override public String executor ( ) { return Names . SAME ; } @ Override public void handleResponse ( BenchmarkMessage response ) { } @ Override public void handleException ( TransportException exp ) { exp . printStackTrace ( ) ; } } ) . txGet ( ) ; } latch . countDown ( ) ; } } ) . start ( ) ; } new Thread ( new Runnable ( ) { @ Override public void run ( ) { <START_BUG> for ( int i = 0 ; i < NUMBER_OF_ITERATIONS ; i ++ ) { <END_BUG> BenchmarkMessage message = new BenchmarkMessage ( 2 , Bytes . EMPTY_ARRAY ) ; long start = System . currentTimeMillis ( ) ; transportServiceClient . submitRequest ( smallNode , "benchmark" , message , options ( ) . withHighType ( ) , new BaseTransportResponseHandler < BenchmarkMessage > ( ) { @ Override public BenchmarkMessage newInstance ( ) { return new BenchmarkMessage ( ) ; } @ Override public String executor ( ) { return Names . SAME ; } @ Override public void handleResponse ( BenchmarkMessage response ) { } @ Override public void handleException ( TransportException exp ) { exp . printStackTrace ( ) ; } } ) . txGet ( ) ; long took = ( System . currentTimeMillis ( ) ) - start ; System . out . println ( ( ( "Took<seq2seq4repair_space>" + took ) + "ms" ) ) ; } } } ) . start ( ) ; latch . await ( ) ; } }<BUG2FIX>for ( int i = 0 ; i < 1 ; i ++ ) {
public class NoneIndexGateway extends AbstractIndexComponent implements IndexGateway { @ Inject public NoneIndexGateway ( Index index , @ IndexSettings Settings indexSettings ) { } @ Override public String type ( ) { } @ Override public Class < ? extends IndexShardGateway > shardGatewayClass ( ) { } @ Override public String toString ( ) { } @ Override <START_BUG> public void close ( boolean delete ) { <END_BUG> } }<BUG2FIX>public void close ( ) {
public class ViewportTest2 extends GdxTest { Array < Viewport > viewports = new Array ( ) ; Viewport viewport ; private SpriteBatch batch ; private Texture texture ; private BitmapFont font ; private OrthographicCamera camera ; public void create ( ) { } public void render ( ) { batch . setProjectionMatrix ( camera . projection ) ; batch . setTransformMatrix ( camera . view ) ; gl . glClear ( GL_COLOR_BUFFER_BIT ) ; batch . begin ( ) ; batch . setColor ( 1 , 1 , 1 , 1 ) ; batch . draw ( texture , ( - 4096 ) , ( - 4096 ) , 4096 , 4096 , 8192 , 8192 , 1 , 1 , 0 , 0 , 0 , 16 , 16 , false , false ) ; batch . setColor ( 1 , 0 , 0 , 1 ) ; batch . draw ( texture , 150 , 100 , 16 , 16 , 32 , 32 , 1 , 1 , 45 , 0 , 0 , 16 , 16 , false , false ) ; font . draw ( batch , viewport . toString ( ) , 150 , 100 ) ; batch . end ( ) ; if ( ( viewport ) instanceof ScalingViewport ) { ScalingViewport scalingViewport = ( ( ScalingViewport ) ( viewport ) ) ; int screenWidth = graphics . getWidth ( ) ; int screenHeight = graphics . getHeight ( ) ; gl . glViewport ( 0 , 0 , screenWidth , screenHeight ) ; batch . getProjectionMatrix ( ) . idt ( ) . setToOrtho2D ( 0 , 0 , screenWidth , screenHeight ) ; batch . getTransformMatrix ( ) . idt ( ) ; batch . begin ( ) ; float leftGutterWidth = scalingViewport . getLeftGutterWidth ( ) ; if ( leftGutterWidth > 0 ) { batch . draw ( texture , 0 , 0 , leftGutterWidth , screenHeight ) ; batch . draw ( texture , scalingViewport . getRightGutterX ( ) , 0 , scalingViewport . getRightGutterWidth ( ) , screenHeight ) ; } float bottomGutterHeight = scalingViewport . getBottomGutterHeight ( ) ; if ( bottomGutterHeight > 0 ) { batch . draw ( texture , 0 , 0 , screenWidth , bottomGutterHeight ) ; batch . draw ( texture , 0 , scalingViewport . getTopGutterY ( ) , screenWidth , scalingViewport . getTopGutterHeight ( ) ) ; } batch . end ( ) ; <START_BUG> viewport . update ( screenWidth , screenHeight ) ; <END_BUG> } } public void resize ( int width , int height ) { } public void dispose ( ) { } }<BUG2FIX>viewport . update ( screenWidth , screenHeight , true ) ;
public class IntArray { public int [ ] items ; public int size ; public boolean ordered ; public IntArray ( ) { } public IntArray ( int capacity ) { } public IntArray ( boolean ordered , int capacity ) { } public IntArray ( IntArray array ) { } public IntArray ( int [ ] array ) { } public IntArray ( boolean ordered , int [ ] array ) { } public void add ( int value ) { } public void addAll ( IntArray array ) { } public void addAll ( IntArray array , int offset , int length ) { } public void addAll ( int [ ] array ) { } public void addAll ( int [ ] array , int offset , int length ) { } public int get ( int index ) { } public void set ( int index , int value ) { } public void insert ( int index , int value ) { } public void swap ( int first , int second ) { } public boolean contains ( int value ) { } public int indexOf ( int value ) { } public int lastIndexOf ( int value ) { } public boolean removeValue ( int value ) { } public int removeIndex ( int index ) { } public boolean removeAll ( IntArray array ) { int size = this . size ; int startSize = size ; int [ ] items = this . items ; for ( int i = 0 , n = array . size ; i < n ; i ++ ) { int item = array . get ( i ) ; <START_BUG> for ( int ii = 0 , nn = size ; ii < nn ; ii ++ ) { <END_BUG> if ( item == ( items [ ii ] ) ) { removeIndex ( ii ) ; size -- ; break ; } } } return size != startSize ; } public int pop ( ) { } public int peek ( ) { } public int first ( ) { } public void clear ( ) { } public void shrink ( ) { } public int [ ] ensureCapacity ( int additionalCapacity ) { } protected int [ ] resize ( int newSize ) { } public void sort ( ) { } public void reverse ( ) { } public void shuffle ( ) { } public void truncate ( int newSize ) { } public int random ( ) { } public int [ ] toArray ( ) { } public boolean equals ( Object object ) { } public String toString ( ) { } public String toString ( String separator ) { } }<BUG2FIX>for ( int ii = 0 ; ii < size ; ii ++ ) {
} indexTime = ( System . currentTimeMillis ( ) ) - time ; } final AtomicInteger translogNumberOfOperations = new AtomicInteger ( ) ; long translogTime = 0 ; if ( ( snapshot . newTranslogCreated ( ) ) || ( snapshot . sameTranslogNewOperations ( ) ) ) { long time = System . currentTimeMillis ( ) ; if ( ( snapshot . newTranslogCreated ( ) ) && ( ( translogBlob ) != null ) ) { translogBlob . close ( ) ; translogBlob = null ; } if ( ( translogBlob ) == null ) { try { translogBlob = translogContainer . appendBlob ( ( "translog-" + ( translogSnapshot . translogId ( ) ) ) ) ; } catch ( IOException e ) { throw new IndexShardGatewaySnapshotFailedException ( shardId , "Failed<seq2seq4repair_space>to<seq2seq4repair_space>create<seq2seq4repair_space>translog" , e ) ; } } final CountDownLatch latch = new CountDownLatch ( 1 ) ; final AtomicReference < Throwable > failure = new AtomicReference < Throwable > ( ) ; translogBlob . append ( new AppendableBlobContainer . AppendBlobListener ( ) { @ Override public void withStream ( StreamOutput os ) throws IOException { if ( ! ( snapshot . newTranslogCreated ( ) ) ) { translogSnapshot . seekForward ( snapshot . lastTranslogPosition ( ) ) ; } FastByteArrayOutputStream bos = cachedBos . get ( ) ; if ( bos == null ) { bos = new FastByteArrayOutputStream ( ) ; cachedBos = new SoftReference < FastByteArrayOutputStream > ( bos ) ; } int totalNumberOfOperations = 0 ; OutputStreamStreamOutput bosOs = new OutputStreamStreamOutput ( bos ) ; while ( translogSnapshot . hasNext ( ) ) { bos . reset ( ) ; TranslogStreams . writeTranslogOperation ( bosOs , translogSnapshot . next ( ) ) ; bosOs . flush ( ) ; os . writeVInt ( bos . size ( ) ) ; os . writeBytes ( bos . unsafeByteArray ( ) , bos . size ( ) ) ; totalNumberOfOperations ++ ; } translogNumberOfOperations . set ( totalNumberOfOperations ) ; } @ Override public void onCompleted ( ) { latch . countDown ( ) ; } @ Override public void onFailure ( Throwable t ) { failure . set ( t ) ; latch . countDown ( ) ; } } ) ; try { latch . await ( ) ; } catch ( InterruptedException e ) { failure . set ( e ) ; } if ( ( failure . get ( ) ) != null ) { throw new IndexShardGatewaySnapshotFailedException ( shardId , "Failed<seq2seq4repair_space>to<seq2seq4repair_space>snapshot<seq2seq4repair_space>translog" , failure . get ( ) ) ; } translogTime = ( System . currentTimeMillis ( ) ) - time ; } if ( indexDirty ) { try { indexNumberOfFiles ++ ; if ( indicesBlobs . containsKey ( snapshotIndexCommit . getSegmentsFileName ( ) ) ) { cachedMd5 . remove ( snapshotIndexCommit . getSegmentsFileName ( ) ) ; indexContainer . deleteBlob ( snapshotIndexCommit . getSegmentsFileName ( ) ) ; } StoreFileMetaData snapshotFileMetaData = store . metaDataWithMd5 ( snapshotIndexCommit . getSegmentsFileName ( ) ) ; indexTotalFilesSize += snapshotFileMetaData . sizeInBytes ( ) ; long time = System . currentTimeMillis ( ) ; CountDownLatch latch = new CountDownLatch ( 1 ) ; CopyOnWriteArrayList < Throwable > failures = new CopyOnWriteArrayList < Throwable > ( ) ; snapshotFile ( snapshotIndexCommit . getDirectory ( ) , snapshotFileMetaData , latch , failures ) ; latch . await ( ) ; if ( ! ( failures . isEmpty ( ) ) ) { throw new IndexShardGatewaySnapshotFailedException ( shardId ( ) , "Failed<seq2seq4repair_space>to<seq2seq4repair_space>perform<seq2seq4repair_space>snapshot<seq2seq4repair_space>(segment<seq2seq4repair_space>index<seq2seq4repair_space>file)" , failures . get ( ( ( failures . size ( ) ) - 1 ) ) ) ; } indexTime += ( System . currentTimeMillis ( ) ) - time ; } catch ( Exception e ) { if ( e instanceof IndexShardGatewaySnapshotFailedException ) { throw ( ( IndexShardGatewaySnapshotFailedException ) ( e ) ) ; } throw new IndexShardGatewaySnapshotFailedException ( shardId ( ) , ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>finalize<seq2seq4repair_space>index<seq2seq4repair_space>snapshot<seq2seq4repair_space>into<seq2seq4repair_space>[" + ( snapshotIndexCommit . getSegmentsFileName ( ) ) ) + "]" ) , e ) ; } } if ( snapshot . newTranslogCreated ( ) ) { try { translogContainer . deleteBlob ( ( "translog-" + ( snapshot . lastTranslogId ( ) ) ) ) ; <START_BUG> } catch ( IOException e ) { <END_BUG> } } if ( indexDirty ) { for ( BlobMetaData md : virtualIndicesBlobs . values ( ) ) { boolean found = false ; for ( final String fileName : snapshotIndexCommit . getFiles ( ) ) { if ( md . name ( ) . equals ( fileName ) ) { found = true ; break ; } } if ( ! found ) { try { cachedMd5 . remove ( md . name ( ) ) ; indexContainer . deleteBlobsByPrefix ( md . name ( ) ) ; } catch ( IOException e ) { logger . debug ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>delete<seq2seq4repair_space>unused<seq2seq4repair_space>index<seq2seq4repair_space>files,<seq2seq4repair_space>will<seq2seq4repair_space>retry<seq2seq4repair_space>later..." , e ) ; } } } } return new SnapshotStatus ( new TimeValue ( ( ( System . currentTimeMillis ( ) ) - totalTimeStart ) ) , new SnapshotStatus . Index ( indexNumberOfFiles , new ByteSizeValue ( indexTotalFilesSize ) , new TimeValue ( indexTime ) ) , new SnapshotStatus . Translog ( translogNumberOfOperations . get ( ) , new TimeValue ( translogTime ) ) ) ; } @ Override public RecoveryStatus recover ( ) throws IndexShardGatewayRecoveryException { } private Translog recoverTranslog ( ) throws IndexShardGatewayRecoveryException { } private Index recoverIndex ( ) throws IndexShardGatewayRecoveryException { } private void recoverFile ( final BlobMetaData fileToRecover , final ImmutableMap < String , BlobMetaData > blobs , final CountDownLatch latch , final List < Throwable > failures ) { } private void snapshotFile ( Directory dir , final StoreFileMetaData fileMetaData , final CountDownLatch latch , final List < Throwable > failures ) throws IOException { } public static ImmutableMap < String , BlobMetaData > buildVirtualBlobs ( ImmutableBlobContainer container , ImmutableMap < String , BlobMetaData > blobs , @ Nullable Map < String , String > cachedMd5 ) { } }<BUG2FIX>} catch ( Exception e ) {
public class PerlinNoiseGenerator { public static float [ ] [ ] generateWhiteNoise ( int width , int height ) { } public static float interpolate ( float x0 , float x1 , float alpha ) { } public static float [ ] [ ] generateSmoothNoise ( float [ ] [ ] baseNoise , int octave ) { } public static float [ ] [ ] generatePerlinNoise ( float [ ] [ ] baseNoise , int octaveCount ) { } public static float [ ] [ ] generatePerlinNoise ( int width , int height , int octaveCount ) { } public static byte [ ] generateHeightMap ( int width , int height , int min , int max , int octaveCount ) { } public static Pixmap generatePixmap ( int width , int height , int min , int max , int octaveCount ) { } public static void generateVoxels ( VoxelWorld voxelWorld , int min , int max , int octaveCount ) { <START_BUG> byte [ ] heightMap = PerlinNoiseGenerator . generateHeightMap ( voxelWorld . voxelsX , voxelWorld . voxelsZ , min , max , 8 ) ; <END_BUG> int idx = 0 ; for ( int z = 0 ; z < ( voxelWorld . voxelsZ ) ; z ++ ) { for ( int x = 0 ; x < ( voxelWorld . voxelsX ) ; x ++ ) { voxelWorld . setColumn ( x , heightMap [ ( idx ++ ) ] , z , ( ( byte ) ( 1 ) ) ) ; } } } }<BUG2FIX>byte [ ] heightMap = PerlinNoiseGenerator . generateHeightMap ( voxelWorld . voxelsX , voxelWorld . voxelsZ , min , max , octaveCount ) ;
public class UserRepositoryListFragment extends PagedItemFragment < Repository > { @ Inject private RepositoryService service ; @ InjectExtra ( Intents . EXTRA_USER ) private User user ; @ Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; <START_BUG> setEmptyText ( getString ( no_repositories ) ) ; <END_BUG> } @ Override protected ResourcePager < Repository > createPager ( ) { } @ Override protected int getLoadingMessage ( ) { } @ Override protected ItemListAdapter < Repository , ? extends ItemView > createAdapter ( List < Repository > items ) { } @ Override public void onListItemClick ( ListView list , View v , int position , long id ) { } }<BUG2FIX>setEmptyText ( no_repositories ) ;
public class BranchFileViewActivity extends BaseActivity implements LoaderCallbacks < CharSequence > { private static final String TAG = "BranchFileViewActivity" ; private static final String ARG_TEXT = "text" ; private static final String ARG_REPO = "repo" ; public static Intent createIntent ( Repository repository , String branch , String file , String blobSha ) { } private Repository repo ; private String sha ; private String path ; private String file ; private String branch ; private boolean isMarkdownFile ; private String renderedMarkdown ; private Blob blob ; private ProgressBar loadingBar ; private WebView codeView ; private SourceEditor editor ; private MenuItem markdownItem ; @ Inject private AvatarLoader avatars ; @ Inject private HttpImageGetter imageGetter ; @ Override protected void onCreate ( Bundle savedInstanceState ) { } @ Override public boolean onCreateOptionsMenu ( final Menu optionsMenu ) { } @ Override public boolean onOptionsItemSelected ( MenuItem item ) { } @ Override public Loader < CharSequence > onCreateLoader ( int loader , Bundle args ) { } @ Override public void onLoadFinished ( Loader < CharSequence > loader , CharSequence rendered ) { } @ Override public void onLoaderReset ( Loader < CharSequence > loader ) { } private void shareFile ( ) { } private void loadMarkdown ( ) { ViewUtils . setGone ( loadingBar , false ) ; ViewUtils . setGone ( codeView , true ) ; String markdown = new String ( EncodingUtils . fromBase64 ( blob . getContent ( ) ) ) ; Bundle args = new Bundle ( ) ; args . putCharSequence ( BranchFileViewActivity . ARG_TEXT , markdown ) ; if ( ( repo ) instanceof Serializable ) <START_BUG> args . putSerializable ( BranchFileViewActivity . ARG_REPO , ( ( Serializable ) ( repo ) ) ) ; <END_BUG> getSupportLoaderManager ( ) . restartLoader ( 0 , args , this ) ; } private void loadContent ( ) { } }<BUG2FIX>args . putSerializable ( BranchFileViewActivity . ARG_REPO , repo ) ;
public abstract class FieldMapperListener { public static class Aggregator extends FieldMapperListener { public final List < FieldMapper > mappers = new ArrayList < > ( ) ; @ Override public void fieldMapper ( FieldMapper fieldMapper ) { } } public abstract void fieldMapper ( FieldMapper fieldMapper ) { } <START_BUG> public void fieldMappers ( Iterable < FieldMapper > fieldMappers ) { <END_BUG> for ( FieldMapper mapper : fieldMappers ) { fieldMapper ( mapper ) ; } } }<BUG2FIX>public void fieldMappers ( List < FieldMapper > fieldMappers ) {
public class StageTest extends GdxTest implements InputProcessor { private static final int NUM_GROUPS = 5 ; private static final int NUM_SPRITES = ( ( int ) ( Math . sqrt ( ( 400 / ( StageTest . NUM_GROUPS ) ) ) ) ) ; private static final float SPACING = 5 ; ShapeRenderer renderer ; Stage stage ; Stage ui ; Texture texture ; Texture uiTexture ; BitmapFont font ; boolean rotateSprites = false ; boolean scaleSprites = false ; float angle ; List < Image > images = new ArrayList < Image > ( ) ; float scale = 1 ; float vScale = 1 ; Label fps ; @ Override public void create ( ) { } private void fillGroup ( Group group , Texture texture ) { } @ Override public void render ( ) { gl . glViewport ( 0 , 0 , graphics . getWidth ( ) , graphics . getHeight ( ) ) ; gl . glClearColor ( 0.2F , 0.2F , 0.2F , 1 ) ; gl . glClear ( GL_COLOR_BUFFER_BIT ) ; if ( input . isTouched ( ) ) { Vector2 stageCoords = Vector2 . tmp ; stage . screenToStageCoordinates ( stageCoords . set ( input . getX ( ) , input . getY ( ) ) ) ; <START_BUG> Actor actor = stage . hit ( stageCoords . x , stageCoords . y ) ; <END_BUG> if ( actor instanceof Image ) ( ( Image ) ( actor ) ) . setColor ( ( ( float ) ( Math . random ( ) ) ) , ( ( float ) ( Math . random ( ) ) ) , ( ( float ) ( Math . random ( ) ) ) , ( 0.5F + ( 0.5F * ( ( float ) ( Math . random ( ) ) ) ) ) ) ; } Array < Actor > actors = stage . getActors ( ) ; int len = actors . size ; if ( rotateSprites ) { for ( int i = 0 ; i < len ; i ++ ) actors . get ( i ) . rotate ( ( ( graphics . getDeltaTime ( ) ) * 10 ) ) ; } scale += ( vScale ) * ( graphics . getDeltaTime ( ) ) ; if ( ( scale ) > 1 ) { scale = 1 ; vScale = - ( vScale ) ; } if ( ( scale ) < 0.5F ) { scale = 0.5F ; vScale = - ( vScale ) ; } len = images . size ( ) ; for ( int i = 0 ; i < len ; i ++ ) { Image img = images . get ( i ) ; if ( rotateSprites ) img . rotate ( ( ( - 40 ) * ( graphics . getDeltaTime ( ) ) ) ) ; else img . setRotation ( 0 ) ; if ( scaleSprites ) { img . setScale ( scale ) ; } else { img . setScale ( 1 ) ; } img . invalidate ( ) ; } stage . draw ( ) ; renderer . begin ( Point ) ; renderer . setColor ( 1 , 0 , 0 , 1 ) ; len = actors . size ; for ( int i = 0 ; i < len ; i ++ ) { Group group = ( ( Group ) ( actors . get ( i ) ) ) ; renderer . point ( ( ( group . getX ( ) ) + ( group . getOriginX ( ) ) ) , ( ( group . getY ( ) ) + ( group . getOriginY ( ) ) ) , 0 ) ; } renderer . end ( ) ; fps . setText ( ( ( ( ( ( "fps:<seq2seq4repair_space>" + ( graphics . getFramesPerSecond ( ) ) ) + ",<seq2seq4repair_space>actors<seq2seq4repair_space>" ) + ( images . size ( ) ) ) + ",<seq2seq4repair_space>groups<seq2seq4repair_space>" ) + ( actors . size ) ) ) ; ui . draw ( ) ; } @ Override public boolean touchDown ( int x , int y , int pointer , int button ) { } @ Override public void dispose ( ) { } }<BUG2FIX>Actor actor = stage . hit ( stageCoords . x , stageCoords . y , true ) ;
public class SpriteBatch implements Batch { private Mesh mesh ; private Mesh [ ] buffers ; private int currBufferIdx = 0 ; private final float [ ] vertices ; private int idx = 0 ; private Texture lastTexture = null ; private float invTexWidth = 0 ; private float invTexHeight = 0 ; private boolean drawing = false ; private final Matrix4 transformMatrix = new Matrix4 ( ) ; private final Matrix4 projectionMatrix = new Matrix4 ( ) ; private final Matrix4 combinedMatrix = new Matrix4 ( ) ; private boolean blendingDisabled = false ; private int blendSrcFunc = GL11 . GL_SRC_ALPHA ; private int blendDstFunc = GL11 . GL_ONE_MINUS_SRC_ALPHA ; private final ShaderProgram shader ; private ShaderProgram customShader = null ; private boolean ownsShader ; float color = WHITE . toFloatBits ( ) ; private Color tempColor = new Color ( 1 , 1 , 1 , 1 ) ; public int renderCalls = 0 ; public int totalRenderCalls = 0 ; public int maxSpritesInBatch = 0 ; public SpriteBatch ( ) { } public SpriteBatch ( int size ) { } public SpriteBatch ( int size , ShaderProgram defaultShader ) { } public SpriteBatch ( int size , int buffers ) { } public SpriteBatch ( int size , int buffers , ShaderProgram defaultShader ) { } public static ShaderProgram createDefaultShader ( ) { } @ Override public void begin ( ) { } @ Override public void end ( ) { } @ Override public void setColor ( Color tint ) { } @ Override public void setColor ( float r , float g , float b , float a ) { } @ Override public void setColor ( float color ) { } @ Override public Color getColor ( ) { int intBits = NumberUtils . floatToIntColor ( color ) ; <START_BUG> Color color = this . tempColor ; <END_BUG> color . r = ( intBits & 255 ) / 255.0F ; color . g = ( ( intBits > > > 8 ) & 255 ) / 255.0F ; color . b = ( ( intBits > > > 16 ) & 255 ) / 255.0F ; color . a = ( ( intBits > > > 24 ) & 255 ) / 255.0F ; return color ; } @ Override public void draw ( Texture texture , float x , float y , float originX , float originY , float width , float height , float scaleX , float scaleY , float rotation , int srcX , int srcY , int srcWidth , int srcHeight , boolean flipX , boolean flipY ) { } @ Override public void draw ( Texture texture , float x , float y , float width , float height , int srcX , int srcY , int srcWidth , int srcHeight , boolean flipX , boolean flipY ) { } @ Override public void draw ( Texture texture , float x , float y , int srcX , int srcY , int srcWidth , int srcHeight ) { } @ Override public void draw ( Texture texture , float x , float y , float width , float height , float u , float v , float u2 , float v2 ) { } @ Override public void draw ( Texture texture , float x , float y ) { } @ Override public void draw ( Texture texture , float x , float y , float width , float height ) { } @ Override public void draw ( Texture texture , float [ ] spriteVertices , int offset , int count ) { } @ Override public void draw ( TextureRegion region , float x , float y ) { } @ Override public void draw ( TextureRegion region , float x , float y , float width , float height ) { } @ Override public void draw ( TextureRegion region , float x , float y , float originX , float originY , float width , float height , float scaleX , float scaleY , float rotation ) { } @ Override public void draw ( TextureRegion region , float x , float y , float originX , float originY , float width , float height , float scaleX , float scaleY , float rotation , boolean clockwise ) { } @ Override public void flush ( ) { } @ Override public void disableBlending ( ) { } @ Override public void enableBlending ( ) { } @ Override public void setBlendFunction ( int srcFunc , int dstFunc ) { } @ Override public int getBlendSrcFunc ( ) { } @ Override public int getBlendDstFunc ( ) { } @ Override public void dispose ( ) { } @ Override public Matrix4 getProjectionMatrix ( ) { } @ Override public Matrix4 getTransformMatrix ( ) { } @ Override public void setProjectionMatrix ( Matrix4 projection ) { } @ Override public void setTransformMatrix ( Matrix4 transform ) { } private void setupMatrices ( ) { } private void switchTexture ( Texture texture ) { } @ Override public void setShader ( ShaderProgram shader ) { } @ Override public boolean isBlendingEnabled ( ) { } }<BUG2FIX>Color color = tempColor ;
public class ObjectSet < T > implements Iterable < T > { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; public int size ; T [ ] keyTable ; int capacity ; int stashSize ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private ObjectSet . SetIterator iterator1 ; private ObjectSet . SetIterator iterator2 ; public ObjectSet ( ) { } public ObjectSet ( int initialCapacity ) { } public ObjectSet ( int initialCapacity , float loadFactor ) { } public ObjectSet ( ObjectSet set ) { } public boolean add ( T key ) { } public void addAll ( Array < ? extends T > array ) { } public void addAll ( Array < ? extends T > array , int offset , int length ) { } public void addAll ( T ... array ) { } public void addAll ( T [ ] array , int offset , int length ) { } public void addAll ( ObjectSet < T > set ) { } private void addResize ( T key ) { } private void push ( T insertKey , int index1 , T key1 , int index2 , T key2 , int index3 , T key3 ) { } private void addStash ( T key ) { } public boolean remove ( T key ) { } boolean removeStash ( T key ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean contains ( T key ) { } private boolean containsKeyStash ( T key ) { } public T first ( ) { } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( int h ) { } private int hash3 ( int h ) { } public String toString ( ) { } public String toString ( String separator ) { } public ObjectSet . SetIterator < T > iterator ( ) { } public static < T > ObjectSet < T > with ( T ... array ) { } public static class SetIterator < K > implements Iterable < K > , Iterator < K > { public boolean hasNext ; final ObjectSet < K > set ; int nextIndex ; int currentIndex ; boolean valid = true ; public SetIterator ( ObjectSet < K > set ) { } public void reset ( ) { } void findNextIndex ( ) { } public void remove ( ) { if ( ( currentIndex ) < 0 ) throw new IllegalStateException ( "next<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>called<seq2seq4repair_space>before<seq2seq4repair_space>remove." ) ; if ( ( currentIndex ) >= ( set . capacity ) ) { set . removeStashIndex ( currentIndex ) ; <START_BUG> nextIndex = currentIndex ; <END_BUG> findNextIndex ( ) ; } else { set . keyTable [ currentIndex ] = null ; } currentIndex = - 1 ; ( set . size ) -- ; } public boolean hasNext ( ) { } public K next ( ) { } public Iterator < K > iterator ( ) { } public Array < K > toArray ( ) { } } }<BUG2FIX>nextIndex = ( currentIndex ) - 1 ;
public class RestNodesShutdownAction extends BaseRestHandler { @ Inject public RestNodesShutdownAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { String [ ] nodesIds = RestActions . splitNodes ( request . param ( "nodeId" ) ) ; NodesShutdownRequest nodesShutdownRequest = new NodesShutdownRequest ( nodesIds ) ; nodesShutdownRequest . listenerThreaded ( false ) ; nodesShutdownRequest . delay ( request . paramAsTime ( "delay" , nodesShutdownRequest . delay ( ) ) ) ; nodesShutdownRequest . exit ( request . paramAsBoolean ( "exit" , nodesShutdownRequest . exit ( ) ) ) ; client . admin ( ) . cluster ( ) . nodesShutdown ( nodesShutdownRequest , new org . elasticsearch . action . ActionListener < NodesShutdownResponse > ( ) { @ Override public void onResponse ( NodesShutdownResponse response ) { try { XContentBuilder builder = restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( "cluster_name" , response . getClusterName ( ) . value ( ) ) ; builder . startObject ( "nodes" ) ; for ( DiscoveryNode node : response . getNodes ( ) ) { builder . startObject ( node . id ( ) , NONE ) ; builder . field ( "name" , node . name ( ) , NONE ) ; builder . endObject ( ) ; } builder . endObject ( ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class PixmapBlendingTest extends GdxTest { private SpriteBatch spriteBatch ; private Texture text ; private Sprite logoSprite ; private Sprite test3 ; private Sprite test4 ; private Pixmap pixD ; private Pixmap pixS1 ; private Pixmap pixS2 ; InputProcessor inputProcessor ; @ Override public void create ( ) { if ( ( spriteBatch ) != null ) return ; spriteBatch = new SpriteBatch ( ) ; Matrix4 transform = new Matrix4 ( ) ; transform . setToTranslation ( 0 , graphics . getHeight ( ) , 0 ) ; transform . mul ( new Matrix4 ( ) . setToScaling ( 1 , ( - 1 ) , 1 ) ) ; spriteBatch . setTransformMatrix ( transform ) ; pixS1 = graphics . newPixmap ( files . getFileHandle ( "data/test4.png" , Internal ) ) ; pixS2 = graphics . newPixmap ( files . getFileHandle ( "data/test3.png" , Internal ) ) ; pixD = graphics . newPixmap ( 64 , 128 , RGBA8888 ) ; pixD . drawPixmap ( pixS1 , 0 , 0 , 0 , 0 , 76 , 76 ) ; pixD . drawPixmap ( pixS2 , 0 , 0 , 0 , 0 , 76 , 76 ) ; logoSprite = new Sprite ( graphics . newUnmanagedTexture ( pixD , Nearest , Linear , ClampToEdge , ClampToEdge ) ) ; <START_BUG> logoSprite . getRegion ( ) . flip ( false , true ) ; <END_BUG> } @ Override public void render ( ) { } public boolean needsGL20 ( ) { } }<BUG2FIX>logoSprite . flip ( false , true ) ;
public class Stage extends InputAdapter implements Disposable { private float width ; private float height ; private float gutterWidth ; private float gutterHeight ; private float centerX ; private float centerY ; private Camera camera ; private final SpriteBatch batch ; private final boolean ownsBatch ; private Group root ; private final Vector2 stageCoords = new Vector2 ( ) ; private Actor [ ] pointerOverActors = new Actor [ 20 ] ; private boolean [ ] pointerTouched = new boolean [ 20 ] ; private int [ ] pointerScreenX = new int [ 20 ] ; private int [ ] pointerScreenY = new int [ 20 ] ; private int mouseScreenX ; private int mouseScreenY ; private Actor mouseOverActor ; private Actor keyboardFocus ; private Actor scrollFocus ; private SnapshotArray < Stage . TouchFocus > touchFocuses = new SnapshotArray ( true , 4 , Stage . TouchFocus . class ) ; public Stage ( ) { } public Stage ( float width , float height , boolean stretch ) { } public Stage ( float width , float height , boolean stretch , SpriteBatch batch ) { } private void initialize ( float width , float height , boolean stretch ) { } public void setViewport ( float width , float height , boolean keepAspectRatio ) { } public void draw ( ) { } public void act ( ) { } public void act ( float delta ) { } private Actor fireEnterAndExit ( Actor overLast , int screenX , int screenY , int pointer ) { screenToStageCoordinates ( stageCoords . set ( screenX , screenY ) ) ; <START_BUG> Actor over = hit ( stageCoords . x , stageCoords . y , false ) ; <END_BUG> if ( over == overLast ) return overLast ; InputEvent event = Pools . obtain ( InputEvent . class ) ; event . setStage ( this ) ; event . setStageX ( stageCoords . x ) ; event . setStageY ( stageCoords . y ) ; event . setPointer ( pointer ) ; if ( overLast != null ) { event . setType ( exit ) ; event . setRelatedActor ( over ) ; overLast . fire ( event ) ; } if ( over != null ) { event . setType ( enter ) ; event . setRelatedActor ( overLast ) ; over . fire ( event ) ; } Pools . free ( event ) ; return over ; } public boolean touchDown ( int screenX , int screenY , int pointer , int button ) { } public boolean touchDragged ( int screenX , int screenY , int pointer ) { } public boolean touchUp ( int screenX , int screenY , int pointer , int button ) { } public boolean mouseMoved ( int screenX , int screenY ) { } public boolean scrolled ( int amount ) { } public boolean keyDown ( int keyCode ) { } public boolean keyUp ( int keyCode ) { } public boolean keyTyped ( char character ) { } public void addTouchFocus ( EventListener listener , Actor listenerActor , Actor target , int pointer , int button ) { } public void removeTouchFocus ( EventListener listener , Actor listenerActor , Actor target , int pointer , int button ) { } public void cancelTouchFocus ( ) { } public void cancelTouchFocus ( EventListener listener , Actor actor ) { } public void addActor ( Actor actor ) { } public Array < Actor > getActors ( ) { } public boolean addListener ( EventListener listener ) { } public boolean removeListener ( EventListener listener ) { } public boolean addCaptureListener ( EventListener listener ) { } public boolean removeCaptureListener ( EventListener listener ) { } public void clear ( ) { } public void unfocusAll ( ) { } public void unfocus ( Actor actor ) { } public void setKeyboardFocus ( Actor actor ) { } public Actor getKeyboardFocus ( ) { } public void setScrollFocus ( Actor actor ) { } public Actor getScrollFocus ( ) { } public float getWidth ( ) { } public float getHeight ( ) { } public float getGutterWidth ( ) { } public float getGutterHeight ( ) { } public SpriteBatch getSpriteBatch ( ) { } public Camera getCamera ( ) { } public void setCamera ( Camera camera ) { } public Group getRoot ( ) { } public Actor hit ( float stageX , float stageY , boolean touchable ) { } public Vector2 screenToStageCoordinates ( Vector2 screenCoords ) { } public Vector2 stageToScreenCoordinates ( Vector2 stageCoords ) { } public Vector2 toScreenCoordinates ( Vector2 coords , Matrix4 transformMatrix ) { } public void dispose ( ) { } public static final class TouchFocus implements Poolable { EventListener listener ; Actor listenerActor ; Actor target ; int pointer ; int button ; public void reset ( ) { } } }<BUG2FIX>Actor over = hit ( stageCoords . x , stageCoords . y , true ) ;
public abstract class AbstractSimpleTransportTests { protected ThreadPool threadPool ; protected TransportService serviceA ; protected TransportService serviceB ; protected DiscoveryNode serviceANode ; protected DiscoveryNode serviceBNode ; @ BeforeMethod public void setUp ( ) { } @ AfterMethod public void tearDown ( ) { } protected abstract void build ( ) { } @ Test public void testHelloWorld ( ) { } @ Test public void testHelloWorldCompressed ( ) { serviceA . registerHandler ( "sayHello" , new BaseTransportRequestHandler < AbstractSimpleTransportTests . StringMessage > ( ) { @ Override public AbstractSimpleTransportTests . StringMessage newInstance ( ) { return new AbstractSimpleTransportTests . StringMessage ( ) ; } @ Override public String executor ( ) { return Names . CACHED ; } @ Override public void messageReceived ( AbstractSimpleTransportTests . StringMessage request , TransportChannel channel ) { assertThat ( "moshe" , equalTo ( request . message ) ) ; try { <START_BUG> channel . sendResponse ( new AbstractSimpleTransportTests . StringMessage ( ( "hello<seq2seq4repair_space>" + ( request . message ) ) ) , TransportResponseOptions . options ( ) . withCompress ( ) ) ; <END_BUG> } catch ( IOException e ) { e . printStackTrace ( ) ; assertThat ( e . getMessage ( ) , false , equalTo ( true ) ) ; } } } ) ; TransportFuture < AbstractSimpleTransportTests . StringMessage > res = serviceB . submitRequest ( serviceANode , "sayHello" , new AbstractSimpleTransportTests . StringMessage ( "moshe" ) , TransportRequestOptions . TransportRequestOptions . options ( ) . withCompress ( true ) , new BaseTransportResponseHandler < AbstractSimpleTransportTests . StringMessage > ( ) { @ Override public AbstractSimpleTransportTests . StringMessage newInstance ( ) { return new AbstractSimpleTransportTests . StringMessage ( ) ; } @ Override public String executor ( ) { return Names . CACHED ; } @ Override public void handleResponse ( AbstractSimpleTransportTests . StringMessage response ) { assertThat ( "hello<seq2seq4repair_space>moshe" , equalTo ( response . message ) ) ; } @ Override public void handleException ( TransportException exp ) { exp . printStackTrace ( ) ; assertThat ( ( "got<seq2seq4repair_space>exception<seq2seq4repair_space>instead<seq2seq4repair_space>of<seq2seq4repair_space>a<seq2seq4repair_space>response:<seq2seq4repair_space>" + ( exp . getMessage ( ) ) ) , false , equalTo ( true ) ) ; } } ) ; try { AbstractSimpleTransportTests . StringMessage message = res . get ( ) ; assertThat ( "hello<seq2seq4repair_space>moshe" , equalTo ( message . message ) ) ; } catch ( Exception e ) { assertThat ( e . getMessage ( ) , false , equalTo ( true ) ) ; } serviceA . removeHandler ( "sayHello" ) ; } @ Test public void testErrorMessage ( ) { } @ Test public void testDisconnectListener ( ) throws Exception { } @ Test public void testTimeoutSendExceptionWithNeverSendingBackResponse ( ) throws Exception { } @ Test public void testTimeoutSendExceptionWithDelayedResponse ( ) throws Exception { } private class StringMessage implements Streamable { private String message ; private StringMessage ( String message ) { } private StringMessage ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } }<BUG2FIX>channel . sendResponse ( new AbstractSimpleTransportTests . StringMessage ( ( "hello<seq2seq4repair_space>" + ( request . message ) ) ) , TransportResponseOptions . options ( ) . withCompress ( true ) ) ;
public class TopChildrenQuery extends Query implements ScopePhase . TopDocsPhase { public static enum ScoreType { MAX , AVG , SUM ; public static TopChildrenQuery . ScoreType fromString ( String type ) { } } private Query query ; private String scope ; private String parentType ; private String childType ; private TopChildrenQuery . ScoreType scoreType ; private int factor ; private int incrementalFactor ; private Map < Object , TopChildrenQuery . ParentDoc [ ] > parentDocs ; private int numHits = 0 ; private boolean properlyInvoked = false ; public TopChildrenQuery ( Query query , String scope , String childType , String parentType , TopChildrenQuery . ScoreType scoreType , int factor , int incrementalFactor ) { } @ Override public Query query ( ) { } @ Override public String scope ( ) { } @ Override public void clear ( ) { } @ Override public int numHits ( ) { } @ Override public int factor ( ) { } @ Override public int incrementalFactor ( ) { } @ Override public void processResults ( TopDocs topDocs , SearchContext context ) { Map < Object , TIntObjectHashMap < TopChildrenQuery . ParentDoc > > parentDocsPerReader = new HashMap < Object , TIntObjectHashMap < TopChildrenQuery . ParentDoc > > ( ) ; for ( ScoreDoc scoreDoc : topDocs . scoreDocs ) { int readerIndex = ReaderUtil . subIndex ( scoreDoc . doc , context . searcher ( ) . getIndexReader ( ) . leaves ( ) ) ; AtomicReaderContext subContext = context . searcher ( ) . getIndexReader ( ) . leaves ( ) . get ( readerIndex ) ; int subDoc = ( scoreDoc . doc ) - ( subContext . docBase ) ; HashedBytesArray parentId = context . idCache ( ) . reader ( subContext . reader ( ) ) . parentIdByDoc ( parentType , subDoc ) ; if ( parentId == null ) { continue ; } for ( AtomicReaderContext atomicReaderContext : context . searcher ( ) . getIndexReader ( ) . leaves ( ) ) { AtomicReader indexReader = atomicReaderContext . reader ( ) ; int parentDocId = context . idCache ( ) . reader ( indexReader ) . docById ( parentType , parentId ) ; <START_BUG> if ( ( parentDocId != ( - 1 ) ) && ( ! ( indexReader . getLiveDocs ( ) . get ( parentDocId ) ) ) ) { <END_BUG> TIntObjectHashMap < TopChildrenQuery . ParentDoc > readerParentDocs = parentDocsPerReader . get ( indexReader . getCoreCacheKey ( ) ) ; if ( readerParentDocs == null ) { readerParentDocs = new TIntObjectHashMap < TopChildrenQuery . ParentDoc > ( ) ; parentDocsPerReader . put ( indexReader . getCoreCacheKey ( ) , readerParentDocs ) ; } TopChildrenQuery . ParentDoc parentDoc = readerParentDocs . get ( parentDocId ) ; if ( parentDoc == null ) { ( numHits ) ++ ; parentDoc = new TopChildrenQuery . ParentDoc ( ) ; parentDoc . docId = parentDocId ; parentDoc . count = 1 ; parentDoc . maxScore = scoreDoc . score ; parentDoc . sumScores = scoreDoc . score ; readerParentDocs . put ( parentDocId , parentDoc ) ; } else { ( parentDoc . count ) ++ ; parentDoc . sumScores += scoreDoc . score ; if ( ( scoreDoc . score ) > ( parentDoc . maxScore ) ) { parentDoc . maxScore = scoreDoc . score ; } } } } } this . parentDocs = new HashMap < Object , TopChildrenQuery . ParentDoc [ ] > ( ) ; for ( Map . Entry < Object , TIntObjectHashMap < TopChildrenQuery . ParentDoc > > entry : parentDocsPerReader . entrySet ( ) ) { TopChildrenQuery . ParentDoc [ ] values = entry . getValue ( ) . values ( new TopChildrenQuery . ParentDoc [ entry . getValue ( ) . size ( ) ] ) ; Arrays . sort ( values , TopChildrenQuery . PARENT_DOC_COMP ) ; parentDocs . put ( entry . getKey ( ) , values ) ; } } private static final TopChildrenQuery . ParentDocComparator PARENT_DOC_COMP = new TopChildrenQuery . ParentDocComparator ( ) ; static class ParentDocComparator implements Comparator < TopChildrenQuery . ParentDoc > { @ Override public int compare ( TopChildrenQuery . ParentDoc o1 , TopChildrenQuery . ParentDoc o2 ) { } } public static class ParentDoc { public int docId ; public int count ; public float maxScore = Float . NaN ; public float sumScores = 0 ; } @ Override public Query rewrite ( IndexReader reader ) throws IOException { } @ Override public void extractTerms ( Set < Term > terms ) { } @ Override public Weight createWeight ( IndexSearcher searcher ) throws IOException { } public String toString ( String field ) { } class ParentWeight extends Weight { final IndexSearcher searcher ; final Weight queryWeight ; public ParentWeight ( IndexSearcher searcher , Weight queryWeight ) throws IOException { } public Query getQuery ( ) { } public float getValue ( ) { } @ Override public float getValueForNormalization ( ) throws IOException { } @ Override public void normalize ( float norm , float topLevelBoost ) { } @ Override public Scorer scorer ( AtomicReaderContext context , boolean scoreDocsInOrder , boolean topScorer , Bits acceptDocs ) throws IOException { } @ Override public Explanation explain ( AtomicReaderContext context , int doc ) throws IOException { } } class ParentScorer extends Scorer { private final TopChildrenQuery . ParentDoc [ ] docs ; private int index = - 1 ; private ParentScorer ( TopChildrenQuery . ParentWeight weight , TopChildrenQuery . ParentDoc [ ] docs ) throws IOException { } @ Override public int docID ( ) { } @ Override public int advance ( int target ) throws IOException { } @ Override public int nextDoc ( ) throws IOException { } @ Override public float score ( ) throws IOException { } @ Override public float freq ( ) throws IOException { } } }<BUG2FIX>if ( ( parentDocId != ( - 1 ) ) && ( indexReader . getLiveDocs ( ) . get ( parentDocId ) ) ) {
public class Hiero4 extends JFrame { static final String NEHE = "ABCDEFGHIJKLMNOPQRSTUVWXYZ\n" + ( "abcdefghijklmnopqrstuvwxyz\n1234567890\n" + "\"!`?\'.,;:()[]{}<>|/@\\^$-%+=#_&~*" ) ; Color renderingBackgroundColor = Color . BLACK ; Preferences prefs ; Hiero4 . Renderer renderer ; FontData fontData ; FontGenerator fontGenerator ; HashSet < Character > sampleChars = new HashSet ( 256 ) ; HashSet < Character > remainingSampleChars = new HashSet ( 256 ) ; JScrollPane appliedEffectsScroll ; JPanel appliedEffectsPanel ; JButton addEffectButton ; JTextPane sampleTextPane ; JSpinner padAdvanceXSpinner ; JList effectsList ; JPanel gamePanel ; JTextField fontFileText ; JRadioButton fontFileRadio ; JRadioButton systemFontRadio ; JSpinner padBottomSpinner ; JSpinner padLeftSpinner ; JSpinner padRightSpinner ; JSpinner padTopSpinner ; JList fontList ; JSpinner fontSizeSpinner ; DefaultComboBoxModel fontListModel ; JLabel backgroundColorLabel ; JButton browseButton ; JSpinner padAdvanceYSpinner ; JCheckBox italicCheckBox ; JCheckBox boldCheckBox ; JRadioButton vectorRadio ; JRadioButton drawStringRadio ; JRadioButton freetypeRadio ; JComboBox glyphPageHeightCombo ; JComboBox glyphPageWidthCombo ; JPanel glyphCachePanel ; JRadioButton glyphCacheRadio ; JRadioButton sampleTextRadio ; JButton sampleAsciiButton ; JButton sampleNeheButton ; DefaultComboBoxModel effectsListModel ; JMenuItem openMenuItem ; JMenuItem saveMenuItem ; JMenuItem exitMenuItem ; JMenuItem saveBMFontMenuItem ; public Hiero4 ( ) { } void initialize ( ) { } void changeFont ( ) { } void updateFont ( boolean force ) { if ( ( ( fontData ) == null ) || ( ( renderer . batch ) == null ) ) return ; final String text = sampleTextPane . getText ( ) ; if ( ! force ) { boolean newCharFound = false ; remainingSampleChars . clear ( ) ; remainingSampleChars . addAll ( sampleChars ) ; for ( int i = ( text . length ( ) ) - 1 ; i >= 0 ; i -- ) { Character ch = text . charAt ( i ) ; if ( sampleChars . add ( ch ) ) newCharFound = true ; remainingSampleChars . remove ( ch ) ; } if ( ( ! newCharFound ) && ( remainingSampleChars . isEmpty ( ) ) ) return ; } sampleChars . clear ( ) ; for ( int i = ( text . length ( ) ) - 1 ; i >= 0 ; i -- ) sampleChars . add ( text . charAt ( i ) ) ; int fontSize = ( ( Integer ) ( fontSizeSpinner . getValue ( ) ) ) . intValue ( ) ; int style = Font . PLAIN ; if ( boldCheckBox . isSelected ( ) ) { style = Font . BOLD ; if ( italicCheckBox . isSelected ( ) ) style |= Font . ITALIC ; } else if ( italicCheckBox . isSelected ( ) ) style = Font . ITALIC ; fontData = fontData . deriveFont ( fontSize , style ) ; int sampleFontSize = sampleTextPane . getFont ( ) . getSize ( ) ; if ( sampleFontSize < 14 ) sampleFontSize = 14 ; sampleTextPane . setFont ( fontData . getJavaFont ( ) . deriveFont ( ( ( float ) ( sampleFontSize ) ) ) ) ; final Padding padding = new Padding ( ( ( Integer ) ( padTopSpinner . getValue ( ) ) ) , ( ( Integer ) ( padLeftSpinner . getValue ( ) ) ) , ( ( Integer ) ( padBottomSpinner . getValue ( ) ) ) , ( ( Integer ) ( padRightSpinner . getValue ( ) ) ) , ( ( Integer ) ( padAdvanceXSpinner . getValue ( ) ) ) ) ; final int width = ( ( Integer ) ( glyphPageWidthCombo . getSelectedItem ( ) ) ) ; final int height = ( ( Integer ) ( glyphPageHeightCombo . getSelectedItem ( ) ) ) ; final GeneratorMethod method ; if ( vectorRadio . isSelected ( ) ) method = GeneratorMethod . AWT_VECTOR ; else if ( drawStringRadio . isSelected ( ) ) method = GeneratorMethod . AWT_DRAWSTRING ; else method = GeneratorMethod . FREETYPE2 ; new Thread ( ) { public void run ( ) { fontGenerator = new FontGenerator ( fontData , method ) ; CharSet charset = new CharSet ( ) ; charset . setManualCharacters ( text ) ; try { fontGenerator . generate ( width , height , charset , padding , new Effect . Renderer [ 0 ] , true ) ; fontGenerator . write ( new File ( "out" ) , TEXT ) ; } catch ( IOException ex ) { ex . printStackTrace ( ) ; } EventQueue . invokeLater ( new Runnable ( ) { public void run ( ) { final ByteBuffer buffer = ByteBuffer . allocateDirect ( ( ( 1024 * 1024 ) * 4 ) ) ; buffer . order ( ByteOrder . LITTLE_ENDIAN ) ; fontGenerator . getTextureData ( buffer . asIntBuffer ( ) ) ; TextureRegion glyphRegion = new TextureRegion ( new Texture ( new TextureData ( ) { Pixmap pixmap ; public int getWidth ( ) { return width ; } public int getHeight ( ) { return height ; } @ Override public Pixmap consumePixmap ( ) { this . pixmap = new Pixmap ( width , height , Format . RGBA8888 ) ; pixmap . getPixels ( ) . put ( buffer ) ; pixmap . getPixels ( ) . rewind ( ) ; return pixmap ; } @ Override public boolean disposePixmap ( ) { return true ; } @ Override public Format getFormat ( ) { return pixmap . getFormat ( ) ; } @ Override public boolean useMipMaps ( ) { return false ; } @ Override public boolean isManaged ( ) { return true ; } @ Override public TextureDataType getType ( ) { return TextureDataType . Pixmap ; } @ Override <START_BUG> public void consumeCompressedData ( int target ) { <END_BUG> } @ Override public boolean isPrepared ( ) { return true ; } @ Override public void prepare ( ) { } } ) ) ; renderer . font = new BitmapFont ( files . absolute ( "out" ) , glyphRegion , false ) ; } } ) ; } } . start ( ) ; } private void initializeEvents ( ) { } private void initializeComponents ( ) { } private void initializeMenus ( ) { } static Icon getColorIcon ( java . awt . Color color ) { } private static class Splash extends JWindow { final int minMillis ; final long startTime ; public Splash ( Frame frame , String imageFile , int minMillis ) { }<BUG2FIX>public void consumeCompressedData ( ) {
public class IssuesFragment extends PagedItemFragment < Issue > { @ Inject private AccountDataManager cache ; @ Inject private IssueService service ; @ Inject private IssueStore store ; @ InjectExtra ( value = Intents . EXTRA_ISSUE_FILTER , optional = true ) private IssueFilter filter ; @ InjectExtra ( Intents . EXTRA_REPOSITORY ) private Repository repository ; private TextView filterTextView ; @ Inject private AvatarLoader avatarHelper ; @ Override public void onCreate ( Bundle savedInstanceState ) { } @ Override public void onViewCreated ( View view , Bundle savedInstanceState ) { } private void updateFilterSummary ( ) { } @ Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; setEmptyText ( getString ( no_issues ) ) ; <START_BUG> ListViewUtils . configure ( getActivity ( ) , getListView ( ) , true ) ; <END_BUG> } @ Override public void onListItemClick ( ListView l , View v , int position , long id ) { } @ Override public void onCreateOptionsMenu ( Menu optionsMenu , MenuInflater inflater ) { } @ Override public boolean onOptionsItemSelected ( MenuItem item ) { } @ Override public void onActivityResult ( int requestCode , int resultCode , Intent data ) { } @ Override protected ResourcePager < Issue > createPager ( ) { } @ Override protected int getLoadingMessage ( ) { } protected ItemListAdapter < Issue , ? extends ItemView > createAdapter ( List < Issue > items ) { } }<BUG2FIX>ListViewUtils . configure ( getActivity ( ) , getListView ( ) ) ;
public class ConstantScoreQueryParser extends AbstractIndexComponent implements XContentQueryParser { public static final String NAME = "constant_score" ; @ Inject public ConstantScoreQueryParser ( Index index , @ IndexSettings Settings settings ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; Filter filter = null ; float boost = 1.0F ; boolean cache = false ; String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_OBJECT ) ) { if ( "filter" . equals ( currentFieldName ) ) { filter = parseContext . parseInnerFilter ( ) ; } } else if ( token . isValue ( ) ) { if ( "boost" . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } else if ( "_cache" . equals ( currentFieldName ) ) { cache = parser . booleanValue ( ) ; } } } if ( filter == null ) { throw new QueryParsingException ( index , "[constant_score]<seq2seq4repair_space>requires<seq2seq4repair_space>'filter'<seq2seq4repair_space>element" ) ; } if ( cache ) { filter = parseContext . cacheFilter ( filter ) ; } <START_BUG> Query query = new org . apache . lucene . search . DeletionAwareConstantScoreQuery ( filter , true ) ; <END_BUG> query . setBoost ( boost ) ; return query ; } }<BUG2FIX>Query query = new org . apache . lucene . search . DeletionAwareConstantScoreQuery ( filter ) ;
public class ObjectMap < K , V > { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; public int size ; K [ ] keyTable ; V [ ] valueTable ; int capacity ; int stashSize ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private ObjectMap . Entries entries1 ; private ObjectMap . Entries entries2 ; private ObjectMap . Values values1 ; private ObjectMap . Values values2 ; private ObjectMap . Keys keys1 ; private ObjectMap . Keys keys2 ; public ObjectMap ( ) { } public ObjectMap ( int initialCapacity ) { } public ObjectMap ( int initialCapacity , float loadFactor ) { } public ObjectMap ( ObjectMap < ? extends K , ? extends V > map ) { } public V put ( K key , V value ) { } private V put_internal ( K key , V value ) { } public void putAll ( ObjectMap < K , V > map ) { } private void putResize ( K key , V value ) { } private void push ( K insertKey , V insertValue , int index1 , K key1 , int index2 , K key2 , int index3 , K key3 ) { } private void putStash ( K key , V value ) { } public V get ( K key ) { } private V getStash ( K key ) { } public V get ( K key , V defaultValue ) { } private V getStash ( K key , V defaultValue ) { } public V remove ( K key ) { } V removeStash ( K key ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean containsValue ( Object value , boolean identity ) { } public boolean containsKey ( K key ) { } private boolean containsKeyStash ( K key ) { } public K findKey ( Object value , boolean identity ) { } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( int h ) { } private int hash3 ( int h ) { } public String toString ( ) { } public ObjectMap . Entries < K , V > entries ( ) { } public ObjectMap . Values < V > values ( ) { } public ObjectMap . Keys < K > keys ( ) { } public static class Entry < K , V > { public K key ; public V value ; public String toString ( ) { } } private static class MapIterator < K , V > { public boolean hasNext ; final ObjectMap < K , V > map ; int nextIndex ; int currentIndex ; boolean valid = true ; public MapIterator ( ObjectMap < K , V > map ) { } public void reset ( ) { } void advance ( ) { } public void remove ( ) { if ( ( currentIndex ) < 0 ) throw new IllegalStateException ( "next<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>called<seq2seq4repair_space>before<seq2seq4repair_space>remove." ) ; if ( ( currentIndex ) >= ( map . capacity ) ) { map . removeStashIndex ( currentIndex ) ; <START_BUG> nextIndex = ( currentIndex ) - 1 ; <END_BUG> advance ( ) ; } else { map . keyTable [ currentIndex ] = null ; map . valueTable [ currentIndex ] = null ; } currentIndex = - 1 ; ( map . size ) -- ; } } public static class Entries < K , V > extends ObjectMap . MapIterator < K , V > implements Iterable < ObjectMap . Entry < K , V > > , Iterator < ObjectMap . Entry < K , V > > { ObjectMap . Entry < K , V > entry = new ObjectMap . Entry ( ) ; public Entries ( ObjectMap < K , V > map ) { } public ObjectMap . Entry < K , V > next ( ) { } public boolean hasNext ( ) { } public Iterator < ObjectMap . Entry < K , V > > iterator ( ) { } } public static class Values < V > extends ObjectMap . MapIterator < Object , V > implements Iterable < V > , Iterator < V > { public Values ( ObjectMap < ? , V > map ) { } public boolean hasNext ( ) { } public V next ( ) { } public Iterator < V > iterator ( ) { } public Array < V > toArray ( ) { } public void toArray ( Array < V > array ) { } } public static class Keys < K > extends ObjectMap . MapIterator < K , Object > implements Iterable < K > , Iterator < K > { public Keys ( ObjectMap < K , ? > map ) { } public boolean hasNext ( ) { } public K next ( ) { } public Iterator < K > iterator ( ) { } public Array < K > toArray ( ) { } } }<BUG2FIX>nextIndex = currentIndex ;
public class PrefixQueryParser implements QueryParser { public static final String NAME = "prefix" ; @ Inject public PrefixQueryParser ( ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; XContentParser . Token token = parser . nextToken ( ) ; if ( token != ( Token . FIELD_NAME ) ) { throw new QueryParsingException ( parseContext . index ( ) , "[prefix]<seq2seq4repair_space>query<seq2seq4repair_space>malformed,<seq2seq4repair_space>no<seq2seq4repair_space>field" ) ; } String fieldName = parser . currentName ( ) ; String rewriteMethod = null ; String value = null ; float boost = 1.0F ; token = parser . nextToken ( ) ; if ( token == ( Token . START_OBJECT ) ) { String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token . isValue ( ) ) { if ( "prefix" . equals ( currentFieldName ) ) { value = parser . text ( ) ; } else if ( "value" . equals ( currentFieldName ) ) { value = parser . text ( ) ; } else if ( "boost" . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } else if ( "rewrite" . equals ( currentFieldName ) ) { rewriteMethod = parser . textOrNull ( ) ; } } else { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[prefix]<seq2seq4repair_space>query<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>support<seq2seq4repair_space>[" + currentFieldName ) + "]" ) ) ; } } parser . nextToken ( ) ; } else { value = parser . text ( ) ; parser . nextToken ( ) ; } if ( value == null ) { throw new QueryParsingException ( parseContext . index ( ) , "No<seq2seq4repair_space>value<seq2seq4repair_space>specified<seq2seq4repair_space>for<seq2seq4repair_space>prefix<seq2seq4repair_space>query" ) ; } <START_BUG> MultiTermQuery . RewriteMethod method = QueryParsers . parseRewriteMethod ( rewriteMethod ) ; <END_BUG> Query query = null ; MapperService . SmartNameFieldMappers smartNameFieldMappers = parseContext . smartFieldMappers ( fieldName ) ; if ( ( smartNameFieldMappers != null ) && ( smartNameFieldMappers . hasMapper ( ) ) ) { if ( smartNameFieldMappers . explicitTypeInNameWithDocMapper ( ) ) { String [ ] previousTypes = QueryParseContext . setTypesWithPrevious ( new String [ ] { smartNameFieldMappers . docMapper ( ) . type ( ) } ) ; try { query = smartNameFieldMappers . mapper ( ) . prefixQuery ( value , method , parseContext ) ; } finally { QueryParseContext . setTypes ( previousTypes ) ; } } else { query = smartNameFieldMappers . mapper ( ) . prefixQuery ( value , method , parseContext ) ; } } if ( query == null ) { PrefixQuery prefixQuery = new PrefixQuery ( new Term ( fieldName , value ) ) ; prefixQuery . setRewriteMethod ( method ) ; query = prefixQuery ; } query . setBoost ( boost ) ; return wrapSmartNameQuery ( query , smartNameFieldMappers , parseContext ) ; } }<BUG2FIX>MultiTermQuery . RewriteMethod method = QueryParsers . parseRewriteMethod ( rewriteMethod , null ) ;
public class HasChildFilterParser implements FilterParser { public static final String NAME = "has_child" ; @ Inject public HasChildFilterParser ( ) { } @ Override public String [ ] names ( ) { } @ Override public Filter parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; Query query = null ; boolean queryFound = false ; String childType = null ; int shortCircuitParentDocSet = 8192 ; String filterName = null ; String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_OBJECT ) ) { if ( "query" . equals ( currentFieldName ) ) { String [ ] origTypes = QueryParseContext . setTypesWithPrevious ( ( childType == null ? null : new String [ ] { childType } ) ) ; try { query = parseContext . parseInnerQuery ( ) ; queryFound = true ; } finally { QueryParseContext . setTypes ( origTypes ) ; } } else if ( "filter" . equals ( currentFieldName ) ) { String [ ] origTypes = QueryParseContext . setTypesWithPrevious ( ( childType == null ? null : new String [ ] { childType } ) ) ; try { Filter innerFilter = parseContext . parseInnerFilter ( ) ; query = new org . elasticsearch . common . lucene . search . XConstantScoreQuery ( innerFilter ) ; queryFound = true ; } finally { QueryParseContext . setTypes ( origTypes ) ; } } else { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[has_child]<seq2seq4repair_space>filter<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>support<seq2seq4repair_space>[" + currentFieldName ) + "]" ) ) ; } } else if ( token . isValue ( ) ) { if ( ( ( "type" . equals ( currentFieldName ) ) || ( "child_type" . equals ( currentFieldName ) ) ) || ( "childType" . equals ( currentFieldName ) ) ) { childType = parser . text ( ) ; } else if ( "_scope" . equals ( currentFieldName ) ) { throw new QueryParsingException ( parseContext . index ( ) , "the<seq2seq4repair_space>[_scope]<seq2seq4repair_space>support<seq2seq4repair_space>in<seq2seq4repair_space>[has_child]<seq2seq4repair_space>filter<seq2seq4repair_space>has<seq2seq4repair_space>been<seq2seq4repair_space>removed,<seq2seq4repair_space>use<seq2seq4repair_space>a<seq2seq4repair_space>filter<seq2seq4repair_space>as<seq2seq4repair_space>a<seq2seq4repair_space>facet_filter<seq2seq4repair_space>in<seq2seq4repair_space>the<seq2seq4repair_space>relevant<seq2seq4repair_space>global<seq2seq4repair_space>facet" ) ; } else if ( "_name" . equals ( currentFieldName ) ) { filterName = parser . text ( ) ; } else if ( "_cache" . equals ( currentFieldName ) ) { } else if ( ( "_cache_key" . equals ( currentFieldName ) ) || ( "_cacheKey" . equals ( currentFieldName ) ) ) { } else if ( "short_circuit_cutoff" . equals ( currentFieldName ) ) { shortCircuitParentDocSet = parser . intValue ( ) ; } else { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[has_child]<seq2seq4repair_space>filter<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>support<seq2seq4repair_space>[" + currentFieldName ) + "]" ) ) ; } } } if ( ! queryFound ) { throw new QueryParsingException ( parseContext . index ( ) , "[has_child]<seq2seq4repair_space>filter<seq2seq4repair_space>requires<seq2seq4repair_space>'query'<seq2seq4repair_space>field" ) ; } if ( query == null ) { return null ; } if ( childType == null ) { throw new QueryParsingException ( parseContext . index ( ) , "[has_child]<seq2seq4repair_space>filter<seq2seq4repair_space>requires<seq2seq4repair_space>'type'<seq2seq4repair_space>field" ) ; } DocumentMapper childDocMapper = parseContext . mapperService ( ) . documentMapper ( childType ) ; if ( childDocMapper == null ) { throw new QueryParsingException ( parseContext . index ( ) , ( ( "No<seq2seq4repair_space>mapping<seq2seq4repair_space>for<seq2seq4repair_space>for<seq2seq4repair_space>type<seq2seq4repair_space>[" + childType ) + "]" ) ) ; } if ( ! ( childDocMapper . parentFieldMapper ( ) . active ( ) ) ) { throw new QueryParsingException ( parseContext . index ( ) , ( ( "Type<seq2seq4repair_space>[" + childType ) + "]<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>have<seq2seq4repair_space>parent<seq2seq4repair_space>mapping" ) ) ; } String parentType = childDocMapper . parentFieldMapper ( ) . type ( ) ; query = new org . elasticsearch . common . lucene . search . XFilteredQuery ( query , parseContext . cacheFilter ( childDocMapper . typeFilter ( ) , null ) ) ; DocumentMapper parentDocMapper = parseContext . mapperService ( ) . documentMapper ( parentType ) ; if ( parentDocMapper == null ) { throw new QueryParsingException ( parseContext . index ( ) , ( ( ( ( "[has_child]<seq2seq4repair_space>Type<seq2seq4repair_space>[" + childType ) + "]<seq2seq4repair_space>points<seq2seq4repair_space>to<seq2seq4repair_space>a<seq2seq4repair_space>non<seq2seq4repair_space>existent<seq2seq4repair_space>parent<seq2seq4repair_space>type<seq2seq4repair_space>[" ) + parentType ) + "]" ) ) ; } Filter parentFilter = parseContext . cacheFilter ( parentDocMapper . typeFilter ( ) , null ) ; <START_BUG> Query childrenConstantScoreQuery = new org . elasticsearch . index . search . child . ChildrenConstantScoreQuery ( query , parentType , childType , parentFilter , shortCircuitParentDocSet , false ) ; <END_BUG> if ( filterName != null ) { parseContext . addNamedQuery ( filterName , childrenConstantScoreQuery ) ; } boolean deleteByQuery = "delete_by_query" . equals ( SearchContext . current ( ) . source ( ) ) ; if ( deleteByQuery ) { return new org . elasticsearch . index . search . child . DeleteByQueryWrappingFilter ( childrenConstantScoreQuery ) ; } else { return new org . elasticsearch . index . search . child . CustomQueryWrappingFilter ( childrenConstantScoreQuery ) ; } } }<BUG2FIX>Query childrenConstantScoreQuery = new org . elasticsearch . index . search . child . ChildrenConstantScoreQuery ( query , parentType , childType , parentFilter , shortCircuitParentDocSet ) ;
public class GestureDetector extends InputAdapter { final GestureDetector . GestureListener listener ; private float tapSquareSize ; private long tapCountInterval ; private float longPressSeconds ; private long maxFlingDelay ; private boolean inTapSquare ; private int tapCount ; private long lastTapTime ; private float lastTapX ; private float lastTapY ; private int lastTapButton ; private int lastTapPointer ; boolean longPressFired ; private boolean pinching ; private boolean panning ; private final GestureDetector . VelocityTracker tracker = new GestureDetector . VelocityTracker ( ) ; private float tapSquareCenterX ; private float tapSquareCenterY ; private long gestureStartTime ; Vector2 pointer1 = new Vector2 ( ) ; private final Vector2 pointer2 = new Vector2 ( ) ; private final Vector2 initialPointer1 = new Vector2 ( ) ; private final Vector2 initialPointer2 = new Vector2 ( ) ; private final Task longPressTask = new Task ( ) { @ Override public void run ( ) { } } ; public GestureDetector ( GestureDetector . GestureListener listener ) { } public GestureDetector ( float halfTapSquareSize , float tapCountInterval , float longPressDuration , float maxFlingDelay , GestureDetector . GestureListener listener ) { } @ Override public boolean touchDown ( int x , int y , int pointer , int button ) { } public boolean touchDown ( float x , float y , int pointer , int button ) { } @ Override public boolean touchDragged ( int x , int y , int pointer ) { } public boolean touchDragged ( float x , float y , int pointer ) { } @ Override public boolean touchUp ( int x , int y , int pointer , int button ) { } public boolean touchUp ( float x , float y , int pointer , int button ) { } public void cancel ( ) { } public boolean isLongPressed ( ) { } public boolean isLongPressed ( float duration ) { } public boolean isPanning ( ) { } public void reset ( ) { } private boolean isWithinTapSquare ( float x , float y , float centerX , float centerY ) { } public void invalidateTapSquare ( ) { } <START_BUG> public void setTapSquareSize ( int tapSquareSize ) { <END_BUG> this . tapSquareSize = tapSquareSize ; } public void setTapCountInterval ( float tapCountInterval ) { } public void setLongPressSeconds ( float longPressSeconds ) { } public void setMaxFlingDelay ( long maxFlingDelay ) { } public static interface GestureListener { public boolean touchDown ( float x , float y , int pointer , int button ) { } public boolean tap ( float x , float y , int count , int button ) { } public boolean longPress ( float x , float y ) { } public boolean fling ( float velocityX , float velocityY , int button ) { } public boolean pan ( float x , float y , float deltaX , float deltaY ) { } public boolean panStop ( float x , float y , int pointer , int button ) { } public boolean zoom ( float initialDistance , float distance ) { } public boolean pinch ( Vector2 initialPointer1 , Vector2 initialPointer2 , Vector2 pointer1 , Vector2 pointer2 ) { } } public static class GestureAdapter implements GestureDetector . GestureListener { @ Override public boolean touchDown ( float x , float y , int pointer , int button ) { } @ Override public boolean tap ( float x , float y , int count , int button ) { } @ Override public boolean longPress ( float x , float y ) { } @ Override public boolean fling ( float velocityX , float velocityY , int button ) { } @ Override public boolean pan ( float x , float y , float deltaX , float deltaY ) { } @ Override public boolean panStop ( float x , float y , int pointer , int button ) { } @ Override public boolean zoom ( float initialDistance , float distance ) { } @ Override public boolean pinch ( Vector2 initialPointer1 , Vector2 initialPointer2 , Vector2 pointer1 , Vector2 pointer2 ) { } } static class VelocityTracker { int sampleSize = 10 ; float lastX ; float lastY ; float deltaX ; float deltaY ; long lastTime ; int numSamples ; float [ ] meanX = new float [ sampleSize ] ; float [ ] meanY = new float [ sampleSize ] ; long [ ] meanTime = new long [ sampleSize ] ; public void start ( float x , float y , long timeStamp ) { } public void update ( float x , float y , long timeStamp ) { } public float getVelocityX ( ) { } public float getVelocityY ( ) { } private float getAverage ( float [ ] values , int numSamples ) { } private long getAverage ( long [ ] values , int numSamples ) { } private float getSum ( float [ ] values , int numSamples ) { } } }<BUG2FIX>public void setTapSquareSize ( float tapSquareSize ) {
public class ClusterAllocationRerouteBenchmark { private static final ESLogger logger = Loggers . getLogger ( ClusterAllocationRerouteBenchmark . class ) ; public static void main ( String [ ] args ) { <START_BUG> final int numberOfRuns = 10 ; <END_BUG> final int numIndices = 5 * 365 ; final int numShards = 6 ; final int numReplicas = 2 ; final int numberOfNodes = 30 ; final int numberOfTags = 2 ; AllocationService strategy = new AllocationService ( settingsBuilder ( ) . build ( ) ) ; MetaData . Builder mb = MetaData . builder ( ) ; for ( int i = 1 ; i <= numIndices ; i ++ ) { mb . put ( IndexMetaData . builder ( ( "test_" + i ) ) . numberOfShards ( numShards ) . numberOfReplicas ( numReplicas ) ) ; } MetaData metaData = mb . build ( ) ; RoutingTable . Builder rb = RoutingTable . builder ( ) ; for ( int i = 1 ; i <= numIndices ; i ++ ) { rb . addAsNew ( metaData . index ( ( "test_" + i ) ) ) ; } RoutingTable routingTable = rb . build ( ) ; DiscoveryNodes . Builder nb = DiscoveryNodes . builder ( ) ; for ( int i = 1 ; i <= numberOfNodes ; i ++ ) { nb . put ( newNode ( ( "node" + i ) , ImmutableMap . of ( "tag" , ( "tag_" + ( i % numberOfTags ) ) ) ) ) ; } ClusterState initialClusterState = ClusterState . builder ( ) . metaData ( metaData ) . routingTable ( routingTable ) . nodes ( nb ) . build ( ) ; long start = System . currentTimeMillis ( ) ; for ( int i = 0 ; i < numberOfRuns ; i ++ ) { ClusterAllocationRerouteBenchmark . logger . info ( "[{}]<seq2seq4repair_space>starting...<seq2seq4repair_space>" , i ) ; long runStart = System . currentTimeMillis ( ) ; ClusterState clusterState = initialClusterState ; while ( clusterState . readOnlyRoutingNodes ( ) . hasUnassignedShards ( ) ) { ClusterAllocationRerouteBenchmark . logger . info ( "[{}]<seq2seq4repair_space>remaining<seq2seq4repair_space>unassigned<seq2seq4repair_space>{}" , i , clusterState . readOnlyRoutingNodes ( ) . unassigned ( ) . size ( ) ) ; RoutingAllocation . Result result = strategy . applyStartedShards ( clusterState , clusterState . readOnlyRoutingNodes ( ) . shardsWithState ( INITIALIZING ) ) ; clusterState = ClusterState . builder ( clusterState ) . routingResult ( result ) . build ( ) ; result = strategy . reroute ( clusterState ) ; clusterState = ClusterState . builder ( clusterState ) . routingResult ( result ) . build ( ) ; } ClusterAllocationRerouteBenchmark . logger . info ( "[{}]<seq2seq4repair_space>took<seq2seq4repair_space>{}" , i , TimeValue . timeValueMillis ( ( ( System . currentTimeMillis ( ) ) - runStart ) ) ) ; } long took = ( System . currentTimeMillis ( ) ) - start ; ClusterAllocationRerouteBenchmark . logger . info ( "total<seq2seq4repair_space>took<seq2seq4repair_space>{},<seq2seq4repair_space>AVG<seq2seq4repair_space>{}" , TimeValue . timeValueMillis ( took ) , TimeValue . timeValueMillis ( ( took / numberOfRuns ) ) ) ; } }<BUG2FIX>final int numberOfRuns = 1 ;
public class ScrollPane2Test extends GdxTest { Stage stage ; Skin skin ; public void create ( ) { stage = new Stage ( 0 , 0 , false ) ; input . setInputProcessor ( stage ) ; <START_BUG> skin = new Skin ( files . internal ( "data/uiskin.json" ) , files . internal ( "data/uiskin.png" ) ) ; <END_BUG> Table mytable = new Table ( ) ; mytable . debug ( ) ; mytable . add ( new com . badlogic . gdx . scenes . scene2d . ui . Image ( new Texture ( "data/group-debug.png" ) ) ) ; mytable . row ( ) ; mytable . add ( new com . badlogic . gdx . scenes . scene2d . ui . Image ( new Texture ( "data/group-debug.png" ) ) ) ; mytable . row ( ) ; mytable . add ( new com . badlogic . gdx . scenes . scene2d . ui . Image ( new Texture ( "data/group-debug.png" ) ) ) ; mytable . row ( ) ; mytable . add ( new com . badlogic . gdx . scenes . scene2d . ui . Image ( new Texture ( "data/group-debug.png" ) ) ) ; ScrollPane pane = new ScrollPane ( mytable , skin ) ; pane . setScrollingDisabled ( true , false ) ; if ( false ) { pane . pack ( ) ; pane . setHeight ( graphics . getHeight ( ) ) ; } else { pane . setWidth ( 300 ) ; pane . setHeight ( graphics . getHeight ( ) ) ; } stage . addActor ( pane ) ; } public void render ( ) { } public void resize ( int width , int height ) { } @ Override public void dispose ( ) { } public boolean needsGL20 ( ) { } }<BUG2FIX>skin = new Skin ( files . internal ( "data/uiskin.json" ) ) ;
public class TopChildrenQuery extends Query implements ScopePhase . TopDocsPhase { private Query query ; private String scope ; private String parentType ; private String childType ; private ScoreType scoreType ; private int factor ; private int incrementalFactor ; private Map < Object , TopChildrenQuery . ParentDoc [ ] > parentDocs ; private int numHits = 0 ; private boolean [ ] properlyInvoked = new boolean [ ] { false } ; public TopChildrenQuery ( Query query , String scope , String childType , String parentType , ScoreType scoreType , int factor , int incrementalFactor ) { } @ Override public Query query ( ) { } @ Override public String scope ( ) { } @ Override public void clear ( ) { } @ Override public int numHits ( ) { } @ Override public int factor ( ) { } @ Override public int incrementalFactor ( ) { } @ Override public void processResults ( TopDocs topDocs , SearchContext context ) { } private static final TopChildrenQuery . ParentDocComparator PARENT_DOC_COMP = new TopChildrenQuery . ParentDocComparator ( ) ; static class ParentDocComparator implements Comparator < TopChildrenQuery . ParentDoc > { @ Override public int compare ( TopChildrenQuery . ParentDoc o1 , TopChildrenQuery . ParentDoc o2 ) { } } public static class ParentDoc { public int docId ; public int count ; public float maxScore = Float . NaN ; public float sumScores = 0 ; } @ Override public Query rewrite ( IndexReader reader ) throws IOException { } @ Override public void extractTerms ( Set < Term > terms ) { } @ Override public Weight createWeight ( IndexSearcher searcher ) throws IOException { } public String toString ( String field ) { } class ParentWeight extends Weight { final IndexSearcher searcher ; final Weight queryWeight ; public ParentWeight ( IndexSearcher searcher , Weight queryWeight ) throws IOException { } public Query getQuery ( ) { } @ Override public float getValueForNormalization ( ) throws IOException { } @ Override public void normalize ( float norm , float topLevelBoost ) { } @ Override public Scorer scorer ( AtomicReaderContext context , boolean scoreDocsInOrder , boolean topScorer , Bits acceptDocs ) throws IOException { } @ Override public Explanation explain ( AtomicReaderContext context , int doc ) throws IOException { } } class ParentScorer extends Scorer { private final TopChildrenQuery . ParentDoc [ ] docs ; private int index = - 1 ; private ParentScorer ( TopChildrenQuery . ParentWeight weight , TopChildrenQuery . ParentDoc [ ] docs ) throws IOException { } @ Override public int docID ( ) { } @ Override public int advance ( int target ) throws IOException { } @ Override public int nextDoc ( ) throws IOException { } @ Override public float score ( ) throws IOException { } @ Override <START_BUG> public float freq ( ) throws IOException { <END_BUG> return docs [ index ] . count ; } } }<BUG2FIX>public int freq ( ) throws IOException {
public final class ClassReflection { public static Class forName ( String name ) throws ReflectionException { } public static String getSimpleName ( Class c ) { } public static boolean isInstance ( Class c , Object obj ) { <START_BUG> return ( obj != null ) && ( ClassReflection . isAssignableFrom ( c , obj . getClass ( ) ) ) ; <END_BUG> } public static boolean isAssignableFrom ( Class c1 , Class c2 ) { } public static boolean isMemberClass ( Class c ) { } public static boolean isStaticClass ( Class c ) { } public static < T > T newInstance ( Class < T > c ) throws ReflectionException { } public static Constructor [ ] getConstructors ( Class c ) { } public static Constructor getConstructor ( Class c , Class ... parameterTypes ) throws ReflectionException { } public static Constructor getDeclaredConstructor ( Class c , Class ... parameterTypes ) throws ReflectionException { } public static Method [ ] getMethods ( Class c ) { } public static Method getMethod ( Class c , String name , Class ... parameterTypes ) throws ReflectionException { } public static Method [ ] getDeclaredMethods ( Class c ) { } public static Method getDeclaredMethod ( Class c , String name , Class ... parameterTypes ) throws ReflectionException { } public static Field [ ] getFields ( Class c ) { } public static Field getField ( Class c , String name ) throws ReflectionException { } public static Field [ ] getDeclaredFields ( Class c ) { } public static Field getDeclaredField ( Class c , String name ) throws ReflectionException { } }<BUG2FIX>return ClassReflection . isAssignableFrom ( c , obj . getClass ( ) ) ;
public class IOSApplication implements Application { public static abstract class Delegate extends UIApplicationDelegate . Adapter { private IOSApplication app ; protected abstract IOSApplication createApplication ( ) { } @ Override public boolean didFinishLaunching ( UIApplication application , NSDictionary launchOptions ) { application . addStrongRef ( this ) ; this . app = createApplication ( ) ; return app . didFinishLaunching ( application , launchOptions ) ; } @ Override public void didBecomeActive ( UIApplication application ) { } @ Override public void willResignActive ( UIApplication application ) { } @ Override public void willTerminate ( UIApplication application ) { } } UIApplication uiApp ; UIWindow uiWindow ; ApplicationListener listener ; IOSApplicationConfiguration config ; IOSGraphics graphics ; IOSAudio audio ; IOSFiles files ; IOSInput input ; IOSNet net ; int logLevel = Application . LOG_DEBUG ; float displayScaleFactor ; Array < Runnable > runnables = new Array < Runnable > ( ) ; Array < Runnable > executedRunnables = new Array < Runnable > ( ) ; Array < LifecycleListener > lifecycleListeners = new Array < LifecycleListener > ( ) ; public IOSApplication ( ApplicationListener listener , IOSApplicationConfiguration config ) { } final boolean didFinishLaunching ( UIApplication uiApp , NSDictionary options ) { Gdx . app = this ; this . uiApp = uiApp ; UIApplication . getSharedApplication ( ) . setIdleTimerDisabled ( config . preventScreenDimming ) ; if ( ( UIScreen . getMainScreen ( ) . getScale ( ) ) == 2.0F ) { if ( ( UIDevice . getCurrentDevice ( ) . getUserInterfaceIdiom ( ) ) == ( UIUserInterfaceIdiom . Pad ) ) { displayScaleFactor = ( config . displayScaleLargeScreenIfRetina ) * 2.0F ; } else { displayScaleFactor = ( config . displayScaleSmallScreenIfRetina ) * 2.0F ; } } else { if ( ( UIDevice . getCurrentDevice ( ) . getUserInterfaceIdiom ( ) ) == ( UIUserInterfaceIdiom . Pad ) ) { displayScaleFactor = config . displayScaleLargeScreenIfNonRetina ; } else { displayScaleFactor = config . displayScaleSmallScreenIfNonRetina ; } } GL20 gl20 = new IOSGLES20 ( ) ; Gdx . gl = gl20 ; Gdx . gl20 = gl20 ; this . input = new IOSInput ( this ) ; this . graphics = new IOSGraphics ( getBounds ( null ) , this , config , input , gl20 ) ; this . files = new IOSFiles ( ) ; <START_BUG> this . audio = new IOSAudio ( ) ; <END_BUG> this . net = new IOSNet ( this ) ; Gdx . files = this . files ; Gdx . graphics = this . graphics ; Gdx . audio = this . audio ; Gdx . input = this . input ; Gdx . net = this . net ; this . input . setupPeripherals ( ) ; this . uiWindow = new UIWindow ( UIScreen . getMainScreen ( ) . getBounds ( ) ) ; this . uiWindow . setRootViewController ( this . graphics . viewController ) ; this . uiWindow . makeKeyAndVisible ( ) ; app . debug ( "IOSApplication" , "created" ) ; return true ; } public UIViewController getUIViewController ( ) { } CGSize getBounds ( UIViewController viewController ) { } final void didBecomeActive ( UIApplication uiApp ) { } final void willResignActive ( UIApplication uiApp ) { } final void willTerminate ( UIApplication uiApp ) { } @ Override public ApplicationListener getApplicationListener ( ) { } @ Override public Graphics getGraphics ( ) { } @ Override public Audio getAudio ( ) { } @ Override public Input getInput ( ) { } @ Override public Files getFiles ( ) { } @ Override public Net getNet ( ) { } @ Override public void log ( String tag , String message ) { } @ Override public void log ( String tag , String message , Throwable exception ) { } @ Override public void error ( String tag , String message ) { } @ Override public void error ( String tag , String message , Throwable exception ) { } @ Override public void debug ( String tag , String message ) { } @ Override public void debug ( String tag , String message , Throwable exception ) { } @ Override public void setLogLevel ( int logLevel ) { } @ Override public int getLogLevel ( ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } @ Override public Preferences getPreferences ( String name ) { } @ Override public void postRunnable ( Runnable runnable ) { } public void processRunnables ( ) { } @ Override public void exit ( ) { } @ Override public Clipboard getClipboard ( ) { } @ Override public void addLifecycleListener ( LifecycleListener listener ) { } @ Override public void removeLifecycleListener ( LifecycleListener listener ) { } }<BUG2FIX>this . audio = new IOSAudio ( config ) ;
} logger . info ( "start<seq2seq4repair_space>two<seq2seq4repair_space>nodes<seq2seq4repair_space>and<seq2seq4repair_space>fully<seq2seq4repair_space>start<seq2seq4repair_space>the<seq2seq4repair_space>shards" ) ; clusterState = ClusterState . builder ( clusterState ) . nodes ( DiscoveryNodes . builder ( ) . put ( RoutingAllocationTests . newNode ( "node1" ) ) . put ( RoutingAllocationTests . newNode ( "node2" ) ) ) . build ( ) ; RoutingTable prevRoutingTable = routingTable ; routingTable = strategy . reroute ( clusterState ) . routingTable ( ) ; clusterState = ClusterState . builder ( clusterState ) . routingTable ( routingTable ) . build ( ) ; for ( int i = 0 ; i < ( routingTable . index ( "test" ) . shards ( ) . size ( ) ) ; i ++ ) { assertThat ( routingTable . index ( "test" ) . shard ( i ) . shards ( ) . size ( ) , equalTo ( 2 ) ) ; assertThat ( routingTable . index ( "test" ) . shard ( i ) . primaryShard ( ) . state ( ) , equalTo ( INITIALIZING ) ) ; assertThat ( routingTable . index ( "test" ) . shard ( i ) . replicaShards ( ) . get ( 0 ) . state ( ) , equalTo ( UNASSIGNED ) ) ; } logger . info ( "start<seq2seq4repair_space>all<seq2seq4repair_space>the<seq2seq4repair_space>primary<seq2seq4repair_space>shards,<seq2seq4repair_space>replicas<seq2seq4repair_space>will<seq2seq4repair_space>start<seq2seq4repair_space>initializing" ) ; RoutingNodes routingNodes = clusterState . routingNodes ( ) ; prevRoutingTable = routingTable ; routingTable = strategy . applyStartedShards ( clusterState , routingNodes . shardsWithState ( INITIALIZING ) ) . routingTable ( ) ; clusterState = ClusterState . builder ( clusterState ) . routingTable ( routingTable ) . build ( ) ; routingNodes = clusterState . routingNodes ( ) ; for ( int i = 0 ; i < ( routingTable . index ( "test" ) . shards ( ) . size ( ) ) ; i ++ ) { assertThat ( routingTable . index ( "test" ) . shard ( i ) . shards ( ) . size ( ) , equalTo ( 2 ) ) ; assertThat ( routingTable . index ( "test" ) . shard ( i ) . primaryShard ( ) . state ( ) , equalTo ( STARTED ) ) ; assertThat ( routingTable . index ( "test" ) . shard ( i ) . replicaShards ( ) . get ( 0 ) . state ( ) , equalTo ( INITIALIZING ) ) ; } logger . info ( "now,<seq2seq4repair_space>start<seq2seq4repair_space>8<seq2seq4repair_space>more<seq2seq4repair_space>nodes,<seq2seq4repair_space>and<seq2seq4repair_space>check<seq2seq4repair_space>that<seq2seq4repair_space>no<seq2seq4repair_space>rebalancing/relocation<seq2seq4repair_space>have<seq2seq4repair_space>happened" ) ; clusterState = ClusterState . builder ( clusterState ) . nodes ( DiscoveryNodes . builder ( clusterState . nodes ( ) ) . put ( RoutingAllocationTests . newNode ( "node3" ) ) . put ( RoutingAllocationTests . newNode ( "node4" ) ) . put ( RoutingAllocationTests . newNode ( "node5" ) ) . put ( RoutingAllocationTests . newNode ( "node6" ) ) . put ( RoutingAllocationTests . newNode ( "node7" ) ) . put ( RoutingAllocationTests . newNode ( "node8" ) ) . put ( RoutingAllocationTests . newNode ( "node9" ) ) . put ( RoutingAllocationTests . newNode ( "node10" ) ) ) . build ( ) ; prevRoutingTable = routingTable ; routingTable = strategy . reroute ( clusterState ) . routingTable ( ) ; clusterState = ClusterState . builder ( clusterState ) . routingTable ( routingTable ) . build ( ) ; routingNodes = clusterState . routingNodes ( ) ; for ( int i = 0 ; i < ( routingTable . index ( "test" ) . shards ( ) . size ( ) ) ; i ++ ) { assertThat ( routingTable . index ( "test" ) . shard ( i ) . shards ( ) . size ( ) , equalTo ( 2 ) ) ; assertThat ( routingTable . index ( "test" ) . shard ( i ) . primaryShard ( ) . state ( ) , equalTo ( STARTED ) ) ; assertThat ( routingTable . index ( "test" ) . shard ( i ) . replicaShards ( ) . get ( 0 ) . state ( ) , equalTo ( INITIALIZING ) ) ; } logger . info ( "start<seq2seq4repair_space>the<seq2seq4repair_space>replica<seq2seq4repair_space>shards,<seq2seq4repair_space>rebalancing<seq2seq4repair_space>should<seq2seq4repair_space>start" ) ; routingNodes = clusterState . routingNodes ( ) ; prevRoutingTable = routingTable ; routingTable = strategy . applyStartedShards ( clusterState , routingNodes . shardsWithState ( INITIALIZING ) ) . routingTable ( ) ; clusterState = ClusterState . builder ( clusterState ) . routingTable ( routingTable ) . build ( ) ; routingNodes = clusterState . routingNodes ( ) ; assertThat ( routingTable . shardsWithState ( STARTED ) . size ( ) , equalTo ( 5 ) ) ; assertThat ( routingTable . shardsWithState ( RELOCATING ) . size ( ) , equalTo ( 5 ) ) ; logger . info ( "complete<seq2seq4repair_space>relocation,<seq2seq4repair_space>other<seq2seq4repair_space>half<seq2seq4repair_space>of<seq2seq4repair_space>relocation<seq2seq4repair_space>should<seq2seq4repair_space>happen" ) ; routingNodes = clusterState . routingNodes ( ) ; prevRoutingTable = routingTable ; routingTable = strategy . applyStartedShards ( clusterState , routingNodes . shardsWithState ( INITIALIZING ) ) . routingTable ( ) ; clusterState = ClusterState . builder ( clusterState ) . routingTable ( routingTable ) . build ( ) ; routingNodes = clusterState . routingNodes ( ) ; assertThat ( routingTable . shardsWithState ( STARTED ) . size ( ) , equalTo ( 7 ) ) ; assertThat ( routingTable . shardsWithState ( RELOCATING ) . size ( ) , equalTo ( 3 ) ) ; logger . info ( "complete<seq2seq4repair_space>relocation,<seq2seq4repair_space>thats<seq2seq4repair_space>it!" ) ; routingNodes = clusterState . routingNodes ( ) ; prevRoutingTable = routingTable ; routingTable = strategy . applyStartedShards ( clusterState , routingNodes . shardsWithState ( INITIALIZING ) ) . routingTable ( ) ; clusterState = ClusterState . builder ( clusterState ) . routingTable ( routingTable ) . build ( ) ; routingNodes = clusterState . routingNodes ( ) ; assertThat ( routingTable . shardsWithState ( STARTED ) . size ( ) , equalTo ( 10 ) ) ; for ( RoutingNode routingNode : routingNodes ) { <START_BUG> assertThat ( routingNode . shards ( ) . size ( ) , equalTo ( 1 ) ) ; <END_BUG> } } }<BUG2FIX>assertThat ( routingNode . size ( ) , equalTo ( 1 ) ) ;
public class ScriptFilterBuilder extends BaseFilterBuilder { private final String script ; private Map < String , Object > params ; private String lang ; private Boolean cache ; private String filterName ; public ScriptFilterBuilder ( String script ) { } public ScriptFilterBuilder addParam ( String name , Object value ) { } public ScriptFilterBuilder params ( Map < String , Object > params ) { <START_BUG> if ( params == null ) { <END_BUG> this . params = params ; } else { this . params . putAll ( params ) ; } return this ; } public ScriptFilterBuilder lang ( String lang ) { } public ScriptFilterBuilder filterName ( String filterName ) { } public ScriptFilterBuilder cache ( boolean cache ) { } @ Override protected void doXContent ( XContentBuilder builder , Params params ) throws IOException { } }<BUG2FIX>if ( ( this . params ) == null ) {
@ ClusterScope ( scope = Scope . SUITE , numNodes = 1 ) public class IndexTemplateFileLoadingTests extends ElasticsearchIntegrationTest { @ Rule public TemporaryFolder temporaryFolder = new TemporaryFolder ( ) ; @ Override protected Settings nodeSettings ( int nodeOrdinal ) { ImmutableSettings . Builder settingsBuilder = ImmutableSettings . settingsBuilder ( ) ; settingsBuilder . put ( super . nodeSettings ( nodeOrdinal ) ) ; try { File directory = temporaryFolder . newFolder ( ) ; settingsBuilder . put ( "path.conf" , directory . getPath ( ) ) ; File templatesDir = new File ( ( ( directory + ( File . separator ) ) + "templates" ) ) ; templatesDir . mkdir ( ) ; File dst = new File ( templatesDir , "template.json" ) ; <START_BUG> String template = Streams . copyToStringFromClasspath ( ( ( "/org/elasticsearch/indices/template/template" + ( randomInt ( 1 ) ) ) + ".json" ) ) ; <END_BUG> Files . write ( template , dst , Charsets . UTF_8 ) ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } return settingsBuilder . build ( ) ; } @ Test public void testThatLoadingTemplateFromFileWorks ( ) throws Exception { } }<BUG2FIX>String template = Streams . copyToStringFromClasspath ( ( ( "/org/elasticsearch/indices/template/template" + ( randomInt ( 2 ) ) ) + ".json" ) ) ;
public interface EventListener { <START_BUG> public void handle ( Event event ) ; <END_BUG> }<BUG2FIX>public boolean handle ( Event event ) ;
public class FloatArray { public float [ ] items ; public int size ; public boolean ordered ; public FloatArray ( ) { } public FloatArray ( int capacity ) { } public FloatArray ( boolean ordered , int capacity ) { } public FloatArray ( FloatArray array ) { } public FloatArray ( float [ ] array ) { } public FloatArray ( boolean ordered , float [ ] array ) { } public void add ( float value ) { } public void addAll ( FloatArray array ) { } public void addAll ( FloatArray array , int offset , int length ) { } public void addAll ( float [ ] array ) { } public void addAll ( float [ ] array , int offset , int length ) { } public float get ( int index ) { } public void set ( int index , float value ) { } public void insert ( int index , float value ) { } public void swap ( int first , int second ) { } public boolean contains ( float value ) { } public int indexOf ( float value ) { } public int lastIndexOf ( char value ) { } public boolean removeValue ( float value ) { } public float removeIndex ( int index ) { } public boolean removeAll ( FloatArray array ) { int size = this . size ; int startSize = size ; float [ ] items = this . items ; for ( int i = 0 , n = array . size ; i < n ; i ++ ) { float item = array . get ( i ) ; <START_BUG> for ( int ii = 0 , nn = size ; ii < nn ; ii ++ ) { <END_BUG> if ( item == ( items [ ii ] ) ) { removeIndex ( ii ) ; size -- ; break ; } } } return size != startSize ; } public float pop ( ) { } public float peek ( ) { } public float first ( ) { } public void clear ( ) { } public void shrink ( ) { } public float [ ] ensureCapacity ( int additionalCapacity ) { } protected float [ ] resize ( int newSize ) { } public void sort ( ) { } public void reverse ( ) { } public void shuffle ( ) { } public void truncate ( int newSize ) { } public float random ( ) { } public float [ ] toArray ( ) { } public boolean equals ( Object object ) { } public String toString ( ) { } public String toString ( String separator ) { } }<BUG2FIX>for ( int ii = 0 ; ii < size ; ii ++ ) {
public class Mesh implements Disposable { public enum VertexDataType { VertexArray , VertexBufferObject , VertexBufferObjectSubData ; } static final Map < Application , List < Mesh > > meshes = new HashMap < Application , List < Mesh > > ( ) ; public static boolean forceVBO = false ; final VertexData vertices ; final IndexData indices ; boolean autoBind = true ; final boolean isVertexArray ; public Mesh ( boolean isStatic , int maxVertices , int maxIndices , VertexAttribute ... attributes ) { } public Mesh ( boolean isStatic , int maxVertices , int maxIndices , VertexAttributes attributes ) { } public Mesh ( boolean staticVertices , boolean staticIndices , int maxVertices , int maxIndices , VertexAttributes attributes ) { } public Mesh ( Mesh . VertexDataType type , boolean isStatic , int maxVertices , int maxIndices , VertexAttribute ... attributes ) { } public static Mesh create ( boolean isStatic , final Mesh base , final Matrix4 [ ] transformations ) { } public static Mesh create ( boolean isStatic , final Mesh [ ] meshes ) { } public static Mesh create ( boolean isStatic , final Mesh [ ] meshes , final Matrix4 [ ] transformations ) { if ( ( transformations != null ) && ( ( transformations . length ) < ( meshes . length ) ) ) throw new IllegalArgumentException ( "Not<seq2seq4repair_space>enough<seq2seq4repair_space>transformations<seq2seq4repair_space>specified" ) ; final VertexAttributes attributes = meshes [ 0 ] . getVertexAttributes ( ) ; int vertCount = meshes [ 0 ] . getNumVertices ( ) ; int idxCount = meshes [ 0 ] . getNumIndices ( ) ; for ( int i = 1 ; i < ( meshes . length ) ; i ++ ) { if ( ! ( meshes [ i ] . getVertexAttributes ( ) . equals ( attributes ) ) ) throw new IllegalArgumentException ( "Inconsistent<seq2seq4repair_space>VertexAttributes" ) ; vertCount += meshes [ i ] . getNumVertices ( ) ; idxCount += meshes [ i ] . getNumIndices ( ) ; } final VertexAttribute posAttr = meshes [ 0 ] . getVertexAttribute ( Position ) ; final int offset = ( posAttr . offset ) / 4 ; final int numComponents = posAttr . numComponents ; final int vertexSize = ( attributes . vertexSize ) / 4 ; final float [ ] vertices = new float [ vertCount * vertexSize ] ; final short [ ] indices = new short [ idxCount ] ; meshes [ 0 ] . getVertices ( vertices ) ; meshes [ 0 ] . getIndices ( indices ) ; int voffset = ( meshes [ 0 ] . getNumVertices ( ) ) * vertexSize ; int ioffset = meshes [ 0 ] . getNumIndices ( ) ; for ( int i = 1 ; i < ( meshes . length ) ; i ++ ) { final Mesh mesh = meshes [ i ] ; final int vsize = ( mesh . getNumVertices ( ) ) * vertexSize ; final int isize = mesh . getNumIndices ( ) ; mesh . getVertices ( 0 , vsize , vertices , voffset ) ; if ( transformations != null ) Mesh . transform ( transformations [ i ] , vertices , vertexSize , offset , numComponents , ( voffset / vertexSize ) , ( vsize / vertexSize ) ) ; mesh . getIndices ( indices , ioffset ) ; <START_BUG> for ( int j = 0 ; j < isize ; i ++ ) <END_BUG> indices [ ( ioffset + j ) ] = ( ( short ) ( ( indices [ ( ioffset + j ) ] ) + voffset ) ) ; voffset += vsize ; ioffset += isize ; } final Mesh result = new Mesh ( isStatic , ( ( vertices . length ) / vertexSize ) , indices . length , attributes ) ; result . setVertices ( vertices ) ; result . setIndices ( indices ) ; return result ; } public Mesh setVertices ( float [ ] vertices ) { } public Mesh setVertices ( float [ ] vertices , int offset , int count ) { } public void getVertices ( float [ ] vertices ) { } public void getVertices ( int srcOffset , float [ ] vertices ) { } public void getVertices ( int srcOffset , int count , float [ ] vertices ) { } public void getVertices ( int srcOffset , int count , float [ ] vertices , int destOffset ) { } public Mesh setIndices ( short [ ] indices ) { } public Mesh setIndices ( short [ ] indices , int offset , int count ) { } public void getIndices ( short [ ] indices ) { } public void getIndices ( short [ ] indices , int destOffset ) { } public int getNumIndices ( ) { } public int getNumVertices ( ) { } public int getMaxVertices ( ) { } public int getMaxIndices ( ) { } public int getVertexSize ( ) { } public void setAutoBind ( boolean autoBind ) { } public void bind ( ) { } public void unbind ( ) { } public void bind ( final ShaderProgram shader ) { } public void bind ( final ShaderProgram shader , final int [ ] locations ) { } public void unbind ( final ShaderProgram shader ) { } public void unbind ( final ShaderProgram shader , final int [ ] locations ) { } public void render ( int primitiveType ) { } public void render ( int primitiveType , int offset , int count ) { } public void render ( int primitiveType , int offset , int count , boolean autoBind ) { } public void render ( ShaderProgram shader , int primitiveType ) { } public void render ( ShaderProgram shader , int primitiveType , int offset , int count ) { }<BUG2FIX>for ( int j = 0 ; j < isize ; j ++ )
public class IndexBufferObject implements IndexData { static final IntBuffer tmpHandle = BufferUtils . newIntBuffer ( 1 ) ; ShortBuffer buffer ; ByteBuffer byteBuffer ; int bufferHandle ; final boolean isDirect ; boolean isDirty = true ; boolean isBound = false ; final int usage ; public IndexBufferObject ( boolean isStatic , int maxIndices ) { } public IndexBufferObject ( int maxIndices ) { } private int createBufferObject ( ) { } public int getNumIndices ( ) { } public int getNumMaxIndices ( ) { } public void setIndices ( short [ ] indices , int offset , int count ) { isDirty = true ; buffer . clear ( ) ; buffer . put ( indices , offset , count ) ; buffer . flip ( ) ; byteBuffer . position ( 0 ) ; byteBuffer . limit ( ( count << 1 ) ) ; if ( isBound ) { if ( ( Gdx . gl11 ) != null ) { GL11 gl = Gdx . gl11 ; gl . glBufferData ( GL_ELEMENT_ARRAY_BUFFER , byteBuffer . limit ( ) , byteBuffer , usage ) ; } else <START_BUG> if ( ( Gdx . gl11 ) != null ) { <END_BUG> GL20 gl = Gdx . gl20 ; gl . glBufferData ( GL20 . GL_ELEMENT_ARRAY_BUFFER , byteBuffer . limit ( ) , byteBuffer , usage ) ; } isDirty = false ; } } public ShortBuffer getBuffer ( ) { } public void bind ( ) { } public void unbind ( ) { } public void invalidate ( ) { } public void dispose ( ) { } }<BUG2FIX>if ( ( Gdx . gl20 ) != null ) {
public class UserRepositoryListFragment extends PagedItemFragment < Repository > { @ Inject private RepositoryService service ; @ InjectExtra ( Intents . EXTRA_USER ) private User user ; @ Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; setEmptyText ( getString ( no_repositories ) ) ; <START_BUG> ListViewUtils . configure ( getActivity ( ) , getListView ( ) , true ) ; <END_BUG> } @ Override protected ResourcePager < Repository > createPager ( ) { } @ Override protected int getLoadingMessage ( ) { } @ Override protected ItemListAdapter < Repository , ? extends ItemView > createAdapter ( List < Repository > items ) { } @ Override public void onListItemClick ( ListView list , View v , int position , long id ) { } }<BUG2FIX>ListViewUtils . configure ( getActivity ( ) , getListView ( ) ) ;
public class ParticleEmitterBox2D extends ParticleEmitter { final World world ; final Vector2 startPoint = new Vector2 ( ) ; final Vector2 endPoint = new Vector2 ( ) ; boolean particleCollided ; float normalAngle ; private static final float EPSILON = 0.001F ; final RayCastCallback rayCallBack = new RayCastCallback ( ) { public float reportRayFixture ( Fixture fixture , Vector2 point , Vector2 normal , float fraction ) { } } ; public ParticleEmitterBox2D ( World world ) { } public ParticleEmitterBox2D ( World world , BufferedReader reader ) throws IOException { } public ParticleEmitterBox2D ( World world , ParticleEmitter emitter ) { } @ Override protected Particle newParticle ( Sprite sprite ) { } private class ParticleBox2D extends Particle { public ParticleBox2D ( Sprite sprite ) { } @ Override public void translate ( float velocityX , float velocityY ) { if ( ( ( velocityX * velocityX ) + ( velocityY * velocityY ) ) < ( ParticleEmitterBox2D . EPSILON ) ) return ; final float x = ( getX ( ) ) + ( ( getWidth ( ) ) / 2.0F ) ; final float y = ( getY ( ) ) + ( ( getHeight ( ) ) / 2.0F ) ; particleCollided = false ; startPoint . set ( x , y ) ; endPoint . set ( ( x + velocityX ) , ( y + velocityY ) ) ; if ( ( world ) != null ) world . rayCast ( rayCallBack , startPoint , endPoint ) ; <START_BUG> if ( ! ( particleCollided ) ) { <END_BUG> angle = ( ( 2.0F * ( normalAngle ) ) - ( angle ) ) - 180.0F ; angleCos = MathUtils . cosDeg ( angle ) ; angleSin = MathUtils . sinDeg ( angle ) ; velocityX = ( velocity ) * ( angleCos ) ; velocityY = ( velocity ) * ( angleSin ) ; } super . translate ( velocityX , velocityY ) ; } } }<BUG2FIX>if ( particleCollided ) {
public class TransportGetFieldMappingsAction extends TransportAction < GetFieldMappingsRequest , GetFieldMappingsResponse > { private final ClusterService clusterService ; private final TransportGetFieldMappingsIndexAction shardAction ; private final String transportAction ; @ Inject public TransportGetFieldMappingsAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool , TransportGetFieldMappingsIndexAction shardAction ) { } @ Override protected void doExecute ( GetFieldMappingsRequest request , final ActionListener < GetFieldMappingsResponse > listener ) { ClusterState clusterState = clusterService . state ( ) ; String [ ] concreteIndices = clusterState . metaData ( ) . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ; final AtomicInteger indexCounter = new AtomicInteger ( ) ; final AtomicInteger completionCounter = new AtomicInteger ( concreteIndices . length ) ; final AtomicReferenceArray < Object > indexResponses = new AtomicReferenceArray < > ( concreteIndices . length ) ; <START_BUG> if ( ( concreteIndices == null ) || ( ( concreteIndices . length ) == 0 ) ) { <END_BUG> listener . onResponse ( new GetFieldMappingsResponse ( ) ) ; } else { boolean probablySingleFieldRequest = ( ( ( concreteIndices . length ) == 1 ) && ( ( request . types ( ) . length ) == 1 ) ) && ( ( request . fields ( ) . length ) == 1 ) ; for ( final String index : concreteIndices ) { GetFieldMappingsIndexRequest shardRequest = new GetFieldMappingsIndexRequest ( request , index , probablySingleFieldRequest ) ; shardRequest . listenerThreaded ( false ) ; shardAction . execute ( shardRequest , new ActionListener < GetFieldMappingsResponse > ( ) { @ Override public void onResponse ( GetFieldMappingsResponse result ) { indexResponses . set ( indexCounter . getAndIncrement ( ) , result ) ; if ( ( completionCounter . decrementAndGet ( ) ) == 0 ) { listener . onResponse ( merge ( indexResponses ) ) ; } } @ Override public void onFailure ( Throwable e ) { int index = indexCounter . getAndIncrement ( ) ; indexResponses . set ( index , e ) ; if ( ( completionCounter . decrementAndGet ( ) ) == 0 ) { listener . onResponse ( merge ( indexResponses ) ) ; } } } ) ; } } } private GetFieldMappingsResponse merge ( AtomicReferenceArray < Object > indexResponses ) { } private class TransportHandler extends BaseTransportRequestHandler < GetFieldMappingsRequest > { @ Override public GetFieldMappingsRequest newInstance ( ) { } @ Override public String executor ( ) { } @ Override public void messageReceived ( final GetFieldMappingsRequest request , final TransportChannel channel ) throws Exception { } } }<BUG2FIX>if ( ( concreteIndices . length ) == 0 ) {
public class BouncyDesktop { public static void main ( String [ ] argv ) { <START_BUG> new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new Bouncy ( ) , "Bouncy" , 320 , 480 , true ) ; <END_BUG> } }<BUG2FIX>new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new Bouncy ( ) , "Bouncy" , 320 , 480 ) ;
public class Label extends Widget { private Label . LabelStyle style ; private final TextBounds bounds = new TextBounds ( ) ; private String text ; private BitmapFontCache cache ; private float prefWidth ; private float prefHeight ; private int labelAlign = Align . LEFT ; private HAlignment lineAlign = HAlignment . LEFT ; private boolean wrap ; private float lastPrefHeight ; public Label ( Skin skin ) { } public Label ( String text , Skin skin ) { } public Label ( String text , String fontName , Color color , Skin skin ) { } public Label ( String text , String fontName , String colorName , Skin skin ) { } public Label ( String text , Label . LabelStyle style ) { } public Label ( String text , Label . LabelStyle style , String name ) { } public void setStyle ( Label . LabelStyle style ) { } public Label . LabelStyle getStyle ( ) { } public void setText ( String text ) { } public String getText ( ) { } public TextBounds getTextBounds ( ) { } public void setWrap ( boolean wrap ) { } public void setAlignment ( int wrapAlign ) { } public void setAlignment ( int labelAlign , int lineAlign ) { } public void setColor ( float color ) { } public void setColor ( Color tint ) { } public void setColor ( float r , float g , float b , float a ) { } public Color getColor ( ) { } private void computeBounds ( ) { } @ Override public void layout ( ) { } @ Override public void draw ( SpriteBatch batch , float parentAlpha ) { } public float getPrefWidth ( ) { if ( wrap ) <START_BUG> return 150 ; <END_BUG> return bounds . width ; } public float getPrefHeight ( ) { } public static class LabelStyle { public BitmapFont font ; public Color fontColor ; public LabelStyle ( ) { } public LabelStyle ( BitmapFont font , Color fontColor ) { } } }<BUG2FIX>return 0 ;
public class ClickListener extends InputListener { private float tapSquareSize = 14 ; private float touchDownX = - 1 ; private float touchDownY = - 1 ; private int pressedPointer = - 1 ; private int button ; private boolean pressed ; private boolean over ; private boolean cancelled ; private long tapCountInterval = ( ( long ) ( 0.4F * 1000000000L ) ) ; private int tapCount ; private long lastTapTime ; public boolean touchDown ( InputEvent event , float x , float y , int pointer , int button ) { } public void touchDragged ( InputEvent event , float x , float y , int pointer ) { } public void touchUp ( InputEvent event , float x , float y , int pointer , int button ) { } public void enter ( InputEvent event , float x , float y , int pointer , Actor fromActor ) { } public void exit ( InputEvent event , float x , float y , int pointer , Actor toActor ) { } public void cancel ( ) { } public void clicked ( InputEvent event , float x , float y ) { } public void dragStart ( InputEvent event , float x , float y , int pointer ) { } public void drag ( InputEvent event , float x , float y , int pointer ) { } public void dragStop ( InputEvent event , float x , float y , int pointer ) { } public boolean isOver ( Actor actor , float x , float y ) { <START_BUG> Actor hit = actor . hit ( x , y ) ; <END_BUG> if ( ( hit == null ) || ( ! ( hit . isDescendant ( actor ) ) ) ) { if ( ( ( touchDownX ) == ( - 1 ) ) && ( ( touchDownY ) == ( - 1 ) ) ) return false ; return ( ( Math . abs ( ( x - ( touchDownX ) ) ) ) < ( tapSquareSize ) ) && ( ( Math . abs ( ( y - ( touchDownY ) ) ) ) < ( tapSquareSize ) ) ; } return true ; } public boolean isPressed ( ) { } public boolean isOver ( ) { } public void setTapSquareSize ( float halfTapSquareSize ) { } public float getTapSquareSize ( ) { } public void setTapCountInterval ( float tapCountInterval ) { } public int getTapCount ( ) { } public float getTouchDownX ( ) { } public float getTouchDownY ( ) { } public int getButton ( ) { } public void setButton ( int button ) { } }<BUG2FIX>Actor hit = actor . hit ( x , y , true ) ;
public abstract class TransportIndicesReplicationOperationAction < Request extends IndicesReplicationOperationRequest , Response extends ActionResponse , IndexRequest extends IndexReplicationOperationRequest , IndexResponse extends ActionResponse , ShardRequest extends ShardReplicationOperationRequest , ShardReplicaRequest extends ShardReplicationOperationRequest , ShardResponse extends ActionResponse > extends TransportAction < Request , Response > { protected final ClusterService clusterService ; protected final TransportIndexReplicationOperationAction < IndexRequest , IndexResponse , ShardRequest , ShardReplicaRequest , ShardResponse > indexAction ; final String transportAction ; @ Inject public TransportIndicesReplicationOperationAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool , TransportIndexReplicationOperationAction < IndexRequest , IndexResponse , ShardRequest , ShardReplicaRequest , ShardResponse > indexAction ) { } protected abstract Map < String , Set < String > > resolveRouting ( ClusterState clusterState , Request request ) throws ElasticsearchException { } @ Override protected void doExecute ( final Request request , final ActionListener < Response > listener ) { ClusterState clusterState = clusterService . state ( ) ; ClusterBlockException blockException = checkGlobalBlock ( clusterState , request ) ; if ( blockException != null ) { throw blockException ; } String [ ] concreteIndices = clusterState . metaData ( ) . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ; blockException = checkRequestBlock ( clusterState , request , concreteIndices ) ; if ( blockException != null ) { throw blockException ; } final AtomicInteger indexCounter = new AtomicInteger ( ) ; final AtomicInteger completionCounter = new AtomicInteger ( concreteIndices . length ) ; final AtomicReferenceArray < Object > indexResponses = new AtomicReferenceArray < > ( concreteIndices . length ) ; final long startTimeInMillis = System . currentTimeMillis ( ) ; Map < String , Set < String > > routingMap = resolveRouting ( clusterState , request ) ; <START_BUG> if ( ( concreteIndices == null ) || ( ( concreteIndices . length ) == 0 ) ) { <END_BUG> listener . onResponse ( newResponseInstance ( request , indexResponses ) ) ; } else { for ( final String index : concreteIndices ) { Set < String > routing = null ; if ( routingMap != null ) { routing = routingMap . get ( index ) ; } IndexRequest indexRequest = newIndexRequestInstance ( request , index , routing , startTimeInMillis ) ; indexRequest . listenerThreaded ( false ) ; indexAction . execute ( indexRequest , new ActionListener < IndexResponse > ( ) { @ Override public void onResponse ( IndexResponse result ) { indexResponses . set ( indexCounter . getAndIncrement ( ) , result ) ; if ( ( completionCounter . decrementAndGet ( ) ) == 0 ) { listener . onResponse ( newResponseInstance ( request , indexResponses ) ) ; } } @ Override public void onFailure ( Throwable e ) { int index = indexCounter . getAndIncrement ( ) ; if ( accumulateExceptions ( ) ) { indexResponses . set ( index , e ) ; } if ( ( completionCounter . decrementAndGet ( ) ) == 0 ) { listener . onResponse ( newResponseInstance ( request , indexResponses ) ) ; } } } ) ; } } } protected abstract Request newRequestInstance ( ) { } protected abstract Response newResponseInstance ( Request request , AtomicReferenceArray indexResponses ) { } protected abstract String transportAction ( ) { } protected abstract IndexRequest newIndexRequestInstance ( Request request , String index , Set < String > routing , long startTimeInMillis ) { } protected abstract boolean accumulateExceptions ( ) { } protected abstract ClusterBlockException checkGlobalBlock ( ClusterState state , Request request ) { } protected abstract ClusterBlockException checkRequestBlock ( ClusterState state , Request request , String [ ] concreteIndices ) { } private class TransportHandler extends BaseTransportRequestHandler < Request > { @ Override public Request newInstance ( ) { } @ Override public String executor ( ) { } @ Override public void messageReceived ( final Request request , final TransportChannel channel ) throws Exception { } } }<BUG2FIX>if ( ( concreteIndices . length ) == 0 ) {
public class TransportSearchQueryThenFetchAction extends TransportSearchTypeAction { @ Inject public TransportSearchQueryThenFetchAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , SearchServiceTransportAction searchService , SearchPhaseController searchPhaseController ) { } @ Override protected void doExecute ( SearchRequest searchRequest , ActionListener < SearchResponse > listener ) { } private class AsyncAction extends BaseAsyncAction < QuerySearchResult > { final AtomicArray < FetchSearchResult > fetchResults ; final AtomicArray < ExtTIntArrayList > docIdsToLoad ; private AsyncAction ( SearchRequest request , ActionListener < SearchResponse > listener ) { } @ Override protected String firstPhaseName ( ) { } @ Override protected void sendExecuteFirstPhase ( DiscoveryNode node , ShardSearchRequest request , SearchServiceListener < QuerySearchResult > listener ) { } @ Override protected void moveToSecondPhase ( ) { } void executeFetch ( final int shardIndex , final SearchShardTarget shardTarget , final AtomicInteger counter , final FetchSearchRequest fetchSearchRequest , DiscoveryNode node ) { } void finishHim ( ) { try { innerFinishHim ( ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> ReduceSearchPhaseException failure = new ReduceSearchPhaseException ( "fetch" , "" , e , buildShardFailures ( ) ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>reduce<seq2seq4repair_space>search" , failure ) ; } listener . onFailure ( failure ) ; } finally { releaseIrrelevantSearchContexts ( firstResults , docIdsToLoad ) ; } } void innerFinishHim ( ) throws Exception { } } }<BUG2FIX>} catch ( Throwable e ) {
public class ByteArrayRef extends AbstractList < Byte > implements RandomAccess { public static final ByteArrayRef EMPTY = new ByteArrayRef ( new byte [ 0 ] ) ; public byte [ ] values ; public int start ; public int end ; public ByteArrayRef ( byte [ ] values ) { } public ByteArrayRef ( byte [ ] values , int length ) { } public ByteArrayRef ( byte [ ] values , int start , int end ) { } public void reset ( int newLength ) { } @ Override public int size ( ) { } @ Override public boolean isEmpty ( ) { <START_BUG> return ( size ( ) ) != 0 ; <END_BUG> } @ Override public Byte get ( int index ) { } @ Override public boolean contains ( Object target ) { } @ Override public int indexOf ( Object target ) { } @ Override public int lastIndexOf ( Object target ) { } @ Override public Byte set ( int index , Byte element ) { } @ Override public boolean equals ( Object object ) { } @ Override public int hashCode ( ) { } @ Override public String toString ( ) { } private static int indexOf ( byte [ ] array , byte target , int start , int end ) { } private static int lastIndexOf ( byte [ ] array , byte target , int start , int end ) { } }<BUG2FIX>return ( size ( ) ) == 0 ;
public class HasChildQueryParser implements QueryParser { public static final String NAME = "has_child" ; @ Inject public HasChildQueryParser ( ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; Query innerQuery = null ; boolean queryFound = false ; float boost = 1.0F ; String childType = null ; ScoreType scoreType = null ; int shortCircuitParentDocSet = 8192 ; String queryName = null ; String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_OBJECT ) ) { if ( "query" . equals ( currentFieldName ) ) { String [ ] origTypes = QueryParseContext . setTypesWithPrevious ( ( childType == null ? null : new String [ ] { childType } ) ) ; try { innerQuery = parseContext . parseInnerQuery ( ) ; queryFound = true ; } finally { QueryParseContext . setTypes ( origTypes ) ; } } else { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[has_child]<seq2seq4repair_space>query<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>support<seq2seq4repair_space>[" + currentFieldName ) + "]" ) ) ; } } else if ( token . isValue ( ) ) { if ( ( ( "type" . equals ( currentFieldName ) ) || ( "child_type" . equals ( currentFieldName ) ) ) || ( "childType" . equals ( currentFieldName ) ) ) { childType = parser . text ( ) ; } else if ( "_scope" . equals ( currentFieldName ) ) { throw new QueryParsingException ( parseContext . index ( ) , "the<seq2seq4repair_space>[_scope]<seq2seq4repair_space>support<seq2seq4repair_space>in<seq2seq4repair_space>[has_child]<seq2seq4repair_space>query<seq2seq4repair_space>has<seq2seq4repair_space>been<seq2seq4repair_space>removed,<seq2seq4repair_space>use<seq2seq4repair_space>a<seq2seq4repair_space>filter<seq2seq4repair_space>as<seq2seq4repair_space>a<seq2seq4repair_space>facet_filter<seq2seq4repair_space>in<seq2seq4repair_space>the<seq2seq4repair_space>relevant<seq2seq4repair_space>global<seq2seq4repair_space>facet" ) ; } else if ( ( "score_type" . equals ( currentFieldName ) ) || ( "scoreType" . equals ( currentFieldName ) ) ) { String scoreTypeValue = parser . text ( ) ; if ( ! ( "none" . equals ( scoreTypeValue ) ) ) { scoreType = ScoreType . fromString ( scoreTypeValue ) ; } } else if ( ( "score_mode" . equals ( currentFieldName ) ) || ( "scoreMode" . equals ( currentFieldName ) ) ) { String scoreModeValue = parser . text ( ) ; if ( ! ( "none" . equals ( scoreModeValue ) ) ) { scoreType = ScoreType . fromString ( scoreModeValue ) ; } } else if ( "boost" . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } else if ( "short_circuit_cutoff" . equals ( currentFieldName ) ) { shortCircuitParentDocSet = parser . intValue ( ) ; } else if ( "_name" . equals ( currentFieldName ) ) { queryName = parser . text ( ) ; } else { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[has_child]<seq2seq4repair_space>query<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>support<seq2seq4repair_space>[" + currentFieldName ) + "]" ) ) ; } } } if ( ! queryFound ) { throw new QueryParsingException ( parseContext . index ( ) , "[has_child]<seq2seq4repair_space>requires<seq2seq4repair_space>'query'<seq2seq4repair_space>field" ) ; } if ( innerQuery == null ) { return null ; } if ( childType == null ) { throw new QueryParsingException ( parseContext . index ( ) , "[has_child]<seq2seq4repair_space>requires<seq2seq4repair_space>'type'<seq2seq4repair_space>field" ) ; } innerQuery . setBoost ( boost ) ; DocumentMapper childDocMapper = parseContext . mapperService ( ) . documentMapper ( childType ) ; if ( childDocMapper == null ) { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[has_child]<seq2seq4repair_space>No<seq2seq4repair_space>mapping<seq2seq4repair_space>for<seq2seq4repair_space>for<seq2seq4repair_space>type<seq2seq4repair_space>[" + childType ) + "]" ) ) ; } if ( ! ( childDocMapper . parentFieldMapper ( ) . active ( ) ) ) { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[has_child]<seq2seq4repair_space>Type<seq2seq4repair_space>[" + childType ) + "]<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>have<seq2seq4repair_space>parent<seq2seq4repair_space>mapping" ) ) ; } String parentType = childDocMapper . parentFieldMapper ( ) . type ( ) ; DocumentMapper parentDocMapper = parseContext . mapperService ( ) . documentMapper ( parentType ) ; if ( parentDocMapper == null ) { throw new QueryParsingException ( parseContext . index ( ) , ( ( ( ( "[has_child]<seq2seq4repair_space>Type<seq2seq4repair_space>[" + childType ) + "]<seq2seq4repair_space>points<seq2seq4repair_space>to<seq2seq4repair_space>a<seq2seq4repair_space>non<seq2seq4repair_space>existent<seq2seq4repair_space>parent<seq2seq4repair_space>type<seq2seq4repair_space>[" ) + parentType ) + "]" ) ) ; } innerQuery = new org . elasticsearch . common . lucene . search . XFilteredQuery ( innerQuery , parseContext . cacheFilter ( childDocMapper . typeFilter ( ) , null ) ) ; boolean deleteByQuery = "delete_by_query" . equals ( SearchContext . current ( ) . source ( ) ) ; Query query ; Filter parentFilter = parseContext . cacheFilter ( parentDocMapper . typeFilter ( ) , null ) ; if ( ( ! deleteByQuery ) && ( scoreType != null ) ) { query = new org . elasticsearch . index . search . child . ChildrenQuery ( parentType , childType , parentFilter , innerQuery , scoreType , shortCircuitParentDocSet ) ; } else { <START_BUG> query = new org . elasticsearch . index . search . child . ChildrenConstantScoreQuery ( innerQuery , parentType , childType , parentFilter , shortCircuitParentDocSet , true ) ; <END_BUG> if ( deleteByQuery ) { query = new XConstantScoreQuery ( new org . elasticsearch . index . search . child . DeleteByQueryWrappingFilter ( query ) ) ; } } if ( queryName != null ) { parseContext . addNamedQuery ( queryName , query ) ; } query . setBoost ( boost ) ; return query ; } }<BUG2FIX>query = new org . elasticsearch . index . search . child . ChildrenConstantScoreQuery ( innerQuery , parentType , childType , parentFilter , shortCircuitParentDocSet ) ;
public class AnimationController extends BaseAnimationController { public interface AnimationListener { void onEnd ( final AnimationController . AnimationDesc animation ) { } void onLoop ( final AnimationController . AnimationDesc animation ) { } } public static class AnimationDesc { public AnimationController . AnimationListener listener ; public Animation animation ; public float speed ; public float time ; public float offset ; public float duration ; public int loopCount ; protected AnimationDesc ( ) { } protected float update ( float delta ) { } } protected final Pool < AnimationController . AnimationDesc > animationPool = new Pool < AnimationController . AnimationDesc > ( ) { @ Override protected AnimationController . AnimationDesc newObject ( ) { } } ; public AnimationController . AnimationDesc current ; public AnimationController . AnimationDesc queued ; public float queuedTransitionTime ; public AnimationController . AnimationDesc previous ; public float transitionCurrentTime ; public float transitionTargetTime ; public boolean inAction ; public boolean paused ; public boolean allowSameAnimation ; private boolean justChangedAnimation = false ; public AnimationController ( final ModelInstance target ) { } private AnimationController . AnimationDesc obtain ( final Animation anim , float offset , float duration , int loopCount , float speed , final AnimationController . AnimationListener listener ) { } private AnimationController . AnimationDesc obtain ( final String id , float offset , float duration , int loopCount , float speed , final AnimationController . AnimationListener listener ) { } private AnimationController . AnimationDesc obtain ( final AnimationController . AnimationDesc anim ) { } private boolean updating ; public void update ( float delta ) { } public AnimationController . AnimationDesc setAnimation ( final String id ) { } public AnimationController . AnimationDesc setAnimation ( final String id , int loopCount ) { } public AnimationController . AnimationDesc setAnimation ( final String id , final AnimationController . AnimationListener listener ) { } public AnimationController . AnimationDesc setAnimation ( final String id , int loopCount , final AnimationController . AnimationListener listener ) { } public AnimationController . AnimationDesc setAnimation ( final String id , int loopCount , float speed , final AnimationController . AnimationListener listener ) { } public AnimationController . AnimationDesc setAnimation ( final String id , float offset , float duration , int loopCount , float speed , final AnimationController . AnimationListener listener ) { } protected AnimationController . AnimationDesc setAnimation ( final Animation anim , float offset , float duration , int loopCount , float speed , final AnimationController . AnimationListener listener ) { } protected AnimationController . AnimationDesc setAnimation ( final AnimationController . AnimationDesc anim ) { if ( updating ) throw new GdxRuntimeException ( "Cannot<seq2seq4repair_space>change<seq2seq4repair_space>animation<seq2seq4repair_space>during<seq2seq4repair_space>update" ) ; if ( ( current ) == null ) current = anim ; else { <START_BUG> if ( ( ( ! ( allowSameAnimation ) ) && ( anim != null ) ) && ( ( current . animation ) == ( anim . animation ) ) ) <END_BUG> anim . time = current . time ; else removeAnimation ( current . animation ) ; animationPool . free ( current ) ; current = anim ; } justChangedAnimation = true ; return anim ; } public AnimationController . AnimationDesc animate ( final String id , float transitionTime ) { } public AnimationController . AnimationDesc animate ( final String id , final AnimationController . AnimationListener listener , float transitionTime ) { } public AnimationController . AnimationDesc animate ( final String id , int loopCount , final AnimationController . AnimationListener listener , float transitionTime ) { } public AnimationController . AnimationDesc animate ( final String id , int loopCount , float speed , final AnimationController . AnimationListener listener , float transitionTime ) { } public AnimationController . AnimationDesc animate ( final String id , float offset , float duration , int loopCount , float speed , final AnimationController . AnimationListener listener , float transitionTime ) { } protected AnimationController . AnimationDesc animate ( final Animation anim , float offset , float duration , int loopCount , float speed , final AnimationController . AnimationListener listener , float transitionTime ) { } protected AnimationController . AnimationDesc animate ( final AnimationController . AnimationDesc anim , float transitionTime ) { } public AnimationController . AnimationDesc queue ( final String id , int loopCount , float speed , final AnimationController . AnimationListener listener , float transitionTime ) { } public AnimationController . AnimationDesc queue ( final String id , float offset , float duration , int loopCount , float speed , final AnimationController . AnimationListener listener , float transitionTime ) { } protected AnimationController . AnimationDesc queue ( final Animation anim , float offset , float duration , int loopCount , float speed , final AnimationController . AnimationListener listener , float transitionTime ) { } protected AnimationController . AnimationDesc queue ( final AnimationController . AnimationDesc anim , float transitionTime ) { } public AnimationController . AnimationDesc action ( final String id , int loopCount , float speed , final AnimationController . AnimationListener listener , float transitionTime ) { } public AnimationController . AnimationDesc action ( final String id , float offset , float duration , int loopCount , float speed , final AnimationController . AnimationListener listener , float transitionTime ) { } protected AnimationController . AnimationDesc action ( final Animation anim , float offset , float duration , int loopCount , float speed , final AnimationController . AnimationListener listener , float transitionTime ) { } protected AnimationController . AnimationDesc action ( final AnimationController . AnimationDesc anim , float transitionTime ) { } }<BUG2FIX>if ( ( anim != null ) && ( ( current . animation ) == ( anim . animation ) ) )
public class GdxInvadersAndroid extends AndroidApplication { @ Override public void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; setRequestedOrientation ( SCREEN_ORIENTATION_LANDSCAPE ) ; AndroidApplicationConfiguration config = new AndroidApplicationConfiguration ( ) ; config . useWakelock = true ; <START_BUG> config . useGL20 = true ; <END_BUG> initialize ( new GdxInvaders ( ) , config ) ; } }<BUG2FIX>config . useGL20 = false ;
public class TermsStatsStringFacetCollector extends AbstractFacetCollector { private final ComparatorType comparatorType ; private final FieldDataCache fieldDataCache ; private final String keyFieldName ; private final String valueFieldName ; private final int size ; private final int numberOfShards ; private final FieldDataType keyFieldDataType ; private FieldData keyFieldData ; private final FieldDataType valueFieldDataType ; private final SearchScript script ; private final TermsStatsStringFacetCollector . Aggregator aggregator ; public TermsStatsStringFacetCollector ( String facetName , String keyFieldName , String valueFieldName , int size , TermsStatsFacet . ComparatorType comparatorType , SearchContext context , String scriptLang , String script , Map < String , Object > params ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override protected void doSetNextReader ( AtomicReaderContext context ) throws IOException { keyFieldData = fieldDataCache . cache ( keyFieldDataType , context . reader ( ) , keyFieldName ) ; if ( ( script ) != null ) { <START_BUG> script . setNextReader ( context . reader ( ) ) ; <END_BUG> } else { aggregator . valueFieldData = ( ( NumericFieldData ) ( fieldDataCache . cache ( valueFieldDataType , context . reader ( ) , valueFieldName ) ) ) ; } } @ Override protected void doCollect ( int doc ) throws IOException { } @ Override public Facet facet ( ) { } public static class Aggregator implements FieldData . StringValueInDocProc { final ExtTHashMap < BytesRef , InternalTermsStatsStringFacet . StringEntry > entries = CacheRecycler . popHashMap ( ) ; int missing = 0 ; NumericFieldData valueFieldData ; TermsStatsStringFacetCollector . Aggregator . ValueAggregator valueAggregator = new TermsStatsStringFacetCollector . Aggregator . ValueAggregator ( ) ; @ Override public void onValue ( int docId , BytesRef value ) { } @ Override public void onMissing ( int docId ) { } public static class ValueAggregator implements NumericFieldData . DoubleValueInDocProc { StringEntry stringEntry ; @ Override public void onValue ( int docId , double value ) { } } } public static class ScriptAggregator extends TermsStatsStringFacetCollector . Aggregator { private final SearchScript script ; public ScriptAggregator ( SearchScript script ) { } @ Override public void onValue ( int docId , BytesRef value ) { } } }<BUG2FIX>script . setNextReader ( context ) ;
public class PostingsFormatService extends AbstractIndexComponent { private final ImmutableMap < String , PostingsFormatProvider > providers ; public PostingsFormatService ( Index index ) { } public PostingsFormatService ( Index index , @ IndexSettings Settings indexSettings ) { } @ Inject public PostingsFormatService ( Index index , @ IndexSettings Settings indexSettings , Map < String , PostingsFormatProvider . Factory > postingFormatFactories ) { } public PostingsFormatProvider get ( String name ) throws ElasticSearchIllegalArgumentException { PostingsFormatProvider provider = providers . get ( name ) ; <START_BUG> if ( name == null ) { <END_BUG> throw new ElasticSearchIllegalArgumentException ( ( ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>find<seq2seq4repair_space>postings_format<seq2seq4repair_space>[" + name ) + "]" ) ) ; } return provider ; } }<BUG2FIX>if ( provider == null ) {
public class IssuesFragment extends PagedItemFragment < Issue > { @ Inject private AccountDataManager cache ; @ Inject private IssueService service ; @ Inject private IssueStore store ; @ InjectExtra ( value = Intents . EXTRA_ISSUE_FILTER , optional = true ) private IssueFilter filter ; @ InjectExtra ( Intents . EXTRA_REPOSITORY ) private Repository repository ; private TextView filterTextView ; @ Inject private AvatarLoader avatarHelper ; @ Override public void onCreate ( Bundle savedInstanceState ) { } @ Override public void onViewCreated ( View view , Bundle savedInstanceState ) { } private void updateFilterSummary ( ) { } @ Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; <START_BUG> setEmptyText ( getString ( no_issues ) ) ; <END_BUG> } @ Override public void onListItemClick ( ListView l , View v , int position , long id ) { } @ Override public void onCreateOptionsMenu ( Menu optionsMenu , MenuInflater inflater ) { } @ Override public boolean onOptionsItemSelected ( MenuItem item ) { } @ Override public void onActivityResult ( int requestCode , int resultCode , Intent data ) { } @ Override protected ResourcePager < Issue > createPager ( ) { } @ Override protected int getLoadingMessage ( ) { } protected ItemListAdapter < Issue , ? extends ItemView > createAdapter ( List < Issue > items ) { } }<BUG2FIX>setEmptyText ( no_issues ) ;
public class EmptyOrdinals implements Ordinals { private final int numDocs ; public EmptyOrdinals ( int numDocs ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override public boolean hasSingleArrayBackingStorage ( ) { } @ Override public Object getBackingStorage ( ) { } @ Override public boolean isMultiValued ( ) { } @ Override public int getNumDocs ( ) { } @ Override public int getNumOrds ( ) { <START_BUG> return 1 ; <END_BUG> } @ Override public EmptyOrdinals . Docs ordinals ( ) { } public static class Docs implements Ordinals . Docs { private final EmptyOrdinals parent ; public Docs ( EmptyOrdinals parent ) { } @ Override public Ordinals ordinals ( ) { } @ Override public int getNumDocs ( ) { } @ Override public int getNumOrds ( ) { return parent . getNumOrds ( ) ; } @ Override public boolean isMultiValued ( ) { } @ Override public int getOrd ( int docId ) { } @ Override public IntArrayRef getOrds ( int docId ) { } @ Override public Iter getIter ( int docId ) { } @ Override public void forEachOrdinalInDoc ( int docId , OrdinalInDocProc proc ) { } } }<BUG2FIX>return 0 ;
public abstract class BasePolygonBuilder < E extends BasePolygonBuilder < E > > extends ShapeBuilder { public static final GeoShapeType TYPE = GeoShapeType . POLYGON ; protected BasePolygonBuilder . Ring < E > shell ; protected final ArrayList < BaseLineStringBuilder < ? > > holes = new ArrayList < > ( ) ; @ SuppressWarnings ( "unchecked" ) private E thisRef ( ) { } public E point ( double longitude , double latitude ) { } public E point ( Coordinate coordinate ) { } public E points ( Coordinate ... coordinates ) { } public E hole ( BaseLineStringBuilder < ? > hole ) { } public BasePolygonBuilder . Ring < E > hole ( ) { } public ShapeBuilder close ( ) { } public Coordinate [ ] [ ] [ ] coordinates ( ) { } @ Override public Shape build ( ) { } protected XContentBuilder coordinatesArray ( XContentBuilder builder , Params params ) throws IOException { } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } public Geometry buildGeometry ( GeometryFactory factory , boolean fixDateline ) { } public Polygon toPolygon ( ) { } protected Polygon toPolygon ( GeometryFactory factory ) { } protected static LinearRing linearRing ( GeometryFactory factory , ArrayList < Coordinate > coordinates ) { } @ Override public GeoShapeType type ( ) { } protected static Polygon polygon ( GeometryFactory factory , Coordinate [ ] [ ] polygon ) { } protected static MultiPolygon multipolygon ( GeometryFactory factory , Coordinate [ ] [ ] [ ] polygons ) { } private static int component ( final Edge edge , final int id , final ArrayList < Edge > edges ) { } private static Coordinate [ ] coordinates ( Edge component , Coordinate [ ] coordinates ) { } private static Coordinate [ ] [ ] [ ] buildCoordinates ( ArrayList < ArrayList < Coordinate [ ] > > components ) { } private static final Coordinate [ ] [ ] EMPTY = new Coordinate [ 0 ] [ ] ; private static Coordinate [ ] [ ] holes ( Edge [ ] holes , int numHoles ) { } private static Edge [ ] edges ( Edge [ ] edges , int numHoles , ArrayList < ArrayList < Coordinate [ ] > > components ) { } private static Coordinate [ ] [ ] [ ] compose ( Edge [ ] edges , Edge [ ] holes , int numHoles ) { } private static void assign ( Edge [ ] holes , Coordinate [ ] [ ] points , int numHoles , Edge [ ] edges , ArrayList < ArrayList < Coordinate [ ] > > components ) { if ( BasePolygonBuilder . debugEnabled ( ) ) { LOGGER . debug ( ( "Holes:<seq2seq4repair_space>" + ( Arrays . toString ( holes ) ) ) ) ; } for ( int i = 0 ; i < numHoles ; i ++ ) { final Edge current = new Edge ( holes [ i ] . coordinate , holes [ i ] . next ) ; current . intersect = current . coordinate ; final int intersections = intersections ( current . coordinate . x , edges ) ; final int pos = Arrays . binarySearch ( edges , 0 , intersections , current , INTERSECTION_ORDER ) ; <START_BUG> if ( pos < 0 ) { <END_BUG> throw new ElasticsearchParseException ( "Invaild<seq2seq4repair_space>shape:<seq2seq4repair_space>Hole<seq2seq4repair_space>is<seq2seq4repair_space>not<seq2seq4repair_space>within<seq2seq4repair_space>polygon" ) ; } final int index = - ( pos + 2 ) ; final int component = ( ( - ( edges [ index ] . component ) ) - numHoles ) - 1 ; if ( BasePolygonBuilder . debugEnabled ( ) ) { LOGGER . debug ( ( ( ( ( ( "\tposition<seq2seq4repair_space>(" + index ) + ")<seq2seq4repair_space>of<seq2seq4repair_space>edge<seq2seq4repair_space>" ) + current ) + ":<seq2seq4repair_space>" ) + ( edges [ index ] ) ) ) ; LOGGER . debug ( ( "\tComponent:<seq2seq4repair_space>" + component ) ) ; LOGGER . debug ( ( ( ( "\tHole<seq2seq4repair_space>intersections<seq2seq4repair_space>(" + ( current . coordinate . x ) ) + "):<seq2seq4repair_space>" ) + ( Arrays . toString ( edges ) ) ) ) ; } components . get ( component ) . add ( points [ i ] ) ; } } private static int merge ( Edge [ ] intersections , int offset , int length , Edge [ ] holes , int numHoles ) { } private static void connect ( Edge in , Edge out ) { } private static int createEdges ( int component , boolean direction , BaseLineStringBuilder < ? > line , Edge [ ] edges , int offset ) { } public static class Ring < P extends ShapeBuilder > extends BaseLineStringBuilder < BasePolygonBuilder . Ring < P > > { private final P parent ; protected Ring ( P parent ) { } protected Ring ( P parent , ArrayList < Coordinate > points ) { } public P close ( ) { } @ Override public GeoShapeType type ( ) { } } }<BUG2FIX>if ( pos >= 0 ) {
public class RestSearchScrollAction extends BaseRestHandler { @ Inject public RestSearchScrollAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { String scrollId = request . param ( "scroll_id" ) ; if ( ( scrollId == null ) && ( request . hasContent ( ) ) ) { scrollId = request . content ( ) . toUtf8 ( ) ; } SearchScrollRequest searchScrollRequest = new SearchScrollRequest ( scrollId ) ; searchScrollRequest . listenerThreaded ( false ) ; try { String scroll = request . param ( "scroll" ) ; if ( scroll != null ) { searchScrollRequest . scroll ( new org . elasticsearch . search . Scroll ( parseTimeValue ( scroll , null ) ) ) ; } SearchOperationThreading operationThreading = SearchOperationThreading . fromString ( request . param ( "operation_threading" ) , null ) ; if ( operationThreading != null ) { if ( operationThreading == ( SearchOperationThreading . NO_THREADS ) ) { operationThreading = SearchOperationThreading . SINGLE_THREAD ; } searchScrollRequest . operationThreading ( operationThreading ) ; } } catch ( Exception e ) { try { XContentBuilder builder = restContentBuilder ( request ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . BAD_REQUEST , builder . startObject ( ) . field ( "error" , e . getMessage ( ) ) . endObject ( ) ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } return ; } client . searchScroll ( searchScrollRequest , new org . elasticsearch . action . ActionListener < SearchResponse > ( ) { @ Override public void onResponse ( SearchResponse response ) { try { XContentBuilder builder = restContentBuilder ( request ) ; builder . startObject ( ) ; response . toXContent ( builder , request ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , response . status ( ) , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class BulletBuild { public static void main ( String [ ] args ) throws Exception { new NativeCodeGenerator ( ) . generate ( "src" , "bin" , "jni" ) ; String cppFlags = "" ; cppFlags += "<seq2seq4repair_space>-fno-strict-aliasing" ; cppFlags += "<seq2seq4repair_space>-fno-rtti" ; cppFlags += "<seq2seq4repair_space>-DBT_NO_PROFILE" ; String [ ] excludes = new String [ ] { "src/bullet/BulletMultiThreaded/GpuSoftBodySolvers/**" } ; <START_BUG> String [ ] headers = new String [ ] { "src/bullet/" , "src/custom/" , "src/extras/serialize/" } ; <END_BUG> BuildTarget win32home = BuildTarget . newDefaultTarget ( Windows , false ) ; win32home . compilerPrefix = "" ; win32home . buildFileName = "build-windows32home.xml" ; win32home . excludeFromMasterBuildFile = true ; win32home . cExcludes = win32home . cppExcludes = excludes ; win32home . headerDirs = headers ; win32home . cppFlags += cppFlags ; BuildTarget win32 = BuildTarget . newDefaultTarget ( Windows , false ) ; win32 . cExcludes = win32 . cppExcludes = excludes ; win32 . headerDirs = headers ; win32 . cppFlags += cppFlags ; BuildTarget win64 = BuildTarget . newDefaultTarget ( Windows , true ) ; win64 . cExcludes = win64 . cppExcludes = excludes ; win64 . headerDirs = headers ; win64 . cppFlags += cppFlags ; BuildTarget lin32 = BuildTarget . newDefaultTarget ( Linux , false ) ; lin32 . cExcludes = lin32 . cppExcludes = excludes ; lin32 . headerDirs = headers ; lin32 . cppFlags += cppFlags ; BuildTarget lin64 = BuildTarget . newDefaultTarget ( Linux , true ) ; lin64 . cExcludes = lin64 . cppExcludes = excludes ; lin64 . headerDirs = headers ; lin64 . cppFlags += cppFlags ; BuildTarget mac = BuildTarget . newDefaultTarget ( MacOsX , false ) ; mac . cExcludes = mac . cppExcludes = excludes ; mac . headerDirs = headers ; mac . cppFlags += cppFlags ; BuildTarget android = BuildTarget . newDefaultTarget ( Android , false ) ; android . cExcludes = android . cppExcludes = excludes ; android . headerDirs = headers ; android . cppFlags += cppFlags ; BuildTarget ios = BuildTarget . newDefaultTarget ( IOS , false ) ; ios . cExcludes = ios . cppExcludes = excludes ; ios . headerDirs = headers ; ios . cppFlags += cppFlags ; new AntScriptGenerator ( ) . generate ( new BuildConfig ( "gdx-bullet" ) , win32home , win32 , win64 , lin32 , lin64 , mac , android , ios ) ; } }<BUG2FIX>String [ ] headers = new String [ ] { "src/bullet/" , "src/custom/" } ;
private static final int UPDATE_ANGLE = 1 << 1 ; private static final int UPDATE_ROTATION = 1 << 2 ; private static final int UPDATE_VELOCITY = 1 << 3 ; private static final int UPDATE_WIND = 1 << 4 ; private static final int UPDATE_GRAVITY = 1 << 5 ; private static final int UPDATE_TINT = 1 << 6 ; private ParticleEmitter . RangedNumericValue delayValue = new ParticleEmitter . RangedNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue lifeOffsetValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . RangedNumericValue durationValue = new ParticleEmitter . RangedNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue lifeValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue emissionValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue scaleValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue rotationValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue velocityValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue angleValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue windValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue gravityValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue transparencyValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . GradientColorValue tintValue = new ParticleEmitter . GradientColorValue ( ) ; private ParticleEmitter . RangedNumericValue xOffsetValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . RangedNumericValue yOffsetValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue spawnWidthValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue spawnHeightValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . SpawnShapeValue spawnShapeValue = new ParticleEmitter . SpawnShapeValue ( ) ; private float accumulator ; private Sprite sprite ; private ParticleEmitter . Particle [ ] particles ; private int minParticleCount ; private int maxParticleCount = 4 ; private float x ; private float y ; private String name ; private String imagePath ; private int activeCount ; private BitSet active ; private boolean firstUpdate ; private boolean flipX ; private boolean flipY ; private int updateFlags ; private boolean allowCompletion ; private int emission ; private int emissionDiff ; private int emissionDelta ; private int lifeOffset ; private int lifeOffsetDiff ; private int life ; private int lifeDiff ; private int spawnWidth ; private int spawnWidthDiff ; private int spawnHeight ; private int spawnHeightDiff ; public float duration = 1 ; public float durationTimer ; private float delay ; private float delayTimer ; private boolean attached ; private boolean continuous ; private boolean aligned ; private boolean behind ; private boolean additive = true ; public ParticleEmitter ( ) { } public ParticleEmitter ( BufferedReader reader ) throws IOException { } public ParticleEmitter ( ParticleEmitter emitter ) { } private void initialize ( ) { } public void setMaxParticleCount ( int maxParticleCount ) { } public void addParticle ( ) { } public void addParticles ( int count ) { } public void draw ( SpriteBatch spriteBatch , float delta ) { } public void start ( ) { } public void reset ( ) { } private void restart ( ) { } private void activateParticle ( int index ) { } private boolean updateParticle ( int index , float delta , int deltaMillis ) { } public void setPosition ( float x , float y ) { } public void setSprite ( Sprite sprite ) { this . sprite = sprite ; if ( sprite == null ) return ; float originX = sprite . getOriginX ( ) ; float originY = sprite . getOriginY ( ) ; Texture texture = sprite . getTexture ( ) ; for ( int i = 0 , n = particles . length ; i < n ; i ++ ) { ParticleEmitter . Particle particle = particles [ i ] ; if ( particle == null ) <START_BUG> break ; <END_BUG> particle . setTexture ( texture ) ; particle . setOrigin ( originX , originY ) ; } } public void allowCompletion ( ) { } public Sprite getSprite ( ) { } public String getName ( ) { } public void setName ( String name ) { } public ParticleEmitter . ScaledNumericValue getLife ( ) { } public ParticleEmitter . ScaledNumericValue getScale ( ) { } public ParticleEmitter . ScaledNumericValue getRotation ( ) { } public ParticleEmitter . GradientColorValue getTint ( ) { } public ParticleEmitter . ScaledNumericValue getVelocity ( ) { } public ParticleEmitter . ScaledNumericValue getWind ( ) { } public ParticleEmitter . ScaledNumericValue getGravity ( ) { } public ParticleEmitter . ScaledNumericValue getAngle ( ) { } public ParticleEmitter . ScaledNumericValue getEmission ( ) { } public ParticleEmitter . ScaledNumericValue getTransparency ( ) { } public ParticleEmitter . RangedNumericValue getDuration ( ) { } public ParticleEmitter . RangedNumericValue getDelay ( ) { } public ParticleEmitter . ScaledNumericValue getLifeOffset ( ) { } public ParticleEmitter . RangedNumericValue getXOffsetValue ( ) { } public ParticleEmitter . RangedNumericValue getYOffsetValue ( ) { } public ParticleEmitter . ScaledNumericValue getSpawnWidth ( ) { } public ParticleEmitter . ScaledNumericValue getSpawnHeight ( ) { } public ParticleEmitter . SpawnShapeValue getSpawnShape ( ) { } public boolean isAttached ( ) { } public void setAttached ( boolean attached ) { } public boolean isContinuous ( ) { } public void setContinuous ( boolean continuous ) { } public boolean isAligned ( ) { } public void setAligned ( boolean aligned ) { } public boolean isAdditive ( ) { } public void setAdditive ( boolean additive ) { } public boolean isBehind ( ) { } public void setBehind ( boolean behind ) { } public int getMinParticleCount ( ) { } public void setMinParticleCount ( int minParticleCount ) { } public int getMaxParticleCount ( ) { } public boolean isComplete ( ) { } public float getPercentComplete ( ) { }<BUG2FIX>continue ;
public class FlickScrollPaneTest extends GdxTest { private Stage stage ; private BitmapFont font ; private Table container ; public void create ( ) { stage = new Stage ( 0 , 0 , false ) ; font = new BitmapFont ( ) ; input . setInputProcessor ( stage ) ; graphics . setVSync ( false ) ; container = new Table ( ) ; stage . addActor ( container ) ; container . getTableLayout ( ) . debug ( ) ; Table table = new Table ( ) ; <START_BUG> FlickScrollPane scroll = new FlickScrollPane ( table , stage ) ; <END_BUG> container . add ( scroll ) . expand ( ) . fill ( ) ; table . parse ( "pad:10<seq2seq4repair_space>*<seq2seq4repair_space>expand:x<seq2seq4repair_space>space:4" ) ; for ( int i = 0 ; i < 100 ; i ++ ) { table . row ( ) ; table . add ( new Label ( ( i + "uno" ) , new com . badlogic . gdx . scenes . scene2d . ui . Label . LabelStyle ( font , Color . RED ) ) ) . expandX ( ) . fillX ( ) ; table . add ( new Label ( ( i + "dos" ) , new com . badlogic . gdx . scenes . scene2d . ui . Label . LabelStyle ( font , Color . RED ) ) ) ; table . add ( new Label ( ( i + "tres<seq2seq4repair_space>long0<seq2seq4repair_space>long1<seq2seq4repair_space>long2<seq2seq4repair_space>long3<seq2seq4repair_space>long4<seq2seq4repair_space>long5<seq2seq4repair_space>long6<seq2seq4repair_space>long7<seq2seq4repair_space>long8<seq2seq4repair_space>long9<seq2seq4repair_space>long10<seq2seq4repair_space>long11<seq2seq4repair_space>long12" ) , new com . badlogic . gdx . scenes . scene2d . ui . Label . LabelStyle ( font , Color . RED ) ) ) ; } container . getTableLayout ( ) . row ( ) ; container . getTableLayout ( ) . add ( new Label ( "stuff<seq2seq4repair_space>at<seq2seq4repair_space>bottom!" , new com . badlogic . gdx . scenes . scene2d . ui . Label . LabelStyle ( font , Color . WHITE ) ) ) . pad ( 20 , 20 , 20 , 20 ) ; } public void render ( ) { } public void resize ( int width , int height ) { } public void pause ( ) { } public void resume ( ) { } public void dispose ( ) { } public boolean needsGL20 ( ) { } }<BUG2FIX>FlickScrollPane scroll = new FlickScrollPane ( table ) ;
public class StreamUtils { public static final int DEFAULT_BUFFER_SIZE = 8192 ; public static final byte [ ] EMPTY_BYTES = new byte [ 0 ] ; public static void copyStream ( InputStream input , OutputStream output ) throws IOException { } public static void copyStream ( InputStream input , OutputStream output , int bufferSize ) throws IOException { } public static byte [ ] copyStreamToByteArray ( InputStream input ) throws IOException { } public static byte [ ] copyStreamToByteArray ( InputStream input , int estimatedSize ) throws IOException { } public static String copyStreamToString ( InputStream input ) throws IOException { } public static String copyStreamToString ( InputStream input , int approxStringLength ) throws IOException { } public static void closeQuietly ( Closeable c ) { if ( c != null ) try { c . close ( ) ; <START_BUG> } catch ( IOException e ) { <END_BUG> } } private static class OptimizedByteArrayOutputStream extends ByteArrayOutputStream { OptimizedByteArrayOutputStream ( int initialSize ) { } @ Override public synchronized byte [ ] toByteArray ( ) { } } }<BUG2FIX>} catch ( Exception e ) {
public class Text { public enum HorizontalAlign { Left , Center , Right ; } private Graphics graphics ; private Font font ; private MeshRenderer mesh ; private String text = "" ; private Text . HorizontalAlign hAlign = Text . HorizontalAlign . Left ; private String [ ] lines ; private int [ ] widths ; private int width ; private boolean dirty = true ; protected Text ( Graphics graphics , Font font ) { } public int getWidth ( ) { } public int getHeight ( ) { } public void setHorizontalAlign ( Text . HorizontalAlign hAlign ) { } public void setText ( String text ) { } private void rebuild ( ) { if ( ( mesh ) == null ) { FloatMesh m = new FloatMesh ( ( 6 * ( text . length ( ) ) ) , 3 , false , false , true , 1 , 2 , false , 0 ) ; mesh = new MeshRenderer ( graphics . getGL10 ( ) , m , false , font . isManaged ( ) ) ; } <START_BUG> if ( ( ( mesh . getMesh ( ) . getMaximumVertices ( ) ) / 6 ) < ( text . length ( ) ) ) { <END_BUG> mesh . dispose ( ) ; FloatMesh m = new FloatMesh ( ( 6 * ( text . length ( ) ) ) , 3 , false , false , true , 1 , 2 , false , 0 ) ; mesh = new MeshRenderer ( graphics . getGL10 ( ) , m , false , font . isManaged ( ) ) ; } float [ ] vertices = ( ( FloatMesh ) ( mesh . getMesh ( ) ) ) . getVerticesArray ( ) ; int vertIdx = 0 ; int lineHeight = font . getLineHeight ( ) ; int height = ( lines . length ) * lineHeight ; for ( int i = 0 ; i < ( lines . length ) ; i ++ ) { String line = lines [ i ] ; int x = 0 ; int y = height ; if ( ( hAlign ) == ( Text . HorizontalAlign . Left ) ) x = 0 ; if ( ( hAlign ) == ( Text . HorizontalAlign . Center ) ) x = ( ( width ) / 2 ) - ( ( widths [ i ] ) / 2 ) ; if ( ( hAlign ) == ( Text . HorizontalAlign . Right ) ) x = ( width ) - ( widths [ i ] ) ; y -= i * ( ( font . getLineHeight ( ) ) + ( font . getLineGap ( ) ) ) ; for ( int j = 0 ; j < ( line . length ( ) ) ; j ++ ) { Glyph glyph = font . getGlyph ( line . charAt ( j ) ) ; vertices [ ( vertIdx ++ ) ] = x ; vertices [ ( vertIdx ++ ) ] = y ; vertices [ ( vertIdx ++ ) ] = 0 ; vertices [ ( vertIdx ++ ) ] = glyph . u ; vertices [ ( vertIdx ++ ) ] = glyph . v ; vertices [ ( vertIdx ++ ) ] = x + ( glyph . width ) ; vertices [ ( vertIdx ++ ) ] = y ; vertices [ ( vertIdx ++ ) ] = 0 ; vertices [ ( vertIdx ++ ) ] = ( glyph . u ) + ( glyph . uWidth ) ; vertices [ ( vertIdx ++ ) ] = glyph . v ; vertices [ ( vertIdx ++ ) ] = x + ( glyph . width ) ; vertices [ ( vertIdx ++ ) ] = y - lineHeight ; vertices [ ( vertIdx ++ ) ] = 0 ; vertices [ ( vertIdx ++ ) ] = ( glyph . u ) + ( glyph . uWidth ) ; vertices [ ( vertIdx ++ ) ] = ( glyph . v ) + ( glyph . vHeight ) ; vertices [ ( vertIdx ++ ) ] = x + ( glyph . width ) ; vertices [ ( vertIdx ++ ) ] = y - lineHeight ; vertices [ ( vertIdx ++ ) ] = 0 ; vertices [ ( vertIdx ++ ) ] = ( glyph . u ) + ( glyph . uWidth ) ; vertices [ ( vertIdx ++ ) ] = ( glyph . v ) + ( glyph . vHeight ) ; vertices [ ( vertIdx ++ ) ] = x ; vertices [ ( vertIdx ++ ) ] = y - lineHeight ; vertices [ ( vertIdx ++ ) ] = 0 ; vertices [ ( vertIdx ++ ) ] = glyph . u ; vertices [ ( vertIdx ++ ) ] = ( glyph . v ) + ( glyph . vHeight ) ; vertices [ ( vertIdx ++ ) ] = x ; vertices [ ( vertIdx ++ ) ] = y ; vertices [ ( vertIdx ++ ) ] = 0 ; vertices [ ( vertIdx ++ ) ] = glyph . u ; vertices [ ( vertIdx ++ ) ] = glyph . v ; x += glyph . advance ; } } ( ( FloatMesh ) ( mesh . getMesh ( ) ) ) . updateVertexBufferFromArray ( ( vertIdx / 5 ) ) ; mesh . update ( ) ; dirty = false ; } public void render ( ) { } }<BUG2FIX>if ( ( ( mesh . getMesh ( ) . getMaximumVertices ( ) ) / 6 ) <= ( text . length ( ) ) ) {
public class MetaDataDeleteIndexService extends AbstractComponent { private final ThreadPool threadPool ; private final ClusterService clusterService ; private final AllocationService allocationService ; private final NodeIndexDeletedAction nodeIndexDeletedAction ; private final MetaDataService metaDataService ; @ Inject public MetaDataDeleteIndexService ( Settings settings , ThreadPool threadPool , ClusterService clusterService , AllocationService allocationService , NodeIndexDeletedAction nodeIndexDeletedAction , MetaDataService metaDataService ) { } public void deleteIndex ( final MetaDataDeleteIndexService . Request request , final MetaDataDeleteIndexService . Listener userListener ) { MetaDataService . MdLock mdLock = metaDataService . indexMetaDataLock ( request . index ) ; try { mdLock . lock ( ) ; } catch ( InterruptedException e ) { userListener . onFailure ( e ) ; return ; } final MetaDataDeleteIndexService . DeleteIndexListener listener = new MetaDataDeleteIndexService . DeleteIndexListener ( mdLock , request , userListener ) ; <START_BUG> clusterService . submitStateUpdateTask ( ( ( "delete-index<seq2seq4repair_space>[" + ( request . index ) ) + "]" ) , URGENT , new ClusterStateUpdateTask ( ) { <END_BUG> @ Override public ClusterState execute ( ClusterState currentState ) { try { if ( ! ( currentState . metaData ( ) . hasConcreteIndex ( request . index ) ) ) { listener . onFailure ( new org . elasticsearch . indices . IndexMissingException ( new Index ( request . index ) ) ) ; return currentState ; } logger . info ( "[{}]<seq2seq4repair_space>deleting<seq2seq4repair_space>index" , request . index ) ; RoutingTable . Builder routingTableBuilder = RoutingTable . builder ( ) . routingTable ( currentState . routingTable ( ) ) ; routingTableBuilder . remove ( request . index ) ; MetaData newMetaData = MetaData . newMetaDataBuilder ( ) . metaData ( currentState . metaData ( ) ) . remove ( request . index ) . build ( ) ; RoutingAllocation . Result routingResult = allocationService . reroute ( ClusterState . newClusterStateBuilder ( ) . state ( currentState ) . routingTable ( routingTableBuilder ) . metaData ( newMetaData ) . build ( ) ) ; ClusterBlocks blocks = ClusterBlocks . builder ( ) . blocks ( currentState . blocks ( ) ) . removeIndexBlocks ( request . index ) . build ( ) ; final AtomicInteger counter = new AtomicInteger ( currentState . nodes ( ) . size ( ) ) ; final NodeIndexDeletedAction . Listener nodeIndexDeleteListener = new NodeIndexDeletedAction . Listener ( ) { @ Override public void onNodeIndexDeleted ( String index , String nodeId ) { if ( index . equals ( request . index ) ) { if ( ( counter . decrementAndGet ( ) ) == 0 ) { listener . onResponse ( new MetaDataDeleteIndexService . Response ( true ) ) ; nodeIndexDeletedAction . remove ( this ) ; } } } } ; nodeIndexDeletedAction . add ( nodeIndexDeleteListener ) ; listener . future = threadPool . schedule ( request . timeout , SAME , new Runnable ( ) { @ Override public void run ( ) { listener . onResponse ( new MetaDataDeleteIndexService . Response ( false ) ) ; nodeIndexDeletedAction . remove ( nodeIndexDeleteListener ) ; } } ) ; return ClusterState . newClusterStateBuilder ( ) . state ( currentState ) . routingResult ( routingResult ) . metaData ( newMetaData ) . blocks ( blocks ) . build ( ) ; } catch ( Throwable e ) { listener . onFailure ( e ) ; return currentState ; } } } ) ; } class DeleteIndexListener implements MetaDataDeleteIndexService . Listener { private final AtomicBoolean notified = new AtomicBoolean ( ) ; private final MdLock mdLock ; private final MetaDataDeleteIndexService . Request request ; private final MetaDataDeleteIndexService . Listener listener ; volatile ScheduledFuture future ; private DeleteIndexListener ( MetaDataService . MdLock mdLock , MetaDataDeleteIndexService . Request request , MetaDataDeleteIndexService . Listener listener ) { } @ Override public void onResponse ( final MetaDataDeleteIndexService . Response response ) { } @ Override public void onFailure ( Throwable t ) { } } public static interface Listener { void onResponse ( MetaDataDeleteIndexService . Response response ) { } void onFailure ( Throwable t ) { } } public static class Request { final String index ; TimeValue timeout = TimeValue . timeValueSeconds ( 10 ) ; public Request ( String index ) { } public MetaDataDeleteIndexService . Request timeout ( TimeValue timeout ) { } } public static class Response { private final boolean acknowledged ; public Response ( boolean acknowledged ) { } public boolean acknowledged ( ) { } } }<BUG2FIX>clusterService . submitStateUpdateTask ( ( ( "delete-index<seq2seq4repair_space>[" + ( request . index ) ) + "]" ) , new ClusterStateUpdateTask ( ) {
@ Test public void testWithTwoClausesOfEachOccur_allFixedBitsetFilters ( ) throws Exception { } @ Test public void testWithTwoClausesOfEachOccur_allBitsBasedFilters ( ) throws Exception { } @ Test public void testWithTwoClausesOfEachOccur_allFilterTypes ( ) throws Exception { } @ Test public void testWithTwoClausesOfEachOccur_singleClauseOptimisation ( ) throws Exception { } @ Test public void testOnlyShouldClauses ( ) throws Exception { } @ Test public void testOnlyMustClauses ( ) throws Exception { } @ Test public void testOnlyMustNotClauses ( ) throws Exception { } @ Test public void testNonMatchingSlowShouldWithMatchingMust ( ) throws Exception { } @ Test public void testSlowShouldClause_atLeastOneShouldMustMatch ( ) throws Exception { } @ Test public void testOneFastMustNotOneFastShouldAndOneSlowShould ( ) throws Exception { } @ Test public void testOneFastShouldClauseAndOneSlowShouldClause ( ) throws Exception { } @ Test public void testOneMustClauseOneFastShouldClauseAndOneSlowShouldClause ( ) throws Exception { } private static FilterClause newFilterClause ( int field , char character , BooleanClause . Occur occur , boolean slowerBitsBackedFilter ) { } private static XBooleanFilter createBooleanFilter ( FilterClause ... clauses ) { } @ Test public void testRandom ( ) throws IOException { int iterations = atLeast ( 400 ) ; for ( int iter = 0 ; iter < iterations ; iter ++ ) { int numClauses = 1 + ( random ( ) . nextInt ( 10 ) ) ; FilterClause [ ] clauses = new FilterClause [ numClauses ] ; BooleanQuery topLevel = new BooleanQuery ( ) ; BooleanQuery orQuery = new BooleanQuery ( ) ; boolean hasMust = false ; boolean hasShould = false ; boolean hasMustNot = false ; for ( int i = 0 ; i < numClauses ; i ++ ) { int field = random ( ) . nextInt ( 5 ) ; char value = XBooleanFilterTests . distinctValues [ random ( ) . nextInt ( XBooleanFilterTests . distinctValues . length ) ] ; switch ( random ( ) . nextInt ( 10 ) ) { case 9 : case 8 : case 7 : case 6 : case 5 : hasMust = true ; clauses [ i ] = XBooleanFilterTests . newFilterClause ( field , value , MUST , random ( ) . nextBoolean ( ) ) ; topLevel . add ( new BooleanClause ( new TermQuery ( new Term ( String . valueOf ( field ) , String . valueOf ( value ) ) ) , MUST ) ) ; break ; case 4 : case 3 : case 2 : case 1 : hasShould = true ; clauses [ i ] = XBooleanFilterTests . newFilterClause ( field , value , SHOULD , random ( ) . nextBoolean ( ) ) ; orQuery . add ( new BooleanClause ( new TermQuery ( new Term ( String . valueOf ( field ) , String . valueOf ( value ) ) ) , SHOULD ) ) ; break ; case 0 : hasMustNot = true ; clauses [ i ] = XBooleanFilterTests . newFilterClause ( field , value , MUST_NOT , random ( ) . nextBoolean ( ) ) ; topLevel . add ( new BooleanClause ( new TermQuery ( new Term ( String . valueOf ( field ) , String . valueOf ( value ) ) ) , MUST_NOT ) ) ; break ; } } if ( ( orQuery . getClauses ( ) . length ) > 0 ) { topLevel . add ( new BooleanClause ( orQuery , MUST ) ) ; } if ( ( hasMustNot && ( ! hasMust ) ) && ( ! hasShould ) ) { topLevel . add ( new BooleanClause ( new MatchAllDocsQuery ( ) , MUST ) ) ; } XBooleanFilter booleanFilter = XBooleanFilterTests . createBooleanFilter ( clauses ) ; FixedBitSet leftResult = new FixedBitSet ( reader . maxDoc ( ) ) ; FixedBitSet rightResult = new FixedBitSet ( reader . maxDoc ( ) ) ; DocIdSet left = booleanFilter . getDocIdSet ( reader . getContext ( ) , reader . getLiveDocs ( ) ) ; DocIdSet right = new QueryWrapperFilter ( topLevel ) . getDocIdSet ( reader . getContext ( ) , reader . getLiveDocs ( ) ) ; if ( ( left == null ) || ( right == null ) ) { if ( ( left == null ) && ( right != null ) ) { assertThat ( errorMsg ( clauses , topLevel ) , ( ( right . iterator ( ) ) == null ? DocIdSetIterator . NO_MORE_DOCS : right . iterator ( ) . nextDoc ( ) ) , equalTo ( NO_MORE_DOCS ) ) ; } if ( ( left != null ) && ( right == null ) ) { assertThat ( errorMsg ( clauses , topLevel ) , ( ( left . iterator ( ) ) == null ? DocIdSetIterator . NO_MORE_DOCS : left . iterator ( ) . nextDoc ( ) ) , equalTo ( NO_MORE_DOCS ) ) ; } } else { DocIdSetIterator leftIter = left . iterator ( ) ; DocIdSetIterator rightIter = right . iterator ( ) ; if ( leftIter != null ) { leftResult . or ( leftIter ) ; } if ( rightIter != null ) { rightResult . or ( rightIter ) ; } <START_BUG> assertThat ( leftResult . cardinality ( ) , equalTo ( leftResult . cardinality ( ) ) ) ; <END_BUG> for ( int i = 0 ; i < ( reader . maxDoc ( ) ) ; i ++ ) { assertThat ( ( ( ( errorMsg ( clauses , topLevel ) ) + "<seq2seq4repair_space>--<seq2seq4repair_space>failed<seq2seq4repair_space>at<seq2seq4repair_space>index<seq2seq4repair_space>" ) + i ) , leftResult . get ( i ) , equalTo ( rightResult . get ( i ) ) ) ; } } } } private String errorMsg ( FilterClause [ ] clauses , BooleanQuery query ) { } public static final class PrettyPrintFieldCacheTermsFilter extends FieldCacheTermsFilter { private final String value ; private final String field ; public PrettyPrintFieldCacheTermsFilter ( String field , String value ) { } @ Override public String toString ( ) { } } }<BUG2FIX>assertThat ( leftResult . cardinality ( ) , equalTo ( rightResult . cardinality ( ) ) ) ;
public class TermFilterParser extends AbstractIndexComponent implements XContentFilterParser { public static final String NAME = "term" ; @ Inject public TermFilterParser ( Index index , @ IndexSettings Settings settings ) { } @ Override public String [ ] names ( ) { } @ Override public Filter parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; <START_BUG> boolean cache = false ; <END_BUG> String fieldName = null ; String value = null ; String filterName = null ; String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token . isValue ( ) ) { if ( "_name" . equals ( currentFieldName ) ) { filterName = parser . text ( ) ; } else if ( "_cache" . equals ( currentFieldName ) ) { cache = parser . booleanValue ( ) ; } else { fieldName = currentFieldName ; value = parser . text ( ) ; } } } if ( fieldName == null ) { throw new QueryParsingException ( index , "No<seq2seq4repair_space>field<seq2seq4repair_space>specified<seq2seq4repair_space>for<seq2seq4repair_space>term<seq2seq4repair_space>filter" ) ; } if ( value == null ) { throw new QueryParsingException ( index , "No<seq2seq4repair_space>value<seq2seq4repair_space>specified<seq2seq4repair_space>for<seq2seq4repair_space>term<seq2seq4repair_space>filter" ) ; } Filter filter = null ; MapperService . SmartNameFieldMappers smartNameFieldMappers = parseContext . smartFieldMappers ( fieldName ) ; if ( smartNameFieldMappers != null ) { if ( smartNameFieldMappers . hasMapper ( ) ) { filter = smartNameFieldMappers . mapper ( ) . fieldFilter ( value ) ; } } if ( filter == null ) { filter = new org . elasticsearch . common . lucene . search . TermFilter ( new Term ( fieldName , value ) ) ; } if ( cache ) { filter = parseContext . cacheFilter ( filter ) ; } else { filter = parseContext . cacheWeakFilter ( filter ) ; } filter = wrapSmartNameFilter ( filter , smartNameFieldMappers , parseContext ) ; if ( filterName != null ) { parseContext . addNamedFilter ( filterName , filter ) ; } return filter ; } }<BUG2FIX>boolean cache = true ;
final class JoglPanel extends JPanel implements KeyListener , MouseListener , MouseMotionListener , GLEventListener { private static final long serialVersionUID = - 3638194405409146221L ; private static boolean loaded = false ; private static GLContext context = null ; private final GLCanvas canvas ; private final Animator animator ; private boolean vSynch = true ; private final Point mousePosition = new Point ( ) ; private final HashSet < Integer > buttons = new HashSet < Integer > ( ) ; private final HashSet < Integer > keys = new HashSet < Integer > ( ) ; private final ArrayList < RenderListener > listeners = new ArrayList < RenderListener > ( ) ; private final ArrayList < RenderListener > setupListeners = new ArrayList < RenderListener > ( ) ; private long frameStart = System . nanoTime ( ) ; private float deltaTime = 0 ; private WindowedMean mean = new WindowedMean ( 10 ) ; private Application application = null ; private JoglInputMultiplexer multiplexer ; private static void loadLibraries ( ) { } private static void loadLibrary ( String resource ) { } JoglPanel ( Application application ) { } public void dispose ( ) { } public float getDeltaTime ( ) { } public GLCanvas getCanvas ( ) { } public void setVerticalSynch ( boolean v_synch ) { } public boolean getVerticalSynch ( ) { } public void mouseDragged ( MouseEvent arg0 ) { } public void mouseMoved ( MouseEvent arg0 ) { } public int getMouseX ( ) { } public int getMouseY ( ) { } public void mouseClicked ( MouseEvent arg0 ) { } public void mouseEntered ( MouseEvent arg0 ) { } public void mouseExited ( MouseEvent arg0 ) { } public void mousePressed ( MouseEvent arg0 ) { } public void mouseReleased ( MouseEvent arg0 ) { } public void keyPressed ( KeyEvent arg0 ) { } public void keyReleased ( KeyEvent arg0 ) { } public void keyTyped ( KeyEvent arg0 ) { } public boolean isButtonDown ( int button ) { } public boolean isKeyDown ( int key ) { } public void addGraphicListener ( RenderListener listener ) { } public void removeGraphicListener ( RenderListener listener ) { } @ Override public void display ( GLAutoDrawable arg0 ) { } @ Override public void displayChanged ( GLAutoDrawable arg0 , boolean arg1 , boolean arg2 ) { } @ Override public void init ( GLAutoDrawable arg0 ) { for ( RenderListener listener : listeners ) listener . surfaceCreated ( ) ; <START_BUG> setVerticalSynch ( false ) ; <END_BUG> } @ Override public void reshape ( GLAutoDrawable arg0 , int arg1 , int arg2 , int arg3 , int arg4 ) { } public GL getGL ( ) { } public Point getLastMousePosition ( ) { } public void setInputMultiplexer ( JoglInputMultiplexer inputMultiplexer ) { } public boolean isAnyKeyDown ( ) { } }<BUG2FIX>setVerticalSynch ( true ) ;
public class RestAllocationAction extends AbstractCatAction { @ Inject public RestAllocationAction ( Settings settings , Client client , RestController controller ) { } @ Override void documentation ( StringBuilder sb ) { } @ Override public void doRequest ( final RestRequest request , final RestChannel channel ) { } @ Override Table getTableWithHeader ( final RestRequest request ) { } private Table buildTable ( RestRequest request , final ClusterStateResponse state , final NodesStatsResponse stats ) { <START_BUG> final ObjectIntOpenHashMap < String > allocs = new ObjectIntOpenHashMap < String > ( ) ; <END_BUG> for ( ShardRouting shard : state . getState ( ) . routingTable ( ) . allShards ( ) ) { String nodeId = "UNASSIGNED" ; if ( shard . assignedToNode ( ) ) { nodeId = shard . currentNodeId ( ) ; } allocs . addTo ( nodeId , 1 ) ; } Table table = getTableWithHeader ( request ) ; for ( NodeStats nodeStats : stats . getNodes ( ) ) { DiscoveryNode node = nodeStats . getNode ( ) ; int shardCount = 0 ; if ( allocs . containsKey ( node . id ( ) ) ) { shardCount = allocs . lget ( ) ; } long used = ( nodeStats . getFs ( ) . getTotal ( ) . getTotal ( ) . bytes ( ) ) - ( nodeStats . getFs ( ) . getTotal ( ) . getAvailable ( ) . bytes ( ) ) ; long avail = nodeStats . getFs ( ) . getTotal ( ) . getAvailable ( ) . bytes ( ) ; short diskPercent = - 1 ; if ( ( used >= 0 ) && ( avail >= 0 ) ) { diskPercent = ( ( short ) ( ( used * 100 ) / ( used + avail ) ) ) ; } table . startRow ( ) ; table . addCell ( shardCount ) ; table . addCell ( ( used < 0 ? null : new ByteSizeValue ( used ) ) ) ; table . addCell ( ( avail < 0 ? null : new ByteSizeValue ( avail ) ) ) ; table . addCell ( nodeStats . getFs ( ) . getTotal ( ) . getTotal ( ) ) ; table . addCell ( ( diskPercent < 0 ? null : diskPercent ) ) ; table . addCell ( ( node == null ? null : node . getHostName ( ) ) ) ; table . addCell ( ( node == null ? null : node . getHostAddress ( ) ) ) ; table . addCell ( ( node == null ? "UNASSIGNED" : node . name ( ) ) ) ; table . endRow ( ) ; } if ( allocs . containsKey ( "UNASSIGNED" ) ) { table . startRow ( ) ; table . addCell ( allocs . lget ( ) ) ; table . addCell ( null ) ; table . addCell ( null ) ; table . addCell ( null ) ; table . addCell ( null ) ; table . addCell ( null ) ; table . addCell ( null ) ; table . addCell ( "UNASSIGNED" ) ; table . endRow ( ) ; } return table ; } }<BUG2FIX>final ObjectIntOpenHashMap < String > allocs = new ObjectIntOpenHashMap ( ) ;
public class BoundedValueScriptHistogramFacetCollector extends AbstractFacetCollector { private final String indexFieldName ; private final ComparatorType comparatorType ; private final FieldDataCache fieldDataCache ; private final FieldDataType fieldDataType ; private NumericFieldData fieldData ; private final SearchScript valueScript ; private final BoundedValueScriptHistogramFacetCollector . HistogramProc histoProc ; public BoundedValueScriptHistogramFacetCollector ( String facetName , String fieldName , String scriptLang , String valueScript , Map < String , Object > params , long interval , long from , long to , HistogramFacet . ComparatorType comparatorType , SearchContext context ) { } @ Override protected void doCollect ( int doc ) throws IOException { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override protected void doSetNextReader ( AtomicReaderContext context ) throws IOException { fieldData = ( ( NumericFieldData ) ( fieldDataCache . cache ( fieldDataType , context . reader ( ) , indexFieldName ) ) ) ; <START_BUG> valueScript . setNextReader ( context . reader ( ) ) ; <END_BUG> } @ Override public Facet facet ( ) { } public static long bucket ( double value , long interval ) { } public static class HistogramProc implements NumericFieldData . LongValueInDocProc { final long from ; final long to ; final long interval ; final long offset ; final int size ; final Object [ ] entries ; private final SearchScript valueScript ; public HistogramProc ( long from , long to , long interval , long offset , int size , SearchScript valueScript ) { } @ Override public void onValue ( int docId , long value ) { } } }<BUG2FIX>valueScript . setNextReader ( context ) ;
} } for ( String key : updatedSettingsBuilder . internalMap ( ) . keySet ( ) ) { if ( key . equals ( SETTING_NUMBER_OF_SHARDS ) ) { listener . onFailure ( new ElasticSearchIllegalArgumentException ( "can't<seq2seq4repair_space>change<seq2seq4repair_space>the<seq2seq4repair_space>number<seq2seq4repair_space>of<seq2seq4repair_space>shards<seq2seq4repair_space>for<seq2seq4repair_space>an<seq2seq4repair_space>index" ) ) ; return ; } } final Settings closeSettings = updatedSettingsBuilder . build ( ) ; final Set < String > removedSettings = Sets . newHashSet ( ) ; final Set < String > errors = Sets . newHashSet ( ) ; for ( Map . Entry < String , String > setting : updatedSettingsBuilder . internalMap ( ) . entrySet ( ) ) { if ( ! ( dynamicSettings . hasDynamicSetting ( setting . getKey ( ) ) ) ) { removedSettings . add ( setting . getKey ( ) ) ; } else { String error = dynamicSettings . validateDynamicSetting ( setting . getKey ( ) , setting . getValue ( ) ) ; if ( error != null ) { errors . add ( ( ( ( "[" + ( setting . getKey ( ) ) ) + "]<seq2seq4repair_space>-<seq2seq4repair_space>" ) + error ) ) ; } } } if ( ! ( errors . isEmpty ( ) ) ) { listener . onFailure ( new ElasticSearchIllegalArgumentException ( ( "can't<seq2seq4repair_space>process<seq2seq4repair_space>the<seq2seq4repair_space>settings:<seq2seq4repair_space>" + ( errors . toString ( ) ) ) ) ) ; return ; } if ( ! ( removedSettings . isEmpty ( ) ) ) { for ( String removedSetting : removedSettings ) { updatedSettingsBuilder . remove ( removedSetting ) ; } } final Settings openSettings = updatedSettingsBuilder . build ( ) ; clusterService . submitStateUpdateTask ( "update-settings" , URGENT , new ProcessedClusterStateUpdateTask ( ) { @ Override public ClusterState execute ( ClusterState currentState ) { try { String [ ] actualIndices = currentState . metaData ( ) . concreteIndices ( indices ) ; RoutingTable . Builder routingTableBuilder = RoutingTable . builder ( ) . routingTable ( currentState . routingTable ( ) ) ; MetaData . Builder metaDataBuilder = MetaData . newMetaDataBuilder ( ) . metaData ( currentState . metaData ( ) ) ; Set < String > openIndices = Sets . newHashSet ( ) ; Set < String > closeIndices = Sets . newHashSet ( ) ; for ( String index : actualIndices ) { if ( ( currentState . metaData ( ) . index ( index ) . state ( ) ) == ( State . OPEN ) ) { openIndices . add ( index ) ; } else { closeIndices . add ( index ) ; } } if ( ( ! ( removedSettings . isEmpty ( ) ) ) && ( ! ( openIndices . isEmpty ( ) ) ) ) { listener . onFailure ( new ElasticSearchIllegalArgumentException ( String . format ( "Can't<seq2seq4repair_space>update<seq2seq4repair_space>non<seq2seq4repair_space>dynamic<seq2seq4repair_space>settings[%s]<seq2seq4repair_space>for<seq2seq4repair_space>open<seq2seq4repair_space>indices[%s]" , removedSettings , openIndices ) ) ) ; return currentState ; } int updatedNumberOfReplicas = openSettings . getAsInt ( SETTING_NUMBER_OF_REPLICAS , ( - 1 ) ) ; if ( updatedNumberOfReplicas != ( - 1 ) ) { routingTableBuilder . updateNumberOfReplicas ( updatedNumberOfReplicas , actualIndices ) ; metaDataBuilder . updateNumberOfReplicas ( updatedNumberOfReplicas , actualIndices ) ; logger . info ( "updating<seq2seq4repair_space>number_of_replicas<seq2seq4repair_space>to<seq2seq4repair_space>[{}]<seq2seq4repair_space>for<seq2seq4repair_space>indices<seq2seq4repair_space>{}" , updatedNumberOfReplicas , actualIndices ) ; } ClusterBlocks . Builder blocks = ClusterBlocks . builder ( ) . blocks ( currentState . blocks ( ) ) ; Boolean updatedReadOnly = openSettings . getAsBoolean ( SETTING_READ_ONLY , null ) ; if ( updatedReadOnly != null ) { for ( String index : actualIndices ) { if ( updatedReadOnly ) { blocks . addIndexBlock ( index , INDEX_READ_ONLY_BLOCK ) ; } else { blocks . removeIndexBlock ( index , INDEX_READ_ONLY_BLOCK ) ; } } } Boolean updateMetaDataBlock = openSettings . getAsBoolean ( SETTING_BLOCKS_METADATA , null ) ; if ( updateMetaDataBlock != null ) { for ( String index : actualIndices ) { if ( updateMetaDataBlock ) { blocks . addIndexBlock ( index , INDEX_METADATA_BLOCK ) ; } else { blocks . removeIndexBlock ( index , INDEX_METADATA_BLOCK ) ; } } } Boolean updateWriteBlock = openSettings . getAsBoolean ( SETTING_BLOCKS_WRITE , null ) ; if ( updateWriteBlock != null ) { for ( String index : actualIndices ) { if ( updateWriteBlock ) { blocks . addIndexBlock ( index , INDEX_WRITE_BLOCK ) ; } else { blocks . removeIndexBlock ( index , INDEX_WRITE_BLOCK ) ; } } } Boolean updateReadBlock = openSettings . getAsBoolean ( SETTING_BLOCKS_READ , null ) ; if ( updateReadBlock != null ) { for ( String index : actualIndices ) { if ( updateReadBlock ) { blocks . addIndexBlock ( index , INDEX_READ_BLOCK ) ; } else { blocks . removeIndexBlock ( index , INDEX_READ_BLOCK ) ; } } } if ( ! ( openIndices . isEmpty ( ) ) ) { String [ ] indices = openIndices . toArray ( new String [ openIndices . size ( ) ] ) ; metaDataBuilder . updateSettings ( openSettings , indices ) ; } if ( ! ( closeIndices . isEmpty ( ) ) ) { String [ ] indices = closeIndices . toArray ( new String [ closeIndices . size ( ) ] ) ; metaDataBuilder . updateSettings ( closeSettings , indices ) ; } ClusterState updatedState = ClusterState . builder ( ) . state ( currentState ) . metaData ( metaDataBuilder ) . routingTable ( routingTableBuilder ) . blocks ( blocks ) . build ( ) ; RoutingAllocation . Result routingResult = allocationService . reroute ( updatedState ) ; updatedState = org . elasticsearch . cluster . ClusterState . newClusterStateBuilder ( ) . state ( updatedState ) . routingResult ( routingResult ) . build ( ) ; return updatedState ; <START_BUG> } catch ( Exception e ) { <END_BUG> listener . onFailure ( e ) ; return currentState ; } } @ Override public void clusterStateProcessed ( ClusterState clusterState ) { listener . onSuccess ( ) ; } } ) ; } public static interface Listener { void onSuccess ( ) { } void onFailure ( Throwable t ) { } } }<BUG2FIX>} catch ( Throwable e ) {
public class DeleteByQueryRequest extends IndicesReplicationOperationRequest { private static final XContentType contentType = Requests . CONTENT_TYPE ; private BytesReference querySource ; private boolean querySourceUnsafe ; private String [ ] types = Strings . EMPTY_ARRAY ; @ Nullable private String routing ; public DeleteByQueryRequest ( String ... indices ) { } public DeleteByQueryRequest ( ) { } @ Override public DeleteByQueryRequest listenerThreaded ( boolean threadedListener ) { } @ Override public ActionRequestValidationException validate ( ) { } public DeleteByQueryRequest indices ( String ... indices ) { } BytesReference querySource ( ) { } @ Required public DeleteByQueryRequest query ( QueryBuilder queryBuilder ) { } @ Required public DeleteByQueryRequest query ( String querySource ) { } @ Required public DeleteByQueryRequest query ( Map querySource ) { } @ Required public DeleteByQueryRequest query ( XContentBuilder builder ) { } @ Required public DeleteByQueryRequest query ( byte [ ] querySource ) { } @ Required public DeleteByQueryRequest query ( byte [ ] querySource , int offset , int length , boolean unsafe ) { } public DeleteByQueryRequest query ( BytesReference source , boolean unsafe ) { } String [ ] types ( ) { } @ Override public String routing ( ) { } public DeleteByQueryRequest routing ( String routing ) { } public DeleteByQueryRequest routing ( String ... routings ) { } public DeleteByQueryRequest types ( String ... types ) { } public DeleteByQueryRequest timeout ( TimeValue timeout ) { } public DeleteByQueryRequest timeout ( String timeout ) { } public DeleteByQueryRequest replicationType ( ReplicationType replicationType ) { } public DeleteByQueryRequest consistencyLevel ( WriteConsistencyLevel consistencyLevel ) { } public DeleteByQueryRequest replicationType ( String replicationType ) { } public void readFrom ( StreamInput in ) throws IOException { } public void writeTo ( StreamOutput out ) throws IOException { super . writeTo ( out ) ; <START_BUG> out . writeBytesReference ( querySource , true ) ; <END_BUG> if ( ( routing ) == null ) { out . writeBoolean ( false ) ; } else { out . writeBoolean ( true ) ; out . writeUTF ( routing ) ; } out . writeVInt ( types . length ) ; for ( String type : types ) { out . writeUTF ( type ) ; } } @ Override public String toString ( ) { } }<BUG2FIX>out . writeBytesReference ( querySource ) ;
public class CloudIndexShardGateway extends AbstractIndexShardComponent implements IndexShardGateway { private final InternalIndexShard indexShard ; private final ThreadPool threadPool ; private final RecoveryThrottler recoveryThrottler ; private final Store store ; private final Location shardLocation ; private final String container ; private final String shardDirectory ; private final String shardIndexDirectory ; private final String shardTranslogDirectory ; private final BlobStoreContext blobStoreContext ; private final ByteSizeValue chunkSize ; private volatile int currentTranslogPartToWrite = 1 ; @ Inject public CloudIndexShardGateway ( ShardId shardId , @ IndexSettings Settings indexSettings , IndexShard indexShard , ThreadPool threadPool , Store store , RecoveryThrottler recoveryThrottler , IndexGateway cloudIndexGateway , CloudBlobStoreService blobStoreService ) { } @ Override public String type ( ) { } @ Override public boolean requiresSnapshotScheduling ( ) { } @ Override public String toString ( ) { } @ Override public void close ( boolean delete ) { } @ Override public RecoveryStatus recover ( ) throws IndexShardGatewayRecoveryException { } @ Override public SnapshotStatus snapshot ( Snapshot snapshot ) { } private Index recoverIndex ( ) throws IndexShardGatewayRecoveryException { } private Translog recoverTranslog ( ) throws IndexShardGatewayRecoveryException { final Map < String , StorageMetadata > allMetaDatas = listAllMetadatas ( container , shardTranslogDirectory ) ; long latestTranslogId = - 1 ; for ( String name : allMetaDatas . keySet ( ) ) { String translogName = name . substring ( ( ( shardTranslogDirectory . length ( ) ) + 1 ) ) ; long translogId = Long . parseLong ( translogName . substring ( 0 , translogName . lastIndexOf ( '.' ) ) ) ; if ( translogId > latestTranslogId ) { latestTranslogId = translogId ; } } if ( latestTranslogId == ( - 1 ) ) { indexShard . start ( ) ; return new RecoveryStatus . Translog ( 0 ) ; } try { ArrayList < Translog . Operation > operations = Lists . newArrayList ( ) ; long size = 0 ; int index = 1 ; while ( true ) { String translogPartName = ( ( ( ( shardTranslogDirectory ) + "/" ) + ( String . valueOf ( latestTranslogId ) ) ) + "." ) + index ; if ( ! ( allMetaDatas . containsKey ( translogPartName ) ) ) { break ; } Blob blob = blobStoreContext . getBlobStore ( ) . getBlob ( container , translogPartName ) ; if ( blob == null ) { break ; } size += blob . getContentLength ( ) ; InputStreamStreamInput streamInput = new InputStreamStreamInput ( blob . getContent ( ) ) ; int numberOfOperations = streamInput . readInt ( ) ; for ( int i = 0 ; i < numberOfOperations ; i ++ ) { operations . add ( readTranslogOperation ( streamInput ) ) ; } index ++ ; } currentTranslogPartToWrite = index ; indexShard . performRecoveryPrepareForTranslog ( ) ; <START_BUG> indexShard . performRecoveryFinalization ( ) ; <END_BUG> return new RecoveryStatus . Translog ( operations . size ( ) ) ; } catch ( Exception e ) { throw new IndexShardGatewayRecoveryException ( shardId ( ) , "Failed<seq2seq4repair_space>to<seq2seq4repair_space>perform<seq2seq4repair_space>recovery<seq2seq4repair_space>of<seq2seq4repair_space>translog" , e ) ; } } private Map < String , StorageMetadata > listAllMetadatas ( String container , String directory ) { } private void deleteFile ( String fileName , Map < String , StorageMetadata > allIndicesMetadata ) { } private void copyFromDirectory ( Directory dir , String fileName , final CountDownLatch latch , final CopyOnWriteArrayList < Throwable > failures ) throws Exception { } private void copyToDirectory ( StorageMetadata metadata , Map < String , StorageMetadata > allMetadatas ) throws IOException { } private void copy ( InputStream is , IndexOutput indexOutput , byte [ ] buffer ) throws IOException { } }<BUG2FIX>indexShard . performRecoveryFinalization ( true ) ;
public class SoundTest extends GdxTest { Sound sound ; float volume = 0.5F ; long soundId = 0 ; Stage ui ; Skin skin ; @ Override public void create ( ) { sound = audio . newSound ( files . getFileHandle ( "data/shotgun.mp3" , Internal ) ) ; <START_BUG> skin = new Skin ( files . internal ( "data/uiskin.json" ) , files . internal ( "data/uiskin.png" ) ) ; <END_BUG> ui = new Stage ( graphics . getWidth ( ) , graphics . getHeight ( ) , true ) ; TextButton play = new TextButton ( "Play" , skin ) ; TextButton stop = new TextButton ( "Stop" , skin ) ; final Slider pitch = new Slider ( 0.1F , 4 , 0.1F , skin ) ; pitch . setValue ( 1 ) ; final Label pitchValue = new Label ( "1.0" , skin ) ; final Slider volume = new Slider ( 0.1F , 1 , 0.1F , skin ) ; volume . setValue ( 1 ) ; final Label volumeValue = new Label ( "1.0" , skin ) ; Table table = new Table ( ) ; final Slider pan = new Slider ( ( - 1.0F ) , 1.0F , 0.1F , skin ) ; pan . setValue ( 0 ) ; final Label panValue = new Label ( "0.0" , skin ) ; table . setFillParent ( true ) ; table . align ( ( ( Align . center ) | ( Align . top ) ) ) ; table . add ( play ) ; table . add ( stop ) ; table . row ( ) ; table . add ( new Label ( "Pitch" , skin ) ) ; table . add ( pitch ) ; table . add ( pitchValue ) ; table . row ( ) ; table . add ( new Label ( "Volume" , skin ) ) ; table . add ( volume ) ; table . add ( volumeValue ) ; table . row ( ) ; table . add ( new Label ( "Pan" , skin ) ) ; table . add ( pan ) ; table . add ( panValue ) ; ui . addActor ( table ) ; play . addListener ( new ClickListener ( ) { public void clicked ( ActorEvent event , float x , float y ) { soundId = sound . play ( volume . getValue ( ) ) ; sound . setPitch ( soundId , pitch . getValue ( ) ) ; sound . setPan ( soundId , pan . getValue ( ) , volume . getValue ( ) ) ; } } ) ; stop . addListener ( new ClickListener ( ) { public void clicked ( ActorEvent event , float x , float y ) { sound . stop ( soundId ) ; } } ) ; pitch . addListener ( new ChangeListener ( ) { public void changed ( ChangeEvent event , Actor actor ) { sound . setPitch ( soundId , pitch . getValue ( ) ) ; pitchValue . setText ( ( "" + ( pitch . getValue ( ) ) ) ) ; } } ) ; volume . addListener ( new ChangeListener ( ) { public void changed ( ChangeEvent event , Actor actor ) { sound . setVolume ( soundId , volume . getValue ( ) ) ; volumeValue . setText ( ( "" + ( volume . getValue ( ) ) ) ) ; } } ) ; pan . addListener ( new ChangeListener ( ) { public void changed ( ChangeEvent event , Actor actor ) { sound . setPan ( soundId , pan . getValue ( ) , volume . getValue ( ) ) ; panValue . setText ( ( "" + ( pan . getValue ( ) ) ) ) ; } } ) ; input . setInputProcessor ( ui ) ; } @ Override public void render ( ) { } @ Override public void dispose ( ) { } @ Override public boolean needsGL20 ( ) { } }<BUG2FIX>skin = new Skin ( files . internal ( "data/uiskin.json" ) ) ;
public class RestXContentBuilder { public static XContentBuilder restContentBuilder ( RestRequest request ) throws IOException { } public static void restDocumentSource ( byte [ ] source , XContentBuilder builder , ToXContent . Params params ) throws IOException { } public static void restDocumentSource ( byte [ ] source , int offset , int length , XContentBuilder builder , ToXContent . Params params ) throws IOException { if ( LZF . isCompressed ( source , offset , length ) ) { <START_BUG> BytesStreamInput siBytes = new BytesStreamInput ( source , offset , length ) ; <END_BUG> LZFStreamInput siLzf = CachedStreamInput . cachedLzf ( siBytes ) ; XContentType contentType = XContentFactory . xContentType ( siLzf ) ; siLzf . resetToBufferStart ( ) ; if ( contentType == ( builder . contentType ( ) ) ) { builder . rawField ( "_source" , siLzf ) ; } else { XContentParser parser = XContentFactory . xContent ( contentType ) . createParser ( siLzf ) ; try { parser . nextToken ( ) ; builder . field ( "_source" ) ; builder . copyCurrentStructure ( parser ) ; } finally { parser . close ( ) ; } } } else { XContentType contentType = XContentFactory . xContentType ( source , offset , length ) ; if ( contentType == ( builder . contentType ( ) ) ) { builder . rawField ( "_source" , source , offset , length ) ; } else { XContentParser parser = XContentFactory . xContent ( contentType ) . createParser ( source ) ; try { parser . nextToken ( ) ; builder . field ( "_source" ) ; builder . copyCurrentStructure ( parser ) ; } finally { parser . close ( ) ; } } } } }<BUG2FIX>BytesStreamInput siBytes = new BytesStreamInput ( source , offset , length , false ) ;
public class ViewIssueActivity extends RoboFragmentActivity { private static final int REQUEST_CODE_COMMENT = 1 ; public static Intent viewIssueIntentFor ( Issue issue ) { } @ Inject private ContextScopedProvider < IssueService > service ; @ InjectView ( id . list ) private ListView comments ; private IssueBodyViewHolder body ; @ InjectExtra ( EXTRA_REPOSITORY_NAME ) private String repository ; @ InjectExtra ( EXTRA_REPOSITORY_OWNER ) private String repositoryOwner ; @ InjectExtra ( EXTRA_ISSUE_NUMBER ) private int issueNumber ; private HttpImageGetter imageGetter ; protected void onCreate ( Bundle savedInstanceState ) { } private Issue getIssue ( ) { } @ SuppressWarnings ( { "unchecked" } ) private List < Comment > getComments ( ) { } @ Override public boolean onCreateOptionsMenu ( Menu options ) { } @ Override public boolean onOptionsItemSelected ( MenuItem item ) { } protected void onActivityResult ( int requestCode , int resultCode , Intent data ) { } private void createComment ( final String comment ) { } private void loadIssue ( boolean force ) { } private void loadComments ( boolean force ) { } private void displayComments ( List < Comment > issueComments ) { } private void displayIssue ( Issue issue ) { ( ( TextView ) ( findViewById ( tv_issue_title ) ) ) . setText ( issue . getTitle ( ) ) ; String reported = ( ( "<b>" + ( issue . getUser ( ) . getLogin ( ) ) ) + "</b><seq2seq4repair_space>" ) + ( Time . relativeTimeFor ( issue . getCreatedAt ( ) ) ) ; TextView creation = ( ( TextView ) ( findViewById ( tv_issue_creation ) ) ) ; creation . setText ( Html . encode ( reported ) ) ; Avatar . bind ( this , ( ( ImageView ) ( findViewById ( iv_gravatar ) ) ) , issue . getUser ( ) ) ; View view = getLayoutInflater ( ) . inflate ( issue_view_body , null ) ; <START_BUG> body = new IssueBodyViewHolder ( this , imageGetter , view ) ; <END_BUG> body . updateViewFor ( issue ) ; LinearLayout labels = ( ( LinearLayout ) ( findViewById ( ll_labels ) ) ) ; if ( ! ( issue . getLabels ( ) . isEmpty ( ) ) ) { LabelsDrawable drawable = new LabelsDrawable ( creation . getTextSize ( ) , issue . getLabels ( ) ) ; drawable . getPaint ( ) . setColor ( getResources ( ) . getColor ( item_background ) ) ; labels . setBackgroundDrawable ( drawable ) ; LayoutParams params = new LayoutParams ( drawable . getBounds ( ) . width ( ) , drawable . getBounds ( ) . height ( ) ) ; labels . setLayoutParams ( params ) ; } comments . addHeaderView ( view ) ; loadComments ( false ) ; } }<BUG2FIX>body = new IssueBodyViewHolder ( imageGetter , view ) ;
protected void postPrimaryOperation ( Request request , TransportShardReplicationOperationAction . PrimaryResponse < Response > response ) { } protected abstract ShardIterator shards ( ClusterState clusterState , Request request ) throws ElasticSearchException { } protected abstract boolean checkWriteConsistency ( ) { } protected void checkBlock ( Request request , ClusterState state ) { } protected TransportRequestOptions transportOptions ( ) { } protected boolean ignoreReplicas ( ) { } private String transportReplicaAction ( ) { } protected IndexShard indexShard ( TransportShardReplicationOperationAction < Request , Response > . ShardOperationRequest shardRequest ) { } class OperationTransportHandler extends BaseTransportRequestHandler < Request > { @ Override public Request newInstance ( ) { } @ Override public void messageReceived ( final Request request , final TransportChannel channel ) throws Exception { } @ Override public boolean spawn ( ) { } } class ReplicaOperationTransportHandler extends BaseTransportRequestHandler < TransportShardReplicationOperationAction < Request , Response > . ShardOperationRequest > { @ Override public TransportShardReplicationOperationAction < Request , Response > . ShardOperationRequest newInstance ( ) { } @ Override public void messageReceived ( TransportShardReplicationOperationAction < Request , Response > . ShardOperationRequest request , TransportChannel channel ) throws Exception { } @ Override public boolean spawn ( ) { } } protected class ShardOperationRequest implements Streamable { public int shardId ; public Request request ; public ShardOperationRequest ( ) { } public ShardOperationRequest ( int shardId , Request request ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } protected class AsyncShardOperationAction { private final ActionListener < Response > listener ; private final Request request ; private DiscoveryNodes nodes ; private ShardIterator shardIt ; private final AtomicBoolean primaryOperationStarted = new AtomicBoolean ( ) ; private final ReplicationType replicationType ; AsyncShardOperationAction ( Request request , ActionListener < Response > listener ) { } public void start ( ) { } public boolean start ( final boolean fromClusterEvent ) throws ElasticSearchException { final ClusterState clusterState = clusterService . state ( ) ; nodes = clusterState . nodes ( ) ; if ( ! ( clusterState . routingTable ( ) . hasIndex ( request . index ( ) ) ) ) { retry ( fromClusterEvent , null ) ; return false ; } try { shardIt = shards ( clusterState , request ) ; } catch ( Exception e ) { listener . onFailure ( e ) ; return true ; } if ( ( shardIt . size ( ) ) == 0 ) { retry ( fromClusterEvent , shardIt . shardId ( ) ) ; return false ; } boolean foundPrimary = false ; for ( final ShardRouting shard : shardIt ) { if ( ! ( shard . primary ( ) ) ) { continue ; } if ( ( ! ( shard . active ( ) ) ) || ( ! ( nodes . nodeExists ( shard . currentNodeId ( ) ) ) ) ) { retry ( fromClusterEvent , shard . shardId ( ) ) ; return false ; } if ( checkWriteConsistency ( ) ) { WriteConsistencyLevel consistencyLevel = defaultWriteConsistencyLevel ; if ( ( request . consistencyLevel ( ) ) != ( WriteConsistencyLevel . DEFAULT ) ) { consistencyLevel = request . consistencyLevel ( ) ; } int requiredNumber = 1 ; if ( ( consistencyLevel == ( WriteConsistencyLevel . QUORUM ) ) && ( ( shardIt . size ( ) ) > 2 ) ) { requiredNumber = ( ( shardIt . size ( ) ) / 2 ) + 1 ; } else if ( consistencyLevel == ( WriteConsistencyLevel . ALL ) ) { requiredNumber = shardIt . size ( ) ; } if ( ( shardIt . sizeActive ( ) ) < requiredNumber ) { retry ( fromClusterEvent , shard . shardId ( ) ) ; return false ; } } if ( ! ( primaryOperationStarted . compareAndSet ( false , true ) ) ) { <START_BUG> return false ; <END_BUG> } foundPrimary = true ; if ( shard . currentNodeId ( ) . equals ( nodes . localNodeId ( ) ) ) { if ( request . operationThreaded ( ) ) { request . beforeLocalFork ( ) ; threadPool . execute ( new Runnable ( ) { @ Override public void run ( ) { performOnPrimary ( shard . id ( ) , fromClusterEvent , true , shard , clusterState ) ; } } ) ; } else { performOnPrimary ( shard . id ( ) , fromClusterEvent , false , shard , clusterState ) ; } } else { DiscoveryNode node = nodes . get ( shard . currentNodeId ( ) ) ; transportService . sendRequest ( node , transportAction ( ) , request , transportOptions ( ) , new BaseTransportResponseHandler < Response > ( ) { @ Override public Response newInstance ( ) { return newResponseInstance ( ) ; } @ Override public void handleResponse ( Response response ) { listener . onResponse ( response ) ; } @ Override public void handleException ( TransportException exp ) { if ( ( ( ( exp . unwrapCause ( ) ) instanceof ConnectTransportException ) || ( ( exp . unwrapCause ( ) ) instanceof NodeClosedException ) ) || ( ( exp . unwrapCause ( ) ) instanceof IllegalIndexShardStateException ) ) { primaryOperationStarted . set ( false ) ; retry ( false , shard . shardId ( ) ) ; } else { listener . onFailure ( exp ) ; } } @ Override public boolean spawn ( ) { return request . listenerThreaded ( ) ; } } ) ; } break ; } if ( ! foundPrimary ) { final UnavailableShardsException failure = new UnavailableShardsException ( shardIt . shardId ( ) , request . toString ( ) ) ; if ( request . listenerThreaded ( ) ) { threadPool . execute ( new Runnable ( ) { @ Override public void run ( ) { listener . onFailure ( failure ) ;<BUG2FIX>return true ;
public class TermQueryParser extends AbstractIndexComponent implements XContentQueryParser { public static final String NAME = "term" ; @ Inject public TermQueryParser ( Index index , @ IndexSettings Settings settings ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; XContentParser . Token token = parser . nextToken ( ) ; assert token == ( Token . FIELD_NAME ) ; String fieldName = parser . currentName ( ) ; String value = null ; float boost = 1.0F ; token = parser . nextToken ( ) ; if ( token == ( Token . START_OBJECT ) ) { String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else { if ( "value" . equals ( currentFieldName ) ) { value = parser . text ( ) ; } else if ( "boost" . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } } } parser . nextToken ( ) ; } else { value = parser . text ( ) ; parser . nextToken ( ) ; } if ( value == null ) { throw new QueryParsingException ( index , "No<seq2seq4repair_space>value<seq2seq4repair_space>specified<seq2seq4repair_space>for<seq2seq4repair_space>term<seq2seq4repair_space>query" ) ; } Query query = null ; MapperService . SmartNameFieldMappers smartNameFieldMappers = parseContext . smartFieldMappers ( fieldName ) ; if ( smartNameFieldMappers != null ) { if ( smartNameFieldMappers . hasMapper ( ) ) { query = smartNameFieldMappers . mapper ( ) . fieldQuery ( value ) ; } } if ( query == null ) { query = new org . apache . lucene . search . TermQuery ( new Term ( fieldName , value ) ) ; } query . setBoost ( boost ) ; <START_BUG> return wrapSmartNameQuery ( query , smartNameFieldMappers , parseContext . indexCache ( ) ) ; <END_BUG> } }<BUG2FIX>return wrapSmartNameQuery ( query , smartNameFieldMappers , parseContext ) ;
public class DoubleArrayRef extends AbstractList < Double > implements RandomAccess { public static final DoubleArrayRef EMPTY = new DoubleArrayRef ( new double [ 0 ] ) ; public double [ ] values ; public int start ; public int end ; public DoubleArrayRef ( double [ ] values ) { } public DoubleArrayRef ( double [ ] values , int length ) { } public DoubleArrayRef ( double [ ] values , int start , int end ) { } public void reset ( int newLength ) { } @ Override public int size ( ) { } @ Override public boolean isEmpty ( ) { <START_BUG> return ( size ( ) ) != 0 ; <END_BUG> } @ Override public Double get ( int index ) { } @ Override public boolean contains ( Object target ) { } @ Override public int indexOf ( Object target ) { } @ Override public int lastIndexOf ( Object target ) { } @ Override public Double set ( int index , Double element ) { } @ Override public boolean equals ( Object object ) { } @ Override public int hashCode ( ) { } @ Override public String toString ( ) { } private static int indexOf ( double [ ] array , double target , int start , int end ) { } private static int lastIndexOf ( double [ ] array , double target , int start , int end ) { } }<BUG2FIX>return ( size ( ) ) == 0 ;
public abstract class FloatArrayAtomicFieldData extends AbstractAtomicNumericFieldData { public static FloatArrayAtomicFieldData empty ( ) { } protected long size = - 1 ; public FloatArrayAtomicFieldData ( ) { } @ Override public void close ( ) { } static class Empty extends FloatArrayAtomicFieldData { Empty ( ) { } @ Override public LongValues getLongValues ( ) { } @ Override public DoubleValues getDoubleValues ( ) { } @ Override public boolean isMultiValued ( ) { } @ Override public long getNumberUniqueValues ( ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override <START_BUG> public BytesValues getBytesValues ( boolean needsHashes ) { <END_BUG> return BytesValues . EMPTY ; } @ Override public ScriptDocValues getScriptValues ( ) { } } public static class WithOrdinals extends FloatArrayAtomicFieldData { private final Ordinals ordinals ; private final FloatArray values ; public WithOrdinals ( FloatArray values , Ordinals ordinals ) { } @ Override public boolean isMultiValued ( ) { } @ Override public long getNumberUniqueValues ( ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override public FloatArrayAtomicFieldData . WithOrdinals . LongValues getLongValues ( ) { } @ Override public FloatArrayAtomicFieldData . WithOrdinals . DoubleValues getDoubleValues ( ) { } static class LongValues extends org . elasticsearch . index . fielddata . LongValues . WithOrdinals { private final FloatArray values ; LongValues ( FloatArray values , Ordinals . Docs ordinals ) { } @ Override public long getValueByOrd ( long ord ) { } } static class DoubleValues extends org . elasticsearch . index . fielddata . DoubleValues . WithOrdinals { private final FloatArray values ; DoubleValues ( FloatArray values , Ordinals . Docs ordinals ) { } @ Override public double getValueByOrd ( long ord ) { } } } public static class SingleFixedSet extends FloatArrayAtomicFieldData { private final FloatArray values ; private final FixedBitSet set ; private final long numOrd ; public SingleFixedSet ( FloatArray values , FixedBitSet set , long numOrd ) { } @ Override public boolean isMultiValued ( ) { } @ Override public long getNumberUniqueValues ( ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override public FloatArrayAtomicFieldData . SingleFixedSet . LongValues getLongValues ( ) { } @ Override public FloatArrayAtomicFieldData . SingleFixedSet . DoubleValues getDoubleValues ( ) { } static class LongValues extends org . elasticsearch . index . fielddata . LongValues { private final FloatArray values ; private final FixedBitSet set ; LongValues ( FloatArray values , FixedBitSet set ) { } @ Override public int setDocument ( int docId ) { } @ Override public long nextValue ( ) { } } static class DoubleValues extends org . elasticsearch . index . fielddata . DoubleValues { private final FloatArray values ; private final FixedBitSet set ; DoubleValues ( FloatArray values , FixedBitSet set ) { } @ Override public int setDocument ( int docId ) { } @ Override public double nextValue ( ) { } } } public static class Single extends FloatArrayAtomicFieldData { private final FloatArray values ; private final long numOrd ; public Single ( FloatArray values , long numOrd ) { } @ Override public boolean isMultiValued ( ) { } @ Override public long getNumberUniqueValues ( ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override public FloatArrayAtomicFieldData . Single . LongValues getLongValues ( ) { } @ Override public FloatArrayAtomicFieldData . Single . DoubleValues getDoubleValues ( ) { } static class LongValues extends DenseLongValues { private final FloatArray values ; LongValues ( FloatArray values ) { } @ Override public long nextValue ( ) { } } static class DoubleValues extends DenseDoubleValues { private final FloatArray values ; DoubleValues ( FloatArray values ) { } @ Override public double nextValue ( ) { } } } }<BUG2FIX>public BytesValues getBytesValues ( ) {
public class IssueDashboardPagerAdapter extends FragmentStatePagerAdapter { private final Resources resources ; public IssueDashboardPagerAdapter ( final Resources resources , final FragmentManager fragmentManager ) { } @ Override public int getCount ( ) { } @ Override public Fragment getItem ( final int position ) { } @ Override <START_BUG> public CharSequence getPageTitle ( int position ) { <END_BUG> switch ( position ) { case 0 : return resources . getString ( dashboard_watched ) ; case 1 : return resources . getString ( dashboard_assigned ) ; case 2 : return resources . getString ( dashboard_created ) ; case 3 : return resources . getString ( dashboard_mentioned ) ; default : return null ; } } }<BUG2FIX>public CharSequence getPageTitle ( final int position ) {
public class GeoMappingTests extends ElasticsearchIntegrationTest { public void testUpdatePrecision ( ) throws Exception { } private void assertPrecision ( Distance expected ) throws Exception { ImmutableOpenMap < String , ImmutableOpenMap < String , MappingMetaData > > mappings = client ( ) . admin ( ) . indices ( ) . getMappings ( new GetMappingsRequest ( ) . indices ( "test" ) . types ( "type1" ) ) . actionGet ( ) . getMappings ( ) ; assertNotNull ( mappings ) ; Map < String , ? > properties = ( ( Map < String , ? > ) ( mappings . get ( "test" ) . get ( "type1" ) . getSourceAsMap ( ) . get ( "properties" ) ) ) ; Map < String , ? > pinProperties = ( ( Map < String , ? > ) ( properties . get ( "pin" ) ) ) ; Map < String , ? > pinFieldData = ( ( Map < String , ? > ) ( pinProperties . get ( "fielddata" ) ) ) ; <START_BUG> Distance precision = Distance . parseDistance ( pinFieldData . get ( "precision" ) . toString ( ) , METERS ) ; <END_BUG> assertEquals ( expected , precision ) ; } }<BUG2FIX>Distance precision = Distance . parseDistance ( pinFieldData . get ( "precision" ) . toString ( ) ) ;
public final class ClassReflection { public static Class forName ( String name ) throws ReflectionException { } public static String getSimpleName ( Class c ) { } public static boolean isInstance ( Class c , Object obj ) { } public static boolean isAssignableFrom ( Class c1 , Class c2 ) { Type c1Type = ReflectionCache . getType ( c1 ) ; Type c2Type = ReflectionCache . getType ( c2 ) ; <START_BUG> return c1Type . isAssignableFrom ( c2Type ) ; <END_BUG> } public static boolean isMemberClass ( Class c ) { } public static boolean isStaticClass ( Class c ) { } public static < T > T newInstance ( Class < T > c ) throws ReflectionException { } public static Constructor [ ] getConstructors ( Class c ) { } public static Constructor getConstructor ( Class c , Class ... parameterTypes ) throws ReflectionException { } public static Constructor getDeclaredConstructor ( Class c , Class ... parameterTypes ) throws ReflectionException { } public static Method [ ] getMethods ( Class c ) { } public static Method getMethod ( Class c , String name , Class ... parameterTypes ) throws ReflectionException { } public static Method [ ] getDeclaredMethods ( Class c ) { } public static Method getDeclaredMethod ( Class c , String name , Class ... parameterTypes ) throws ReflectionException { } public static Field [ ] getFields ( Class c ) { } public static Field getField ( Class c , String name ) throws ReflectionException { } public static Field [ ] getDeclaredFields ( Class c ) { } public static Field getDeclaredField ( Class c , String name ) throws ReflectionException { } }<BUG2FIX>return c2Type . isAssignableFrom ( c1Type ) ;
public class ClusterSerializationTests { @ Test public void testClusterStateSerialization ( ) throws Exception { } @ Test public void testRoutingTableSerialization ( ) throws Exception { MetaData metaData = newMetaDataBuilder ( ) . put ( newIndexMetaDataBuilder ( "test" ) . numberOfShards ( 10 ) . numberOfReplicas ( 1 ) ) . build ( ) ; RoutingTable routingTable = routingTable ( ) . add ( indexRoutingTable ( "test" ) . initializeEmpty ( metaData . index ( "test" ) ) ) . build ( ) ; DiscoveryNodes nodes = DiscoveryNodes . newNodesBuilder ( ) . put ( newNode ( "node1" ) ) . put ( newNode ( "node2" ) ) . put ( newNode ( "node3" ) ) . build ( ) ; ClusterState clusterState = newClusterStateBuilder ( ) . nodes ( nodes ) . metaData ( metaData ) . routingTable ( routingTable ) . build ( ) ; AllocationService strategy = new AllocationService ( ) ; RoutingTable source = strategy . reroute ( clusterState ) . routingTable ( ) ; BytesStreamOutput outStream = new BytesStreamOutput ( ) ; Builder . writeTo ( source , outStream ) ; <START_BUG> BytesStreamInput inStream = new BytesStreamInput ( outStream . copiedByteArray ( ) ) ; <END_BUG> RoutingTable target = Builder . readFrom ( inStream ) ; assertThat ( target . prettyPrint ( ) , equalTo ( source . prettyPrint ( ) ) ) ; } private DiscoveryNode newNode ( String nodeId ) { } }<BUG2FIX>BytesStreamInput inStream = new BytesStreamInput ( outStream . copiedByteArray ( ) , false ) ;
public class ClusterStateResponse extends ActionResponse { private ClusterName clusterName ; private ClusterState clusterState ; public ClusterStateResponse ( ) { } public ClusterStateResponse ( ClusterName clusterName , ClusterState clusterState ) { } public ClusterState getState ( ) { } public ClusterName getClusterName ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { super . readFrom ( in ) ; clusterName = ClusterName . readClusterName ( in ) ; <START_BUG> clusterState = Builder . readFrom ( in , null , clusterName ) ; <END_BUG> } @ Override public void writeTo ( StreamOutput out ) throws IOException { } }<BUG2FIX>clusterState = Builder . readFrom ( in , null ) ;
public class MeshShaderTest implements RenderListener { ShaderProgram shader ; Mesh mesh ; Texture texture ; Matrix matrix = new Matrix ( ) ; @ Override public void surfaceCreated ( Application app ) { String vertexShader = "attribute<seq2seq4repair_space>vec4<seq2seq4repair_space>a_position;<seq2seq4repair_space>\n" + ( ( ( ( ( ( ( ( ( ( "attribute<seq2seq4repair_space>vec4<seq2seq4repair_space>a_color;\n" + "attribute<seq2seq4repair_space>vec2<seq2seq4repair_space>a_texCoords;\n" ) + "uniform<seq2seq4repair_space>mat4<seq2seq4repair_space>u_worldView;\n" ) + "varying<seq2seq4repair_space>vec4<seq2seq4repair_space>v_color;" ) + "varying<seq2seq4repair_space>vec2<seq2seq4repair_space>v_texCoords;" ) + "void<seq2seq4repair_space>main()<seq2seq4repair_space>\n" ) + "{<seq2seq4repair_space>\n" ) + "<seq2seq4repair_space>v_color<seq2seq4repair_space>=<seq2seq4repair_space>vec4(a_color.x,<seq2seq4repair_space>a_color.y,<seq2seq4repair_space>a_color.z,<seq2seq4repair_space>1);<seq2seq4repair_space>\n" ) + "<seq2seq4repair_space>v_texCoords<seq2seq4repair_space>=<seq2seq4repair_space>a_texCoords;<seq2seq4repair_space>\n" ) + "<seq2seq4repair_space>gl_Position<seq2seq4repair_space>=<seq2seq4repair_space>u_worldView<seq2seq4repair_space>*<seq2seq4repair_space>a_position;<seq2seq4repair_space>\n" ) + "}<seq2seq4repair_space>\n" ) ; String fragmentShader = "precision<seq2seq4repair_space>mediump<seq2seq4repair_space>float;\n" + ( ( ( ( ( ( "varying<seq2seq4repair_space>vec4<seq2seq4repair_space>v_color;\n" + "varying<seq2seq4repair_space>vec2<seq2seq4repair_space>v_texCoords;\n" ) + "uniform<seq2seq4repair_space>sampler2D<seq2seq4repair_space>u_texture;\n" ) + "void<seq2seq4repair_space>main()<seq2seq4repair_space>\n" ) + "{<seq2seq4repair_space>\n" ) + "<seq2seq4repair_space>gl_FragColor<seq2seq4repair_space>=<seq2seq4repair_space>v_color<seq2seq4repair_space>*<seq2seq4repair_space>texture2D(u_texture,<seq2seq4repair_space>v_texCoords);\n" ) + "}" ) ; <START_BUG> shader = new ShaderProgram ( app . getGraphics ( ) . getGL20 ( ) , vertexShader , fragmentShader ) ; <END_BUG> if ( ( shader . isCompiled ( ) ) == false ) { app . log ( "ShaderTest" , shader . getLog ( ) ) ; System . exit ( 0 ) ; } mesh = new Mesh ( app . getGraphics ( ) , true , true , false , 3 , 3 , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . Position , 3 , "a_position" ) , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . Color , 4 , "a_color" ) , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . TextureCoordinates , 2 , "a_texCoords" ) ) ; mesh . setVertices ( new float [ ] { - 0.5F , - 0.5F , 0 , 1 , 0 , 0 , 1 , 0 , 0 , 0.5F , - 0.5F , 0 , 0 , 1 , 0 , 1 , 1 , 0 , 0 , 0.5F , 0 , 0 , 0 , 1 , 1 , 0.5F , 1 } ) ; mesh . setIndices ( new short [ ] { 0 , 1 , 2 } ) ; matrix . setToTranslation ( 0.3F , 0.2F , 0 ) ; Pixmap pixmap = app . getGraphics ( ) . newPixmap ( 256 , 256 , RGBA8888 ) ; pixmap . setColor ( 1 , 1 , 1 , 1 ) ; pixmap . fill ( ) ; pixmap . setColor ( 0 , 0 , 0 , 1 ) ; pixmap . drawLine ( 0 , 0 , 256 , 256 ) ; pixmap . drawLine ( 256 , 0 , 0 , 256 ) ; texture = app . getGraphics ( ) . newTexture ( pixmap , MipMap , Linear , ClampToEdge , ClampToEdge , true ) ; } @ Override public void render ( Application app ) { } @ Override public void surfaceChanged ( Application app , int width , int height ) { } @ Override public void dispose ( Application app ) { } public static void main ( String [ ] argv ) { } }<BUG2FIX>shader = new ShaderProgram ( app . getGraphics ( ) . getGL20 ( ) , vertexShader , fragmentShader , true ) ;
private static final String FOLDER_SEPARATOR = "/" ; private static final String WINDOWS_FOLDER_SEPARATOR = "\\" ; private static final String TOP_PATH = "src/test" ; private static final String CURRENT_PATH = "." ; private static final char EXTENSION_SEPARATOR = '.' ; public static void tabify ( int tabs , String from , StringBuilder to ) throws Exception { } public static void spaceify ( int spaces , String from , StringBuilder to ) throws Exception { } public static List < String > splitSmart ( String s , String separator , boolean decode ) { } public static List < String > splitWS ( String s , boolean decode ) { } public static boolean hasLength ( CharSequence str ) { } public static boolean hasLength ( String str ) { } public static boolean hasText ( CharSequence str ) { } public static boolean hasText ( String str ) { } public static boolean containsWhitespace ( CharSequence str ) { } public static boolean containsWhitespace ( String str ) { } public static String trimWhitespace ( String str ) { } public static String trimAllWhitespace ( String str ) { } public static String trimLeadingWhitespace ( String str ) { } public static String trimTrailingWhitespace ( String str ) { } public static String trimLeadingCharacter ( String str , char leadingCharacter ) { } public static String trimTrailingCharacter ( String str , char trailingCharacter ) { } public static boolean startsWithIgnoreCase ( String str , String prefix ) { } public static boolean endsWithIgnoreCase ( String str , String suffix ) { } public static boolean substringMatch ( CharSequence str , int index , CharSequence substring ) { } public static int countOccurrencesOf ( String str , String sub ) { } public static String replace ( String inString , String oldPattern , String newPattern ) { } public static String delete ( String inString , String pattern ) { } public static String deleteAny ( String inString , String charsToDelete ) { } public static String quote ( String str ) { } public static Object quoteIfString ( Object obj ) { } public static String unqualify ( String qualifiedName ) { } public static String unqualify ( String qualifiedName , char separator ) { } public static String capitalize ( String str ) { } public static String uncapitalize ( String str ) { } private static String changeFirstCharacterCase ( String str , boolean capitalize ) { } public static final ImmutableSet < Character > INVALID_FILENAME_CHARS = ImmutableSet . of ( '\\' , '/' , '*' , '?' , '"' , '<' , '>' , '|' , '<seq2seq4repair_space>' , ',' ) ; public static boolean validFileName ( String fileName ) { } public static boolean validFileNameExcludingAstrix ( String fileName ) { } public static String getFilename ( String path ) { } public static String getFilenameExtension ( String path ) { } public static String stripFilenameExtension ( String path ) { } public static String applyRelativePath ( String path , String relativePath ) { } public static String cleanPath ( String path ) { } public static boolean pathEquals ( String path1 , String path2 ) { } public static Locale parseLocaleString ( String localeString ) { } public static String toLanguageTag ( Locale locale ) { } public static String [ ] addStringToArray ( String [ ] array , String str ) { } public static String [ ] concatenateStringArrays ( String [ ] array1 , String [ ] array2 ) { } public static String [ ] mergeStringArrays ( String [ ] array1 , String [ ] array2 ) { } public static String [ ] sortStringArray ( String [ ] array ) { } public static String [ ] toStringArray ( Collection < String > collection ) { } public static String [ ] toStringArray ( Enumeration < String > enumeration ) { } public static String [ ] trimArrayElements ( String [ ] array ) { } public static String [ ] removeDuplicateStrings ( String [ ] array ) { } public static Set < String > splitStringByCommaToSet ( final String s ) { } public static String [ ] splitStringByCommaToArray ( final String s ) { } public static Set < String > splitStringToSet ( final String s , final char c ) { } public static String [ ] splitStringToArray ( final CharSequence s , final char c ) { <START_BUG> if ( ( s . length ( ) ) == 0 ) { <END_BUG> return Strings . EMPTY_ARRAY ; } int count = 1 ; for ( int i = 0 ; i < ( s . length ( ) ) ; i ++ ) { if ( ( s . charAt ( i ) ) == c ) { count ++ ; } } final String [ ] result = new String [ count ] ; final StringBuilder builder = new StringBuilder ( ) ; int res = 0 ; for ( int i = 0 ; i < ( s . length ( ) ) ; i ++ ) { if ( ( s . charAt ( i ) ) == c ) { if ( ( builder . length ( ) ) > 0 ) { result [ ( res ++ ) ] = builder . toString ( ) ; builder . setLength ( 0 ) ; } } else { builder . append ( s . charAt ( i ) ) ; } } if ( ( builder . length ( ) ) > 0 ) { result [ ( res ++ ) ] = builder . toString ( ) ; } if ( res != count ) { String [ ] result1 = new String [ res ] ; System . arraycopy ( result , 0 , result1 , 0 , res ) ; return result1 ; } return result ; }<BUG2FIX>if ( ( s == null ) || ( ( s . length ( ) ) == 0 ) ) {
public class FsTranslog extends AbstractIndexShardComponent implements Translog { private final File location ; private final boolean useStream ; private final Object mutex = new Object ( ) ; private boolean syncOnEachOperation = false ; private volatile long id = 0 ; private final AtomicInteger operationCounter = new AtomicInteger ( ) ; private long lastPosition = 0 ; private RafReference raf ; @ Inject public FsTranslog ( ShardId shardId , @ IndexSettings Settings indexSettings , NodeEnvironment nodeEnv ) { } public FsTranslog ( ShardId shardId , @ IndexSettings Settings indexSettings , File location ) { } public FsTranslog ( ShardId shardId , @ IndexSettings Settings indexSettings , File location , boolean useStream ) { } public File location ( ) { } @ Override public long currentId ( ) { } @ Override public int size ( ) { } @ Override public ByteSizeValue estimateMemorySize ( ) { } @ Override public void clearUnreferenced ( ) { } @ Override public void newTranslog ( ) throws TranslogException { } @ Override public void newTranslog ( long id ) throws TranslogException { } @ Override public void add ( Operation operation ) throws TranslogException { } @ Override public Snapshot snapshot ( ) throws TranslogException { synchronized ( mutex ) { try { raf . increaseRefCount ( ) ; if ( useStream ) { return new FsStreamSnapshot ( shardId , this . id , raf , lastPosition , operationCounter . get ( ) , operationCounter . get ( ) ) ; } else { return new FsChannelSnapshot ( shardId , this . id , raf , lastPosition , operationCounter . get ( ) , operationCounter . get ( ) ) ; } <START_BUG> } catch ( IOException e ) { <END_BUG> throw new TranslogException ( shardId , "Failed<seq2seq4repair_space>to<seq2seq4repair_space>snapshot" , e ) ; } } } @ Override public Snapshot snapshot ( Snapshot snapshot ) { } @ Override public void sync ( ) { } @ Override public void syncOnEachOperation ( boolean syncOnEachOperation ) { } @ Override public void close ( boolean delete ) { } }<BUG2FIX>} catch ( Exception e ) {
@ Override public void glPixelStorei ( int pname , int param ) { } @ Override public void glPolygonOffset ( float factor , float units ) { } @ Override public void glReadPixels ( int x , int y , int width , int height , int format , int type , Buffer pixels ) { } @ Override public void glReleaseShaderCompiler ( ) { } @ Override public void glRenderbufferStorage ( int target , int internalformat , int width , int height ) { } @ Override public void glSampleCoverage ( float value , boolean invert ) { } @ Override public void glScissor ( int x , int y , int width , int height ) { } @ Override public void glShaderBinary ( int n , IntBuffer shaders , int binaryformat , Buffer binary , int length ) { } @ Override public void glShaderSource ( int shader , String string ) { } @ Override public void glStencilFunc ( int func , int ref , int mask ) { } @ Override public void glStencilFuncSeparate ( int face , int func , int ref , int mask ) { } @ Override public void glStencilMask ( int mask ) { } @ Override public void glStencilMaskSeparate ( int face , int mask ) { } @ Override public void glStencilOp ( int fail , int zfail , int zpass ) { } @ Override public void glStencilOpSeparate ( int face , int fail , int zfail , int zpass ) { } @ Override public void glTexImage2D ( int target , int level , int internalformat , int width , int height , int border , int format , int type , Buffer pixels ) { } @ Override public void glTexParameterf ( int target , int pname , float param ) { } @ Override public void glTexParameterfv ( int target , int pname , FloatBuffer params ) { } @ Override public void glTexParameteri ( int target , int pname , int param ) { } @ Override public void glTexParameteriv ( int target , int pname , IntBuffer params ) { } @ Override public void glTexSubImage2D ( int target , int level , int xoffset , int yoffset , int width , int height , int format , int type , Buffer pixels ) { } @ Override public void glUniform1f ( int location , float x ) { } @ Override public void glUniform1fv ( int location , int count , FloatBuffer v ) { } @ Override public void glUniform1i ( int location , int x ) { } @ Override public void glUniform1iv ( int location , int count , IntBuffer v ) { } @ Override public void glUniform2f ( int location , float x , float y ) { } @ Override public void glUniform2fv ( int location , int count , FloatBuffer v ) { } @ Override public void glUniform2i ( int location , int x , int y ) { } @ Override public void glUniform2iv ( int location , int count , IntBuffer v ) { } @ Override public void glUniform3f ( int location , float x , float y , float z ) { } @ Override public void glUniform3fv ( int location , int count , FloatBuffer v ) { } @ Override public void glUniform3i ( int location , int x , int y , int z ) { } @ Override public void glUniform3iv ( int location , int count , IntBuffer v ) { } @ Override public void glUniform4f ( int location , float x , float y , float z , float w ) { } @ Override public void glUniform4fv ( int location , int count , FloatBuffer v ) { } @ Override public void glUniform4i ( int location , int x , int y , int z , int w ) { } @ Override public void glUniform4iv ( int location , int count , IntBuffer v ) { } @ Override public void glUniformMatrix2fv ( int location , int count , boolean transpose , FloatBuffer value ) { } @ Override public void glUniformMatrix3fv ( int location , int count , boolean transpose , FloatBuffer value ) { } @ Override public void glUniformMatrix4fv ( int location , int count , boolean transpose , FloatBuffer value ) { <START_BUG> gl . glUniformMatrix2x4fv ( location , count , transpose , value ) ; <END_BUG> } @ Override public void glUseProgram ( int program ) { } @ Override public void glValidateProgram ( int program ) { } @ Override public void glVertexAttrib1f ( int indx , float x ) { } @ Override public void glVertexAttrib1fv ( int indx , FloatBuffer values ) { } @ Override public void glVertexAttrib2f ( int indx , float x , float y ) { } @ Override public void glVertexAttrib2fv ( int indx , FloatBuffer values ) { } @ Override public void glVertexAttrib3f ( int indx , float x , float y , float z ) { } @ Override public void glVertexAttrib3fv ( int indx , FloatBuffer values ) { } @ Override public void glVertexAttrib4f ( int indx , float x , float y , float z , float w ) { } @ Override public void glVertexAttrib4fv ( int indx , FloatBuffer values ) { } @ Override public void glVertexAttribPointer ( int indx , int size , int type , boolean normalized , int stride , Buffer ptr ) { } @ Override public void glViewport ( int x , int y , int width , int height ) { } @ Override public void glDrawElements ( int mode , int count , int type , int indices ) { } @ Override public void glVertexAttribPointer ( int indx , int size , int type , boolean normalized , int stride , int ptr ) { } }<BUG2FIX>gl . glUniformMatrix4fv ( location , count , transpose , value ) ;
public class LongMap < V > { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; private static final int EMPTY = 0 ; public int size ; long [ ] keyTable ; V [ ] valueTable ; int capacity ; int stashSize ; V zeroValue ; boolean hasZeroValue ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private LongMap . Entries entries1 ; private LongMap . Entries entries2 ; private LongMap . Values values1 ; private LongMap . Values values2 ; private LongMap . Keys keys1 ; private LongMap . Keys keys2 ; public LongMap ( ) { } public LongMap ( int initialCapacity ) { } public LongMap ( int initialCapacity , float loadFactor ) { } public LongMap ( LongMap < ? extends V > map ) { } public V put ( long key , V value ) { } public void putAll ( LongMap < V > map ) { } private void putResize ( long key , V value ) { } private void push ( long insertKey , V insertValue , int index1 , long key1 , int index2 , long key2 , int index3 , long key3 ) { } private void putStash ( long key , V value ) { } public V get ( long key ) { } public V get ( long key , V defaultValue ) { } private V getStash ( long key , V defaultValue ) { } public V remove ( long key ) { } V removeStash ( long key ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean containsValue ( Object value , boolean identity ) { } public boolean containsKey ( long key ) { } private boolean containsKeyStash ( long key ) { } public long findKey ( Object value , boolean identity , long notFound ) { } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( long h ) { } private int hash3 ( long h ) { } public String toString ( ) { } public LongMap . Entries < V > entries ( ) { } public LongMap . Values < V > values ( ) { } public LongMap . Keys keys ( ) { } public static class Entry < V > { public long key ; public V value ; public String toString ( ) { } } private static class MapIterator < V > { static final int INDEX_ILLEGAL = - 2 ; static final int INDEX_ZERO = - 1 ; public boolean hasNext ; final LongMap < V > map ; int nextIndex ; int currentIndex ; boolean valid = true ; public MapIterator ( LongMap < V > map ) { } public void reset ( ) { } void findNextIndex ( ) { } public void remove ( ) { if ( ( ( currentIndex ) == ( LongMap . MapIterator . INDEX_ZERO ) ) && ( map . hasZeroValue ) ) { map . zeroValue = null ; map . hasZeroValue = false ; } else if ( ( currentIndex ) < 0 ) { throw new IllegalStateException ( "next<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>called<seq2seq4repair_space>before<seq2seq4repair_space>remove." ) ; } else if ( ( currentIndex ) >= ( map . capacity ) ) { map . removeStashIndex ( currentIndex ) ; <START_BUG> nextIndex = ( currentIndex ) - 1 ; <END_BUG> findNextIndex ( ) ; } else { map . keyTable [ currentIndex ] = LongMap . EMPTY ; map . valueTable [ currentIndex ] = null ; } currentIndex = LongMap . MapIterator . INDEX_ILLEGAL ; ( map . size ) -- ; } } public static class Entries < V > extends LongMap . MapIterator < V > implements Iterable < LongMap . Entry < V > > , Iterator < LongMap . Entry < V > > { private LongMap . Entry < V > entry = new LongMap . Entry ( ) ; public Entries ( LongMap map ) { } public LongMap . Entry < V > next ( ) { } public boolean hasNext ( ) { } public Iterator < LongMap . Entry < V > > iterator ( ) { } } public static class Values < V > extends LongMap . MapIterator < V > implements Iterable < V > , Iterator < V > { public Values ( LongMap < V > map ) { } public boolean hasNext ( ) { } public V next ( ) { } public Iterator < V > iterator ( ) { } public Array < V > toArray ( ) { } } public static class Keys extends LongMap . MapIterator { public Keys ( LongMap map ) { } public long next ( ) { } public LongArray toArray ( ) { } } }<BUG2FIX>nextIndex = currentIndex ;
public class RestPercolateAction extends BaseRestHandler { @ Inject public RestPercolateAction ( Settings settings , Client client , RestController controller ) { } void parseDocPercolate ( PercolateRequest percolateRequest , RestRequest restRequest , RestChannel restChannel ) { } void parseExistingDocPercolate ( PercolateRequest percolateRequest , RestRequest restRequest , RestChannel restChannel ) { String index = restRequest . param ( "index" ) ; String type = restRequest . param ( "type" ) ; percolateRequest . indices ( Strings . splitStringByCommaToArray ( restRequest . param ( "percolate_index" , index ) ) ) ; percolateRequest . documentType ( restRequest . param ( "percolate_type" , type ) ) ; GetRequest getRequest = new GetRequest ( index , type , restRequest . param ( "id" ) ) ; getRequest . routing ( restRequest . param ( "routing" ) ) ; getRequest . preference ( restRequest . param ( "preference" ) ) ; getRequest . refresh ( restRequest . paramAsBoolean ( "refresh" , getRequest . refresh ( ) ) ) ; <START_BUG> getRequest . realtime ( restRequest . paramAsBooleanOptional ( "realtime" , null ) ) ; <END_BUG> getRequest . version ( RestActions . parseVersion ( restRequest ) ) ; getRequest . versionType ( VersionType . fromString ( restRequest . param ( "version_type" ) , getRequest . versionType ( ) ) ) ; percolateRequest . getRequest ( getRequest ) ; percolateRequest . routing ( restRequest . param ( "percolate_routing" ) ) ; percolateRequest . preference ( restRequest . param ( "percolate_preference" ) ) ; percolateRequest . source ( restRequest . content ( ) , restRequest . contentUnsafe ( ) ) ; percolateRequest . indicesOptions ( IndicesOptions . fromRequest ( restRequest , percolateRequest . indicesOptions ( ) ) ) ; executePercolate ( percolateRequest , restRequest , restChannel ) ; } void executePercolate ( final PercolateRequest percolateRequest , final RestRequest restRequest , final RestChannel restChannel ) { } @ Override public void handleRequest ( RestRequest restRequest , RestChannel restChannel ) { } final class RestCountPercolateDocHandler implements RestHandler { @ Override public void handleRequest ( RestRequest restRequest , RestChannel restChannel ) { } } final class RestPercolateExistingDocHandler implements RestHandler { @ Override public void handleRequest ( RestRequest restRequest , RestChannel restChannel ) { } } final class RestCountPercolateExistingDocHandler implements RestHandler { @ Override public void handleRequest ( RestRequest restRequest , RestChannel restChannel ) { } } }<BUG2FIX>getRequest . realtime ( restRequest . paramAsBoolean ( "realtime" , null ) ) ;
public class TermsFloatFacetCollector extends AbstractFacetCollector { private final FieldDataCache fieldDataCache ; private final String indexFieldName ; private final ComparatorType comparatorType ; private final int size ; private final int numberOfShards ; private final FieldDataType fieldDataType ; private FloatFieldData fieldData ; private final TermsFloatFacetCollector . StaticAggregatorValueProc aggregator ; private final SearchScript script ; public TermsFloatFacetCollector ( String facetName , String fieldName , int size , TermsFacet . ComparatorType comparatorType , boolean allTerms , SearchContext context , ImmutableSet < BytesRef > excluded , String scriptLang , String script , Map < String , Object > params ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override protected void doSetNextReader ( AtomicReaderContext context ) throws IOException { fieldData = ( ( FloatFieldData ) ( fieldDataCache . cache ( fieldDataType , context . reader ( ) , indexFieldName ) ) ) ; if ( ( script ) != null ) { <START_BUG> script . setNextReader ( context . reader ( ) ) ; <END_BUG> } } @ Override protected void doCollect ( int doc ) throws IOException { } @ Override public Facet facet ( ) { } public static class AggregatorValueProc extends TermsFloatFacetCollector . StaticAggregatorValueProc { private final SearchScript script ; private final TFloatHashSet excluded ; public AggregatorValueProc ( TFloatIntHashMap facets , Set < BytesRef > excluded , SearchScript script ) { } @ Override public void onValue ( int docId , float value ) { } } public static class StaticAggregatorValueProc implements FloatFieldData . ValueInDocProc , FloatFieldData . ValueProc { private final TFloatIntHashMap facets ; private int missing ; private int total ; public StaticAggregatorValueProc ( TFloatIntHashMap facets ) { } @ Override public void onValue ( float value ) { } @ Override public void onValue ( int docId , float value ) { } @ Override public void onMissing ( int docId ) { } public final TFloatIntHashMap facets ( ) { } public final int missing ( ) { } public final int total ( ) { } } }<BUG2FIX>script . setNextReader ( context ) ;
final class LwjglInput implements Input { class KeyEvent { static final int KEY_DOWN = 0 ; static final int KEY_UP = 1 ; static final int KEY_TYPED = 2 ; long timeStamp ; int type ; int keyCode ; char keyChar ; } class TouchEvent { static final int TOUCH_DOWN = 0 ; static final int TOUCH_UP = 1 ; static final int TOUCH_DRAGGED = 2 ; static final int TOUCH_SCROLLED = 3 ; static final int TOUCH_MOVED = 4 ; long timeStamp ; int type ; int x ; int y ; int scrollAmount ; int button ; int pointer ; } Pool < LwjglInput . KeyEvent > usedKeyEvents = new Pool < LwjglInput . KeyEvent > ( 16 , 1000 ) { protected LwjglInput . KeyEvent newObject ( ) { } } ; Pool < LwjglInput . TouchEvent > usedTouchEvents = new Pool < LwjglInput . TouchEvent > ( 16 , 1000 ) { protected LwjglInput . TouchEvent newObject ( ) { } } ; List < LwjglInput . KeyEvent > keyEvents = new ArrayList < LwjglInput . KeyEvent > ( ) ; List < LwjglInput . TouchEvent > touchEvents = new ArrayList < LwjglInput . TouchEvent > ( ) ; boolean mousePressed = false ; int mouseX ; int mouseY ; int deltaX ; int deltaY ; int pressedKeys = 0 ; boolean justTouched = false ; Set < Integer > pressedButtons = new HashSet < Integer > ( ) ; InputProcessor processor ; char lastKeyCharPressed ; float keyRepeatTimer ; long currentEventTimeStamp ; public LwjglInput ( ) { } public float getAccelerometerX ( ) { } public float getAccelerometerY ( ) { } public float getAccelerometerZ ( ) { } public void getTextInput ( final TextInputListener listener , final String title , final String text ) { } public int getX ( ) { } public int getY ( ) { <START_BUG> return ( ( graphics . getHeight ( ) ) - 1 ) - ( Mouse . getY ( ) ) ; <END_BUG> } public boolean isAccelerometerAvailable ( ) { } public boolean isKeyPressed ( int key ) { } public boolean isTouched ( ) { } public int getX ( int pointer ) { } public int getY ( int pointer ) { } public boolean isTouched ( int pointer ) { } public boolean supportsMultitouch ( ) { } @ Override public void setOnscreenKeyboardVisible ( boolean visible ) { } @ Override public void setCatchBackKey ( boolean catchBack ) { } void processEvents ( ) { } public static int getGdxKeyCode ( int lwjglKeyCode ) { } public static int getLwjglKeyCode ( int gdxKeyCode ) { } public void update ( ) { } private int toGdxButton ( int button ) { } void updateMouse ( ) { } void updateKeyboard ( ) { } @ Override public void setInputProcessor ( InputProcessor processor ) { } @ Override public InputProcessor getInputProcessor ( ) { } @ Override public void vibrate ( int milliseconds ) { } @ Override public boolean justTouched ( ) { } private int toLwjglButton ( int button ) { } @ Override public boolean isButtonPressed ( int button ) { } @ Override public void vibrate ( long [ ] pattern , int repeat ) { } @ Override public void cancelVibrate ( ) { } @ Override public float getAzimuth ( ) { } @ Override public float getPitch ( ) { } @ Override public float getRoll ( ) { } @ Override public boolean isPeripheralAvailable ( Peripheral peripheral ) { } @ Override public int getRotation ( ) { } @ Override public Orientation getNativeOrientation ( ) { } @ Override public void setCursorCatched ( boolean catched ) { } @ Override public boolean isCursorCatched ( ) { } @ Override public int getDeltaX ( ) { } @ Override public int getDeltaX ( int pointer ) { } @ Override public int getDeltaY ( ) { } @ Override public int getDeltaY ( int pointer ) { } @ Override public void setCursorPosition ( int x , int y ) { } @ Override public void setCatchMenuKey ( boolean catchMenu ) { } @ Override public long getCurrentEventTime ( ) { } @ Override public void getRotationMatrix ( float [ ] matrix ) { } }<BUG2FIX>return ( graphics . getHeight ( ) ) - ( Mouse . getY ( ) ) ;
public class CreateGistActivity extends RoboSherlockFragmentActivity { @ InjectView ( id . et_gist_description ) private EditText descriptionText ; @ InjectView ( id . et_gist_name ) private EditText nameText ; @ InjectView ( id . et_gist_content ) private EditText contentText ; @ InjectView ( id . cb_public ) private CheckBox publicCheckBox ; @ Override protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; setContentView ( gist_create ) ; setTitle ( new_gist ) ; String text = getIntent ( ) . getStringExtra ( Intent . EXTRA_TEXT ) ; <START_BUG> if ( TextUtils . isEmpty ( text ) ) <END_BUG> contentText . setText ( text ) ; contentText . addTextChangedListener ( new TextWatcherAdapter ( ) { @ Override public void afterTextChanged ( Editable s ) { invalidateOptionsMenu ( ) ; } } ) ; } @ Override public boolean onCreateOptionsMenu ( Menu options ) { } @ Override public boolean onPrepareOptionsMenu ( Menu menu ) { } @ Override public boolean onOptionsItemSelected ( MenuItem item ) { } private void createGist ( ) { } }<BUG2FIX>if ( ! ( TextUtils . isEmpty ( text ) ) )
public class BitmapFontCache { private final BitmapFont font ; private float [ ] [ ] vertexData ; private int [ ] idx ; private int [ ] tmpGlyphCount ; private float x ; private float y ; private float color = WHITE . toFloatBits ( ) ; private final Color tempColor = new Color ( 1 , 1 , 1 , 1 ) ; private final TextBounds textBounds = new TextBounds ( ) ; private boolean integer = true ; private int glyphCount = 0 ; private IntArray [ ] glyphIndices ; public BitmapFontCache ( BitmapFont font ) { } public BitmapFontCache ( BitmapFont font , boolean integer ) { } public void setPosition ( float x , float y ) { } public void translate ( float xAmount , float yAmount ) { } public void setColors ( float color ) { } public void setColors ( Color tint ) { } public void setColors ( float r , float g , float b , float a ) { } public void setColors ( Color tint , int start , int end ) { } public void setColor ( Color tint ) { } public void setColor ( float r , float g , float b , float a ) { } public void setColor ( float color ) { } public Color getColor ( ) { } public void draw ( Batch spriteBatch ) { TextureRegion [ ] regions = font . getRegions ( ) ; for ( int j = 0 , n = vertexData . length ; j < n ; j ++ ) { <START_BUG> if ( ( idx [ j ] ) > 0 ) { <END_BUG> float [ ] vertices = vertexData [ j ] ; spriteBatch . draw ( regions [ j ] . getTexture ( ) , vertices , 0 , idx [ j ] ) ; } } } public void draw ( Batch spriteBatch , int start , int end ) { } public void draw ( Batch spriteBatch , float alphaModulation ) { } public void clear ( ) { } private void requireSequence ( CharSequence seq , int start , int end ) { } private void require ( int page , int glyphCount ) { } private float addToCache ( CharSequence str , float x , float y , int start , int end ) { } private void addGlyph ( Glyph glyph , float x , float y , float width , float height ) { } public TextBounds setText ( CharSequence str , float x , float y ) { } public TextBounds setText ( CharSequence str , float x , float y , int start , int end ) { } public TextBounds addText ( CharSequence str , float x , float y ) { } public TextBounds addText ( CharSequence str , float x , float y , int start , int end ) { } public TextBounds setMultiLineText ( CharSequence str , float x , float y ) { } public TextBounds setMultiLineText ( CharSequence str , float x , float y , float alignmentWidth , HAlignment alignment ) { } public TextBounds addMultiLineText ( CharSequence str , float x , float y ) { } public TextBounds addMultiLineText ( CharSequence str , float x , float y , float alignmentWidth , HAlignment alignment ) { } public TextBounds setWrappedText ( CharSequence str , float x , float y , float wrapWidth ) { } public TextBounds setWrappedText ( CharSequence str , float x , float y , float wrapWidth , HAlignment alignment ) { } public TextBounds addWrappedText ( CharSequence str , float x , float y , float wrapWidth ) { } public TextBounds addWrappedText ( CharSequence str , float x , float y , float wrapWidth , HAlignment alignment ) { } public TextBounds getBounds ( ) { } public float getX ( ) { } public float getY ( ) { } public BitmapFont getFont ( ) { } public void setUseIntegerPositions ( boolean use ) { } public boolean usesIntegerPositions ( ) { } public float [ ] getVertices ( ) { } public float [ ] getVertices ( int page ) { } }<BUG2FIX>if ( ( idx [ j ] ) >= 0 ) {
public class SimpleMapperTests { @ Test public void testSimpleMapper ( ) throws Exception { DocumentMapperParser mapperParser = MapperTests . newParser ( ) ; <START_BUG> DocumentMapper docMapper = doc ( "test" , rootObject ( "person" ) . add ( object ( "name" ) . add ( stringField ( "first" ) . store ( YES ) . index ( Field . Index . NO ) ) ) ) . sourceField ( source ( ) ) . build ( mapperParser ) ; <END_BUG> byte [ ] json = copyToBytesFromClasspath ( "/org/elasticsearch/index/mapper/simple/test1.json" ) ; Document doc = docMapper . parse ( "person" , "1" , json ) . rootDoc ( ) ; assertThat ( ( ( double ) ( doc . getBoost ( ) ) ) , closeTo ( 3.7 , 0.01 ) ) ; assertThat ( doc . get ( docMapper . mappers ( ) . name ( "first" ) . mapper ( ) . names ( ) . indexName ( ) ) , equalTo ( "shay" ) ) ; assertThat ( docMapper . mappers ( ) . name ( "first" ) . mapper ( ) . names ( ) . fullName ( ) , equalTo ( "name.first" ) ) ; doc = docMapper . parse ( json ) . rootDoc ( ) ; } @ Test public void testParseToJsonAndParse ( ) throws Exception { } @ Test public void testSimpleParser ( ) throws Exception { } @ Test public void testSimpleParserNoTypeNoId ( ) throws Exception { } @ Test public void testAttributes ( ) throws Exception { } }<BUG2FIX>DocumentMapper docMapper = doc ( "test" , rootObject ( "person" ) . add ( object ( "name" ) . add ( stringField ( "first" ) . store ( YES ) . index ( Field . Index . NO ) ) ) ) . build ( mapperParser ) ;
public class IntSet { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; private static final int EMPTY = 0 ; public int size ; int [ ] keyTable ; int capacity ; int stashSize ; boolean hasZeroValue ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private IntSet . IntSetIterator iterator1 ; private IntSet . IntSetIterator iterator2 ; public IntSet ( ) { } public IntSet ( int initialCapacity ) { } public IntSet ( int initialCapacity , float loadFactor ) { } public IntSet ( IntSet map ) { } public boolean add ( int key ) { } public void addAll ( IntArray array ) { } public void addAll ( IntArray array , int offset , int length ) { } public void addAll ( int ... array ) { } public void addAll ( int [ ] array , int offset , int length ) { } public void addAll ( IntSet set ) { } private void addResize ( int key ) { } private void push ( int insertKey , int index1 , int key1 , int index2 , int key2 , int index3 , int key3 ) { } private void addStash ( int key ) { } public boolean remove ( int key ) { } boolean removeStash ( int key ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean contains ( int key ) { } private boolean containsKeyStash ( int key ) { } public int first ( ) { } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( int h ) { } private int hash3 ( int h ) { } public String toString ( ) { } public IntSet . IntSetIterator iterator ( ) { } public static IntSet with ( int ... array ) { } public static class Entry < V > { public int key ; public V value ; public String toString ( ) { } } public static class IntSetIterator { static final int INDEX_ILLEGAL = - 2 ; static final int INDEX_ZERO = - 1 ; public boolean hasNext ; final IntSet set ; int nextIndex ; int currentIndex ; boolean valid = true ; public IntSetIterator ( IntSet set ) { } public void reset ( ) { } void findNextIndex ( ) { } public void remove ( ) { if ( ( ( currentIndex ) == ( IntSet . IntSetIterator . INDEX_ZERO ) ) && ( set . hasZeroValue ) ) { set . hasZeroValue = false ; } else if ( ( currentIndex ) < 0 ) { throw new IllegalStateException ( "next<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>called<seq2seq4repair_space>before<seq2seq4repair_space>remove." ) ; } else if ( ( currentIndex ) >= ( set . capacity ) ) { set . removeStashIndex ( currentIndex ) ; <START_BUG> nextIndex = currentIndex ; <END_BUG> findNextIndex ( ) ; } else { set . keyTable [ currentIndex ] = IntSet . EMPTY ; } currentIndex = IntSet . IntSetIterator . INDEX_ILLEGAL ; ( set . size ) -- ; } public int next ( ) { } public IntArray toArray ( ) { } } }<BUG2FIX>nextIndex = ( currentIndex ) - 1 ;
public class IndicesClusterStateService extends AbstractLifecycleComponent < IndicesClusterStateService > implements ClusterStateListener { private final IndicesService indicesService ; private final ClusterService clusterService ; private final ThreadPool threadPool ; private final ShardStateAction shardStateAction ; private final NodeIndexCreatedAction nodeIndexCreatedAction ; private final NodeIndexDeletedAction nodeIndexDeletedAction ; private final NodeMappingCreatedAction nodeMappingCreatedAction ; @ Inject public IndicesClusterStateService ( Settings settings , IndicesService indicesService , ClusterService clusterService , ThreadPool threadPool , ShardStateAction shardStateAction , NodeIndexCreatedAction nodeIndexCreatedAction , NodeIndexDeletedAction nodeIndexDeletedAction , NodeMappingCreatedAction nodeMappingCreatedAction ) { } @ Override protected void doStart ( ) throws ElasticSearchException { } @ Override protected void doStop ( ) throws ElasticSearchException { } @ Override protected void doClose ( ) throws ElasticSearchException { } @ Override public void clusterChanged ( final ClusterChangedEvent event ) { } private void applyDeletedIndices ( final ClusterChangedEvent event ) { } private void applyDeletedShards ( final ClusterChangedEvent event ) { } private void applyNewIndices ( final ClusterChangedEvent event ) { } private void applyMappings ( ClusterChangedEvent event ) { } private void applyNewOrUpdatedShards ( final ClusterChangedEvent event ) throws ElasticSearchException { } private void applyInitializingShard ( final RoutingTable routingTable , final DiscoveryNodes nodes , final ShardRouting shardRouting ) throws ElasticSearchException { final IndexService indexService = indicesService . indexServiceSafe ( shardRouting . index ( ) ) ; final int shardId = shardRouting . id ( ) ; if ( indexService . hasShard ( shardId ) ) { IndexShard indexShard = indexService . shardSafe ( shardId ) ; if ( ( indexShard . state ( ) ) == ( IndexShardState . STARTED ) ) { if ( logger . isTraceEnabled ( ) ) { logger . trace ( "[{}][{}]<seq2seq4repair_space>master<seq2seq4repair_space>[{}]<seq2seq4repair_space>marked<seq2seq4repair_space>shard<seq2seq4repair_space>as<seq2seq4repair_space>initializing,<seq2seq4repair_space>but<seq2seq4repair_space>shard<seq2seq4repair_space>already<seq2seq4repair_space>created,<seq2seq4repair_space>mark<seq2seq4repair_space>shard<seq2seq4repair_space>as<seq2seq4repair_space>started" ) ; } shardStateAction . shardStarted ( shardRouting , ( ( "master<seq2seq4repair_space>" + ( nodes . masterNode ( ) ) ) + "<seq2seq4repair_space>marked<seq2seq4repair_space>shard<seq2seq4repair_space>as<seq2seq4repair_space>initializing,<seq2seq4repair_space>but<seq2seq4repair_space>shard<seq2seq4repair_space>already<seq2seq4repair_space>started,<seq2seq4repair_space>mark<seq2seq4repair_space>shard<seq2seq4repair_space>as<seq2seq4repair_space>started" ) ) ; return ; } else { if ( indexShard . ignoreRecoveryAttempt ( ) ) { return ; } } } if ( ! ( indexService . hasShard ( shardId ) ) ) { try { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "[{}][{}]<seq2seq4repair_space>creating<seq2seq4repair_space>shard" , shardRouting . index ( ) , shardId ) ; } InternalIndexShard indexShard = ( ( InternalIndexShard ) ( indexService . createShard ( shardId ) ) ) ; indexShard . routingEntry ( shardRouting ) ; } catch ( IndexShardAlreadyExistsException e ) { } catch ( Exception e ) { logger . warn ( "[{}][{}]<seq2seq4repair_space>failed<seq2seq4repair_space>to<seq2seq4repair_space>create<seq2seq4repair_space>shard" , e , shardRouting . index ( ) , shardRouting . id ( ) ) ; try { indexService . cleanShard ( shardId ) ; } catch ( IndexShardMissingException e1 ) { } catch ( Exception e1 ) { logger . warn ( "[{}][{}]<seq2seq4repair_space>failed<seq2seq4repair_space>to<seq2seq4repair_space>delete<seq2seq4repair_space>shard<seq2seq4repair_space>after<seq2seq4repair_space>failed<seq2seq4repair_space>creation" , e1 , shardRouting . index ( ) , shardRouting . id ( ) ) ; } shardStateAction . shardFailed ( shardRouting , ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>create<seq2seq4repair_space>shard,<seq2seq4repair_space>message<seq2seq4repair_space>[" + ( detailedMessage ( e ) ) ) + "]" ) ) ; return ; } } final InternalIndexShard indexShard = ( ( InternalIndexShard ) ( indexService . shardSafe ( shardId ) ) ) ; if ( indexShard . ignoreRecoveryAttempt ( ) ) { return ; } threadPool . execute ( new Runnable ( ) { @ Override public void run ( ) { if ( indexShard . ignoreRecoveryAttempt ( ) ) { return ; } try { RecoveryAction recoveryAction = indexService . shardInjector ( shardId ) . getInstance ( RecoveryAction . class ) ; if ( ! ( shardRouting . primary ( ) ) ) { IndexShardRoutingTable shardRoutingTable = routingTable . index ( shardRouting . index ( ) ) . shard ( shardRouting . id ( ) ) ; for ( ShardRouting entry : shardRoutingTable ) { if ( ( entry . primary ( ) ) && ( entry . started ( ) ) ) { DiscoveryNode node = nodes . get ( entry . currentNodeId ( ) ) ; try { recoveryAction . startRecovery ( nodes . localNode ( ) , node , false ) ; shardStateAction . shardStarted ( shardRouting , ( ( "after<seq2seq4repair_space>recovery<seq2seq4repair_space>(backup)<seq2seq4repair_space>from<seq2seq4repair_space>node<seq2seq4repair_space>[" + node ) + "]" ) ) ; } catch ( IgnoreRecoveryException e ) { break ; } break ; } } } else { if ( ( shardRouting . relocatingNodeId ( ) ) == null ) { IndexShardGatewayService shardGatewayService = indexService . shardInjector ( shardId ) . getInstance ( IndexShardGatewayService . class ) ; try { shardGatewayService . recover ( ) ; shardStateAction . shardStarted ( shardRouting , "after<seq2seq4repair_space>recovery<seq2seq4repair_space>from<seq2seq4repair_space>gateway" ) ; } catch ( IgnoreGatewayRecoveryException e ) { } } else { DiscoveryNode node = nodes . get ( shardRouting . relocatingNodeId ( ) ) ; try { recoveryAction . startRecovery ( nodes . localNode ( ) , node , true ) ; shardStateAction . shardStarted ( shardRouting , ( ( "after<seq2seq4repair_space>recovery<seq2seq4repair_space>(primary)<seq2seq4repair_space>from<seq2seq4repair_space>node<seq2seq4repair_space>[" + node ) + "]" ) ) ; } catch ( IgnoreRecoveryException e ) { } } } } catch ( Exception e ) { logger . warn ( "[{}][{}]<seq2seq4repair_space>failed<seq2seq4repair_space>to<seq2seq4repair_space>start<seq2seq4repair_space>shard" , e , indexService . index ( ) . name ( ) , shardRouting . id ( ) ) ; if ( indexService . hasShard ( shardId ) ) { try { indexService . cleanShard ( shardId ) ; } catch ( Exception e1 ) { <START_BUG> logger . warn ( "[{}][{}]<seq2seq4repair_space>failed<seq2seq4repair_space>to<seq2seq4repair_space>delete<seq2seq4repair_space>shard<seq2seq4repair_space>after<seq2seq4repair_space>failed<seq2seq4repair_space>startup" , e , indexService . index ( ) . name ( ) , shardRouting . id ( ) ) ; <END_BUG> } } try { shardStateAction . shardFailed ( shardRouting , ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>start<seq2seq4repair_space>shard,<seq2seq4repair_space>message<seq2seq4repair_space>[" + ( detailedMessage ( e ) ) ) + "]" ) ) ; } catch ( Exception e1 ) { logger . warn ( "[{}][{}]<seq2seq4repair_space>failed<seq2seq4repair_space>to<seq2seq4repair_space>mark<seq2seq4repair_space>shard<seq2seq4repair_space>as<seq2seq4repair_space>failed<seq2seq4repair_space>after<seq2seq4repair_space>a<seq2seq4repair_space>failed<seq2seq4repair_space>start" , e1 , indexService . index ( ) . name ( ) , shardRouting . id ( ) ) ; } } } } ) ; } }<BUG2FIX>logger . warn ( "[{}][{}]<seq2seq4repair_space>failed<seq2seq4repair_space>to<seq2seq4repair_space>delete<seq2seq4repair_space>shard<seq2seq4repair_space>after<seq2seq4repair_space>failed<seq2seq4repair_space>startup" , e1 , indexService . index ( ) . name ( ) , shardRouting . id ( ) ) ;
public LwjglApplication ( ApplicationListener listener , String title , int width , int height , boolean useGL2 ) { } public LwjglApplication ( ApplicationListener listener ) { } public LwjglApplication ( ApplicationListener listener , LwjglApplicationConfiguration config ) { } public LwjglApplication ( ApplicationListener listener , boolean useGL2 , Canvas canvas ) { } public LwjglApplication ( ApplicationListener listener , LwjglApplicationConfiguration config , Canvas canvas ) { } public LwjglApplication ( ApplicationListener listener , LwjglApplicationConfiguration config , LwjglGraphics graphics ) { } private static LwjglApplicationConfiguration createConfig ( String title , int width , int height , boolean useGL2 ) { } private void initialize ( ) { } void mainLoop ( ) { try { graphics . setupDisplay ( ) ; } catch ( LWJGLException e ) { throw new com . badlogic . gdx . utils . GdxRuntimeException ( e ) ; } listener . create ( ) ; listener . resize ( graphics . getWidth ( ) , graphics . getHeight ( ) ) ; graphics . resize = false ; int lastWidth = graphics . getWidth ( ) ; int lastHeight = graphics . getHeight ( ) ; graphics . lastTime = System . nanoTime ( ) ; boolean wasActive = true ; while ( running ) { Display . processMessages ( ) ; if ( Display . isCloseRequested ( ) ) exit ( ) ; boolean isActive = Display . isActive ( ) ; if ( wasActive && ( ! isActive ) ) { wasActive = false ; listener . pause ( ) ; } if ( ( ! wasActive ) && isActive ) { wasActive = true ; listener . resume ( ) ; } boolean shouldRender = false ; if ( ( graphics . canvas ) != null ) { int width = graphics . canvas . getWidth ( ) ; int height = graphics . canvas . getHeight ( ) ; if ( ( lastWidth != width ) || ( lastHeight != height ) ) { lastWidth = width ; lastHeight = height ; gl . glViewport ( 0 , 0 , lastWidth , lastHeight ) ; listener . resize ( lastWidth , lastHeight ) ; shouldRender = true ; } } else { graphics . config . x = Display . getX ( ) ; graphics . config . y = Display . getY ( ) ; if ( ( ( ( graphics . resize ) || ( Display . wasResized ( ) ) ) || ( ( Display . getWidth ( ) ) != ( graphics . config . width ) ) ) || ( ( Display . getHeight ( ) ) != ( graphics . config . height ) ) ) { graphics . resize = false ; gl . glViewport ( 0 , 0 , Display . getWidth ( ) , Display . getHeight ( ) ) ; graphics . config . width = Display . getWidth ( ) ; graphics . config . height = Display . getHeight ( ) ; if ( ( listener ) != null ) listener . resize ( Display . getWidth ( ) , Display . getHeight ( ) ) ; graphics . requestRendering ( ) ; } } synchronized ( runnables ) { executedRunnables . clear ( ) ; executedRunnables . addAll ( runnables ) ; runnables . clear ( ) ; } for ( int i = 0 ; i < ( executedRunnables . size ) ; i ++ ) { shouldRender = true ; executedRunnables . get ( i ) . run ( ) ; } if ( ! ( running ) ) break ; input . update ( ) ; shouldRender |= graphics . shouldRender ( ) ; input . processEvents ( ) ; if ( ( audio ) != null ) audio . update ( ) ; if ( ( ! isActive ) && ( ( graphics . config . backgroundFPS ) == ( - 1 ) ) ) shouldRender = false ; int frameRate = ( isActive ) ? graphics . config . foregroundFPS : graphics . config . backgroundFPS ; if ( shouldRender ) { graphics . updateTime ( ) ; listener . render ( ) ; <START_BUG> Display . update ( ) ; <END_BUG> } else { if ( frameRate == ( - 1 ) ) frameRate = 10 ; if ( frameRate == 0 ) frameRate = graphics . config . backgroundFPS ; if ( frameRate == 0 ) frameRate = 30 ; } if ( frameRate > 0 ) Display . sync ( frameRate ) ; } Array < LifecycleListener > listeners = lifecycleListeners ; synchronized ( listeners ) { for ( LifecycleListener listener : listeners ) { listener . pause ( ) ; listener . dispose ( ) ; } } listener . pause ( ) ; listener . dispose ( ) ; Display . destroy ( ) ; if ( ( audio ) != null ) audio . dispose ( ) ; if ( graphics . config . forceExit ) System . exit ( ( - 1 ) ) ; } @ Override public ApplicationListener getApplicationListener ( ) { } @ Override public Audio getAudio ( ) { } @ Override public Files getFiles ( ) { } @ Override public LwjglGraphics getGraphics ( ) { } @ Override public Input getInput ( ) { } @ Override public Net getNet ( ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } public void stop ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } Map < String , Preferences > preferences = new HashMap < String , Preferences > ( ) ; @ Override public Preferences getPreferences ( String name ) { } @ Override public Clipboard getClipboard ( ) { } @ Override public void postRunnable ( Runnable runnable ) { }<BUG2FIX>Display . update ( false ) ;
public class UITest extends GdxTest { Object [ ] listEntries = new Object [ ] { "This<seq2seq4repair_space>is<seq2seq4repair_space>a<seq2seq4repair_space>list<seq2seq4repair_space>entry1" , "And<seq2seq4repair_space>another<seq2seq4repair_space>one1" , "The<seq2seq4repair_space>meaning<seq2seq4repair_space>of<seq2seq4repair_space>life1" , "Is<seq2seq4repair_space>hard<seq2seq4repair_space>to<seq2seq4repair_space>come<seq2seq4repair_space>by1" , "This<seq2seq4repair_space>is<seq2seq4repair_space>a<seq2seq4repair_space>list<seq2seq4repair_space>entry2" , "And<seq2seq4repair_space>another<seq2seq4repair_space>one2" , "The<seq2seq4repair_space>meaning<seq2seq4repair_space>of<seq2seq4repair_space>life2" , "Is<seq2seq4repair_space>hard<seq2seq4repair_space>to<seq2seq4repair_space>come<seq2seq4repair_space>by2" , "This<seq2seq4repair_space>is<seq2seq4repair_space>a<seq2seq4repair_space>list<seq2seq4repair_space>entry3" , "And<seq2seq4repair_space>another<seq2seq4repair_space>one3" , "The<seq2seq4repair_space>meaning<seq2seq4repair_space>of<seq2seq4repair_space>life3" , "Is<seq2seq4repair_space>hard<seq2seq4repair_space>to<seq2seq4repair_space>come<seq2seq4repair_space>by3" , "This<seq2seq4repair_space>is<seq2seq4repair_space>a<seq2seq4repair_space>list<seq2seq4repair_space>entry4" , "And<seq2seq4repair_space>another<seq2seq4repair_space>one4" , "The<seq2seq4repair_space>meaning<seq2seq4repair_space>of<seq2seq4repair_space>life4" , "Is<seq2seq4repair_space>hard<seq2seq4repair_space>to<seq2seq4repair_space>come<seq2seq4repair_space>by4" , "This<seq2seq4repair_space>is<seq2seq4repair_space>a<seq2seq4repair_space>list<seq2seq4repair_space>entry5" , "And<seq2seq4repair_space>another<seq2seq4repair_space>one5" , "The<seq2seq4repair_space>meaning<seq2seq4repair_space>of<seq2seq4repair_space>life5" , "Is<seq2seq4repair_space>hard<seq2seq4repair_space>to<seq2seq4repair_space>come<seq2seq4repair_space>by5" } ; Skin skin ; Stage stage ; Texture texture1 ; Texture texture2 ; Label fpsLabel ; @ Override public void create ( ) { } @ Override public void render ( ) { } @ Override public void resize ( int width , int height ) { <START_BUG> stage . getViewport ( ) . update ( width , height ) ; <END_BUG> } @ Override public void dispose ( ) { } }<BUG2FIX>stage . getViewport ( ) . update ( width , height , true ) ;
public class RestGetIndicesAliasesAction extends BaseRestHandler { @ Inject public RestGetIndicesAliasesAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { final String [ ] indices = splitIndices ( request . param ( "index" ) ) ; ClusterStateRequest clusterStateRequest = Requests . clusterStateRequest ( ) . filterRoutingTable ( true ) . filterNodes ( true ) . filteredIndices ( indices ) ; clusterStateRequest . listenerThreaded ( false ) ; client . admin ( ) . cluster ( ) . state ( clusterStateRequest , new org . elasticsearch . action . ActionListener < ClusterStateResponse > ( ) { @ Override public void onResponse ( ClusterStateResponse response ) { try { MetaData metaData = response . getState ( ) . metaData ( ) ; XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; for ( IndexMetaData indexMetaData : metaData ) { builder . startObject ( indexMetaData . index ( ) , NONE ) ; builder . startObject ( "aliases" ) ; for ( AliasMetaData alias : indexMetaData . aliases ( ) . values ( ) ) { Builder . toXContent ( alias , builder , EMPTY_PARAMS ) ; } builder . endObject ( ) ; builder . endObject ( ) ; } builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class JglfwApplication implements Application { JglfwGraphics graphics ; JglfwFiles files ; JglfwInput input ; JglfwNet net ; final ApplicationListener listener ; private final Array < Runnable > runnables = new Array ( ) ; private final Array < Runnable > executedRunnables = new Array ( ) ; private final Array < LifecycleListener > lifecycleListeners = new Array ( ) ; private final Map < String , Preferences > preferences = new HashMap ( ) ; private final JglfwClipboard clipboard = new JglfwClipboard ( ) ; private final GlfwCallbacks callbacks = new GlfwCallbacks ( ) ; private int logLevel = LOG_INFO ; volatile boolean running = true ; boolean isPaused ; private boolean forceExit ; private boolean runOnEDT ; private int foregroundFPS ; private int backgroundFPS ; private int hiddenFPS ; public JglfwApplication ( ApplicationListener listener ) { } public JglfwApplication ( ApplicationListener listener , String title , int width , int height , boolean useGL2 ) { } private static JglfwApplicationConfiguration createConfig ( String title , int width , int height , boolean useGL2 ) { } public JglfwApplication ( final ApplicationListener listener , final JglfwApplicationConfiguration config ) { } protected void exception ( Throwable ex ) { } void initialize ( JglfwApplicationConfiguration config ) { } protected void start ( ) { } protected void frame ( ) { } public boolean executeRunnables ( ) { } void sleep ( int millis ) { } void render ( long time ) { } protected void end ( ) { } public ApplicationListener getApplicationListener ( ) { } public JglfwGraphics getGraphics ( ) { } public Audio getAudio ( ) { } public JglfwInput getInput ( ) { } public JglfwFiles getFiles ( ) { } public JglfwNet getNet ( ) { } public ApplicationType getType ( ) { } public int getVersion ( ) { } public long getJavaHeap ( ) { } public long getNativeHeap ( ) { } public Preferences getPreferences ( String name ) { } public Clipboard getClipboard ( ) { } public void postRunnable ( Runnable runnable ) { } public boolean isPaused ( ) { } public void setForegroundFPS ( int foregroundFPS ) { } public void setBackgroundFPS ( int backgroundFPS ) { } public void setHiddenFPS ( int hiddenFPS ) { } protected boolean shouldExit ( ) { } public void exit ( ) { } public void setLogLevel ( int logLevel ) { } @ Override public int getLogLevel ( ) { } public void debug ( String tag , String message ) { } public void debug ( String tag , String message , Throwable exception ) { } public void log ( String tag , String message ) { } <START_BUG> public void log ( String tag , String message , Exception exception ) { <END_BUG> if ( ( logLevel ) >= ( LOG_INFO ) ) { System . out . println ( ( ( tag + ":<seq2seq4repair_space>" ) + message ) ) ; exception . printStackTrace ( System . out ) ; } } public void error ( String tag , String message ) { } public void error ( String tag , String message , Throwable exception ) { } public void addLifecycleListener ( LifecycleListener listener ) { } public void removeLifecycleListener ( LifecycleListener listener ) { } public GlfwCallbacks getCallbacks ( ) { } }<BUG2FIX>public void log ( String tag , String message , Throwable exception ) {
public class InternalSettingsPerparer { public static Tuple < Settings , Environment > prepareSettings ( Settings pSettings , boolean loadConfigSettings ) { String [ ] ignorePrefixes = new String [ ] { "es.default." , "elasticsearch.default." } ; ImmutableSettings . Builder settingsBuilder = settingsBuilder ( ) . put ( pSettings ) . putProperties ( "elasticsearch.default." , System . getProperties ( ) ) . putProperties ( "es.default." , System . getProperties ( ) ) . putProperties ( "elasticsearch." , System . getProperties ( ) , ignorePrefixes ) . putProperties ( "es." , System . getProperties ( ) , ignorePrefixes ) . replacePropertyPlaceholders ( ) ; Environment environment = new Environment ( settingsBuilder . build ( ) ) ; if ( loadConfigSettings ) { boolean loadFromEnv = true ; if ( ( System . getProperty ( "es.default.config" ) ) != null ) { loadFromEnv = true ; <START_BUG> settingsBuilder . loadFromUrl ( environment . resolveConfig ( System . getProperty ( "es.config" ) ) ) ; <END_BUG> } if ( ( System . getProperty ( "es.config" ) ) != null ) { loadFromEnv = false ; settingsBuilder . loadFromUrl ( environment . resolveConfig ( System . getProperty ( "es.config" ) ) ) ; } if ( ( System . getProperty ( "elasticsearch.config" ) ) != null ) { loadFromEnv = false ; settingsBuilder . loadFromUrl ( environment . resolveConfig ( System . getProperty ( "elasticsearch.config" ) ) ) ; } if ( loadFromEnv ) { try { settingsBuilder . loadFromUrl ( environment . resolveConfig ( "elasticsearch.yml" ) ) ; } catch ( FailedToResolveConfigException e ) { } catch ( NoClassDefFoundError e ) { } try { settingsBuilder . loadFromUrl ( environment . resolveConfig ( "elasticsearch.json" ) ) ; } catch ( FailedToResolveConfigException e ) { } try { settingsBuilder . loadFromUrl ( environment . resolveConfig ( "elasticsearch.properties" ) ) ; } catch ( FailedToResolveConfigException e ) { } } } settingsBuilder . put ( pSettings ) . putProperties ( "elasticsearch." , System . getProperties ( ) , ignorePrefixes ) . putProperties ( "es." , System . getProperties ( ) , ignorePrefixes ) . replacePropertyPlaceholders ( ) ; if ( ( settingsBuilder . get ( "name" ) ) == null ) { String name = System . getProperty ( "name" ) ; if ( ( name == null ) || ( name . isEmpty ( ) ) ) { name = settingsBuilder . get ( "node.name" ) ; if ( ( name == null ) || ( name . isEmpty ( ) ) ) { name = Names . randomNodeName ( environment . resolveConfig ( "names.txt" ) ) ; } } if ( name != null ) { settingsBuilder . put ( "name" , name ) ; } } if ( ( settingsBuilder . get ( SETTING ) ) == null ) { settingsBuilder . put ( SETTING , DEFAULT . value ( ) ) ; } Settings v1 = settingsBuilder . build ( ) ; environment = new Environment ( v1 ) ; settingsBuilder = settingsBuilder ( ) . put ( v1 ) ; settingsBuilder . put ( "path.logs" , cleanPath ( environment . logsFile ( ) . getAbsolutePath ( ) ) ) ; v1 = settingsBuilder . build ( ) ; return new Tuple < Settings , Environment > ( v1 , environment ) ; } }<BUG2FIX>settingsBuilder . loadFromUrl ( environment . resolveConfig ( System . getProperty ( "es.default.config" ) ) ) ;
public class ValueCountParser implements Aggregator . Parser { @ Override public String type ( ) { } @ Override public AggregatorFactory parse ( String aggregationName , XContentParser parser , SearchContext context ) throws IOException { <START_BUG> ValuesSourceConfig < BytesValuesSource > config = new ValuesSourceConfig < BytesValuesSource > ( BytesValuesSource . class ) ; <END_BUG> String field = null ; String script = null ; String scriptLang = null ; Map < String , Object > scriptParams = null ; boolean assumeUnique = false ; XContentParser . Token token ; String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . VALUE_STRING ) ) { if ( "field" . equals ( currentFieldName ) ) { field = parser . text ( ) ; } else if ( "script" . equals ( currentFieldName ) ) { script = parser . text ( ) ; } else if ( "lang" . equals ( currentFieldName ) ) { scriptLang = parser . text ( ) ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( ( ( "Unknown<seq2seq4repair_space>key<seq2seq4repair_space>for<seq2seq4repair_space>a<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>[" ) + aggregationName ) + "]:<seq2seq4repair_space>[" ) + currentFieldName ) + "]." ) ) ; } } else if ( token == ( Token . VALUE_BOOLEAN ) ) { if ( ( "script_values_unique" . equals ( currentFieldName ) ) || ( "scriptValuesUnique" . equals ( currentFieldName ) ) ) { assumeUnique = parser . booleanValue ( ) ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( ( ( "Unknown<seq2seq4repair_space>key<seq2seq4repair_space>for<seq2seq4repair_space>a<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>[" ) + aggregationName ) + "]:<seq2seq4repair_space>[" ) + currentFieldName ) + "]." ) ) ; } } else if ( token == ( Token . START_OBJECT ) ) { if ( "params" . equals ( currentFieldName ) ) { scriptParams = parser . map ( ) ; } } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( "Unexpected<seq2seq4repair_space>token<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>[" ) + aggregationName ) + "]." ) ) ; } } if ( script != null ) { config . script ( context . scriptService ( ) . search ( context . lookup ( ) , scriptLang , script , scriptParams ) ) ; } if ( ! assumeUnique ) { config . ensureUnique ( true ) ; } if ( field == null ) { return new ValueCountAggregator . Factory ( aggregationName , config ) ; } FieldMapper < ? > mapper = context . smartNameFieldMapper ( field ) ; if ( mapper == null ) { config . unmapped ( true ) ; return new ValueCountAggregator . Factory ( aggregationName , config ) ; } IndexFieldData < ? > indexFieldData = context . fieldData ( ) . getForField ( mapper ) ; config . fieldContext ( new org . elasticsearch . search . aggregations . support . FieldContext ( field , indexFieldData ) ) ; return new ValueCountAggregator . Factory ( aggregationName , config ) ; } }<BUG2FIX>ValuesSourceConfig < BytesValuesSource > config = new ValuesSourceConfig ( BytesValuesSource . class ) ;
private final Lock flushLock = new ReentrantLock ( ) ; private final InternalEngine . RecoveryCounter onGoingRecoveries = new InternalEngine . RecoveryCounter ( ) ; private final LiveVersionMap versionMap ; private final Object [ ] dirtyLocks ; private final Object refreshMutex = new Object ( ) ; private final InternalEngine . ApplySettings applySettings = new InternalEngine . ApplySettings ( ) ; private volatile boolean failOnMergeFailure ; private Throwable failedEngine = null ; private final Lock failEngineLock = new ReentrantLock ( ) ; private final CopyOnWriteArrayList < FailedEngineListener > failedEngineListeners = new CopyOnWriteArrayList < > ( ) ; private final AtomicLong translogIdGenerator = new AtomicLong ( ) ; private final AtomicBoolean versionMapRefreshPending = new AtomicBoolean ( ) ; private SegmentInfos lastCommittedSegmentInfos ; private InternalEngine . IndexThrottle throttle ; @ Inject public InternalEngine ( ShardId shardId , @ IndexSettings Settings indexSettings , ThreadPool threadPool , IndexSettingsService indexSettingsService , ShardIndexingService indexingService , @ Nullable IndicesWarmer warmer , Store store , SnapshotDeletionPolicy deletionPolicy , Translog translog , MergePolicyProvider mergePolicyProvider , MergeSchedulerProvider mergeScheduler , AnalysisService analysisService , SimilarityService similarityService , CodecService codecService ) throws EngineException { } @ Override public void updateIndexingBufferSize ( ByteSizeValue indexingBufferSize ) { } @ Override public void addFailedEngineListener ( FailedEngineListener listener ) { } @ Override public void start ( ) throws EngineException { } private void readLastCommittedSegmentsInfo ( ) throws IOException { } @ Override public TimeValue defaultRefreshInterval ( ) { } public ByteSizeValue indexingBufferSize ( ) { } @ Override public void enableGcDeletes ( boolean enableGcDeletes ) { } public GetResult get ( Get get ) throws EngineException { } @ Override public void create ( Create create ) throws EngineException { } private void innerCreate ( Create create , IndexWriter writer ) throws IOException { } private void innerCreateNoLock ( Create create , IndexWriter writer , long currentVersion , VersionValue versionValue ) throws IOException { } @ Override public void index ( Index index ) throws EngineException { } private void checkVersionMapRefresh ( ) { } private void innerIndex ( Index index , IndexWriter writer ) throws IOException { } @ Override public void delete ( Delete delete ) throws EngineException { } private void maybePruneDeletedTombstones ( ) { } private void innerDelete ( Delete delete , IndexWriter writer ) throws IOException { } @ Override public void delete ( DeleteByQuery delete ) throws EngineException { } @ Override public final Searcher acquireSearcher ( String source ) throws EngineException { } protected Searcher newSearcher ( String source , IndexSearcher searcher , SearcherManager manager ) { } @ Override public boolean refreshNeeded ( ) { } @ Override public boolean possibleMergeNeeded ( ) { } @ Override public void refresh ( Refresh refresh ) throws EngineException { } @ Override public void flush ( Flush flush ) throws EngineException { } private void ensureOpen ( ) { } private IndexWriter currentIndexWriter ( ) { } private void pruneDeletedTombstones ( ) { } @ Override public void maybeMerge ( ) throws EngineException { } @ Override public void optimize ( Optimize optimize ) throws EngineException { } @ Override public SnapshotIndexCommit snapshotIndex ( ) throws EngineException { } @ Override public void recover ( RecoveryHandler recoveryHandler ) throws EngineException { } private boolean maybeFailEngine ( Throwable t , String source ) { } private Throwable wrapIfClosed ( Throwable t ) { } private static long getReaderRamBytesUsed ( AtomicReaderContext reader ) { } @ Override public SegmentsStats segmentsStats ( ) { } @ Override public List < Segment > segments ( ) { } @ Override public void close ( ) throws ElasticsearchException { } class FailEngineOnMergeFailure implements MergeSchedulerProvider . FailureListener { @ Override public void onFailedMerge ( MergePolicy . MergeException e ) { } } @ Override public void failEngine ( String reason , Throwable failure ) { assert failure != null ; if ( failEngineLock . tryLock ( ) ) { try { if ( Lucene . isCorruptionException ( failure ) ) { try { store . markStoreCorrupted ( ExceptionsHelper . unwrap ( failure , CorruptIndexException . class ) ) ; } catch ( IOException e ) { logger . warn ( "Couldn't<seq2seq4repair_space>marks<seq2seq4repair_space>store<seq2seq4repair_space>corrupted" , e ) ; } } } finally { assert ! ( readLock . assertLockIsHeld ( ) ) : "readLock<seq2seq4repair_space>is<seq2seq4repair_space>held<seq2seq4repair_space>by<seq2seq4repair_space>a<seq2seq4repair_space>thread<seq2seq4repair_space>that<seq2seq4repair_space>tries<seq2seq4repair_space>to<seq2seq4repair_space>fail<seq2seq4repair_space>the<seq2seq4repair_space>engine" ; if ( ( failedEngine ) != null ) { logger . debug ( "tried<seq2seq4repair_space>to<seq2seq4repair_space>fail<seq2seq4repair_space>engine<seq2seq4repair_space>but<seq2seq4repair_space>engine<seq2seq4repair_space>is<seq2seq4repair_space>already<seq2seq4repair_space>failed.<seq2seq4repair_space>ignoring.<seq2seq4repair_space>[{}]" , reason , failure ) ; return ; } try { <START_BUG> logger . warn ( "failed<seq2seq4repair_space>engine<seq2seq4repair_space>[{}]" , reason , failure ) ; <END_BUG> failedEngine = failure ; for ( FailedEngineListener listener : failedEngineListeners ) { listener . onFailedEngine ( shardId , reason , failure ) ; } } finally { close ( ) ; } } } else { logger . debug ( "tried<seq2seq4repair_space>to<seq2seq4repair_space>fail<seq2seq4repair_space>engine<seq2seq4repair_space>but<seq2seq4repair_space>could<seq2seq4repair_space>not<seq2seq4repair_space>acquire<seq2seq4repair_space>lock<seq2seq4repair_space>-<seq2seq4repair_space>engine<seq2seq4repair_space>should<seq2seq4repair_space>be<seq2seq4repair_space>failed<seq2seq4repair_space>by<seq2seq4repair_space>now<seq2seq4repair_space>[{}]" , reason , failure ) ; } } private Object dirtyLock ( BytesRef uid ) { } private Object dirtyLock ( Term uid ) { } private long loadCurrentVersionFromIndex ( Term uid ) throws IOException { } private static boolean isMergedSegment ( AtomicReader reader ) { } private IndexWriter createWriter ( ) throws IOException { } public static final String INDEX_INDEX_CONCURRENCY = "index.index_concurrency" ; public static final String INDEX_COMPOUND_ON_FLUSH = "index.compound_on_flush" ; public static final String INDEX_GC_DELETES = "index.gc_deletes" ; public static final String INDEX_FAIL_ON_MERGE_FAILURE = "index.fail_on_merge_failure" ; public static final String INDEX_FAIL_ON_CORRUPTION = "index.fail_on_corruption" ; class ApplySettings implements IndexSettingsService . Listener { @ Override public void onRefreshSettings ( Settings settings ) { } } private SearcherManager buildSearchManager ( IndexWriter indexWriter ) throws IOException { } class EngineSearcher implements Searcher { private final String source ; private final IndexSearcher searcher ; private final SearcherManager manager ; private final AtomicBoolean released = new AtomicBoolean ( false ) ; private EngineSearcher ( String source , IndexSearcher searcher , SearcherManager manager ) { } @ Override public String source ( ) { } @ Override public IndexReader reader ( ) { } @ Override public IndexSearcher searcher ( ) { } @ Override public void close ( ) throws ElasticsearchException { }<BUG2FIX>logger . warn ( "failed<seq2seq4repair_space>engine<seq2seq4repair_space>[{}]" , failure , reason ) ;
public class IssueUtils { <START_BUG> public static boolean isPullRequest ( Issue issue ) { <END_BUG> return ( ( issue != null ) && ( ( issue . getPullRequest ( ) ) != null ) ) && ( ! ( TextUtils . isEmpty ( issue . getPullRequest ( ) . getHtmlUrl ( ) ) ) ) ; } public static Issue toIssue ( final PullRequest pullRequest ) { } }<BUG2FIX>public static boolean isPullRequest ( final Issue issue ) {
public class ReleaseChannelFutureListener implements ChannelFutureListener { private final Releasable releasable ; public ReleaseChannelFutureListener ( Releasable releasable ) { } @ Override public void operationComplete ( ChannelFuture future ) throws Exception { <START_BUG> releasable . release ( ) ; <END_BUG> } }<BUG2FIX>releasable . close ( ) ;
public class FetchPhase implements SearchPhase { private final SearchHitPhase [ ] hitPhases ; @ Inject public FetchPhase ( HighlightPhase highlightPhase , ScriptFieldsSearchHitPhase scriptFieldsPhase , MatchedFiltersSearchHitPhase matchFiltersPhase , ExplainSearchHitPhase explainPhase , VersionSearchHitPhase versionPhase ) { } @ Override public Map < String , ? extends SearchParseElement > parseElements ( ) { } @ Override public void preProcess ( SearchContext context ) { } public void execute ( SearchContext context ) { ResetFieldSelector fieldSelector ; List < String > extractFieldNames = null ; if ( ( context . hasScriptFields ( ) ) && ( ! ( context . hasFieldNames ( ) ) ) ) { fieldSelector = UidFieldSelector . INSTANCE ; } else if ( ! ( context . hasFieldNames ( ) ) ) { fieldSelector = new UidAndSourceFieldSelector ( ) ; } else if ( context . fieldNames ( ) . isEmpty ( ) ) { fieldSelector = UidFieldSelector . INSTANCE ; } else if ( context . fieldNames ( ) . get ( 0 ) . equals ( "*" ) ) { fieldSelector = AllButSourceFieldSelector . INSTANCE ; } else { FieldMappersFieldSelector fieldSelectorMapper = new FieldMappersFieldSelector ( ) ; for ( String fieldName : context . fieldNames ( ) ) { <START_BUG> FieldMappers x = context . mapperService ( ) . smartNameFieldMappers ( fieldName ) ; <END_BUG> if ( ( x != null ) && ( x . mapper ( ) . stored ( ) ) ) { fieldSelectorMapper . add ( x ) ; } else { if ( extractFieldNames == null ) { extractFieldNames = Lists . newArrayList ( ) ; } extractFieldNames . add ( fieldName ) ; } } fieldSelectorMapper . add ( NAME ) ; fieldSelector = fieldSelectorMapper ; } InternalSearchHit [ ] hits = new InternalSearchHit [ context . docIdsToLoadSize ( ) ] ; for ( int index = 0 ; index < ( context . docIdsToLoadSize ( ) ) ; index ++ ) { int docId = context . docIdsToLoad ( ) [ ( ( context . docIdsToLoadFrom ( ) ) + index ) ] ; Document doc = loadDocument ( context , fieldSelector , docId ) ; Uid uid = extractUid ( context , doc ) ; DocumentMapper documentMapper = context . mapperService ( ) . documentMapper ( uid . type ( ) ) ; if ( documentMapper == null ) { throw new org . elasticsearch . indices . TypeMissingException ( new org . elasticsearch . index . Index ( context . shardTarget ( ) . index ( ) ) , uid . type ( ) , ( ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>find<seq2seq4repair_space>type<seq2seq4repair_space>loaded<seq2seq4repair_space>for<seq2seq4repair_space>doc<seq2seq4repair_space>[" + ( uid . id ( ) ) ) + "]" ) ) ; } byte [ ] source = extractSource ( doc , documentMapper ) ; InternalSearchHit searchHit = new InternalSearchHit ( docId , uid . id ( ) , uid . type ( ) , source , null ) ; hits [ index ] = searchHit ; for ( Object oField : doc . getFields ( ) ) { Fieldable field = ( ( Fieldable ) ( oField ) ) ; String name = field . name ( ) ; if ( name . equals ( NAME ) ) { continue ; } if ( name . equals ( SourceFieldMapper . NAME ) ) { continue ; } Object value = null ; FieldMappers fieldMappers = documentMapper . mappers ( ) . indexName ( field . name ( ) ) ; if ( fieldMappers != null ) { FieldMapper mapper = fieldMappers . mapper ( ) ; if ( mapper != null ) { name = mapper . names ( ) . fullName ( ) ; value = mapper . valueForSearch ( field ) ; } } if ( value == null ) { if ( field . isBinary ( ) ) { value = field . getBinaryValue ( ) ; } else { value = field . stringValue ( ) ; } } if ( ( searchHit . fieldsOrNull ( ) ) == null ) { searchHit . fields ( new HashMap < String , SearchHitField > ( 2 ) ) ; } SearchHitField hitField = searchHit . fields ( ) . get ( name ) ; if ( hitField == null ) { hitField = new InternalSearchHitField ( name , new ArrayList < Object > ( 2 ) ) ; searchHit . fields ( ) . put ( name , hitField ) ; } hitField . values ( ) . add ( value ) ; } int readerIndex = context . searcher ( ) . readerIndex ( docId ) ; IndexReader subReader = context . searcher ( ) . subReaders ( ) [ readerIndex ] ; int subDoc = docId - ( context . searcher ( ) . docStarts ( ) [ readerIndex ] ) ; context . lookup ( ) . setNextReader ( subReader ) ; context . lookup ( ) . setNextDocId ( docId ) ; if ( extractFieldNames != null ) { for ( String extractFieldName : extractFieldNames ) { Object value = context . lookup ( ) . source ( ) . extractValue ( extractFieldName ) ; if ( value != null ) { if ( ( searchHit . fieldsOrNull ( ) ) == null ) { searchHit . fields ( new HashMap < String , SearchHitField > ( 2 ) ) ; } SearchHitField hitField = searchHit . fields ( ) . get ( extractFieldName ) ; if ( hitField == null ) { hitField = new InternalSearchHitField ( extractFieldName , new ArrayList < Object > ( 2 ) ) ; searchHit . fields ( ) . put ( extractFieldName , hitField ) ; } hitField . values ( ) . add ( value ) ; } } } for ( SearchHitPhase hitPhase : hitPhases ) { SearchHitPhase . HitContext hitContext = new SearchHitPhase . HitContext ( ) ; if ( hitPhase . executionNeeded ( context ) ) { hitContext . reset ( searchHit , subReader , subDoc , doc ) ;<BUG2FIX>FieldMappers x = context . smartNameFieldMappers ( fieldName ) ;
public class FilterCacheTests { @ Test public void testNoCache ( ) throws Exception { } @ Test public void testSoftCache ( ) throws Exception { } @ Test public void testWeakCache ( ) throws Exception { } private void verifyCache ( FilterCache filterCache ) throws Exception { Directory dir = new RAMDirectory ( ) ; IndexWriter indexWriter = new IndexWriter ( dir , Lucene . STANDARD_ANALYZER , true , MaxFieldLength . UNLIMITED ) ; IndexReader reader = indexWriter . getReader ( ) ; for ( int i = 0 ; i < 100 ; i ++ ) { indexWriter . addDocument ( doc ( ) . add ( field ( "id" , Integer . toString ( i ) ) ) . boost ( i ) . build ( ) ) ; } reader = refreshReader ( reader ) ; IndexSearcher searcher = new IndexSearcher ( reader ) ; assertThat ( Lucene . count ( searcher , new ConstantScoreQuery ( filterCache . cache ( new TermFilter ( new Term ( "id" , "1" ) ) ) ) , ( - 1 ) ) , equalTo ( 1L ) ) ; assertThat ( Lucene . count ( searcher , new FilteredQuery ( new MatchAllDocsQuery ( ) , filterCache . cache ( new TermFilter ( new Term ( "id" , "1" ) ) ) ) , ( - 1 ) ) , equalTo ( 1L ) ) ; indexWriter . deleteDocuments ( new Term ( "id" , "1" ) ) ; reader = refreshReader ( reader ) ; searcher = new IndexSearcher ( reader ) ; TermFilter filter = new TermFilter ( new Term ( "id" , "1" ) ) ; Filter cachedFilter = filterCache . cache ( filter ) ; long constantScoreCount = ( filter == cachedFilter ) ? 0 : 1 ; assertThat ( Lucene . count ( searcher , new ConstantScoreQuery ( cachedFilter ) , ( - 1 ) ) , equalTo ( constantScoreCount ) ) ; <START_BUG> assertThat ( Lucene . count ( searcher , new DeletionAwareConstantScoreQuery ( cachedFilter , true ) , ( - 1 ) ) , equalTo ( 0L ) ) ; <END_BUG> assertThat ( Lucene . count ( searcher , new FilteredQuery ( new MatchAllDocsQuery ( ) , cachedFilter ) , ( - 1 ) ) , equalTo ( 0L ) ) ; indexWriter . close ( ) ; } private IndexReader refreshReader ( IndexReader reader ) throws IOException { } }<BUG2FIX>assertThat ( Lucene . count ( searcher , new DeletionAwareConstantScoreQuery ( cachedFilter ) , ( - 1 ) ) , equalTo ( 0L ) ) ;
public class Label extends Widget { private Label . LabelStyle style ; private final TextBounds bounds = new TextBounds ( ) ; private final StringBuilder text = new StringBuilder ( ) ; private StringBuilder tempText ; private BitmapFontCache cache ; private int labelAlign = Align . left ; private HAlignment lineAlign = HAlignment . LEFT ; private boolean wrap ; private float lastPrefHeight ; private boolean sizeInvalid = true ; private float fontScaleX = 1 ; private float fontScaleY = 1 ; private boolean ellipse ; public Label ( CharSequence text , Skin skin ) { } public Label ( CharSequence text , Skin skin , String styleName ) { } public Label ( CharSequence text , Skin skin , String fontName , Color color ) { } public Label ( CharSequence text , Skin skin , String fontName , String colorName ) { } public Label ( CharSequence text , Label . LabelStyle style ) { } public void setStyle ( Label . LabelStyle style ) { } public Label . LabelStyle getStyle ( ) { } public void setText ( CharSequence newText ) { } public boolean textEquals ( CharSequence other ) { } public CharSequence getText ( ) { } public void invalidate ( ) { } private void computeSize ( ) { } public void layout ( ) { } public void draw ( Batch batch , float parentAlpha ) { validate ( ) ; Color color = getColor ( ) ; if ( ( style . background ) != null ) { batch . setColor ( color . r , color . g , color . b , ( ( color . a ) * parentAlpha ) ) ; style . background . draw ( batch , getX ( ) , getY ( ) , getWidth ( ) , getHeight ( ) ) ; } cache . setColor ( ( ( style . fontColor ) == null ? color : tmp . set ( color ) . mul ( style . fontColor ) ) ) ; cache . setPosition ( getX ( ) , getY ( ) ) ; <START_BUG> cache . draw ( batch , ( ( color . a ) * parentAlpha ) ) ; <END_BUG> } public float getPrefWidth ( ) { } public float getPrefHeight ( ) { } public TextBounds getTextBounds ( ) { } public void setWrap ( boolean wrap ) { } public void setAlignment ( int wrapAlign ) { } public void setAlignment ( int labelAlign , int lineAlign ) { } public void setFontScale ( float fontScale ) { } public void setFontScale ( float fontScaleX , float fontScaleY ) { } public float getFontScaleX ( ) { } public void setFontScaleX ( float fontScaleX ) { } public float getFontScaleY ( ) { } public void setFontScaleY ( float fontScaleY ) { } public void setEllipse ( boolean ellipse ) { } public static class LabelStyle { public BitmapFont font ; public Color fontColor ; public Drawable background ; public LabelStyle ( ) { } public LabelStyle ( BitmapFont font , Color fontColor ) { } public LabelStyle ( Label . LabelStyle style ) { } } }<BUG2FIX>cache . draw ( batch , parentAlpha ) ;
public class TransportPutWarmerAction extends TransportMasterNodeOperationAction < PutWarmerRequest , PutWarmerResponse > { private final TransportSearchAction searchAction ; @ Inject public TransportPutWarmerAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool , TransportSearchAction searchAction ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected PutWarmerRequest newRequest ( ) { } @ Override protected PutWarmerResponse newResponse ( ) { } @ Override protected ClusterBlockException checkBlock ( PutWarmerRequest request , ClusterState state ) { } @ Override protected void masterOperation ( final PutWarmerRequest request , final ClusterState state , final ActionListener < PutWarmerResponse > listener ) throws ElasticSearchException { searchAction . execute ( request . searchRequest ( ) , new ActionListener < SearchResponse > ( ) { @ Override public void onResponse ( SearchResponse searchResponse ) { if ( ( searchResponse . getFailedShards ( ) ) > 0 ) { listener . onFailure ( new ElasticSearchException ( ( "search<seq2seq4repair_space>failed<seq2seq4repair_space>with<seq2seq4repair_space>failed<seq2seq4repair_space>shards:<seq2seq4repair_space>" + ( Arrays . toString ( searchResponse . getShardFailures ( ) ) ) ) ) ) ; return ; } clusterService . submitStateUpdateTask ( ( ( "put_warmer<seq2seq4repair_space>[" + ( request . name ( ) ) ) + "]" ) , new AckedClusterStateUpdateTask ( ) { @ Override public boolean mustAck ( DiscoveryNode discoveryNode ) { return true ; } @ Override public void onAllNodesAcked ( @ Nullable Throwable t ) { listener . onResponse ( new PutWarmerResponse ( true ) ) ; } @ Override public void onAckTimeout ( ) { listener . onResponse ( new PutWarmerResponse ( false ) ) ; } @ Override public TimeValue ackTimeout ( ) { return request . timeout ( ) ; } @ Override public TimeValue timeout ( ) { return request . masterNodeTimeout ( ) ; } @ Override public void onFailure ( String source , Throwable t ) { logger . debug ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>put<seq2seq4repair_space>warmer<seq2seq4repair_space>[{}]<seq2seq4repair_space>on<seq2seq4repair_space>indices<seq2seq4repair_space>[{}]" , t , request . name ( ) , request . searchRequest ( ) . indices ( ) ) ; listener . onFailure ( t ) ; } @ Override public ClusterState execute ( ClusterState currentState ) { MetaData metaData = currentState . metaData ( ) ; String [ ] concreteIndices = metaData . concreteIndices ( request . searchRequest ( ) . indices ( ) ) ; BytesReference source = null ; if ( ( ( request . searchRequest ( ) . source ( ) ) != null ) && ( ( request . searchRequest ( ) . source ( ) . length ( ) ) > 0 ) ) { source = request . searchRequest ( ) . source ( ) ; } else if ( ( ( request . searchRequest ( ) . extraSource ( ) ) != null ) && ( ( request . searchRequest ( ) . extraSource ( ) . length ( ) ) > 0 ) ) { source = request . searchRequest ( ) . extraSource ( ) ; } MetaData . Builder mdBuilder = MetaData . builder ( currentState . metaData ( ) ) ; for ( String index : concreteIndices ) { IndexMetaData indexMetaData = metaData . index ( index ) ; if ( indexMetaData == null ) { throw new org . elasticsearch . indices . IndexMissingException ( new Index ( index ) ) ; } IndexWarmersMetaData warmers = indexMetaData . custom ( TYPE ) ; if ( warmers == null ) { logger . info ( "[{}]<seq2seq4repair_space>putting<seq2seq4repair_space>warmer<seq2seq4repair_space>[{}]" , index , request . name ( ) ) ; warmers = new IndexWarmersMetaData ( new IndexWarmersMetaData . Entry ( request . name ( ) , request . searchRequest ( ) . types ( ) , source ) ) ; } else { boolean found = false ; List < IndexWarmersMetaData . Entry > entries = new ArrayList < IndexWarmersMetaData . Entry > ( ( ( warmers . entries ( ) . size ( ) ) + 1 ) ) ; for ( IndexWarmersMetaData . Entry entry : warmers . entries ( ) ) { if ( entry . name ( ) . equals ( request . name ( ) ) ) { found = true ; entries . add ( new IndexWarmersMetaData . Entry ( request . name ( ) , request . searchRequest ( ) . types ( ) , source ) ) ; } else { entries . add ( entry ) ; } } if ( ! found ) { logger . info ( "[{}]<seq2seq4repair_space>put<seq2seq4repair_space>warmer<seq2seq4repair_space>[{}]" , index , request . name ( ) ) ; entries . add ( new IndexWarmersMetaData . Entry ( request . name ( ) , request . searchRequest ( ) . types ( ) , source ) ) ; } else { logger . info ( "[{}]<seq2seq4repair_space>update<seq2seq4repair_space>warmer<seq2seq4repair_space>[{}]" , index , request . name ( ) ) ; } warmers = new IndexWarmersMetaData ( entries . toArray ( new IndexWarmersMetaData . Entry [ entries . size ( ) ] ) ) ; } <START_BUG> IndexMetaData . Builder indexBuilder = IndexMetaData . newIndexMetaDataBuilder ( indexMetaData ) . putCustom ( TYPE , warmers ) ; <END_BUG> mdBuilder . put ( indexBuilder ) ; } return ClusterState . builder ( ) . state ( currentState ) . metaData ( mdBuilder ) . build ( ) ; } @ Override public void clusterStateProcessed ( String source , ClusterState oldState , ClusterState newState ) { } } ) ; } @ Override public void onFailure ( Throwable e ) { listener . onFailure ( e ) ; } } ) ; } }<BUG2FIX>IndexMetaData . Builder indexBuilder = IndexMetaData . builder ( indexMetaData ) . putCustom ( TYPE , warmers ) ;
public class RestDeleteByQueryAction extends BaseRestHandler { @ Inject public RestDeleteByQueryAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { DeleteByQueryRequest deleteByQueryRequest = new DeleteByQueryRequest ( splitIndices ( request . param ( "index" ) ) ) ; deleteByQueryRequest . listenerThreaded ( false ) ; try { if ( request . hasContent ( ) ) { deleteByQueryRequest . query ( request . content ( ) , request . contentUnsafe ( ) ) ; } else { String source = request . param ( "source" ) ; if ( source != null ) { deleteByQueryRequest . query ( source ) ; } else { BytesReference bytes = RestActions . parseQuerySource ( request ) ; deleteByQueryRequest . query ( bytes , false ) ; } } deleteByQueryRequest . types ( splitTypes ( request . param ( "type" ) ) ) ; deleteByQueryRequest . timeout ( request . paramAsTime ( "timeout" , DEFAULT_TIMEOUT ) ) ; deleteByQueryRequest . routing ( request . param ( "routing" ) ) ; String replicationType = request . param ( "replication" ) ; if ( replicationType != null ) { deleteByQueryRequest . replicationType ( ReplicationType . fromString ( replicationType ) ) ; } String consistencyLevel = request . param ( "consistency" ) ; if ( consistencyLevel != null ) { deleteByQueryRequest . consistencyLevel ( WriteConsistencyLevel . fromString ( consistencyLevel ) ) ; } final String ignoreIndices = request . param ( "ignore_indices" ) ; if ( ignoreIndices != null ) { deleteByQueryRequest . ignoreIndices ( IgnoreIndices . fromString ( ignoreIndices ) ) ; } } catch ( Exception e ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . PRECONDITION_FAILED , builder . startObject ( ) . field ( "error" , e . getMessage ( ) ) . endObject ( ) ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } return ; } client . deleteByQuery ( deleteByQueryRequest , new org . elasticsearch . action . ActionListener < DeleteByQueryResponse > ( ) { @ Override public void onResponse ( DeleteByQueryResponse result ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) . field ( "ok" , true ) ; builder . startObject ( "_indices" ) ; for ( IndexDeleteByQueryResponse indexDeleteByQueryResponse : result . getIndices ( ) . values ( ) ) { builder . startObject ( indexDeleteByQueryResponse . getIndex ( ) , NONE ) ; builder . startObject ( "_shards" ) ; builder . field ( "total" , indexDeleteByQueryResponse . getTotalShards ( ) ) ; builder . field ( "successful" , indexDeleteByQueryResponse . getSuccessfulShards ( ) ) ; builder . field ( "failed" , indexDeleteByQueryResponse . getFailedShards ( ) ) ; builder . endObject ( ) ; builder . endObject ( ) ; } builder . endObject ( ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
if ( previousIndex != null ) { throw new SnapshotRestoreException ( snapshotId , ( ( ( ( ( ( "indices<seq2seq4repair_space>[" + index ) + "]<seq2seq4repair_space>and<seq2seq4repair_space>[" ) + previousIndex ) + "]<seq2seq4repair_space>are<seq2seq4repair_space>renamed<seq2seq4repair_space>into<seq2seq4repair_space>the<seq2seq4repair_space>same<seq2seq4repair_space>index<seq2seq4repair_space>[" ) + renamedIndex ) + "]" ) ) ; } } clusterService . submitStateUpdateTask ( request . cause ( ) , new TimeoutClusterStateUpdateTask ( ) { RestoreInfo restoreInfo = null ; @ Override public ClusterState execute ( ClusterState currentState ) { RestoreMetaData restoreMetaData = currentState . metaData ( ) . custom ( TYPE ) ; if ( ( restoreMetaData != null ) && ( ! ( restoreMetaData . entries ( ) . isEmpty ( ) ) ) ) { throw new ConcurrentSnapshotExecutionException ( snapshotId , "Restore<seq2seq4repair_space>process<seq2seq4repair_space>is<seq2seq4repair_space>already<seq2seq4repair_space>running<seq2seq4repair_space>in<seq2seq4repair_space>this<seq2seq4repair_space>cluster" ) ; } MetaData . Builder mdBuilder = MetaData . builder ( currentState . metaData ( ) ) ; ClusterBlocks . Builder blocks = ClusterBlocks . builder ( ) . blocks ( currentState . blocks ( ) ) ; RoutingTable . Builder rtBuilder = RoutingTable . builder ( currentState . routingTable ( ) ) ; if ( ! ( metaData . indices ( ) . isEmpty ( ) ) ) { ImmutableMap . Builder < ShardId , RestoreMetaData . ShardRestoreStatus > shards = ImmutableMap . builder ( ) ; for ( Map . Entry < String , String > indexEntry : renamedIndices . entrySet ( ) ) { String index = indexEntry . getValue ( ) ; if ( failed ( snapshot , index ) ) { throw new SnapshotRestoreException ( snapshotId , ( ( "index<seq2seq4repair_space>[" + index ) + "]<seq2seq4repair_space>wasn't<seq2seq4repair_space>fully<seq2seq4repair_space>snapshotted<seq2seq4repair_space>-<seq2seq4repair_space>cannot<seq2seq4repair_space>restore" ) ) ; } RestoreSource restoreSource = new RestoreSource ( snapshotId , index ) ; String renamedIndex = indexEntry . getKey ( ) ; IndexMetaData snapshotIndexMetaData = metaData . index ( index ) ; IndexMetaData currentIndexMetaData = currentState . metaData ( ) . index ( renamedIndex ) ; if ( currentIndexMetaData == null ) { createIndexService . validateIndexName ( renamedIndex , currentState ) ; IndexMetaData . Builder indexMdBuilder = IndexMetaData . builder ( snapshotIndexMetaData ) . state ( OPEN ) . index ( renamedIndex ) ; IndexMetaData updatedIndexMetaData = indexMdBuilder . build ( ) ; rtBuilder . addAsNewRestore ( updatedIndexMetaData , restoreSource ) ; mdBuilder . put ( updatedIndexMetaData , true ) ; } else { if ( ( currentIndexMetaData . state ( ) ) != ( State . CLOSE ) ) { throw new SnapshotRestoreException ( snapshotId , ( ( "cannot<seq2seq4repair_space>restore<seq2seq4repair_space>index<seq2seq4repair_space>[" + renamedIndex ) + "]<seq2seq4repair_space>because<seq2seq4repair_space>it's<seq2seq4repair_space>open" ) ) ; } if ( ( currentIndexMetaData . getNumberOfShards ( ) ) != ( snapshotIndexMetaData . getNumberOfShards ( ) ) ) { throw new SnapshotRestoreException ( snapshotId , ( ( ( ( ( ( "cannot<seq2seq4repair_space>restore<seq2seq4repair_space>index<seq2seq4repair_space>[" + renamedIndex ) + "]<seq2seq4repair_space>with<seq2seq4repair_space>[" ) + ( currentIndexMetaData . getNumberOfShards ( ) ) ) + "]<seq2seq4repair_space>shard<seq2seq4repair_space>from<seq2seq4repair_space>snapshot<seq2seq4repair_space>with<seq2seq4repair_space>[" ) + ( snapshotIndexMetaData . getNumberOfShards ( ) ) ) + "]<seq2seq4repair_space>shards" ) ) ; } IndexMetaData . Builder indexMdBuilder = IndexMetaData . builder ( snapshotIndexMetaData ) . state ( OPEN ) ; indexMdBuilder . version ( Math . max ( snapshotIndexMetaData . version ( ) , ( ( currentIndexMetaData . version ( ) ) + 1 ) ) ) ; IndexMetaData updatedIndexMetaData = indexMdBuilder . index ( renamedIndex ) . build ( ) ; rtBuilder . addAsRestore ( updatedIndexMetaData , restoreSource ) ; <START_BUG> blocks . removeIndexBlock ( index , MetaDataIndexStateService . INDEX_CLOSED_BLOCK ) ; <END_BUG> mdBuilder . put ( updatedIndexMetaData , true ) ; } for ( int shard = 0 ; shard < ( snapshotIndexMetaData . getNumberOfShards ( ) ) ; shard ++ ) { shards . put ( new ShardId ( renamedIndex , shard ) , new RestoreMetaData . ShardRestoreStatus ( clusterService . state ( ) . nodes ( ) . localNodeId ( ) ) ) ; } } RestoreMetaData . Entry restoreEntry = new RestoreMetaData . Entry ( snapshotId , RestoreMetaData . State . INIT , ImmutableList . copyOf ( renamedIndices . keySet ( ) ) , shards . build ( ) ) ; mdBuilder . putCustom ( TYPE , new RestoreMetaData ( restoreEntry ) ) ; } if ( request . includeGlobalState ( ) ) { if ( ( metaData . persistentSettings ( ) ) != null ) { mdBuilder . persistentSettings ( metaData . persistentSettings ( ) ) ; } if ( ( metaData . templates ( ) ) != null ) { for ( ObjectCursor < IndexTemplateMetaData > cursor : metaData . templates ( ) . values ( ) ) { mdBuilder . put ( cursor . value ) ; } } if ( ( metaData . customs ( ) ) != null ) { for ( ObjectObjectCursor < String , MetaData . Custom > cursor : metaData . customs ( ) ) { if ( ! ( RepositoriesMetaData . TYPE . equals ( cursor . key ) ) ) { mdBuilder . putCustom ( cursor . key , cursor . value ) ; } } } } if ( metaData . indices ( ) . isEmpty ( ) ) { restoreInfo = new RestoreInfo ( request . name ( ) , ImmutableList . < String > of ( ) , 0 , 0 ) ; } ClusterState updatedState = ClusterState . builder ( currentState ) . metaData ( mdBuilder ) . blocks ( blocks ) . routingTable ( rtBuilder ) . build ( ) ; RoutingAllocation . Result routingResult = allocationService . reroute ( ClusterState . builder ( updatedState ) . routingTable ( rtBuilder ) . build ( ) ) ; return ClusterState . builder ( updatedState ) . routingResult ( routingResult ) . build ( ) ; } @ Override public void onFailure ( String source , Throwable t ) { logger . warn ( "[{}]<seq2seq4repair_space>failed<seq2seq4repair_space>to<seq2seq4repair_space>restore<seq2seq4repair_space>snapshot" , t , snapshotId ) ; listener . onFailure ( t ) ; } @ Override public TimeValue timeout ( ) { return request . masterNodeTimeout ( ) ; } @ Override public void clusterStateProcessed ( String source , ClusterState oldState , ClusterState newState ) { listener . onResponse ( restoreInfo ) ; } } ) ; } catch ( Throwable e ) { logger . warn ( "[{}][{}]<seq2seq4repair_space>failed<seq2seq4repair_space>to<seq2seq4repair_space>restore<seq2seq4repair_space>snapshot"<BUG2FIX>blocks . removeIndexBlock ( renamedIndex , MetaDataIndexStateService . INDEX_CLOSED_BLOCK ) ;
final class JoglFiles implements Files { private final String externalPath = ( System . getProperty ( "user.home" ) ) + "/" ; @ Override public FileHandle getFileHandle ( String filename , FileType type ) { File file = null ; if ( ( type == ( FileType . Absolute ) ) || ( type == ( FileType . Internal ) ) ) file = new File ( filename ) ; else file = new File ( ( ( this . externalPath ) + filename ) ) ; if ( ( file . exists ( ) ) == false ) throw new GdxRuntimeException ( ( ( "File<seq2seq4repair_space>'" + filename ) + "'<seq2seq4repair_space>doesn't<seq2seq4repair_space>exist" ) ) ; else <START_BUG> return new JoglFileHandle ( file ) ; <END_BUG> } @ Override public String [ ] listDirectory ( String directory , FileType type ) { } @ Override public boolean makeDirectory ( String directory , FileType type ) { } @ Override public InputStream readFile ( String fileName , FileType type ) { } @ Override public OutputStream writeFile ( String filename , FileType type ) { } }<BUG2FIX>return new JoglFileHandle ( file , type ) ;
public class DfsPhase implements SearchPhase { private static ThreadLocal < ObjectOpenHashSet < Term > > cachedTermsSet = new ThreadLocal < ObjectOpenHashSet < Term > > ( ) { @ Override protected ObjectOpenHashSet < Term > initialValue ( ) { } } ; @ Override public Map < String , ? extends SearchParseElement > parseElements ( ) { } @ Override public void preProcess ( SearchContext context ) { } public void execute ( SearchContext context ) { final ObjectOpenHashSet < Term > termsSet = DfsPhase . cachedTermsSet . get ( ) ; try { if ( ! ( context . queryRewritten ( ) ) ) { context . updateRewriteQuery ( context . searcher ( ) . rewrite ( context . query ( ) ) ) ; } if ( ! ( termsSet . isEmpty ( ) ) ) { termsSet . clear ( ) ; } context . query ( ) . extractTerms ( new DfsPhase . DelegateSet ( termsSet ) ) ; if ( ( context . rescore ( ) ) != null ) { context . rescore ( ) . rescorer ( ) . extractTerms ( context , context . rescore ( ) , new DfsPhase . DelegateSet ( termsSet ) ) ; } Term [ ] terms = termsSet . toArray ( Term . class ) ; TermStatistics [ ] termStatistics = new TermStatistics [ terms . length ] ; IndexReaderContext indexReaderContext = context . searcher ( ) . getTopReaderContext ( ) ; for ( int i = 0 ; i < ( terms . length ) ; i ++ ) { <START_BUG> TermContext termContext = TermContext . build ( indexReaderContext , terms [ i ] , false ) ; <END_BUG> termStatistics [ i ] = context . searcher ( ) . termStatistics ( terms [ i ] , termContext ) ; } ObjectObjectOpenHashMap < String , CollectionStatistics > fieldStatistics = HppcMaps . newNoNullKeysMap ( ) ; for ( Term term : terms ) { assert ( term . field ( ) ) != null : "field<seq2seq4repair_space>is<seq2seq4repair_space>null" ; if ( ! ( fieldStatistics . containsKey ( term . field ( ) ) ) ) { final CollectionStatistics collectionStatistics = context . searcher ( ) . collectionStatistics ( term . field ( ) ) ; fieldStatistics . put ( term . field ( ) , collectionStatistics ) ; } } context . dfsResult ( ) . termsStatistics ( terms , termStatistics ) . fieldStatistics ( fieldStatistics ) . maxDoc ( context . searcher ( ) . getIndexReader ( ) . maxDoc ( ) ) ; } catch ( Exception e ) { throw new DfsPhaseExecutionException ( context , "Exception<seq2seq4repair_space>during<seq2seq4repair_space>dfs<seq2seq4repair_space>phase" , e ) ; } finally { termsSet . clear ( ) ; } } private static class DelegateSet extends AbstractSet < Term > { private final ObjectOpenHashSet < Term > delegate ; private DelegateSet ( ObjectOpenHashSet < Term > delegate ) { } @ Override public boolean add ( Term term ) { } @ Override public boolean addAll ( Collection < ? extends Term > terms ) { } @ Override public Iterator < Term > iterator ( ) { } @ Override public int size ( ) { } } }<BUG2FIX>TermContext termContext = TermContext . build ( indexReaderContext , terms [ i ] ) ;
public class FsImmutableBlobContainer extends AbstractFsBlobContainer implements ImmutableBlobContainer { public FsImmutableBlobContainer ( FsBlobStore blobStore , BlobPath blobPath , File path ) { } @ Override public void writeBlob ( final String blobName , final InputStream is , final long sizeInBytes , final WriterListener listener ) { blobStore . executorService ( ) . execute ( new Runnable ( ) { @ Override public void run ( ) { File file = new File ( path , blobName ) ; <START_BUG> RandomAccessFile raf = null ; <END_BUG> try { raf = new RandomAccessFile ( file , "rw" ) ; } catch ( FileNotFoundException e ) { listener . onFailure ( e ) ; return ; } try { try { byte [ ] buffer = new byte [ 16 * 1024 ] ; int bytesRead ; while ( ( bytesRead = is . read ( buffer ) ) != ( - 1 ) ) { raf . write ( buffer , 0 , bytesRead ) ; } } finally { try { is . close ( ) ; } catch ( IOException ex ) { } try { raf . close ( ) ; } catch ( IOException ex ) { } } FileSystemUtils . syncFile ( file ) ; listener . onCompleted ( ) ; } catch ( Exception e ) { try { if ( file . exists ( ) ) { file . delete ( ) ; } } catch ( Exception e1 ) { } listener . onFailure ( e ) ; } } } ) ; } @ Override public void writeBlob ( String blobName , InputStream is , long sizeInBytes ) throws IOException { } }<BUG2FIX>RandomAccessFile raf ;
public abstract class ValuesSourceMetricsAggregatorParser < S extends MetricsAggregation > implements Aggregator . Parser { protected boolean requiresSortedValues ( ) { } @ Override public AggregatorFactory parse ( String aggregationName , XContentParser parser , SearchContext context ) throws IOException { <START_BUG> ValuesSourceConfig < NumericValuesSource > config = new ValuesSourceConfig < NumericValuesSource > ( NumericValuesSource . class ) ; <END_BUG> String field = null ; String script = null ; String scriptLang = null ; Map < String , Object > scriptParams = null ; boolean assumeSorted = false ; XContentParser . Token token ; String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . VALUE_STRING ) ) { if ( "field" . equals ( currentFieldName ) ) { field = parser . text ( ) ; } else if ( "script" . equals ( currentFieldName ) ) { script = parser . text ( ) ; } else if ( "lang" . equals ( currentFieldName ) ) { scriptLang = parser . text ( ) ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( ( ( "Unknown<seq2seq4repair_space>key<seq2seq4repair_space>for<seq2seq4repair_space>a<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>[" ) + aggregationName ) + "]:<seq2seq4repair_space>[" ) + currentFieldName ) + "]." ) ) ; } } else if ( token == ( Token . START_OBJECT ) ) { if ( "params" . equals ( currentFieldName ) ) { scriptParams = parser . map ( ) ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( ( ( "Unknown<seq2seq4repair_space>key<seq2seq4repair_space>for<seq2seq4repair_space>a<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>[" ) + aggregationName ) + "]:<seq2seq4repair_space>[" ) + currentFieldName ) + "]." ) ) ; } } else if ( token == ( Token . VALUE_BOOLEAN ) ) { if ( ( "script_values_sorted" . equals ( currentFieldName ) ) || ( "scriptValuesSorted" . equals ( currentFieldName ) ) ) { assumeSorted = parser . booleanValue ( ) ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( ( ( "Unknown<seq2seq4repair_space>key<seq2seq4repair_space>for<seq2seq4repair_space>a<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>[" ) + aggregationName ) + "]:<seq2seq4repair_space>[" ) + currentFieldName ) + "]." ) ) ; } } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( "Unexpected<seq2seq4repair_space>token<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>[" ) + aggregationName ) + "]." ) ) ; } } if ( script != null ) { config . script ( context . scriptService ( ) . search ( context . lookup ( ) , scriptLang , script , scriptParams ) ) ; } if ( ( ! assumeSorted ) && ( requiresSortedValues ( ) ) ) { config . ensureSorted ( true ) ; } if ( field == null ) { return createFactory ( aggregationName , config ) ; } FieldMapper < ? > mapper = context . smartNameFieldMapper ( field ) ; if ( mapper == null ) { config . unmapped ( true ) ; return createFactory ( aggregationName , config ) ; } IndexFieldData < ? > indexFieldData = context . fieldData ( ) . getForField ( mapper ) ; config . fieldContext ( new org . elasticsearch . search . aggregations . support . FieldContext ( field , indexFieldData ) ) ; return createFactory ( aggregationName , config ) ; } protected abstract AggregatorFactory createFactory ( String aggregationName , ValuesSourceConfig < NumericValuesSource > config ) { } }<BUG2FIX>ValuesSourceConfig < NumericValuesSource > config = new ValuesSourceConfig ( NumericValuesSource . class ) ;
public class CubocDesktop { public static void main ( String [ ] argv ) { <START_BUG> new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new Cubocy ( ) , "Cubocy" , 480 , 320 ) ; <END_BUG> app . setLogLevel ( LOG_DEBUG ) ; } }<BUG2FIX>new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new Cubocy ( ) , "Cubocy" , 480 , 320 , true ) ;
@ ThreadSafe public class ObjectMapper implements IncludeInAllMapper , XContentMapper { public static final String CONTENT_TYPE = "object" ; public static class Defaults { public static final boolean ENABLED = true ; public static final boolean DYNAMIC = true ; public static final Type PATH_TYPE = Type . FULL ; } public static class Builder < T extends ObjectMapper . Builder , Y extends ObjectMapper > extends XContentMapper . Builder < T , Y > { protected boolean enabled = ObjectMapper . Defaults . ENABLED ; protected boolean dynamic = ObjectMapper . Defaults . DYNAMIC ; protected Type pathType = ObjectMapper . Defaults . PATH_TYPE ; protected Boolean includeInAll ; protected final List < XContentMapper . Builder > mappersBuilders = ObjectMapper . Builder . newArrayList ( ) ; public Builder ( String name ) { } public T enabled ( boolean enabled ) { } public T dynamic ( boolean dynamic ) { } public T pathType ( ContentPath . Type pathType ) { } public T includeInAll ( boolean includeInAll ) { } public T add ( XContentMapper . Builder builder ) { } @ Override public Y build ( BuilderContext context ) { } protected ObjectMapper createMapper ( String name , boolean enabled , boolean dynamic , ContentPath . Type pathType , Map < String , XContentMapper > mappers ) { } } public static class TypeParser implements XContentMapper . TypeParser { @ Override public XContentMapper . Builder parse ( String name , Map < String , Object > node , ParserContext parserContext ) throws MapperParsingException { } private void parseProperties ( ObjectMapper . Builder objBuilder , Map < String , Object > propsNode , ParserContext parserContext ) { for ( Map . Entry < String , Object > entry : propsNode . entrySet ( ) ) { <START_BUG> String propName = Strings . toUnderscoreCase ( entry . getKey ( ) ) ; <END_BUG> Map < String , Object > propNode = ( ( Map < String , Object > ) ( entry . getValue ( ) ) ) ; String type ; Object typeNode = propNode . get ( "type" ) ; if ( typeNode != null ) { type = typeNode . toString ( ) ; } else { if ( ( propNode . get ( "properties" ) ) != null ) { type = ObjectMapper . CONTENT_TYPE ; } else if ( ( propNode . get ( "fields" ) ) != null ) { type = MultiFieldMapper . CONTENT_TYPE ; } else { throw new MapperParsingException ( ( ( "No<seq2seq4repair_space>type<seq2seq4repair_space>specified<seq2seq4repair_space>for<seq2seq4repair_space>property<seq2seq4repair_space>[" + propName ) + "]" ) ) ; } } XContentMapper . TypeParser typeParser = parserContext . typeParser ( type ) ; if ( typeParser == null ) { throw new MapperParsingException ( ( ( ( ( "No<seq2seq4repair_space>handler<seq2seq4repair_space>for<seq2seq4repair_space>type<seq2seq4repair_space>[" + type ) + "]<seq2seq4repair_space>declared<seq2seq4repair_space>on<seq2seq4repair_space>field<seq2seq4repair_space>[" ) + propName ) + "]" ) ) ; } objBuilder . add ( typeParser . parse ( propName , propNode , parserContext ) ) ; } } protected ObjectMapper . Builder createBuilder ( String name ) { } protected void processField ( ObjectMapper . Builder builder , String fieldName , Object fieldNode ) { } } private final String name ; private final boolean enabled ; private final boolean dynamic ; private final Type pathType ; private Boolean includeInAll ; private volatile ImmutableMap < String , XContentMapper > mappers = ImmutableMap . of ( ) ; private final Object mutex = new Object ( ) ; protected ObjectMapper ( String name ) { } protected ObjectMapper ( String name , boolean enabled , boolean dynamic , ContentPath . Type pathType ) { } ObjectMapper ( String name , boolean enabled , boolean dynamic , ContentPath . Type pathType , Map < String , XContentMapper > mappers ) { } @ Override public String name ( ) { } @ Override public void includeInAll ( Boolean includeInAll ) { } public ObjectMapper putMapper ( XContentMapper mapper ) { } @ Override public void traverse ( FieldMapperListener fieldMapperListener ) { } public void parse ( ParseContext context ) throws IOException { } private void serializeNullValue ( ParseContext context , String lastFieldName ) throws IOException { } private void serializeObject ( ParseContext context , String currentFieldName ) throws IOException { } private void serializeArray ( ParseContext context , String lastFieldName ) throws IOException { } private void serializeValue ( final ParseContext context , String currentFieldName , XContentParser . Token token ) throws IOException { } @ Override public void merge ( XContentMapper mergeWith , MergeContext mergeContext ) throws MergeMappingException { } protected void doMerge ( ObjectMapper mergeWith , MergeContext mergeContext ) { } @ Override public void toXContent ( XContentBuilder builder , Params params ) throws IOException { } public void toXContent ( XContentBuilder builder , Params params , ToXContent custom , XContentMapper ... additionalMappers ) throws IOException { } protected void doXContent ( XContentBuilder builder , Params params ) throws IOException { } }<BUG2FIX>String propName = entry . getKey ( ) ;
public void testActualMissingValue ( ) throws IOException { } public void testActualMissingValueReverse ( ) throws IOException { } public void testActualMissingValue ( boolean reverse ) throws IOException { } public void testSortMissingFirst ( ) throws IOException { } public void testSortMissingFirstReverse ( ) throws IOException { } public void testSortMissingLast ( ) throws IOException { } public void testSortMissingLastReverse ( ) throws IOException { } public void testSortMissing ( boolean first , boolean reverse ) throws IOException { } public void testNestedSortingMin ( ) throws IOException { } public void testNestedSortingMax ( ) throws IOException { } public void testNestedSorting ( MultiValueMode sortMode ) throws IOException { final String [ ] values = new String [ randomIntBetween ( 2 , 20 ) ] ; for ( int i = 0 ; i < ( values . length ) ; ++ i ) { values [ i ] = TestUtil . randomSimpleString ( getRandom ( ) ) ; } final int numParents = scaledRandomIntBetween ( 10 , 10000 ) ; List < Document > docs = new ArrayList < > ( ) ; final OpenBitSet parents = new OpenBitSet ( ) ; for ( int i = 0 ; i < numParents ; ++ i ) { docs . clear ( ) ; final int numChildren = randomInt ( 4 ) ; for ( int j = 0 ; j < numChildren ; ++ j ) { final Document child = new Document ( ) ; final int numValues = randomInt ( 3 ) ; for ( int k = 0 ; k < numValues ; ++ k ) { final String value = RandomPicks . randomFrom ( getRandom ( ) , values ) ; child . add ( new org . apache . lucene . document . StringField ( "text" , value , Store . YES ) ) ; } docs . add ( child ) ; } final Document parent = new Document ( ) ; parent . add ( new org . apache . lucene . document . StringField ( "type" , "parent" , Store . YES ) ) ; final String value = RandomPicks . randomFrom ( getRandom ( ) , values ) ; if ( value != null ) { parent . add ( new org . apache . lucene . document . StringField ( "text" , value , Store . YES ) ) ; } docs . add ( parent ) ; parents . set ( ( ( parents . prevSetBit ( ( ( parents . length ( ) ) - 1 ) ) ) + ( docs . size ( ) ) ) ) ; writer . addDocuments ( docs ) ; if ( ( randomInt ( 10 ) ) == 0 ) { writer . commit ( ) ; } } IndexSearcher searcher = new IndexSearcher ( DirectoryReader . open ( writer , true ) ) ; IndexFieldData < ? > fieldData = getForField ( "text" ) ; final Object missingValue ; switch ( randomInt ( 4 ) ) { case 0 : missingValue = "_first" ; break ; case 1 : missingValue = "_last" ; break ; case 2 : missingValue = new BytesRef ( RandomPicks . randomFrom ( getRandom ( ) , values ) ) ; break ; default : missingValue = new BytesRef ( TestUtil . randomSimpleString ( getRandom ( ) ) ) ; break ; } Filter parentFilter = new org . apache . lucene . queries . TermFilter ( new Term ( "type" , "parent" ) ) ; Filter childFilter = new org . elasticsearch . common . lucene . search . NotFilter ( parentFilter ) ; <START_BUG> Nested nested = createNested ( parentFilter , childFilter ) ; <END_BUG> BytesRefFieldComparatorSource nestedComparatorSource = new BytesRefFieldComparatorSource ( fieldData , missingValue , sortMode , nested ) ; ToParentBlockJoinQuery query = new ToParentBlockJoinQuery ( new org . elasticsearch . common . lucene . search . XFilteredQuery ( new MatchAllDocsQuery ( ) , childFilter ) , new org . apache . lucene . search . join . FixedBitSetCachingWrapperFilter ( parentFilter ) , ScoreMode . None ) ; Sort sort = new Sort ( new SortField ( "text" , nestedComparatorSource ) ) ; TopFieldDocs topDocs = searcher . search ( query , randomIntBetween ( 1 , numParents ) , sort ) ; assertTrue ( ( ( topDocs . scoreDocs . length ) > 0 ) ) ; BytesRef previous = null ; for ( int i = 0 ; i < ( topDocs . scoreDocs . length ) ; ++ i ) { final int docID = topDocs . scoreDocs [ i ] . doc ; assertTrue ( ( ( "expected<seq2seq4repair_space>" + docID ) + "<seq2seq4repair_space>to<seq2seq4repair_space>be<seq2seq4repair_space>a<seq2seq4repair_space>parent" ) , parents . get ( docID ) ) ; BytesRef cmpValue = null ; for ( int child = ( parents . prevSetBit ( ( docID - 1 ) ) ) + 1 ; child < docID ; ++ child ) { String [ ] sVals = searcher . doc ( child ) . getValues ( "text" ) ; final BytesRef [ ] vals ; if ( ( sVals . length ) == 0 ) { vals = new BytesRef [ 0 ] ; } else { vals = new BytesRef [ sVals . length ] ; for ( int j = 0 ; j < ( vals . length ) ; ++ j ) { vals [ j ] = new BytesRef ( sVals [ j ] ) ; } } for ( BytesRef value : vals ) { if ( cmpValue == null ) { cmpValue = value ; } else if ( ( sortMode == ( MultiValueMode . MIN ) ) && ( ( value . compareTo ( cmpValue ) ) < 0 ) ) { cmpValue = value ; } else if ( ( sortMode == ( MultiValueMode . MAX ) ) && ( ( value . compareTo ( cmpValue ) ) > 0 ) ) { cmpValue = value ; }<BUG2FIX>Nested nested = new Nested ( parentFilter , childFilter ) ;
public class InterpolationTest extends GdxTest { private static final String [ ] interpolators = new String [ ] { "bounce" , "bounceIn" , "bounceOut" , "circle" , "circleIn" , "circleOut" , "elastic" , "elasticIn" , "elasticOut" , "exp10" , "exp10In" , "exp10Out" , "exp5" , "exp5In" , "exp5Out" , "fade" , "linear" , "pow2" , "pow2In" , "pow2Out" , "pow3" , "pow3In" , "pow3Out" , "pow4" , "pow4In" , "pow4Out" , "pow5" , "pow5In" , "pow5Out" , "sine" , "sineIn" , "sineOut" , "swing" , "swingIn" , "swingOut" } ; private Stage stage ; private Table root ; private List list ; private ShapeRenderer renderer ; Vector2 position = new Vector2 ( 300 , 20 ) ; Vector2 targetPosition = new Vector2 ( position ) ; Vector2 temp = new Vector2 ( ) ; float timer ; public void create ( ) { renderer = new ShapeRenderer ( ) ; stage = new Stage ( 0 , 0 , true ) ; input . setInputProcessor ( new com . badlogic . gdx . InputMultiplexer ( stage , new InputAdapter ( ) { public boolean touchDown ( int x , int y , int pointer , int button ) { Vector2 current = getCurrentPosition ( ) ; position . set ( current ) ; targetPosition . set ( ( x - 10 ) , ( ( ( graphics . getHeight ( ) ) - y ) - 10 ) ) ; timer = 0 ; return true ; } } ) ) ; root = new Table ( ) ; stage . addActor ( root ) ; root . pad ( 10 ) . top ( ) . left ( ) ; Skin skin = new Skin ( files . internal ( "data/uiskin.json" ) , files . internal ( "data/uiskin.png" ) ) ; list = new List ( InterpolationTest . interpolators , skin ) ; <START_BUG> root . add ( new com . badlogic . gdx . scenes . scene2d . ui . FlickScrollPane ( list , stage ) ) . expandY ( ) . fillY ( ) . prefWidth ( ( ( int ) ( list . getPrefWidth ( ) ) ) ) ; <END_BUG> } public void resize ( int width , int height ) { } public void render ( ) { } Vector2 getCurrentPosition ( ) { } private Interpolation getInterpolation ( ) { } public boolean needsGL20 ( ) { } }<BUG2FIX>root . add ( new com . badlogic . gdx . scenes . scene2d . ui . FlickScrollPane ( list ) ) . expandY ( ) . fillY ( ) . prefWidth ( ( ( int ) ( list . getPrefWidth ( ) ) ) ) ;
public class TransportSearchCountAction extends TransportSearchTypeAction { @ Inject public TransportSearchCountAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportSearchCache transportSearchCache , SearchServiceTransportAction searchService , SearchPhaseController searchPhaseController ) { } @ Override protected void doExecute ( SearchRequest searchRequest , ActionListener < SearchResponse > listener ) { } private class AsyncAction extends BaseAsyncAction < QuerySearchResult > { private final Map < SearchShardTarget , QuerySearchResultProvider > queryFetchResults = searchCache . obtainQueryResults ( ) ; private AsyncAction ( SearchRequest request , ActionListener < SearchResponse > listener ) { } @ Override protected String firstPhaseName ( ) { } @ Override protected void sendExecuteFirstPhase ( DiscoveryNode node , InternalSearchRequest request , SearchServiceListener < QuerySearchResult > listener ) { } @ Override protected void processFirstPhaseResult ( ShardRouting shard , QuerySearchResult result ) { } @ Override protected void moveToSecondPhase ( ) throws Exception { final InternalSearchResponse internalResponse = searchPhaseController . merge ( TransportSearchCountAction . EMPTY_DOCS , queryFetchResults , ImmutableMap . < SearchShardTarget , FetchSearchResultProvider > of ( ) ) ; String scrollId = null ; if ( ( request . scroll ( ) ) != null ) { <START_BUG> scrollId = buildScrollId ( request . searchType ( ) , queryFetchResults . values ( ) ) ; <END_BUG> } listener . onResponse ( new SearchResponse ( internalResponse , scrollId , expectedSuccessfulOps , successulOps . get ( ) , buildTookInMillis ( ) , buildShardFailures ( ) ) ) ; searchCache . releaseQueryResults ( queryFetchResults ) ; } } private static ShardDoc [ ] EMPTY_DOCS = new ShardDoc [ 0 ] ; }<BUG2FIX>scrollId = buildScrollId ( request . searchType ( ) , queryFetchResults . values ( ) , null ) ;
private int allocateUniformLocationId ( int program , WebGLUniformLocation location ) { } private WebGLUniformLocation getUniformLocation ( int location ) { } private int allocateShaderId ( WebGLShader shader ) { } private void deallocateShaderId ( int id ) { } private int allocateProgramId ( WebGLProgram program ) { } private void deallocateProgramId ( int id ) { } private int allocateBufferId ( WebGLBuffer buffer ) { } private void deallocateBufferId ( int id ) { } private int allocateFrameBufferId ( WebGLFramebuffer frameBuffer ) { } private void deallocateFrameBufferId ( int id ) { } private int allocateRenderBufferId ( WebGLRenderbuffer renderBuffer ) { } private void deallocateRenderBufferId ( int id ) { } private int allocateTextureId ( WebGLTexture texture ) { } private void deallocateTextureId ( int id ) { } @ Override public void glActiveTexture ( int texture ) { } @ Override public void glBindTexture ( int target , int texture ) { } @ Override public void glBlendFunc ( int sfactor , int dfactor ) { } @ Override public void glClear ( int mask ) { } @ Override public void glClearColor ( float red , float green , float blue , float alpha ) { } @ Override public void glClearDepthf ( float depth ) { } @ Override public void glClearStencil ( int s ) { } @ Override public void glColorMask ( boolean red , boolean green , boolean blue , boolean alpha ) { } @ Override public void glCompressedTexImage2D ( int target , int level , int internalformat , int width , int height , int border , int imageSize , Buffer data ) { } @ Override public void glCompressedTexSubImage2D ( int target , int level , int xoffset , int yoffset , int width , int height , int format , int imageSize , Buffer data ) { } @ Override public void glCopyTexImage2D ( int target , int level , int internalformat , int x , int y , int width , int height , int border ) { } @ Override public void glCopyTexSubImage2D ( int target , int level , int xoffset , int yoffset , int x , int y , int width , int height ) { } @ Override public void glCullFace ( int mode ) { } @ Override public void glDeleteTextures ( int n , IntBuffer textures ) { } @ Override public void glDepthFunc ( int func ) { } @ Override public void glDepthMask ( boolean flag ) { } @ Override public void glDepthRangef ( float zNear , float zFar ) { } @ Override public void glDisable ( int cap ) { } @ Override public void glDrawArrays ( int mode , int first , int count ) { } @ Override public void glDrawElements ( int mode , int count , int type , Buffer indices ) { } @ Override public void glEnable ( int cap ) { } @ Override public void glFinish ( ) { } @ Override public void glFlush ( ) { } @ Override public void glFrontFace ( int mode ) { } @ Override public void glGenTextures ( int n , IntBuffer textures ) { } @ Override public int glGetError ( ) { } @ Override public void glGetIntegerv ( int pname , IntBuffer params ) { } @ Override public String glGetString ( int name ) { } @ Override public void glHint ( int target , int mode ) { } @ Override public void glLineWidth ( float width ) { } @ Override public void glPixelStorei ( int pname , int param ) { } @ Override public void glPolygonOffset ( float factor , float units ) { } @ Override public void glReadPixels ( int x , int y , int width , int height , int format , int type , Buffer pixels ) { <START_BUG> if ( ( format != ( WebGLRenderingContext . UNSIGNED_BYTE ) ) || ( type != ( WebGLRenderingContext . RGBA ) ) ) { <END_BUG> throw new GdxRuntimeException ( "Only<seq2seq4repair_space>format<seq2seq4repair_space>UNSIGNED_BYTE<seq2seq4repair_space>for<seq2seq4repair_space>type<seq2seq4repair_space>RGBA<seq2seq4repair_space>is<seq2seq4repair_space>currently<seq2seq4repair_space>supported." ) ; } if ( ! ( pixels instanceof ByteBuffer ) ) { throw new GdxRuntimeException ( "Inputed<seq2seq4repair_space>pixels<seq2seq4repair_space>buffer<seq2seq4repair_space>needs<seq2seq4repair_space>to<seq2seq4repair_space>be<seq2seq4repair_space>of<seq2seq4repair_space>type<seq2seq4repair_space>ByteBuffer." ) ; } int size = ( 4 * width ) * height ; Uint8Array buffer = Uint8Array . create ( size ) ; gl . readPixels ( x , y , width , height , format , type , buffer ) ; ByteBuffer pixelsByte = ( ( ByteBuffer ) ( pixels ) ) ; for ( int i = 0 ; i < size ; i ++ ) { pixelsByte . put ( ( ( byte ) ( ( buffer . get ( i ) ) & 255 ) ) ) ; } } @ Override public void glScissor ( int x , int y , int width , int height ) { } @ Override public void glStencilFunc ( int func , int ref , int mask ) { } @ Override public void glStencilMask ( int mask ) { } @ Override public void glStencilOp ( int fail , int zfail , int zpass ) { } @ Override public void glTexImage2D ( int target , int level , int internalformat , int width , int height , int border , int format , int type , Buffer pixels ) { } @ Override public void glTexParameterf ( int target , int pname , float param ) { } @ Override public void glTexSubImage2D ( int target , int level , int xoffset , int yoffset , int width , int height , int format , int type , Buffer pixels ) { } @ Override public void glViewport ( int x , int y , int width , int height ) { } @ Override public void glAttachShader ( int program , int shader ) { } @ Override public void glBindAttribLocation ( int program , int index , String name ) { }<BUG2FIX>if ( ( format != ( WebGLRenderingContext . RGBA ) ) || ( type != ( WebGLRenderingContext . UNSIGNED_BYTE ) ) ) {
public class MulticastZenPing extends AbstractLifecycleComponent < ZenPing > implements ZenPing { private final String address ; private final int port ; private final String group ; private final int bufferSize ; private final int ttl ; private final ThreadPool threadPool ; private final TransportService transportService ; private final ClusterName clusterName ; private final NetworkService networkService ; private final NetworkInterface [ ] networkInterfaces ; private final InetAddress groupAddress ; private volatile DiscoveryNodesProvider nodesProvider ; private volatile MulticastZenPing . Receiver receiver ; private volatile Thread receiverThread ; private MulticastSocket multicastSocket ; private DatagramPacket datagramPacketSend ; private DatagramPacket datagramPacketReceive ; private final AtomicInteger pingIdGenerator = new AtomicInteger ( ) ; private final Map < Integer , ConcurrentMap < DiscoveryNode , PingResponse > > receivedResponses = newConcurrentMap ( ) ; private final Object sendMutex = new Object ( ) ; private final Object receiveMutex = new Object ( ) ; public MulticastZenPing ( ThreadPool threadPool , TransportService transportService , ClusterName clusterName ) { } public MulticastZenPing ( Settings settings , ThreadPool threadPool , TransportService transportService , ClusterName clusterName , NetworkService networkService ) { } @ Override public void setNodesProvider ( DiscoveryNodesProvider nodesProvider ) { } @ Override protected void doStart ( ) throws ElasticSearchException { } @ Override protected void doStop ( ) throws ElasticSearchException { } @ Override protected void doClose ( ) throws ElasticSearchException { } public PingResponse [ ] pingAndWait ( TimeValue timeout ) { } @ Override public void ping ( final PingListener listener , final TimeValue timeout ) { } private void sendPingRequest ( int id ) { synchronized ( sendMutex ) { try { HandlesStreamOutput out = Cached . cachedHandles ( ) ; out . writeInt ( id ) ; clusterName . writeTo ( out ) ; nodesProvider . nodes ( ) . localNode ( ) . writeTo ( out ) ; datagramPacketSend . setData ( ( ( BytesStreamOutput ) ( out . wrappedOut ( ) ) ) . copiedByteArray ( ) ) ; datagramPacketSend . setAddress ( groupAddress ) ; datagramPacketSend . setPort ( port ) ; } catch ( IOException e ) { receivedResponses . remove ( id ) ; throw new ZenPingException ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>serialize<seq2seq4repair_space>ping<seq2seq4repair_space>request" , e ) ; } if ( ( networkInterfaces ) != null ) { Exception lastException = null ; boolean sentToAtLeastOne = false ; for ( NetworkInterface inf : networkInterfaces ) { if ( logger . isTraceEnabled ( ) ) { logger . trace ( "[{}]<seq2seq4repair_space>Sending<seq2seq4repair_space>ping<seq2seq4repair_space>request<seq2seq4repair_space>on<seq2seq4repair_space>interface<seq2seq4repair_space>{}" , id , inf ) ; } try { multicastSocket . setNetworkInterface ( inf ) ; multicastSocket . send ( datagramPacketSend ) ; sentToAtLeastOne = true ; } catch ( Exception e ) { <START_BUG> logger . trace ( "[{}]<seq2seq4repair_space>Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>multicast<seq2seq4repair_space>ping<seq2seq4repair_space>on<seq2seq4repair_space>interface<seq2seq4repair_space>{}" , id , inf ) ; <END_BUG> lastException = e ; } } if ( ! sentToAtLeastOne ) { throw new ZenPingException ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>on<seq2seq4repair_space>any<seq2seq4repair_space>of<seq2seq4repair_space>the<seq2seq4repair_space>network<seq2seq4repair_space>interfaces" , lastException ) ; } } else { try { if ( logger . isTraceEnabled ( ) ) { logger . trace ( "[{}]<seq2seq4repair_space>Sending<seq2seq4repair_space>ping<seq2seq4repair_space>request" , id ) ; } multicastSocket . send ( datagramPacketSend ) ; } catch ( IOException e ) { receivedResponses . remove ( id ) ; throw new ZenPingException ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>ping<seq2seq4repair_space>request<seq2seq4repair_space>over<seq2seq4repair_space>multicast" , e ) ; } } } } class MulticastPingResponseRequestHandler extends BaseTransportRequestHandler < MulticastZenPing . MulticastPingResponse > { static final String ACTION = "discovery/zen/multicast" ; @ Override public MulticastZenPing . MulticastPingResponse newInstance ( ) { } @ Override public void messageReceived ( MulticastZenPing . MulticastPingResponse request , TransportChannel channel ) throws Exception { } } static class MulticastPingResponse implements Streamable { int id ; PingResponse pingResponse ; MulticastPingResponse ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } private class Receiver implements Runnable { private volatile boolean running = true ; public void stop ( ) { } @ Override public void run ( ) { } } }<BUG2FIX>logger . trace ( "[{}]<seq2seq4repair_space>Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>multicast<seq2seq4repair_space>ping<seq2seq4repair_space>on<seq2seq4repair_space>interface<seq2seq4repair_space>{}" , e , id , inf ) ;
@ Override public short lastIndex ( ) { } @ Override public short vertex ( final float ... values ) { } @ Override public short vertex ( final VertexInfo info ) { } @ Override public void index ( final short value ) { } @ Override public void index ( final short value1 , final short value2 ) { } @ Override public void index ( final short value1 , final short value2 , final short value3 ) { } @ Override public void index ( final short value1 , final short value2 , final short value3 , final short value4 ) { } @ Override public void index ( short value1 , short value2 , short value3 , short value4 , short value5 , short value6 ) { } @ Override public void index ( short value1 , short value2 , short value3 , short value4 , short value5 , short value6 , short value7 , short value8 ) { } @ Override public void line ( short index1 , short index2 ) { } @ Override public void line ( VertexInfo p1 , VertexInfo p2 ) { } @ Override public void line ( Vector3 p1 , Vector3 p2 ) { } @ Override public void line ( float x1 , float y1 , float z1 , float x2 , float y2 , float z2 ) { } @ Override public void line ( Vector3 p1 , Color c1 , Vector3 p2 , Color c2 ) { } @ Override public void triangle ( short index1 , short index2 , short index3 ) { } @ Override public void triangle ( VertexInfo p1 , VertexInfo p2 , VertexInfo p3 ) { } @ Override public void triangle ( Vector3 p1 , Vector3 p2 , Vector3 p3 ) { } @ Override public void triangle ( Vector3 p1 , Color c1 , Vector3 p2 , Color c2 , Vector3 p3 , Color c3 ) { } @ Override public void rect ( short corner00 , short corner10 , short corner11 , short corner01 ) { } @ Override public void rect ( VertexInfo corner00 , VertexInfo corner10 , VertexInfo corner11 , VertexInfo corner01 ) { } @ Override public void rect ( Vector3 corner00 , Vector3 corner10 , Vector3 corner11 , Vector3 corner01 , Vector3 normal ) { } @ Override public void rect ( float x00 , float y00 , float z00 , float x10 , float y10 , float z10 , float x11 , float y11 , float z11 , float x01 , float y01 , float z01 , float normalX , float normalY , float normalZ ) { } @ Override public void patch ( VertexInfo corner00 , VertexInfo corner10 , VertexInfo corner11 , VertexInfo corner01 , int divisionsU , int divisionsV ) { } @ Override public void patch ( Vector3 corner00 , Vector3 corner10 , Vector3 corner11 , Vector3 corner01 , Vector3 normal , int divisionsU , int divisionsV ) { } public void patch ( float x00 , float y00 , float z00 , float x10 , float y10 , float z10 , float x11 , float y11 , float z11 , float x01 , float y01 , float z01 , float normalX , float normalY , float normalZ , int divisionsU , int divisionsV ) { } @ Override public void box ( VertexInfo corner000 , VertexInfo corner010 , VertexInfo corner100 , VertexInfo corner110 , VertexInfo corner001 , VertexInfo corner011 , VertexInfo corner101 , VertexInfo corner111 ) { ensureVertices ( 8 ) ; final short i000 = vertex ( corner000 ) ; final short i100 = vertex ( corner100 ) ; final short i110 = vertex ( corner110 ) ; final short i010 = vertex ( corner010 ) ; final short i001 = vertex ( corner001 ) ; final short i101 = vertex ( corner101 ) ; final short i111 = vertex ( corner111 ) ; final short i011 = vertex ( corner011 ) ; if ( ( primitiveType ) == ( GL10 . GL_LINES ) ) { ensureIndices ( 24 ) ; rect ( i000 , i100 , i110 , i010 ) ; rect ( i101 , i001 , i011 , i111 ) ; index ( i000 , i001 , i010 , i011 , i110 , i111 , i100 , i101 ) ; } else <START_BUG> if ( ( primitiveType ) != ( GL10 . GL_POINTS ) ) { <END_BUG> ensureRectangleIndices ( 2 ) ; rect ( i000 , i100 , i110 , i010 ) ; rect ( i101 , i001 , i011 , i111 ) ; } else { ensureRectangleIndices ( 6 ) ; rect ( i000 , i100 , i110 , i010 ) ; rect ( i101 , i001 , i011 , i111 ) ; rect ( i000 , i010 , i011 , i001 ) ; rect ( i101 , i111 , i110 , i100 ) ; rect ( i101 , i100 , i000 , i001 ) ; rect ( i110 , i111 , i011 , i010 ) ; } } @ Override public void box ( Vector3 corner000 , Vector3 corner010 , Vector3 corner100 , Vector3 corner110 , Vector3 corner001 , Vector3 corner011 , Vector3 corner101 , Vector3 corner111 ) { } @ Override public void box ( Matrix4 transform ) { } @ Override public void box ( float width , float height , float depth ) { } @ Override public void box ( float x , float y , float z , float width , float height , float depth ) { } @ Override public void circle ( float radius , int divisions , float centerX , float centerY , float centerZ , float normalX , float normalY , float normalZ ) { } @ Override public void circle ( float radius , int divisions , final Vector3 center , final Vector3 normal ) { }<BUG2FIX>if ( ( primitiveType ) == ( GL10 . GL_POINTS ) ) {
@ Override public int count ( ) { } @ Override public int getCount ( ) { } @ Override public double min ( ) { } @ Override public double getMin ( ) { } @ Override public double max ( ) { } @ Override public double getMax ( ) { } @ Override public double total ( ) { } @ Override public double getTotal ( ) { } @ Override public double mean ( ) { } @ Override public double getMean ( ) { } @ Override public int compareTo ( Entry o ) { } } private String name ; int requiredSize ; long missing ; Collection < InternalTermsStatsStringFacet . StringEntry > entries = ImmutableList . of ( ) ; ComparatorType comparatorType ; public InternalTermsStatsStringFacet ( String name , ComparatorType comparatorType , int requiredSize , Collection < InternalTermsStatsStringFacet . StringEntry > entries , long missing ) { } @ Override public String name ( ) { } @ Override public String getName ( ) { } @ Override public String type ( ) { } @ Override public String getType ( ) { } @ Override public List < InternalTermsStatsStringFacet . StringEntry > entries ( ) { } List < InternalTermsStatsStringFacet . StringEntry > mutableList ( ) { } @ Override public List < InternalTermsStatsStringFacet . StringEntry > getEntries ( ) { } @ SuppressWarnings ( { "unchecked" } ) @ Override public Iterator < Entry > iterator ( ) { } @ Override public long missingCount ( ) { } @ Override public long getMissingCount ( ) { } private static ThreadLocal < CleanableValue < ExtTHashMap < String , InternalTermsStatsStringFacet . StringEntry > > > aggregateCache = new ThreadLocal < CleanableValue < ExtTHashMap < String , InternalTermsStatsStringFacet . StringEntry > > > ( ) { @ Override protected CleanableValue < ExtTHashMap < String , StringEntry > > initialValue ( ) { } } ; @ Override public Facet reduce ( String name , List < Facet > facets ) { if ( ( facets . size ( ) ) == 1 ) { if ( ( requiredSize ) == 0 ) { InternalTermsStatsStringFacet tsFacet = ( ( InternalTermsStatsStringFacet ) ( facets . get ( 0 ) ) ) ; if ( ! ( tsFacet . entries . isEmpty ( ) ) ) { List < InternalTermsStatsStringFacet . StringEntry > entries = tsFacet . mutableList ( ) ; Collections . sort ( entries , comparatorType . comparator ( ) ) ; } } return facets . get ( 0 ) ; } int missing = 0 ; ExtTHashMap < String , InternalTermsStatsStringFacet . StringEntry > map = aggregateCache . get ( ) . get ( ) ; map . clear ( ) ; for ( Facet facet : facets ) { InternalTermsStatsStringFacet tsFacet = ( ( InternalTermsStatsStringFacet ) ( facet ) ) ; missing += tsFacet . missing ; for ( Entry entry : tsFacet ) { InternalTermsStatsStringFacet . StringEntry stringEntry = ( ( InternalTermsStatsStringFacet . StringEntry ) ( entry ) ) ; InternalTermsStatsStringFacet . StringEntry current = map . get ( stringEntry . term ( ) ) ; if ( current != null ) { current . count += stringEntry . count ; current . total += stringEntry . total ; if ( ( ( stringEntry . min ) < ( current . min ) ) || ( Double . isNaN ( current . min ) ) ) { current . min = stringEntry . min ; } if ( ( ( stringEntry . max ) > ( current . max ) ) || ( Double . isNaN ( current . max ) ) ) { current . max = stringEntry . max ; } } else { map . put ( stringEntry . term ( ) , stringEntry ) ; } } } if ( ( requiredSize ) == 0 ) { InternalTermsStatsStringFacet . StringEntry [ ] entries1 = map . values ( ) . toArray ( new InternalTermsStatsStringFacet . StringEntry [ map . size ( ) ] ) ; Arrays . sort ( entries1 , comparatorType . comparator ( ) ) ; return new InternalTermsStatsStringFacet ( name , comparatorType , requiredSize , Arrays . asList ( entries1 ) , missing ) ; } else { Object [ ] values = map . internalValues ( ) ; Arrays . sort ( values , ( ( Comparator ) ( comparatorType . comparator ( ) ) ) ) ; <START_BUG> List < InternalTermsStatsStringFacet . StringEntry > ordered = new ArrayList < InternalTermsStatsStringFacet . StringEntry > ( ) ; <END_BUG> for ( int i = 0 ; i < ( requiredSize ) ; i ++ ) { InternalTermsStatsStringFacet . StringEntry value = ( ( InternalTermsStatsStringFacet . StringEntry ) ( values [ i ] ) ) ; if ( value == null ) { break ; } ordered . add ( value ) ; } return new InternalTermsStatsStringFacet ( name , comparatorType , requiredSize , ordered , missing ) ; } } static final class Fields { static final XContentBuilderString _TYPE = new XContentBuilderString ( "_type" ) ; static final XContentBuilderString MISSING = new XContentBuilderString ( "missing" ) ; static final XContentBuilderString TERMS = new XContentBuilderString ( "terms" ) ; static final XContentBuilderString TERM = new XContentBuilderString ( "term" ) ; static final XContentBuilderString COUNT = new XContentBuilderString ( "count" ) ; static final XContentBuilderString TOTAL = new XContentBuilderString ( "total" ) ; static final XContentBuilderString MIN = new XContentBuilderString ( "min" ) ; static final XContentBuilderString MAX = new XContentBuilderString ( "max" ) ; static final XContentBuilderString MEAN = new XContentBuilderString ( "mean" ) ; } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } public static InternalTermsStatsStringFacet readTermsStatsFacet ( StreamInput in ) throws IOException { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } }<BUG2FIX>List < InternalTermsStatsStringFacet . StringEntry > ordered = new ArrayList < InternalTermsStatsStringFacet . StringEntry > ( map . size ( ) ) ;
public class TransportPutMappingAction extends TransportMasterNodeOperationAction < PutMappingRequest , PutMappingResponse > { private final MetaDataMappingService metaDataMappingService ; @ Inject public TransportPutMappingAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool , MetaDataMappingService metaDataMappingService ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected PutMappingRequest newRequest ( ) { } @ Override protected PutMappingResponse newResponse ( ) { } @ Override protected void doExecute ( PutMappingRequest request , ActionListener < PutMappingResponse > listener ) { <START_BUG> request . indices ( clusterService . state ( ) . metaData ( ) . concreteIndices ( request . indices ( ) , request . indicesOptions ( ) ) ) ; <END_BUG> super . doExecute ( request , listener ) ; } @ Override protected ClusterBlockException checkBlock ( PutMappingRequest request , ClusterState state ) { } @ Override protected void masterOperation ( final PutMappingRequest request , final ClusterState state , final ActionListener < PutMappingResponse > listener ) throws ElasticsearchException { } }<BUG2FIX>request . indices ( clusterService . state ( ) . metaData ( ) . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ) ;
public abstract class BlobStoreIndexShardGateway extends AbstractIndexShardComponent implements IndexShardGateway { protected final ThreadPool threadPool ; protected final InternalIndexShard indexShard ; protected final Store store ; protected final RecoveryThrottler recoveryThrottler ; protected final ByteSizeValue chunkSize ; protected final BlobStore blobStore ; protected final BlobPath shardPath ; protected final ImmutableBlobContainer indexContainer ; protected final AppendableBlobContainer translogContainer ; protected final ConcurrentMap < String , String > cachedMd5 = ConcurrentCollections . newConcurrentMap ( ) ; private volatile SoftReference < FastByteArrayOutputStream > cachedBos = new SoftReference < FastByteArrayOutputStream > ( new FastByteArrayOutputStream ( ) ) ; private volatile AppendableBlob translogBlob ; protected BlobStoreIndexShardGateway ( ShardId shardId , @ IndexSettings Settings indexSettings , ThreadPool threadPool , IndexGateway indexGateway , IndexShard indexShard , Store store , RecoveryThrottler recoveryThrottler ) { } @ Override public String toString ( ) { } @ Override public boolean requiresSnapshotScheduling ( ) { } @ Override public void close ( boolean delete ) throws ElasticSearchException { } @ Override public SnapshotStatus snapshot ( final Snapshot snapshot ) throws IndexShardGatewaySnapshotFailedException { } @ Override public RecoveryStatus recover ( ) throws IndexShardGatewayRecoveryException { } private Translog recoverTranslog ( ) throws IndexShardGatewayRecoveryException { } private Index recoverIndex ( ) throws IndexShardGatewayRecoveryException { } private void recoverFile ( final BlobMetaData fileToRecover , final ImmutableMap < String , BlobMetaData > blobs , final CountDownLatch latch , final List < Throwable > failures ) { } private void snapshotFile ( Directory dir , final StoreFileMetaData fileMetaData , final CountDownLatch latch , final List < Throwable > failures ) throws IOException { } public static ImmutableMap < String , BlobMetaData > buildVirtualBlobs ( ImmutableBlobContainer container , ImmutableMap < String , BlobMetaData > blobs , @ Nullable Map < String , String > cachedMd5 ) { Set < String > names = Sets . newHashSet ( ) ; for ( BlobMetaData blob : blobs . values ( ) ) { if ( blob . name ( ) . endsWith ( ".md5" ) ) { names . add ( blob . name ( ) . substring ( 0 , blob . name ( ) . lastIndexOf ( ".md5" ) ) ) ; } } Builder < String , BlobMetaData > builder = ImmutableMap . builder ( ) ; for ( String name : names ) { long sizeInBytes = 0 ; if ( blobs . containsKey ( name ) ) { sizeInBytes = blobs . get ( name ) . sizeInBytes ( ) ; } else { int part = 0 ; while ( true ) { BlobMetaData md = blobs . get ( ( ( name + ".part" ) + part ) ) ; if ( md == null ) { break ; } sizeInBytes += md . sizeInBytes ( ) ; part ++ ; } } if ( ( cachedMd5 != null ) && ( cachedMd5 . containsKey ( name ) ) ) { builder . put ( name , new PlainBlobMetaData ( name , sizeInBytes , cachedMd5 . get ( name ) ) ) ; } else { try { String md5 = Digest . md5HexFromByteArray ( container . readBlobFully ( ( name + ".md5" ) ) ) ; if ( cachedMd5 != null ) { cachedMd5 . put ( name , md5 ) ; } builder . put ( name , new PlainBlobMetaData ( name , sizeInBytes , md5 ) ) ; <START_BUG> } catch ( IOException e ) { <END_BUG> } } } return builder . build ( ) ; } }<BUG2FIX>} catch ( Exception e ) {
public class FuzzyLikeThisFieldQueryParser extends AbstractIndexComponent implements XContentQueryParser { public static final String NAME = "flt_field" ; public FuzzyLikeThisFieldQueryParser ( Index index , @ IndexSettings Settings indexSettings ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; int maxNumTerms = 25 ; float boost = 1.0F ; String likeText = null ; float minSimilarity = 0.5F ; int prefixLength = 0 ; boolean ignoreTF = false ; XContentParser . Token token = parser . nextToken ( ) ; assert token == ( Token . FIELD_NAME ) ; String fieldName = parser . currentName ( ) ; token = parser . nextToken ( ) ; assert token == ( Token . START_OBJECT ) ; String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token . isValue ( ) ) { if ( ( "like_text" . equals ( currentFieldName ) ) || ( "likeText" . equals ( currentFieldName ) ) ) { likeText = parser . text ( ) ; } else if ( ( "max_query_terms" . equals ( currentFieldName ) ) || ( "maxQueryTerms" . equals ( currentFieldName ) ) ) { maxNumTerms = parser . intValue ( ) ; } else if ( "boost" . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } else if ( ( "ignore_tf" . equals ( currentFieldName ) ) || ( "ignoreTF" . equals ( currentFieldName ) ) ) { ignoreTF = parser . booleanValue ( ) ; } } } if ( likeText == null ) { throw new QueryParsingException ( index , "fuzzy_like_This_field<seq2seq4repair_space>requires<seq2seq4repair_space>'like_text'<seq2seq4repair_space>to<seq2seq4repair_space>be<seq2seq4repair_space>specified" ) ; } Analyzer analyzer = null ; MapperService . SmartNameFieldMappers smartNameFieldMappers = parseContext . smartFieldMappers ( fieldName ) ; if ( smartNameFieldMappers != null ) { if ( smartNameFieldMappers . hasMapper ( ) ) { fieldName = smartNameFieldMappers . mapper ( ) . names ( ) . indexName ( ) ; analyzer = smartNameFieldMappers . mapper ( ) . searchAnalyzer ( ) ; } } if ( analyzer == null ) { analyzer = parseContext . mapperService ( ) . searchAnalyzer ( ) ; } FuzzyLikeThisQuery query = new FuzzyLikeThisQuery ( maxNumTerms , analyzer ) ; query . addTerms ( likeText , fieldName , minSimilarity , prefixLength ) ; query . setBoost ( boost ) ; query . setIgnoreTF ( ignoreTF ) ; token = parser . nextToken ( ) ; assert token == ( Token . END_OBJECT ) ; <START_BUG> return wrapSmartNameQuery ( query , smartNameFieldMappers , parseContext . indexCache ( ) ) ; <END_BUG> } }<BUG2FIX>return wrapSmartNameQuery ( query , smartNameFieldMappers , parseContext ) ;
public class ManagedTest extends GdxTest { Mesh mesh ; Texture texture ; @ Override public void create ( ) { mesh = new Mesh ( true , 4 , 4 , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . Position , 2 , "a_position" ) , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . TextureCoordinates , 2 , "a_texCoord" ) ) ; mesh . setVertices ( new float [ ] { - 0.5F , - 0.5F , 0 , 0 , 0.5F , - 0.5F , 1 , 0 , 0.5F , 0.5F , 1 , 1 , - 0.5F , 0.5F , 0 , 1 } ) ; mesh . setIndices ( new short [ ] { 0 , 1 , 2 , 3 } ) ; <START_BUG> texture = new Texture ( files . internal ( "data/badlogic.jpg" ) ) ; <END_BUG> texture . setFilter ( MipMap , Linear ) ; } @ Override public void render ( ) { } @ Override public boolean needsGL20 ( ) { } }<BUG2FIX>texture = new Texture ( files . internal ( "data/badlogic.jpg" ) , true ) ;
public abstract class TransportShardReplicationOperationAction < Request extends ShardReplicationOperationRequest , Response extends ActionResponse > extends BaseAction < Request , Response > { protected final TransportService transportService ; protected final ClusterService clusterService ; protected final IndicesService indicesService ; protected final ThreadPool threadPool ; protected final ShardStateAction shardStateAction ; protected final ReplicationType defaultReplicationType ; protected final WriteConsistencyLevel defaultWriteConsistencyLevel ; protected TransportShardReplicationOperationAction ( Settings settings , TransportService transportService , ClusterService clusterService , IndicesService indicesService , ThreadPool threadPool , ShardStateAction shardStateAction ) { } @ Override protected void doExecute ( Request request , ActionListener < Response > listener ) { } protected abstract Request newRequestInstance ( ) { } protected abstract Response newResponseInstance ( ) { } protected abstract String transportAction ( ) { } protected abstract Response shardOperationOnPrimary ( ClusterState clusterState , TransportShardReplicationOperationAction < Request , Response > . ShardOperationRequest shardRequest ) { } protected abstract void shardOperationOnReplica ( TransportShardReplicationOperationAction < Request , Response > . ShardOperationRequest shardRequest ) { } protected abstract ShardIterator shards ( ClusterState clusterState , Request request ) throws ElasticSearchException { } protected abstract boolean checkWriteConsistency ( ) { } protected void checkBlock ( Request request , ClusterState state ) { } protected TransportRequestOptions transportOptions ( ) { } protected boolean ignoreReplicas ( ) { } private String transportReplicaAction ( ) { } protected IndexShard indexShard ( TransportShardReplicationOperationAction < Request , Response > . ShardOperationRequest shardRequest ) { } class OperationTransportHandler extends BaseTransportRequestHandler < Request > { @ Override public Request newInstance ( ) { } @ Override public void messageReceived ( final Request request , final TransportChannel channel ) throws Exception { } @ Override public boolean spawn ( ) { } } class ReplicaOperationTransportHandler extends BaseTransportRequestHandler < TransportShardReplicationOperationAction < Request , Response > . ShardOperationRequest > { @ Override public TransportShardReplicationOperationAction < Request , Response > . ShardOperationRequest newInstance ( ) { } @ Override public void messageReceived ( TransportShardReplicationOperationAction < Request , Response > . ShardOperationRequest request , TransportChannel channel ) throws Exception { } @ Override public boolean spawn ( ) { } } protected class ShardOperationRequest implements Streamable { public int shardId ; public Request request ; public ShardOperationRequest ( ) { } public ShardOperationRequest ( int shardId , Request request ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } protected class AsyncShardOperationAction { private final ActionListener < Response > listener ; private final Request request ; private DiscoveryNodes nodes ; private ShardIterator shardIt ; private final AtomicBoolean primaryOperationStarted = new AtomicBoolean ( ) ; private final ReplicationType replicationType ; private AsyncShardOperationAction ( Request request , ActionListener < Response > listener ) { } public void start ( ) { } public boolean start ( final boolean fromClusterEvent ) throws ElasticSearchException { } private void retry ( boolean fromClusterEvent , final ShardId shardId ) { } private void performOnPrimary ( int primaryShardId , boolean fromDiscoveryListener , boolean alreadyThreaded , final ShardRouting shard , ClusterState clusterState ) { try { Response response = shardOperationOnPrimary ( clusterState , new ShardOperationRequest ( primaryShardId , request ) ) ; performReplicas ( response , alreadyThreaded ) ; } catch ( Exception e ) { if ( ( ( e instanceof IndexShardMissingException ) || ( e instanceof IllegalIndexShardStateException ) ) || ( e instanceof IndexMissingException ) ) { retry ( fromDiscoveryListener , shard . shardId ( ) ) ; return ; } if ( logger . isDebugEnabled ( ) ) { logger . debug ( ( ( ( ( shard . shortSummary ( ) ) + ":<seq2seq4repair_space>Failed<seq2seq4repair_space>to<seq2seq4repair_space>execute<seq2seq4repair_space>[" ) + ( request ) ) + "]" ) , e ) ; } <START_BUG> listener . onFailure ( new ReplicationShardOperationFailedException ( shardIt . shardId ( ) , e ) ) ; <END_BUG> } } private void performReplicas ( final Response response , boolean alreadyThreaded ) { } private void performOnReplica ( final Response response , boolean alreadyThreaded , final AtomicInteger counter , final ShardRouting shard , String nodeId ) { } private boolean ignoreReplicaException ( Throwable e ) { } } }<BUG2FIX>listener . onFailure ( e ) ;
public class SearchServiceTransportAction extends AbstractComponent { static final class FreeContextResponseHandler extends EmptyTransportResponseHandler { private final ESLogger logger ; FreeContextResponseHandler ( ESLogger logger ) { } @ Override public void handleException ( TransportException exp ) { } } private final TransportService transportService ; private final ClusterService clusterService ; private final SearchService searchService ; private final SearchServiceTransportAction . FreeContextResponseHandler freeContextResponseHandler = new SearchServiceTransportAction . FreeContextResponseHandler ( logger ) ; @ Inject public SearchServiceTransportAction ( Settings settings , TransportService transportService , ClusterService clusterService , SearchService searchService ) { } public void sendFreeContext ( DiscoveryNode node , final long contextId , SearchRequest request ) { } public void sendExecuteDfs ( DiscoveryNode node , final ShardSearchRequest request , final SearchServiceListener < DfsSearchResult > listener ) { } public void sendExecuteQuery ( DiscoveryNode node , final ShardSearchRequest request , final SearchServiceListener < QuerySearchResult > listener ) { if ( clusterService . state ( ) . nodes ( ) . localNodeId ( ) . equals ( node . id ( ) ) ) { try { QuerySearchResult result = searchService . executeQueryPhase ( request ) ; listener . onResult ( result ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> listener . onFailure ( e ) ; } } else { transportService . sendRequest ( node , SearchServiceTransportAction . SearchQueryTransportHandler . ACTION , request , new BaseTransportResponseHandler < QuerySearchResult > ( ) { @ Override public QuerySearchResult newInstance ( ) { return new QuerySearchResult ( ) ; } @ Override public void handleResponse ( QuerySearchResult response ) { listener . onResult ( response ) ; } @ Override public void handleException ( TransportException exp ) { listener . onFailure ( exp ) ; } @ Override public String executor ( ) { return Names . SAME ; } } ) ; } } public void sendExecuteQuery ( DiscoveryNode node , final QuerySearchRequest request , final SearchServiceListener < QuerySearchResult > listener ) { } public void sendExecuteQuery ( DiscoveryNode node , final InternalScrollSearchRequest request , final SearchServiceListener < QuerySearchResult > listener ) { } public void sendExecuteFetch ( DiscoveryNode node , final ShardSearchRequest request , final SearchServiceListener < QueryFetchSearchResult > listener ) { } public void sendExecuteFetch ( DiscoveryNode node , final QuerySearchRequest request , final SearchServiceListener < QueryFetchSearchResult > listener ) { } public void sendExecuteFetch ( DiscoveryNode node , final InternalScrollSearchRequest request , final SearchServiceListener < QueryFetchSearchResult > listener ) { } public void sendExecuteFetch ( DiscoveryNode node , final FetchSearchRequest request , final SearchServiceListener < FetchSearchResult > listener ) { } public void sendExecuteScan ( DiscoveryNode node , final ShardSearchRequest request , final SearchServiceListener < QuerySearchResult > listener ) { } public void sendExecuteScan ( DiscoveryNode node , final InternalScrollSearchRequest request , final SearchServiceListener < QueryFetchSearchResult > listener ) { } class SearchFreeContextRequest extends TransportRequest { private long id ; SearchFreeContextRequest ( ) { } SearchFreeContextRequest ( SearchRequest request , long id ) { } public long id ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } class SearchFreeContextTransportHandler extends BaseTransportRequestHandler < SearchServiceTransportAction . SearchFreeContextRequest > { static final String ACTION = "search/freeContext" ; @ Override public SearchServiceTransportAction . SearchFreeContextRequest newInstance ( ) { } @ Override public void messageReceived ( SearchServiceTransportAction . SearchFreeContextRequest request , TransportChannel channel ) throws Exception { } @ Override public String executor ( ) { } } private class SearchDfsTransportHandler extends BaseTransportRequestHandler < ShardSearchRequest > { static final String ACTION = "search/phase/dfs" ; @ Override public ShardSearchRequest newInstance ( ) { } @ Override public void messageReceived ( ShardSearchRequest request , TransportChannel channel ) throws Exception { } @ Override public String executor ( ) { } } private class SearchQueryTransportHandler extends BaseTransportRequestHandler < ShardSearchRequest > { static final String ACTION = "search/phase/query" ; @ Override public ShardSearchRequest newInstance ( ) { } @ Override public void messageReceived ( ShardSearchRequest request , TransportChannel channel ) throws Exception { } @ Override public String executor ( ) { } } private class SearchQueryByIdTransportHandler extends BaseTransportRequestHandler < QuerySearchRequest > { static final String ACTION = "search/phase/query/id" ; @ Override public QuerySearchRequest newInstance ( ) { } @ Override public void messageReceived ( QuerySearchRequest request , TransportChannel channel ) throws Exception { } @ Override public String executor ( ) { } } private class SearchQueryScrollTransportHandler extends BaseTransportRequestHandler < InternalScrollSearchRequest > { static final String ACTION = "search/phase/query/scroll" ; @ Override public InternalScrollSearchRequest newInstance ( ) { } @ Override public void messageReceived ( InternalScrollSearchRequest request , TransportChannel channel ) throws Exception { } @ Override public String executor ( ) { } } private class SearchQueryFetchTransportHandler extends BaseTransportRequestHandler < ShardSearchRequest > { static final String ACTION = "search/phase/query+fetch" ; @ Override public ShardSearchRequest newInstance ( ) { } @ Override public void messageReceived ( ShardSearchRequest request , TransportChannel channel ) throws Exception { } @ Override public String executor ( ) { } } private class SearchQueryQueryFetchTransportHandler extends BaseTransportRequestHandler < QuerySearchRequest > { static final String ACTION = "search/phase/query/query+fetch" ; @ Override public QuerySearchRequest newInstance ( ) { } @ Override public void messageReceived ( QuerySearchRequest request , TransportChannel channel ) throws Exception { } @ Override public String executor ( ) { } } private class SearchFetchByIdTransportHandler extends BaseTransportRequestHandler < FetchSearchRequest > { static final String ACTION = "search/phase/fetch/id" ; @ Override public FetchSearchRequest newInstance ( ) { } @ Override public void messageReceived ( FetchSearchRequest request , TransportChannel channel ) throws Exception { } @ Override public String executor ( ) { } } private class SearchQueryFetchScrollTransportHandler extends BaseTransportRequestHandler < InternalScrollSearchRequest > { static final String ACTION = "search/phase/query+fetch/scroll" ; @ Override public InternalScrollSearchRequest newInstance ( ) { } @ Override public void messageReceived ( InternalScrollSearchRequest request , TransportChannel channel ) throws Exception { } @ Override public String executor ( ) { } } private class SearchScanTransportHandler extends BaseTransportRequestHandler < ShardSearchRequest > { static final String ACTION = "search/phase/scan" ;<BUG2FIX>} catch ( Throwable e ) {
public class MultiMatchQueryBuilder extends BaseQueryBuilder implements BoostableQueryBuilder < MultiMatchQueryBuilder > { private final Object text ; private final List < String > fields ; private ObjectFloatOpenHashMap < String > fieldsBoosts ; private MultiMatchQueryBuilder . Type type ; private Operator operator ; private String analyzer ; private Float boost ; private Integer slop ; private Fuzziness fuzziness ; private Integer prefixLength ; private Integer maxExpansions ; private String minimumShouldMatch ; private String rewrite = null ; private String fuzzyRewrite = null ; private Boolean useDisMax ; private Float tieBreaker ; private Boolean lenient ; private Float cutoffFrequency = null ; private ZeroTermsQuery zeroTermsQuery = null ; private String queryName ; public enum Type { BEST_FIELDS ( MatchQuery . Type . BOOLEAN , 0.0F , new ParseField ( "best_fields" , "boolean" ) ) , MOST_FIELDS ( MatchQuery . Type . BOOLEAN , 1.0F , new ParseField ( "most_fields" ) ) , CROSS_FIELDS ( MatchQuery . Type . BOOLEAN , 0.0F , new ParseField ( "cross_fields" ) ) , PHRASE ( MatchQuery . Type . PHRASE , 0.0F , new ParseField ( "phrase" ) ) , PHRASE_PREFIX ( MatchQuery . Type . PHRASE_PREFIX , 0.0F , new ParseField ( "phrase_prefix" ) ) ; private MatchQuery . Type matchQueryType ; private final float tieBreaker ; private final ParseField parseField ; Type ( MatchQuery . Type matchQueryType , float tieBreaker , ParseField parseField ) { } public float tieBreaker ( ) { } public MatchQuery . Type matchQueryType ( ) { } public ParseField parseField ( ) { } public static MultiMatchQueryBuilder . Type parse ( String value ) { } public static MultiMatchQueryBuilder . Type parse ( String value , EnumSet < ParseField . Flag > flags ) { } } public MultiMatchQueryBuilder ( Object text , String ... fields ) { } public MultiMatchQueryBuilder field ( String field ) { } public MultiMatchQueryBuilder field ( String field , float boost ) { fields . add ( field ) ; if ( ( fieldsBoosts ) == null ) { <START_BUG> fieldsBoosts = new ObjectFloatOpenHashMap < String > ( ) ; <END_BUG> } fieldsBoosts . put ( field , boost ) ; return this ; } public MultiMatchQueryBuilder type ( MultiMatchQueryBuilder . Type type ) { } public MultiMatchQueryBuilder type ( Object type ) { } public MultiMatchQueryBuilder operator ( MatchQueryBuilder . Operator operator ) { } public MultiMatchQueryBuilder analyzer ( String analyzer ) { } public MultiMatchQueryBuilder boost ( float boost ) { } public MultiMatchQueryBuilder slop ( int slop ) { } public MultiMatchQueryBuilder fuzziness ( Object fuzziness ) { } public MultiMatchQueryBuilder prefixLength ( int prefixLength ) { } public MultiMatchQueryBuilder maxExpansions ( int maxExpansions ) { } public MultiMatchQueryBuilder minimumShouldMatch ( String minimumShouldMatch ) { } public MultiMatchQueryBuilder rewrite ( String rewrite ) { } public MultiMatchQueryBuilder fuzzyRewrite ( String fuzzyRewrite ) { } @ Deprecated public MultiMatchQueryBuilder useDisMax ( boolean useDisMax ) { } public MultiMatchQueryBuilder tieBreaker ( float tieBreaker ) { } public MultiMatchQueryBuilder lenient ( boolean lenient ) { } public MultiMatchQueryBuilder cutoffFrequency ( float cutoff ) { } public MultiMatchQueryBuilder zeroTermsQuery ( MatchQueryBuilder . ZeroTermsQuery zeroTermsQuery ) { } public MultiMatchQueryBuilder queryName ( String queryName ) { } @ Override public void doXContent ( XContentBuilder builder , Params params ) throws IOException { } }<BUG2FIX>fieldsBoosts = new ObjectFloatOpenHashMap ( ) ;
public class TransportDeleteIndexAction extends TransportMasterNodeOperationAction < DeleteIndexRequest , DeleteIndexResponse > { private final MetaDataDeleteIndexService deleteIndexService ; private final DestructiveOperations destructiveOperations ; @ Inject public TransportDeleteIndexAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool , MetaDataDeleteIndexService deleteIndexService , NodeSettingsService nodeSettingsService ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected DeleteIndexRequest newRequest ( ) { } @ Override protected DeleteIndexResponse newResponse ( ) { } @ Override protected void doExecute ( DeleteIndexRequest request , ActionListener < DeleteIndexResponse > listener ) { } @ Override protected ClusterBlockException checkBlock ( DeleteIndexRequest request , ClusterState state ) { } @ Override protected void masterOperation ( final DeleteIndexRequest request , final ClusterState state , final ActionListener < DeleteIndexResponse > listener ) throws ElasticsearchException { <START_BUG> request . indices ( state . metaData ( ) . concreteIndices ( request . indices ( ) , request . indicesOptions ( ) ) ) ; <END_BUG> if ( ( request . indices ( ) . length ) == 0 ) { listener . onResponse ( new DeleteIndexResponse ( true ) ) ; return ; } final CountDown count = new CountDown ( request . indices ( ) . length ) ; for ( final String index : request . indices ( ) ) { deleteIndexService . deleteIndex ( new MetaDataDeleteIndexService . Request ( index ) . timeout ( request . timeout ( ) ) . masterTimeout ( request . masterNodeTimeout ( ) ) , new MetaDataDeleteIndexService . Listener ( ) { private volatile Throwable lastFailure ; private volatile boolean ack = true ; @ Override public void onResponse ( MetaDataDeleteIndexService . Response response ) { if ( ! ( response . acknowledged ( ) ) ) { ack = false ; } if ( count . countDown ( ) ) { if ( ( lastFailure ) != null ) { listener . onFailure ( lastFailure ) ; } else { listener . onResponse ( new DeleteIndexResponse ( ack ) ) ; } } } @ Override public void onFailure ( Throwable t ) { logger . debug ( "[{}]<seq2seq4repair_space>failed<seq2seq4repair_space>to<seq2seq4repair_space>delete<seq2seq4repair_space>index" , t , index ) ; lastFailure = t ; if ( count . countDown ( ) ) { listener . onFailure ( t ) ; } } } ) ; } } }<BUG2FIX>request . indices ( state . metaData ( ) . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ) ;
public class FieldsTermsStringFacetCollector extends AbstractFacetCollector { private final FieldDataCache fieldDataCache ; private final String [ ] indexFieldsNames ; private final ComparatorType comparatorType ; private final int size ; private final int numberOfShards ; private final FieldDataType [ ] fieldsDataType ; private FieldData [ ] fieldsData ; private final FieldsTermsStringFacetCollector . StaticAggregatorValueProc aggregator ; private final SearchScript script ; public FieldsTermsStringFacetCollector ( String facetName , String [ ] fieldsNames , int size , InternalStringTermsFacet . ComparatorType comparatorType , boolean allTerms , SearchContext context , ImmutableSet < BytesRef > excluded , Pattern pattern , String scriptLang , String script , Map < String , Object > params ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override protected void doSetNextReader ( AtomicReaderContext context ) throws IOException { for ( int i = 0 ; i < ( indexFieldsNames . length ) ; i ++ ) { fieldsData [ i ] = fieldDataCache . cache ( fieldsDataType [ i ] , context . reader ( ) , indexFieldsNames [ i ] ) ; } if ( ( script ) != null ) { <START_BUG> script . setNextReader ( context . reader ( ) ) ; <END_BUG> } } @ Override protected void doCollect ( int doc ) throws IOException { } @ Override public Facet facet ( ) { } public static class AggregatorValueProc extends FieldsTermsStringFacetCollector . StaticAggregatorValueProc { private final ImmutableSet < BytesRef > excluded ; private final Matcher matcher ; private final SearchScript script ; public AggregatorValueProc ( TObjectIntHashMap < BytesRef > facets , ImmutableSet < BytesRef > excluded , Pattern pattern , SearchScript script ) { } @ Override public void onValue ( int docId , BytesRef value ) { } } public static class StaticAggregatorValueProc implements FieldData . StringValueInDocProc , FieldData . StringValueProc { private final TObjectIntHashMap < BytesRef > facets ; private int missing ; private int total ; public StaticAggregatorValueProc ( TObjectIntHashMap < BytesRef > facets ) { } @ Override public void onValue ( BytesRef value ) { } @ Override public void onValue ( int docId , BytesRef value ) { } @ Override public void onMissing ( int docId ) { } public final TObjectIntHashMap < BytesRef > facets ( ) { } public final int missing ( ) { } public final int total ( ) { } } }<BUG2FIX>script . setNextReader ( context ) ;
public class RestGetWarmerAction extends BaseRestHandler { @ Inject public RestGetWarmerAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { final String [ ] indices = splitIndices ( request . param ( "index" ) ) ; final String name = request . param ( "name" ) ; ClusterStateRequest clusterStateRequest = Requests . clusterStateRequest ( ) . filterAll ( ) . filterMetaData ( false ) . filteredIndices ( indices ) ; clusterStateRequest . listenerThreaded ( false ) ; client . admin ( ) . cluster ( ) . state ( clusterStateRequest , new org . elasticsearch . action . ActionListener < ClusterStateResponse > ( ) { @ Override public void onResponse ( ClusterStateResponse response ) { try { MetaData metaData = response . getState ( ) . metaData ( ) ; if ( ( ( indices . length ) == 1 ) && ( metaData . indices ( ) . isEmpty ( ) ) ) { channel . sendResponse ( new XContentThrowableRestResponse ( request , new org . elasticsearch . indices . IndexMissingException ( new Index ( indices [ 0 ] ) ) ) ) ; return ; } XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; boolean wroteOne = false ; for ( IndexMetaData indexMetaData : metaData ) { IndexWarmersMetaData warmers = indexMetaData . custom ( TYPE ) ; if ( warmers == null ) { continue ; } boolean foundOne = false ; for ( IndexWarmersMetaData . Entry entry : warmers . entries ( ) ) { if ( ( name == null ) || ( Regex . simpleMatch ( name , entry . name ( ) ) ) ) { foundOne = true ; wroteOne = true ; break ; } } if ( foundOne ) { builder . startObject ( indexMetaData . index ( ) , NONE ) ; builder . startObject ( TYPE , NONE ) ; for ( IndexWarmersMetaData . Entry entry : warmers . entries ( ) ) { if ( ( name == null ) || ( Regex . simpleMatch ( name , entry . name ( ) ) ) ) { FACTORY . toXContent ( entry , builder , request ) ; } } builder . endObject ( ) ; builder . endObject ( ) ; } } builder . endObject ( ) ; if ( ( ! wroteOne ) && ( name != null ) ) { channel . sendResponse ( new XContentThrowableRestResponse ( request , new IndexWarmerMissingException ( name ) ) ) ; return ; } channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class ScriptTermsStringFieldFacetCollector extends AbstractFacetCollector { private final ComparatorType comparatorType ; private final int size ; private final int numberOfShards ; private final SearchScript script ; private final Matcher matcher ; private final ImmutableSet < BytesRef > excluded ; private final TObjectIntHashMap < BytesRef > facets ; private int missing ; private int total ; public ScriptTermsStringFieldFacetCollector ( String facetName , int size , InternalStringTermsFacet . ComparatorType comparatorType , SearchContext context , ImmutableSet < BytesRef > excluded , Pattern pattern , String scriptLang , String script , Map < String , Object > params ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override protected void doSetNextReader ( AtomicReaderContext context ) throws IOException { <START_BUG> script . setNextReader ( context . reader ( ) ) ; <END_BUG> } @ Override protected void doCollect ( int doc ) throws IOException { } private boolean match ( String value ) { } @ Override public Facet facet ( ) { } }<BUG2FIX>script . setNextReader ( context ) ;
public class BulletTestCollection extends GdxTest implements InputProcessor , GestureListener { protected final BulletTest [ ] tests = new BulletTest [ ] { new ShootTest ( ) , new KinematicTest ( ) , new ConstraintsTest ( ) , new MeshShapeTest ( ) , new ConvexHullTest ( ) , new RayCastTest ( ) , new RayPickRagdollTest ( ) , new InternalTickTest ( ) , new CollisionWorldTest ( ) , new CollisionTest ( ) , new FrustumCullingTest ( ) , new ContactCallbackTest ( ) , new SoftBodyTest ( ) , new SoftMeshTest ( ) } ; protected int testIndex = 0 ; private Application app = null ; private BitmapFont font ; private Stage hud ; private Label fpsLabel ; private Label titleLabel ; private Label instructLabel ; private int loading = 0 ; @ Override public void render ( ) { } @ Override public void create ( ) { } @ Override public void dispose ( ) { } public void next ( ) { } public void loadnext ( ) { } @ Override public boolean keyDown ( int keycode ) { } @ Override public boolean keyTyped ( char character ) { } @ Override public boolean keyUp ( int keycode ) { } @ Override public boolean touchDown ( int x , int y , int pointer , int button ) { } @ Override public boolean touchDragged ( int x , int y , int pointer ) { } @ Override public boolean touchUp ( int x , int y , int pointer , int button ) { } @ Override public boolean needsGL20 ( ) { <START_BUG> return true ; <END_BUG> } @ Override public boolean mouseMoved ( int x , int y ) { } @ Override public boolean scrolled ( int amount ) { } @ Override public boolean touchDown ( float x , float y , int pointer , int button ) { } @ Override public boolean tap ( float x , float y , int count , int button ) { } @ Override public boolean longPress ( float x , float y ) { } @ Override public boolean fling ( float velocityX , float velocityY , int button ) { } @ Override public boolean pan ( float x , float y , float deltaX , float deltaY ) { } @ Override public boolean zoom ( float originalDistance , float currentDistance ) { } @ Override public boolean pinch ( Vector2 initialFirstPointer , Vector2 initialSecondPointer , Vector2 firstPointer , Vector2 secondPointer ) { } }<BUG2FIX>return false ;
public class BitmapFontCache { private final BitmapFont font ; private float [ ] vertices = new float [ 0 ] ; private int idx ; private float x ; private float y ; private float color = WHITE . toFloatBits ( ) ; private final Color tempColor = new Color ( Color . WHITE ) ; private final TextBounds textBounds = new TextBounds ( ) ; private boolean integer = true ; public BitmapFontCache ( BitmapFont font ) { } public BitmapFontCache ( BitmapFont font , boolean integer ) { } public void setPosition ( float x , float y ) { } public void translate ( float xAmount , float yAmount ) { } public void setColor ( float color ) { } public void setColor ( Color tint ) { } public void setColor ( float r , float g , float b , float a ) { } public void setColor ( Color tint , int start , int end ) { } public void draw ( SpriteBatch spriteBatch ) { } public void draw ( SpriteBatch spriteBatch , float alphaModulation ) { } public Color getColor ( ) { } public void clear ( ) { } private void require ( int glyphCount ) { } private float addToCache ( CharSequence str , float x , float y , int start , int end ) { } private void addGlyph ( Glyph glyph , float x , float y , float width , float height ) { float x2 = x + width ; float y2 = y + height ; final float u = glyph . u ; final float u2 = glyph . u2 ; final float v = glyph . v ; final float v2 = glyph . v2 ; final float [ ] vertices = this . vertices ; if ( integer ) { x = Math . round ( x ) ; y = Math . round ( y ) ; x2 = Math . round ( x2 ) ; y2 = Math . round ( y2 ) ; } int idx = this . idx ; this . idx += 20 ; vertices [ ( idx ++ ) ] = x ; vertices [ ( idx ++ ) ] = y ; vertices [ ( idx ++ ) ] = color ; vertices [ ( idx ++ ) ] = u ; vertices [ ( idx ++ ) ] = v ; vertices [ ( idx ++ ) ] = x ; vertices [ ( idx ++ ) ] = y2 ; vertices [ ( idx ++ ) ] = color ; vertices [ ( idx ++ ) ] = u ; vertices [ ( idx ++ ) ] = v2 ; vertices [ ( idx ++ ) ] = x2 ; vertices [ ( idx ++ ) ] = y2 ; vertices [ ( idx ++ ) ] = color ; vertices [ ( idx ++ ) ] = u2 ; vertices [ ( idx ++ ) ] = v2 ; vertices [ ( idx ++ ) ] = x2 ; vertices [ ( idx ++ ) ] = y ; vertices [ ( idx ++ ) ] = color ; vertices [ ( idx ++ ) ] = u2 ; <START_BUG> vertices [ idx ] = v ; <END_BUG> } public TextBounds setText ( CharSequence str , float x , float y ) { } public TextBounds setText ( CharSequence str , float x , float y , int start , int end ) { } public TextBounds addText ( CharSequence str , float x , float y ) { } public TextBounds addText ( CharSequence str , float x , float y , int start , int end ) { } public TextBounds setMultiLineText ( CharSequence str , float x , float y ) { } public TextBounds setMultiLineText ( CharSequence str , float x , float y , float alignmentWidth , HAlignment alignment ) { } public TextBounds addMultiLineText ( CharSequence str , float x , float y ) { } public TextBounds addMultiLineText ( CharSequence str , float x , float y , float alignmentWidth , HAlignment alignment ) { } public TextBounds setWrappedText ( CharSequence str , float x , float y , float wrapWidth ) { } public TextBounds setWrappedText ( CharSequence str , float x , float y , float wrapWidth , HAlignment alignment ) { } public TextBounds addWrappedText ( CharSequence str , float x , float y , float wrapWidth ) { } public TextBounds addWrappedText ( CharSequence str , float x , float y , float wrapWidth , HAlignment alignment ) { } public TextBounds getBounds ( ) { } public float getX ( ) { } public float getY ( ) { } public BitmapFont getFont ( ) { } public void setUseIntegerPositions ( boolean use ) { } public boolean usesIntegerPositions ( ) { } public float [ ] getVertices ( ) { } }<BUG2FIX>vertices [ ( idx ++ ) ] = v ;
public class AnalyzerMapper implements InternalMapper , Mapper , RootMapper { public static final String NAME = "_analyzer" ; public static final String CONTENT_TYPE = "_analyzer" ; public static class Defaults { public static final String PATH = "_analyzer" ; } public static class Builder extends Mapper . Builder < AnalyzerMapper . Builder , AnalyzerMapper > { private String field = AnalyzerMapper . Defaults . PATH ; public Builder ( ) { } public AnalyzerMapper . Builder field ( String field ) { } @ Override public AnalyzerMapper build ( BuilderContext context ) { } } public static class TypeParser implements Mapper . TypeParser { @ Override public Mapper . Builder parse ( String name , Map < String , Object > node , ParserContext parserContext ) throws MapperParsingException { } } private final String path ; public AnalyzerMapper ( ) { } public AnalyzerMapper ( String path ) { } @ Override public String name ( ) { } @ Override public void preParse ( ParseContext context ) throws IOException { } @ Override public void postParse ( ParseContext context ) throws IOException { Analyzer analyzer = context . docMapper ( ) . mappers ( ) . indexAnalyzer ( ) ; if ( ( path ) != null ) { String value = null ; List < IndexableField > fields = context . doc ( ) . getFields ( ) ; for ( int i = 0 , fieldsSize = fields . size ( ) ; i < fieldsSize ; i ++ ) { IndexableField field = fields . get ( i ) ; <START_BUG> if ( ( field . name ( ) ) == ( path ) ) { <END_BUG> value = field . stringValue ( ) ; break ; } } if ( value == null ) { value = context . ignoredValue ( path ) ; } if ( value != null ) { analyzer = context . analysisService ( ) . analyzer ( value ) ; if ( analyzer == null ) { throw new MapperParsingException ( ( ( ( ( "No<seq2seq4repair_space>analyzer<seq2seq4repair_space>found<seq2seq4repair_space>for<seq2seq4repair_space>[" + value ) + "]<seq2seq4repair_space>from<seq2seq4repair_space>path<seq2seq4repair_space>[" ) + ( path ) ) + "]" ) ) ; } analyzer = context . docMapper ( ) . mappers ( ) . indexAnalyzer ( analyzer ) ; } } context . analyzer ( analyzer ) ; } @ Override public boolean includeInObject ( ) { } public Analyzer setAnalyzer ( HighlighterContext context ) { } @ Override public void parse ( ParseContext context ) throws IOException { } @ Override public void merge ( Mapper mergeWith , MergeContext mergeContext ) throws MergeMappingException { } @ Override public void traverse ( FieldMapperListener fieldMapperListener ) { } @ Override public void traverse ( ObjectMapperListener objectMapperListener ) { } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } @ Override public void close ( ) { } }<BUG2FIX>if ( field . name ( ) . equals ( path ) ) {
public class RangeFacetParser extends AbstractComponent implements FacetParser { @ Inject public RangeFacetParser ( Settings settings ) { } @ Override public String [ ] types ( ) { } @ Override public Mode defaultMainMode ( ) { } @ Override public Mode defaultGlobalMode ( ) { } @ Override public FacetExecutor parse ( String facetName , XContentParser parser , SearchContext context ) throws IOException { String keyField = null ; String valueField = null ; String scriptLang = null ; String keyScript = null ; String valueScript = null ; Map < String , Object > params = null ; XContentParser . Token token ; String fieldName = null ; List < RangeFacet . Entry > entries = Lists . newArrayList ( ) ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { fieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_ARRAY ) ) { if ( ! ( "ranges" . equals ( fieldName ) ) ) { keyField = fieldName ; } while ( ( token = parser . nextToken ( ) ) != ( Token . END_ARRAY ) ) { RangeFacet . Entry entry = new RangeFacet . Entry ( ) ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { fieldName = parser . currentName ( ) ; } else if ( token == ( Token . VALUE_STRING ) ) { if ( "from" . equals ( fieldName ) ) { entry . fromAsString = parser . text ( ) ; } else if ( "to" . equals ( fieldName ) ) { entry . toAsString = parser . text ( ) ; } } else if ( token . isValue ( ) ) { if ( "from" . equals ( fieldName ) ) { entry . from = parser . doubleValue ( ) ; } else if ( "to" . equals ( fieldName ) ) { entry . to = parser . doubleValue ( ) ; } } } entries . add ( entry ) ; } } else if ( token == ( Token . START_OBJECT ) ) { if ( "params" . equals ( fieldName ) ) { params = parser . map ( ) ; } } else if ( token . isValue ( ) ) { if ( "field" . equals ( fieldName ) ) { keyField = parser . text ( ) ; } else if ( ( "key_field" . equals ( fieldName ) ) || ( "keyField" . equals ( fieldName ) ) ) { keyField = parser . text ( ) ; } else if ( ( "value_field" . equals ( fieldName ) ) || ( "valueField" . equals ( fieldName ) ) ) { valueField = parser . text ( ) ; } else if ( ( "key_script" . equals ( fieldName ) ) || ( "keyScript" . equals ( fieldName ) ) ) { keyScript = parser . text ( ) ; } else if ( ( "value_script" . equals ( fieldName ) ) || ( "valueScript" . equals ( fieldName ) ) ) { valueScript = parser . text ( ) ; } else if ( "lang" . equals ( fieldName ) ) { scriptLang = parser . text ( ) ; } } } if ( entries . isEmpty ( ) ) { throw new FacetPhaseExecutionException ( facetName , "no<seq2seq4repair_space>ranges<seq2seq4repair_space>defined<seq2seq4repair_space>for<seq2seq4repair_space>range<seq2seq4repair_space>facet" ) ; } RangeFacet [ ] rangeEntries = entries . toArray ( new RangeFacet . Entry [ entries . size ( ) ] ) ; if ( ( keyScript != null ) && ( valueScript != null ) ) { return new ScriptRangeFacetExecutor ( scriptLang , keyScript , valueScript , params , rangeEntries , context ) ; } if ( keyField == null ) { throw new FacetPhaseExecutionException ( facetName , "key<seq2seq4repair_space>field<seq2seq4repair_space>is<seq2seq4repair_space>required<seq2seq4repair_space>to<seq2seq4repair_space>be<seq2seq4repair_space>set<seq2seq4repair_space>for<seq2seq4repair_space>range<seq2seq4repair_space>facet,<seq2seq4repair_space>either<seq2seq4repair_space>using<seq2seq4repair_space>[field]<seq2seq4repair_space>or<seq2seq4repair_space>using<seq2seq4repair_space>[key_field]" ) ; } FieldMapper keyFieldMapper = context . smartNameFieldMapper ( keyField ) ; if ( keyFieldMapper == null ) { throw new FacetPhaseExecutionException ( facetName , ( ( "No<seq2seq4repair_space>mapping<seq2seq4repair_space>found<seq2seq4repair_space>for<seq2seq4repair_space>key_field<seq2seq4repair_space>[" + keyField ) + "]" ) ) ; } for ( RangeFacet . Entry entry : rangeEntries ) { if ( ( entry . fromAsString ) != null ) { entry . from = ( ( Number ) ( keyFieldMapper . value ( entry . fromAsString ) ) ) . doubleValue ( ) ; } if ( ( entry . toAsString ) != null ) { entry . to = ( ( Number ) ( keyFieldMapper . value ( entry . toAsString ) ) ) . doubleValue ( ) ; } } IndexNumericFieldData keyIndexFieldData = context . fieldData ( ) . getForField ( keyFieldMapper ) ; if ( ( valueField == null ) || ( keyField . equals ( valueField ) ) ) { return new RangeFacetExecutor ( keyIndexFieldData , rangeEntries , context ) ; } else { FieldMapper valueFieldMapper = context . smartNameFieldMapper ( valueField ) ; if ( valueFieldMapper == null ) { <START_BUG> throw new FacetPhaseExecutionException ( facetName , ( ( "No<seq2seq4repair_space>mapping<seq2seq4repair_space>found<seq2seq4repair_space>for<seq2seq4repair_space>value_field<seq2seq4repair_space>[" + keyField ) + "]" ) ) ; <END_BUG> } IndexNumericFieldData valueIndexFieldData = context . fieldData ( ) . getForField ( valueFieldMapper ) ; return new KeyValueRangeFacetExecutor ( keyIndexFieldData , valueIndexFieldData , rangeEntries , context ) ; } } }<BUG2FIX>throw new FacetPhaseExecutionException ( facetName , ( ( "No<seq2seq4repair_space>mapping<seq2seq4repair_space>found<seq2seq4repair_space>for<seq2seq4repair_space>value_field<seq2seq4repair_space>[" + valueField ) + "]" ) ) ;
public class MultiValueGeoPointFieldData extends GeoPointFieldData { private static final int VALUE_CACHE_SIZE = 100 ; private static ThreadLocal < ThreadLocals . CleanableValue < GeoPoint [ ] [ ] > > valuesArrayCache = new ThreadLocal < ThreadLocals . CleanableValue < GeoPoint [ ] [ ] > > ( ) { @ Override protected ThreadLocals . CleanableValue < GeoPoint [ ] [ ] > initialValue ( ) { } } ; private ThreadLocal < ThreadLocals . CleanableValue < double [ ] [ ] > > valuesLatCache = new ThreadLocal < ThreadLocals . CleanableValue < double [ ] [ ] > > ( ) { @ Override protected ThreadLocals . CleanableValue < double [ ] [ ] > initialValue ( ) { } } ; private ThreadLocal < ThreadLocals . CleanableValue < double [ ] [ ] > > valuesLonCache = new ThreadLocal < ThreadLocals . CleanableValue < double [ ] [ ] > > ( ) { @ Override protected ThreadLocals . CleanableValue < double [ ] [ ] > initialValue ( ) { } } ; private final int [ ] [ ] ordinals ; public MultiValueGeoPointFieldData ( String fieldName , int [ ] [ ] ordinals , double [ ] lat , double [ ] lon ) { } @ Override protected long computeSizeInBytes ( ) { } @ Override public boolean multiValued ( ) { } @ Override public boolean hasValue ( int docId ) { } @ Override public void forEachValueInDoc ( int docId , StringValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , ValueInDocProc proc ) { } @ Override public void forEachOrdinalInDoc ( int docId , OrdinalInDocProc proc ) { boolean found = false ; for ( int [ ] ordinal : ordinals ) { int loc = ordinal [ docId ] ; if ( loc != 0 ) { found = true ; <START_BUG> proc . onOrdinal ( docId , ordinal [ docId ] ) ; <END_BUG> } } if ( ! found ) { proc . onOrdinal ( docId , 0 ) ; } } @ Override public GeoPoint value ( int docId ) { } @ Override public GeoPoint [ ] values ( int docId ) { } @ Override public double latValue ( int docId ) { } @ Override public double lonValue ( int docId ) { } @ Override public double [ ] latValues ( int docId ) { } @ Override public double [ ] lonValues ( int docId ) { } }<BUG2FIX>proc . onOrdinal ( docId , loc ) ;
public class FsChannelSnapshot implements Translog . Snapshot { private final long id ; private final int totalOperations ; private final RafReference raf ; private final FileChannel channel ; private final long length ; private Operation lastOperationRead = null ; private int position = 0 ; private ByteBuffer cacheBuffer ; public FsChannelSnapshot ( long id , RafReference raf , long length , int totalOperations ) throws FileNotFoundException { } @ Override public long translogId ( ) { } @ Override public long position ( ) { } @ Override public long length ( ) { } @ Override public int estimatedTotalOperations ( ) { } @ Override public InputStream stream ( ) throws IOException { } @ Override public long lengthInBytes ( ) { } @ Override public boolean hasNext ( ) { try { if ( ( position ) > ( length ) ) { return false ; } if ( ( cacheBuffer ) == null ) { cacheBuffer = ByteBuffer . allocate ( 1024 ) ; } cacheBuffer . limit ( 4 ) ; int bytesRead = channel . read ( cacheBuffer , position ) ; if ( bytesRead < 4 ) { return false ; } cacheBuffer . flip ( ) ; int opSize = cacheBuffer . getInt ( ) ; position += 4 ; if ( ( ( position ) + opSize ) > ( length ) ) { position -= 4 ; return false ; } if ( ( cacheBuffer . capacity ( ) ) < opSize ) { cacheBuffer = ByteBuffer . allocate ( opSize ) ; } cacheBuffer . clear ( ) ; cacheBuffer . limit ( opSize ) ; channel . read ( cacheBuffer , position ) ; cacheBuffer . flip ( ) ; position += opSize ; <START_BUG> lastOperationRead = TranslogStreams . readTranslogOperation ( new BytesStreamInput ( cacheBuffer . array ( ) , 0 , opSize ) ) ; <END_BUG> return true ; } catch ( Exception e ) { return false ; } } @ Override public Operation next ( ) { } @ Override public void seekForward ( long length ) { } @ Override public boolean release ( ) throws ElasticSearchException { } }<BUG2FIX>lastOperationRead = TranslogStreams . readTranslogOperation ( new BytesStreamInput ( cacheBuffer . array ( ) , 0 , opSize , true ) ) ;
public class Facets implements Iterable < Facet > , Streamable , ToXContent { private final List < Facet > EMPTY = ImmutableList . of ( ) ; private List < Facet > facets = EMPTY ; private Map < String , Facet > facetsAsMap ; private Facets ( ) { } public Facets ( List < Facet > facets ) { } @ Override public Iterator < Facet > iterator ( ) { } public List < Facet > facets ( ) { } public Map < String , Facet > getFacets ( ) { <START_BUG> return facetsAsMap ; <END_BUG> } public Map < String , Facet > facetsAsMap ( ) { } public CountFacet . CountFacet countFacet ( String name ) { } public Facet facet ( String name ) { } @ Override public void toXContent ( XContentBuilder builder , Params params ) throws IOException { } public static Facets readFacets ( StreamInput in ) throws IOException { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } }<BUG2FIX>return facetsAsMap ( ) ;
public class TransportIndicesExistsAction extends TransportMasterNodeReadOperationAction < IndicesExistsRequest , IndicesExistsResponse > { @ Inject public TransportIndicesExistsAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected IndicesExistsRequest newRequest ( ) { } @ Override protected IndicesExistsResponse newResponse ( ) { } @ Override protected void doExecute ( IndicesExistsRequest request , ActionListener < IndicesExistsResponse > listener ) { } @ Override protected ClusterBlockException checkBlock ( IndicesExistsRequest request , ClusterState state ) { } @ Override protected void masterOperation ( final IndicesExistsRequest request , final ClusterState state , final ActionListener < IndicesExistsResponse > listener ) throws ElasticsearchException { boolean exists ; try { <START_BUG> clusterService . state ( ) . metaData ( ) . concreteIndices ( request . indices ( ) , request . indicesOptions ( ) ) ; <END_BUG> exists = true ; } catch ( IndexMissingException e ) { exists = false ; } listener . onResponse ( new IndicesExistsResponse ( exists ) ) ; } }<BUG2FIX>clusterService . state ( ) . metaData ( ) . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ;
public class DateFieldMapper extends NumberFieldMapper < Long > { public static final String CONTENT_TYPE = "date" ; public static class Defaults extends NumberFieldMapper . Defaults { public static final FormatDateTimeFormatter DATE_TIME_FORMATTER = Joda . forPattern ( "dateOptionalTime" , Locale . ROOT ) ; public static final FieldType FIELD_TYPE = new FieldType ( NumberFieldMapper . Defaults . FIELD_TYPE ) ; public static final String NULL_VALUE = null ; public static final TimeUnit TIME_UNIT = TimeUnit . MILLISECONDS ; public static final boolean ROUND_CEIL = true ; } public static class Builder extends NumberFieldMapper . Builder < DateFieldMapper . Builder , DateFieldMapper > { protected TimeUnit timeUnit = DateFieldMapper . Defaults . TIME_UNIT ; protected String nullValue = DateFieldMapper . Defaults . NULL_VALUE ; protected FormatDateTimeFormatter dateTimeFormatter = DateFieldMapper . Defaults . DATE_TIME_FORMATTER ; private Locale locale ; public Builder ( String name ) { } public DateFieldMapper . Builder timeUnit ( TimeUnit timeUnit ) { } public DateFieldMapper . Builder nullValue ( String nullValue ) { } public DateFieldMapper . Builder dateTimeFormatter ( FormatDateTimeFormatter dateTimeFormatter ) { } @ Override public DateFieldMapper build ( BuilderContext context ) { } public DateFieldMapper . Builder locale ( Locale locale ) { } } public static class TypeParser implements Mapper . TypeParser { @ Override public Mapper . Builder < ? , ? > parse ( String name , Map < String , Object > node , ParserContext parserContext ) throws MapperParsingException { DateFieldMapper . Builder builder = MapperBuilders . dateField ( name ) ; TypeParsers . parseNumberField ( builder , name , node , parserContext ) ; for ( Map . Entry < String , Object > entry : node . entrySet ( ) ) { String propName = Strings . toUnderscoreCase ( entry . getKey ( ) ) ; Object propNode = entry . getValue ( ) ; if ( propName . equals ( "null_value" ) ) { builder . nullValue ( propNode . toString ( ) ) ; } else if ( propName . equals ( "format" ) ) { <START_BUG> builder . dateTimeFormatter ( TypeParsers . parseDateTimeFormatter ( propName , propNode ) ) ; <END_BUG> } else if ( propName . equals ( "numeric_resolution" ) ) { builder . timeUnit ( TimeUnit . valueOf ( propNode . toString ( ) . toUpperCase ( Locale . ROOT ) ) ) ; } else if ( propName . equals ( "locale" ) ) { builder . locale ( LocaleUtils . parse ( propNode . toString ( ) ) ) ; } } return builder ; } } protected FormatDateTimeFormatter dateTimeFormatter ; private final boolean roundCeil ; private final DateMathParser dateMathParser ; private String nullValue ; protected final TimeUnit timeUnit ; protected DateFieldMapper ( Names names , FormatDateTimeFormatter dateTimeFormatter , int precisionStep , float boost , FieldType fieldType , Boolean docValues , String nullValue , TimeUnit timeUnit , boolean roundCeil , Explicit < Boolean > ignoreMalformed , Explicit < Boolean > coerce , PostingsFormatProvider postingsProvider , DocValuesFormatProvider docValuesProvider , SimilarityProvider similarity , Loading normsLoading , @ Nullable Settings fieldDataSettings , Settings indexSettings , MultiFields multiFields , CopyTo copyTo ) { } public FormatDateTimeFormatter dateTimeFormatter ( ) { } public DateMathParser dateMathParser ( ) { } @ Override public FieldType defaultFieldType ( ) { } @ Override public FieldDataType defaultFieldDataType ( ) { } @ Override protected int maxPrecisionStep ( ) { } @ Override public Long value ( Object value ) { } @ Override public Object valueForSearch ( Object value ) { } @ Override public BytesRef indexedValueForSearch ( Object value ) { } private long parseValue ( Object value ) { } private String convertToString ( Object value ) { } @ Override public Query fuzzyQuery ( String value , Fuzziness fuzziness , int prefixLength , int maxExpansions , boolean transpositions ) { } @ Override public Query termQuery ( Object value , @ Nullable QueryParseContext context ) { } public long parseToMilliseconds ( Object value , @ Nullable QueryParseContext context ) { } public long parseToMilliseconds ( Object value , @ Nullable QueryParseContext context , boolean includeUpper ) { } public long parseToMilliseconds ( Object value , @ Nullable QueryParseContext context , boolean includeUpper , @ Nullable DateTimeZone zone ) { } public long parseToMilliseconds ( String value , @ Nullable QueryParseContext context , boolean includeUpper , @ Nullable DateTimeZone zone ) { } @ Override public Filter termFilter ( Object value , @ Nullable QueryParseContext context ) { } @ Override public Query rangeQuery ( Object lowerTerm , Object upperTerm , boolean includeLower , boolean includeUpper , @ Nullable QueryParseContext context ) { } public Query rangeQuery ( Object lowerTerm , Object upperTerm , boolean includeLower , boolean includeUpper , @ Nullable DateTimeZone timeZone , @ Nullable QueryParseContext context ) { } @ Override public Filter rangeFilter ( Object lowerTerm , Object upperTerm , boolean includeLower , boolean includeUpper , @ Nullable QueryParseContext context ) { } public Filter rangeFilter ( Object lowerTerm , Object upperTerm , boolean includeLower , boolean includeUpper , @ Nullable DateTimeZone timeZone , @ Nullable QueryParseContext context , @ Nullable Boolean explicitCaching ) { } @ Override public Filter rangeFilter ( QueryParseContext parseContext , Object lowerTerm , Object upperTerm , boolean includeLower , boolean includeUpper , @ Nullable QueryParseContext context ) { } public Filter rangeFilter ( QueryParseContext parseContext , Object lowerTerm , Object upperTerm , boolean includeLower , boolean includeUpper , @ Nullable DateTimeZone timeZone , @ Nullable QueryParseContext context , @ Nullable Boolean explicitCaching ) { } private boolean hasDateExpressionWithNoRounding ( String value ) { } @ Override public Filter nullValueFilter ( ) { } @ Override protected boolean customBoost ( ) { } @ Override protected void innerParseCreateField ( ParseContext context , List < Field > fields ) throws IOException { } @ Override protected String contentType ( ) { } @ Override public void merge ( Mapper mergeWith , MergeContext mergeContext ) throws MergeMappingException { }<BUG2FIX>builder . dateTimeFormatter ( TypeParsers . parseDateTimeFormatter ( propNode ) ) ;
public class MultiValueIntFieldData extends IntFieldData { private static final int VALUE_CACHE_SIZE = 10 ; private ThreadLocal < ThreadLocals . CleanableValue < double [ ] [ ] > > doublesValuesCache = new ThreadLocal < ThreadLocals . CleanableValue < double [ ] [ ] > > ( ) { @ Override protected ThreadLocals . CleanableValue < double [ ] [ ] > initialValue ( ) { } } ; private ThreadLocal < ThreadLocals . CleanableValue < int [ ] [ ] > > valuesCache = new ThreadLocal < ThreadLocals . CleanableValue < int [ ] [ ] > > ( ) { @ Override protected ThreadLocals . CleanableValue < int [ ] [ ] > initialValue ( ) { } } ; private final int [ ] [ ] ordinals ; public MultiValueIntFieldData ( String fieldName , int [ ] [ ] ordinals , int [ ] values ) { } @ Override protected long computeSizeInBytes ( ) { } @ Override public boolean multiValued ( ) { } @ Override public boolean hasValue ( int docId ) { } @ Override public void forEachValueInDoc ( int docId , StringValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , DoubleValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , LongValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , MissingDoubleValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , MissingLongValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , ValueInDocProc proc ) { } @ Override public void forEachOrdinalInDoc ( int docId , OrdinalInDocProc proc ) { boolean found = false ; for ( int [ ] ordinal : ordinals ) { int loc = ordinal [ docId ] ; if ( loc != 0 ) { found = true ; <START_BUG> proc . onOrdinal ( docId , ordinal [ docId ] ) ; <END_BUG> } } if ( ! found ) { proc . onOrdinal ( docId , 0 ) ; } } @ Override public double [ ] doubleValues ( int docId ) { } @ Override public int value ( int docId ) { } @ Override public int [ ] values ( int docId ) { } }<BUG2FIX>proc . onOrdinal ( docId , loc ) ;
public class JglfwApplication implements Application { JglfwGraphics graphics ; JglfwFiles files ; JglfwInput input ; JglfwNet net ; final ApplicationListener listener ; private final Array < Runnable > runnables = new Array ( ) ; private final Array < Runnable > executedRunnables = new Array ( ) ; private final Array < LifecycleListener > lifecycleListeners = new Array ( ) ; private final Map < String , Preferences > preferences = new HashMap ( ) ; private final JglfwClipboard clipboard = new JglfwClipboard ( ) ; private final GlfwCallbacks callbacks = new GlfwCallbacks ( ) ; private boolean forceExit ; private boolean runOnEDT ; volatile boolean running = true ; private int logLevel = LOG_INFO ; public JglfwApplication ( ApplicationListener listener ) { } public JglfwApplication ( ApplicationListener listener , String title , int width , int height , boolean useGL2 ) { } private static JglfwApplicationConfiguration createConfig ( String title , int width , int height , boolean useGL2 ) { } public JglfwApplication ( final ApplicationListener listener , final JglfwApplicationConfiguration config ) { } protected void exception ( Throwable ex ) { } void initialize ( JglfwApplicationConfiguration config ) { forceExit = config . forceExit ; <START_BUG> runOnEDT = config . runOnEDT ; <END_BUG> final Thread glThread = Thread . currentThread ( ) ; GdxNativesLoader . load ( ) ; boolean inputCallbacksOnAppKitThread = isMac ; if ( inputCallbacksOnAppKitThread ) Toolkit . getDefaultToolkit ( ) ; if ( ! ( glfwInit ( ) ) ) throw new GdxRuntimeException ( "Unable<seq2seq4repair_space>to<seq2seq4repair_space>initialize<seq2seq4repair_space>GLFW." ) ; Gdx . app = this ; Gdx . graphics = graphics = new JglfwGraphics ( config ) ; Gdx . files = files = new JglfwFiles ( ) ; Gdx . input = input = new JglfwInput ( this , inputCallbacksOnAppKitThread ) ; Gdx . net = net = new JglfwNet ( ) ; callbacks . add ( new GlfwCallbackAdapter ( ) { public void windowSize ( long window , final int width , final int height ) { Runnable runnable = new Runnable ( ) { public void run ( ) { graphics . sizeChanged ( width , height ) ; } } ; if ( ( Thread . currentThread ( ) ) != glThread ) postRunnable ( runnable ) ; else runnable . run ( ) ; } public void windowPos ( long window , final int x , final int y ) { Runnable runnable = new Runnable ( ) { public void run ( ) { graphics . positionChanged ( x , y ) ; } } ; if ( ( Thread . currentThread ( ) ) != glThread ) postRunnable ( runnable ) ; else runnable . run ( ) ; } public void windowRefresh ( long window ) { if ( ( Thread . currentThread ( ) ) == glThread ) render ( ) ; } public void error ( int error , String description ) { throw new GdxRuntimeException ( ( ( ( "GLFW<seq2seq4repair_space>error<seq2seq4repair_space>" + error ) + ":<seq2seq4repair_space>" ) + description ) ) ; } } ) ; glfwSetCallback ( callbacks ) ; start ( ) ; } protected void start ( ) { } void frame ( ) { } void render ( ) { } void end ( ) { } public ApplicationListener getApplicationListener ( ) { } public JglfwGraphics getGraphics ( ) { } public Audio getAudio ( ) { } public JglfwInput getInput ( ) { } public JglfwFiles getFiles ( ) { } public JglfwNet getNet ( ) { } public ApplicationType getType ( ) { } public int getVersion ( ) { } public long getJavaHeap ( ) { } public long getNativeHeap ( ) { } public Preferences getPreferences ( String name ) { } public Clipboard getClipboard ( ) { } public void postRunnable ( Runnable runnable ) { } public void exit ( ) { } public void setLogLevel ( int logLevel ) { } public void debug ( String tag , String message ) { } public void debug ( String tag , String message , Throwable exception ) { } public void log ( String tag , String message ) { } public void log ( String tag , String message , Exception exception ) { } public void error ( String tag , String message ) { } public void error ( String tag , String message , Throwable exception ) { } public void addLifecycleListener ( LifecycleListener listener ) { } public void removeLifecycleListener ( LifecycleListener listener ) { } public GlfwCallbacks getCallbacks ( ) { } }<BUG2FIX>runOnEDT = config . forceExit ;
public abstract class SnappyCompressedIndexInput extends CompressedIndexInput < SnappyCompressorContext > { protected int chunkSize ; protected int maxCompressedChunkLength ; protected byte [ ] inputBuffer ; public SnappyCompressedIndexInput ( IndexInput in , SnappyCompressorContext context ) throws IOException { } @ Override protected void readHeader ( IndexInput in ) throws IOException { } @ Override protected void doClose ( ) throws IOException { } @ Override <START_BUG> public Object clone ( ) { <END_BUG> SnappyCompressedIndexInput cloned = ( ( SnappyCompressedIndexInput ) ( super . clone ( ) ) ) ; cloned . inputBuffer = new byte [ inputBuffer . length ] ; return cloned ; } }<BUG2FIX>public IndexInput clone ( ) {
public interface Rescorer { public String name ( ) { } <START_BUG> public void rescore ( TopDocs topDocs , SearchContext context , RescoreSearchContext rescoreContext ) throws IOException ; <END_BUG> public Explanation explain ( int topLevelDocId , SearchContext context , RescoreSearchContext rescoreContext , Explanation sourceExplanation ) throws IOException { } public RescoreSearchContext parse ( XContentParser parser , SearchContext context ) throws IOException { } public void extractTerms ( SearchContext context , RescoreSearchContext rescoreContext , Set < Term > termsSet ) { } }<BUG2FIX>public TopDocs rescore ( TopDocs topDocs , SearchContext context , RescoreSearchContext rescoreContext ) throws IOException ;
} else if ( ! ( context . hasFieldNames ( ) ) ) { fieldSelector = new UidAndSourceFieldSelector ( ) ; } else if ( context . fieldNames ( ) . isEmpty ( ) ) { fieldSelector = UidFieldSelector . INSTANCE ; } else if ( context . fieldNames ( ) . get ( 0 ) . equals ( "*" ) ) { fieldSelector = AllButSourceFieldSelector . INSTANCE ; } else { FieldMappersFieldSelector fieldSelectorMapper = new FieldMappersFieldSelector ( ) ; for ( String fieldName : context . fieldNames ( ) ) { FieldMappers x = context . smartNameFieldMappers ( fieldName ) ; if ( ( x != null ) && ( x . mapper ( ) . stored ( ) ) ) { fieldSelectorMapper . add ( x ) ; } else { if ( extractFieldNames == null ) { extractFieldNames = Lists . newArrayList ( ) ; } extractFieldNames . add ( fieldName ) ; } } fieldSelectorMapper . add ( NAME ) ; fieldSelector = fieldSelectorMapper ; } InternalSearchHit [ ] hits = new InternalSearchHit [ context . docIdsToLoadSize ( ) ] ; for ( int index = 0 ; index < ( context . docIdsToLoadSize ( ) ) ; index ++ ) { int docId = context . docIdsToLoad ( ) [ ( ( context . docIdsToLoadFrom ( ) ) + index ) ] ; Document doc = loadDocument ( context , fieldSelector , docId ) ; Uid uid = extractUid ( context , doc ) ; DocumentMapper documentMapper = context . mapperService ( ) . documentMapper ( uid . type ( ) ) ; if ( documentMapper == null ) { throw new org . elasticsearch . indices . TypeMissingException ( new org . elasticsearch . index . Index ( context . shardTarget ( ) . index ( ) ) , uid . type ( ) , ( ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>find<seq2seq4repair_space>type<seq2seq4repair_space>loaded<seq2seq4repair_space>for<seq2seq4repair_space>doc<seq2seq4repair_space>[" + ( uid . id ( ) ) ) + "]" ) ) ; } byte [ ] source = extractSource ( doc , documentMapper ) ; InternalSearchHit searchHit = new InternalSearchHit ( docId , uid . id ( ) , uid . type ( ) , source , null ) ; hits [ index ] = searchHit ; for ( Object oField : doc . getFields ( ) ) { Fieldable field = ( ( Fieldable ) ( oField ) ) ; String name = field . name ( ) ; if ( name . equals ( NAME ) ) { continue ; } if ( name . equals ( SourceFieldMapper . NAME ) ) { continue ; } Object value = null ; FieldMappers fieldMappers = documentMapper . mappers ( ) . indexName ( field . name ( ) ) ; if ( fieldMappers != null ) { FieldMapper mapper = fieldMappers . mapper ( ) ; if ( mapper != null ) { name = mapper . names ( ) . fullName ( ) ; value = mapper . valueForSearch ( field ) ; } } if ( value == null ) { if ( field . isBinary ( ) ) { value = field . getBinaryValue ( ) ; } else { value = field . stringValue ( ) ; } } if ( ( searchHit . fieldsOrNull ( ) ) == null ) { searchHit . fields ( new HashMap < String , SearchHitField > ( 2 ) ) ; } SearchHitField hitField = searchHit . fields ( ) . get ( name ) ; if ( hitField == null ) { hitField = new InternalSearchHitField ( name , new ArrayList < Object > ( 2 ) ) ; searchHit . fields ( ) . put ( name , hitField ) ; } hitField . values ( ) . add ( value ) ; } int readerIndex = context . searcher ( ) . readerIndex ( docId ) ; IndexReader subReader = context . searcher ( ) . subReaders ( ) [ readerIndex ] ; int subDoc = docId - ( context . searcher ( ) . docStarts ( ) [ readerIndex ] ) ; context . lookup ( ) . setNextReader ( subReader ) ; <START_BUG> context . lookup ( ) . setNextDocId ( docId ) ; <END_BUG> if ( extractFieldNames != null ) { for ( String extractFieldName : extractFieldNames ) { Object value = context . lookup ( ) . source ( ) . extractValue ( extractFieldName ) ; if ( value != null ) { if ( ( searchHit . fieldsOrNull ( ) ) == null ) { searchHit . fields ( new HashMap < String , SearchHitField > ( 2 ) ) ; } SearchHitField hitField = searchHit . fields ( ) . get ( extractFieldName ) ; if ( hitField == null ) { hitField = new InternalSearchHitField ( extractFieldName , new ArrayList < Object > ( 2 ) ) ; searchHit . fields ( ) . put ( extractFieldName , hitField ) ; } hitField . values ( ) . add ( value ) ; } } } for ( SearchHitPhase hitPhase : hitPhases ) { SearchHitPhase . HitContext hitContext = new SearchHitPhase . HitContext ( ) ; if ( hitPhase . executionNeeded ( context ) ) { hitContext . reset ( searchHit , subReader , subDoc , doc ) ; hitPhase . execute ( context , hitContext ) ; } } } context . fetchResult ( ) . hits ( new org . elasticsearch . search . internal . InternalSearchHits ( hits , context . queryResult ( ) . topDocs ( ) . totalHits , context . queryResult ( ) . topDocs ( ) . getMaxScore ( ) ) ) ; } private byte [ ] extractSource ( Document doc , DocumentMapper documentMapper ) { } private Uid extractUid ( SearchContext context , Document doc ) { } private Document loadDocument ( SearchContext context , ResetFieldSelector fieldSelector , int docId ) { } }<BUG2FIX>context . lookup ( ) . setNextDocId ( subDoc ) ;
public class InterpolationTest extends GdxTest { Stage stage ; private Skin skin ; private Table table ; List < String > list ; String [ ] interpolationNames ; String selectedInterpolation ; private ShapeRenderer renderer ; float graphSize = 400 ; float steps = ( graphSize ) / 2 ; float time = 0 ; float duration = 2.5F ; Vector2 startPosition = new Vector2 ( ) ; Vector2 targetPosition = new Vector2 ( ) ; Vector2 position = new Vector2 ( ) ; void resetPositions ( ) { } Vector2 getPosition ( float time ) { } private Interpolation getInterpolation ( String name ) { } @ Override public void create ( ) { } public void render ( ) { } public void resize ( int width , int height ) { <START_BUG> stage . getViewport ( ) . update ( width , height ) ; <END_BUG> table . invalidateHierarchy ( ) ; renderer . setProjectionMatrix ( stage . getViewport ( ) . getCamera ( ) . combined ) ; } public void dispose ( ) { } }<BUG2FIX>stage . getViewport ( ) . update ( width , height , true ) ;
public class MoreLikeThisFieldJsonQueryBuilder extends BaseJsonQueryBuilder { private final String name ; private String likeText ; private float percentTermsToMatch = - 1 ; private int minTermFrequency = - 1 ; private int maxQueryTerms = - 1 ; private String [ ] stopWords = null ; private int minDocFreq = - 1 ; private int maxDocFreq = - 1 ; private int minWordLen = - 1 ; private int maxWordLen = - 1 ; private Boolean boostTerms = null ; private float boostTermsFactor = - 1 ; public MoreLikeThisFieldJsonQueryBuilder ( String name ) { } public MoreLikeThisFieldJsonQueryBuilder likeText ( String likeText ) { } public MoreLikeThisFieldJsonQueryBuilder percentTermsToMatch ( float percentTermsToMatch ) { } public MoreLikeThisFieldJsonQueryBuilder minTermFrequency ( int minTermFrequency ) { } public MoreLikeThisFieldJsonQueryBuilder maxQueryTerms ( int maxQueryTerms ) { } public MoreLikeThisFieldJsonQueryBuilder stopWords ( String ... stopWords ) { } public MoreLikeThisFieldJsonQueryBuilder minDocFreq ( int minDocFreq ) { } public MoreLikeThisFieldJsonQueryBuilder maxDocFreq ( int maxDocFreq ) { } public MoreLikeThisFieldJsonQueryBuilder minWordLen ( int minWordLen ) { } public MoreLikeThisFieldJsonQueryBuilder maxWordLen ( int maxWordLen ) { } <START_BUG> public MoreLikeThisFieldJsonQueryBuilder boostTerms ( boolean boostTerms ) { <END_BUG> this . boostTerms = boostTerms ; return this ; } public MoreLikeThisFieldJsonQueryBuilder boostTermsFactor ( float boostTermsFactor ) { } @ Override protected void doJson ( JsonBuilder builder , Params params ) throws IOException { } }<BUG2FIX>public MoreLikeThisFieldJsonQueryBuilder boostTerms ( Boolean boostTerms ) {
public LwjglApplication ( ApplicationListener listener , String title , int width , int height , boolean useGL2 ) { } public LwjglApplication ( ApplicationListener listener ) { } public LwjglApplication ( ApplicationListener listener , LwjglApplicationConfiguration config ) { } public LwjglApplication ( ApplicationListener listener , boolean useGL2 , Canvas canvas ) { } public LwjglApplication ( ApplicationListener listener , LwjglApplicationConfiguration config , Canvas canvas ) { } public LwjglApplication ( ApplicationListener listener , LwjglApplicationConfiguration config , LwjglGraphics graphics ) { } private static LwjglApplicationConfiguration createConfig ( String title , int width , int height , boolean useGL2 ) { } private void initialize ( ) { } void mainLoop ( ) { try { graphics . setupDisplay ( ) ; } catch ( LWJGLException e ) { throw new com . badlogic . gdx . utils . GdxRuntimeException ( e ) ; } listener . create ( ) ; listener . resize ( graphics . getWidth ( ) , graphics . getHeight ( ) ) ; graphics . resize = false ; int lastWidth = graphics . getWidth ( ) ; int lastHeight = graphics . getHeight ( ) ; graphics . lastTime = System . nanoTime ( ) ; boolean wasActive = true ; while ( running ) { Display . processMessages ( ) ; if ( Display . isCloseRequested ( ) ) exit ( ) ; boolean isActive = Display . isActive ( ) ; if ( wasActive && ( ! isActive ) ) { wasActive = false ; listener . pause ( ) ; } if ( ( ! wasActive ) && isActive ) { wasActive = true ; listener . resume ( ) ; } boolean shouldRender = false ; if ( ( graphics . canvas ) != null ) { int width = graphics . canvas . getWidth ( ) ; int height = graphics . canvas . getHeight ( ) ; if ( ( lastWidth != width ) || ( lastHeight != height ) ) { lastWidth = width ; lastHeight = height ; gl . glViewport ( 0 , 0 , lastWidth , lastHeight ) ; listener . resize ( lastWidth , lastHeight ) ; shouldRender = true ; } } else { graphics . config . x = Display . getX ( ) ; graphics . config . y = Display . getY ( ) ; if ( ( ( ( graphics . resize ) || ( Display . wasResized ( ) ) ) || ( ( Display . getWidth ( ) ) != ( graphics . config . width ) ) ) || ( ( Display . getHeight ( ) ) != ( graphics . config . height ) ) ) { graphics . resize = false ; gl . glViewport ( 0 , 0 , Display . getWidth ( ) , Display . getHeight ( ) ) ; graphics . config . width = Display . getWidth ( ) ; graphics . config . height = Display . getHeight ( ) ; if ( ( listener ) != null ) listener . resize ( Display . getWidth ( ) , Display . getHeight ( ) ) ; graphics . requestRendering ( ) ; } } synchronized ( runnables ) { executedRunnables . clear ( ) ; executedRunnables . addAll ( runnables ) ; runnables . clear ( ) ; } for ( int i = 0 ; i < ( executedRunnables . size ) ; i ++ ) { shouldRender = true ; executedRunnables . get ( i ) . run ( ) ; } if ( ! ( running ) ) break ; input . update ( ) ; shouldRender |= graphics . shouldRender ( ) ; input . processEvents ( ) ; if ( ( audio ) != null ) audio . update ( ) ; if ( ( ! isActive ) && ( ( graphics . config . backgroundFPS ) == ( - 1 ) ) ) shouldRender = false ; int frameRate = ( isActive ) ? graphics . config . foregroundFPS : graphics . config . backgroundFPS ; if ( shouldRender ) { graphics . updateTime ( ) ; listener . render ( ) ; <START_BUG> Display . update ( false ) ; <END_BUG> } else { if ( frameRate == ( - 1 ) ) frameRate = 10 ; if ( frameRate == 0 ) frameRate = graphics . config . backgroundFPS ; if ( frameRate == 0 ) frameRate = 30 ; } if ( frameRate > 0 ) Display . sync ( frameRate ) ; } Array < LifecycleListener > listeners = lifecycleListeners ; synchronized ( listeners ) { for ( LifecycleListener listener : listeners ) { listener . pause ( ) ; listener . dispose ( ) ; } } listener . pause ( ) ; listener . dispose ( ) ; Display . destroy ( ) ; if ( ( audio ) != null ) audio . dispose ( ) ; if ( graphics . config . forceExit ) System . exit ( ( - 1 ) ) ; } @ Override public ApplicationListener getApplicationListener ( ) { } @ Override public Audio getAudio ( ) { } @ Override public Files getFiles ( ) { } @ Override public LwjglGraphics getGraphics ( ) { } @ Override public Input getInput ( ) { } @ Override public Net getNet ( ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } public void stop ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } Map < String , Preferences > preferences = new HashMap < String , Preferences > ( ) ; @ Override public Preferences getPreferences ( String name ) { } @ Override public Clipboard getClipboard ( ) { } @ Override public void postRunnable ( Runnable runnable ) { }<BUG2FIX>Display . update ( ) ;
public class GamepadTest extends GdxTest { String descriptor ; Skin skin ; Table ui ; Stage stage ; ScrollPane scrollPane ; List < String > console ; @ Override public void create ( ) { } void print ( String message ) { } void clear ( ) { } private void setupUi ( ) { } @ Override public void resize ( int width , int height ) { ui . setSize ( width , height ) ; ui . invalidate ( ) ; <START_BUG> stage . getViewport ( ) . update ( width , height ) ; <END_BUG> } @ Override public void render ( ) { } }<BUG2FIX>stage . getViewport ( ) . update ( width , height , true ) ;
public class ActionTest extends GdxTest implements Runnable { Stage stage ; Texture texture ; @ Override public void create ( ) { <START_BUG> stage = new Stage ( 480 , 320 , true ) ; <END_BUG> texture = new Texture ( files . internal ( "data/badlogic.jpg" ) , false ) ; texture . setFilter ( Linear , Linear ) ; final Image img = new Image ( new com . badlogic . gdx . graphics . g2d . TextureRegion ( texture ) ) ; img . setSize ( 100 , 100 ) ; img . setOrigin ( 50 , 50 ) ; img . setPosition ( 100 , 100 ) ; img . addAction ( forever ( sequence ( delay ( 1.0F ) , new Action ( ) { public boolean act ( float delta ) { System . out . println ( 1 ) ; img . clearActions ( ) ; return true ; } } ) ) ) ; stage . addActor ( img ) ; } @ Override public void render ( ) { } @ Override public void run ( ) { } @ Override public void dispose ( ) { } }<BUG2FIX>stage = new Stage ( ) ;
public class DateHistogramParser implements Aggregator . Parser { static final ParseField EXTENDED_BOUNDS = new ParseField ( "extended_bounds" ) ; private final ImmutableMap < String , DateTimeUnit > dateFieldUnits ; public DateHistogramParser ( ) { } @ Override public String type ( ) { } @ Override public AggregatorFactory parse ( String aggregationName , XContentParser parser , SearchContext context ) throws IOException { <START_BUG> ValuesSourceConfig < NumericValuesSource > config = new ValuesSourceConfig < NumericValuesSource > ( NumericValuesSource . class ) ; <END_BUG> String field = null ; String script = null ; String scriptLang = null ; Map < String , Object > scriptParams = null ; boolean keyed = false ; long minDocCount = 1 ; ExtendedBounds extendedBounds = null ; InternalOrder order = ( ( InternalOrder ) ( Order . KEY_ASC ) ) ; String interval = null ; boolean preZoneAdjustLargeInterval = false ; DateTimeZone preZone = DateTimeZone . UTC ; DateTimeZone postZone = DateTimeZone . UTC ; String format = null ; long preOffset = 0 ; long postOffset = 0 ; boolean assumeSorted = false ; XContentParser . Token token ; String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . VALUE_STRING ) ) { if ( "field" . equals ( currentFieldName ) ) { field = parser . text ( ) ; } else if ( "script" . equals ( currentFieldName ) ) { script = parser . text ( ) ; } else if ( "lang" . equals ( currentFieldName ) ) { scriptLang = parser . text ( ) ; } else if ( ( "time_zone" . equals ( currentFieldName ) ) || ( "timeZone" . equals ( currentFieldName ) ) ) { preZone = parseZone ( parser . text ( ) ) ; } else if ( ( "pre_zone" . equals ( currentFieldName ) ) || ( "preZone" . equals ( currentFieldName ) ) ) { preZone = parseZone ( parser . text ( ) ) ; } else if ( ( "post_zone" . equals ( currentFieldName ) ) || ( "postZone" . equals ( currentFieldName ) ) ) { postZone = parseZone ( parser . text ( ) ) ; } else if ( ( "pre_offset" . equals ( currentFieldName ) ) || ( "preOffset" . equals ( currentFieldName ) ) ) { preOffset = parseOffset ( parser . text ( ) ) ; } else if ( ( "post_offset" . equals ( currentFieldName ) ) || ( "postOffset" . equals ( currentFieldName ) ) ) { postOffset = parseOffset ( parser . text ( ) ) ; } else if ( "interval" . equals ( currentFieldName ) ) { interval = parser . text ( ) ; } else if ( "format" . equals ( currentFieldName ) ) { format = parser . text ( ) ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( ( ( "Unknown<seq2seq4repair_space>key<seq2seq4repair_space>for<seq2seq4repair_space>a<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>[" ) + aggregationName ) + "]:<seq2seq4repair_space>[" ) + currentFieldName ) + "]." ) ) ; } } else if ( token == ( Token . VALUE_BOOLEAN ) ) { if ( "keyed" . equals ( currentFieldName ) ) { keyed = parser . booleanValue ( ) ; } else if ( ( "script_values_sorted" . equals ( currentFieldName ) ) || ( "scriptValuesSorted" . equals ( currentFieldName ) ) ) { assumeSorted = parser . booleanValue ( ) ; } else if ( ( "pre_zone_adjust_large_interval" . equals ( currentFieldName ) ) || ( "preZoneAdjustLargeInterval" . equals ( currentFieldName ) ) ) { preZoneAdjustLargeInterval = parser . booleanValue ( ) ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( ( ( "Unknown<seq2seq4repair_space>key<seq2seq4repair_space>for<seq2seq4repair_space>a<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>[" ) + aggregationName ) + "]:<seq2seq4repair_space>[" ) + currentFieldName ) + "]." ) ) ; } } else if ( token == ( Token . VALUE_NUMBER ) ) { if ( ( "min_doc_count" . equals ( currentFieldName ) ) || ( "minDocCount" . equals ( currentFieldName ) ) ) { minDocCount = parser . longValue ( ) ; } else if ( ( "time_zone" . equals ( currentFieldName ) ) || ( "timeZone" . equals ( currentFieldName ) ) ) { preZone = DateTimeZone . forOffsetHours ( parser . intValue ( ) ) ; } else if ( ( "pre_zone" . equals ( currentFieldName ) ) || ( "preZone" . equals ( currentFieldName ) ) ) { preZone = DateTimeZone . forOffsetHours ( parser . intValue ( ) ) ; } else if ( ( "post_zone" . equals ( currentFieldName ) ) || ( "postZone" . equals ( currentFieldName ) ) ) { postZone = DateTimeZone . forOffsetHours ( parser . intValue ( ) ) ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( ( ( "Unknown<seq2seq4repair_space>key<seq2seq4repair_space>for<seq2seq4repair_space>a<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>[" ) + aggregationName ) + "]:<seq2seq4repair_space>[" ) + currentFieldName ) + "]." ) ) ; } } else if ( token == ( Token . START_OBJECT ) ) { if ( "params" . equals ( currentFieldName ) ) { scriptParams = parser . map ( ) ; } else if ( "order" . equals ( currentFieldName ) ) { while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . VALUE_STRING ) ) { String dir = parser . text ( ) ; boolean asc = "asc" . equals ( dir ) ;<BUG2FIX>ValuesSourceConfig < NumericValuesSource > config = new ValuesSourceConfig ( NumericValuesSource . class ) ;
public class IndexerClusterService extends AbstractLifecycleComponent < IndexerClusterService > { private final ClusterService clusterService ; private final PublishIndexerClusterStateAction publishAction ; private final List < IndexerClusterStateListener > clusterStateListeners = new CopyOnWriteArrayList < IndexerClusterStateListener > ( ) ; private volatile ExecutorService updateTasksExecutor ; private volatile IndexerClusterState clusterState = IndexerClusterState . builder ( ) . build ( ) ; @ Inject public IndexerClusterService ( Settings settings , TransportService transportService , ClusterService clusterService ) { } @ Override protected void doStart ( ) throws ElasticSearchException { } @ Override protected void doStop ( ) throws ElasticSearchException { } @ Override protected void doClose ( ) throws ElasticSearchException { } public void add ( IndexerClusterStateListener listener ) { } public void remove ( IndexerClusterStateListener listener ) { } public void submitStateUpdateTask ( final String source , final IndexerClusterStateUpdateTask updateTask ) { } private class UpdateClusterStateListener implements PublishIndexerClusterStateAction . NewClusterStateListener { @ Override public void onNewClusterState ( final IndexerClusterState clusterState ) { ClusterState state = clusterService . state ( ) ; <START_BUG> if ( ! ( state . nodes ( ) . localNodeMaster ( ) ) ) { <END_BUG> logger . warn ( "master<seq2seq4repair_space>should<seq2seq4repair_space>not<seq2seq4repair_space>receive<seq2seq4repair_space>new<seq2seq4repair_space>cluster<seq2seq4repair_space>state<seq2seq4repair_space>from<seq2seq4repair_space>[{}]" , state . nodes ( ) . masterNode ( ) ) ; return ; } submitStateUpdateTask ( "received_state" , new IndexerClusterStateUpdateTask ( ) { @ Override public IndexerClusterState execute ( IndexerClusterState currentState ) { return clusterState ; } } ) ; } } }<BUG2FIX>if ( state . nodes ( ) . localNodeMaster ( ) ) {
public class RestMoreLikeThisAction extends BaseRestHandler { @ Inject public RestMoreLikeThisAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { MoreLikeThisRequest mltRequest = moreLikeThisRequest ( request . param ( "index" ) ) . type ( request . param ( "type" ) ) . id ( request . param ( "id" ) ) ; mltRequest . routing ( request . param ( "routing" ) ) ; mltRequest . listenerThreaded ( false ) ; try { mltRequest . fields ( request . paramAsStringArray ( "mlt_fields" , null ) ) ; mltRequest . percentTermsToMatch ( request . paramAsFloat ( "percent_terms_to_match" , ( - 1 ) ) ) ; mltRequest . minTermFreq ( request . paramAsInt ( "min_term_freq" , ( - 1 ) ) ) ; mltRequest . maxQueryTerms ( request . paramAsInt ( "max_query_terms" , ( - 1 ) ) ) ; mltRequest . stopWords ( request . paramAsStringArray ( "stop_words" , null ) ) ; mltRequest . minDocFreq ( request . paramAsInt ( "min_doc_freq" , ( - 1 ) ) ) ; mltRequest . maxDocFreq ( request . paramAsInt ( "max_doc_freq" , ( - 1 ) ) ) ; mltRequest . minWordLen ( request . paramAsInt ( "min_word_len" , ( - 1 ) ) ) ; mltRequest . maxWordLen ( request . paramAsInt ( "max_word_len" , ( - 1 ) ) ) ; mltRequest . boostTerms ( request . paramAsFloat ( "boost_terms" , ( - 1 ) ) ) ; mltRequest . searchType ( SearchType . fromString ( request . param ( "search_type" ) ) ) ; mltRequest . searchIndices ( request . paramAsStringArray ( "search_indices" , null ) ) ; mltRequest . searchTypes ( request . paramAsStringArray ( "search_types" , null ) ) ; mltRequest . searchQueryHint ( request . param ( "search_query_hint" ) ) ; mltRequest . searchSize ( request . paramAsInt ( "search_size" , mltRequest . searchSize ( ) ) ) ; mltRequest . searchFrom ( request . paramAsInt ( "search_from" , mltRequest . searchFrom ( ) ) ) ; String searchScroll = request . param ( "search_scroll" ) ; if ( searchScroll != null ) { mltRequest . searchScroll ( new org . elasticsearch . search . Scroll ( parseTimeValue ( searchScroll , null ) ) ) ; } if ( request . hasContent ( ) ) { mltRequest . searchSource ( request . content ( ) , request . contentUnsafe ( ) ) ; } else { String searchSource = request . param ( "search_source" ) ; if ( searchSource != null ) { mltRequest . searchSource ( searchSource ) ; } } } catch ( Exception e ) { try { XContentBuilder builder = restContentBuilder ( request ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . BAD_REQUEST , builder . startObject ( ) . field ( "error" , e . getMessage ( ) ) . endObject ( ) ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } return ; } client . moreLikeThis ( mltRequest , new org . elasticsearch . action . ActionListener < SearchResponse > ( ) { @ Override public void onResponse ( SearchResponse response ) { try { XContentBuilder builder = restContentBuilder ( request ) ; builder . startObject ( ) ; response . toXContent ( builder , request ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class FrameBuffer implements Disposable { private static final Map < Application , List < FrameBuffer > > buffers = new HashMap < Application , List < FrameBuffer > > ( ) ; protected Texture colorTexture ; private static int defaultFramebufferHandle ; private static boolean defaultFramebufferHandleInitialized = false ; private int framebufferHandle ; private int depthbufferHandle ; protected final int width ; protected final int height ; protected final boolean hasDepth ; protected final Format format ; public FrameBuffer ( Pixmap . Format format , int width , int height , boolean hasDepth ) { } protected void setupTexture ( ) { } private void build ( ) { if ( ! ( graphics . isGL20Available ( ) ) ) throw new GdxRuntimeException ( "GL2<seq2seq4repair_space>is<seq2seq4repair_space>required." ) ; GL20 gl = graphics . getGL20 ( ) ; if ( ! ( FrameBuffer . defaultFramebufferHandleInitialized ) ) { FrameBuffer . defaultFramebufferHandleInitialized = true ; if ( ( app . getType ( ) ) == ( ApplicationType . iOS ) ) { IntBuffer intbuf = ByteBuffer . allocateDirect ( ( ( 16 * ( Integer . SIZE ) ) / 8 ) ) . order ( ByteOrder . nativeOrder ( ) ) . asIntBuffer ( ) ; gl . glGetIntegerv ( GL_FRAMEBUFFER_BINDING , intbuf ) ; <START_BUG> FrameBuffer . defaultFramebufferHandle = intbuf . get ( ) ; <END_BUG> } else { FrameBuffer . defaultFramebufferHandle = 0 ; } } setupTexture ( ) ; IntBuffer handle = BufferUtils . newIntBuffer ( 1 ) ; gl . glGenFramebuffers ( 1 , handle ) ; framebufferHandle = handle . get ( 0 ) ; if ( hasDepth ) { handle . clear ( ) ; gl . glGenRenderbuffers ( 1 , handle ) ; depthbufferHandle = handle . get ( 0 ) ; } gl . glBindTexture ( GL_TEXTURE_2D , colorTexture . getTextureObjectHandle ( ) ) ; if ( hasDepth ) { gl . glBindRenderbuffer ( GL_RENDERBUFFER , depthbufferHandle ) ; gl . glRenderbufferStorage ( GL_RENDERBUFFER , GL_DEPTH_COMPONENT16 , colorTexture . getWidth ( ) , colorTexture . getHeight ( ) ) ; } gl . glBindFramebuffer ( GL_FRAMEBUFFER , framebufferHandle ) ; gl . glFramebufferTexture2D ( GL_FRAMEBUFFER , GL_COLOR_ATTACHMENT0 , GL_TEXTURE_2D , colorTexture . getTextureObjectHandle ( ) , 0 ) ; if ( hasDepth ) { gl . glFramebufferRenderbuffer ( GL_FRAMEBUFFER , GL_DEPTH_ATTACHMENT , GL_RENDERBUFFER , depthbufferHandle ) ; } int result = gl . glCheckFramebufferStatus ( GL_FRAMEBUFFER ) ; gl . glBindRenderbuffer ( GL_RENDERBUFFER , 0 ) ; gl . glBindTexture ( GL_TEXTURE_2D , 0 ) ; gl . glBindFramebuffer ( GL_FRAMEBUFFER , FrameBuffer . defaultFramebufferHandle ) ; if ( result != ( GL20 . GL_FRAMEBUFFER_COMPLETE ) ) { colorTexture . dispose ( ) ; if ( hasDepth ) { handle . clear ( ) ; handle . put ( depthbufferHandle ) ; handle . flip ( ) ; gl . glDeleteRenderbuffers ( 1 , handle ) ; } colorTexture . dispose ( ) ; handle . clear ( ) ; handle . put ( framebufferHandle ) ; handle . flip ( ) ; gl . glDeleteFramebuffers ( 1 , handle ) ; if ( result == ( GL20 . GL_FRAMEBUFFER_INCOMPLETE_ATTACHMENT ) ) throw new IllegalStateException ( "frame<seq2seq4repair_space>buffer<seq2seq4repair_space>couldn't<seq2seq4repair_space>be<seq2seq4repair_space>constructed:<seq2seq4repair_space>incomplete<seq2seq4repair_space>attachment" ) ; if ( result == ( GL20 . GL_FRAMEBUFFER_INCOMPLETE_DIMENSIONS ) ) throw new IllegalStateException ( "frame<seq2seq4repair_space>buffer<seq2seq4repair_space>couldn't<seq2seq4repair_space>be<seq2seq4repair_space>constructed:<seq2seq4repair_space>incomplete<seq2seq4repair_space>dimensions" ) ; if ( result == ( GL20 . GL_FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT ) ) throw new IllegalStateException ( "frame<seq2seq4repair_space>buffer<seq2seq4repair_space>couldn't<seq2seq4repair_space>be<seq2seq4repair_space>constructed:<seq2seq4repair_space>missing<seq2seq4repair_space>attachment" ) ; } } public void dispose ( ) { } public void begin ( ) { } public void end ( ) { } private void addManagedFrameBuffer ( Application app , FrameBuffer frameBuffer ) { } public static void invalidateAllFrameBuffers ( Application app ) { } public static void clearAllFrameBuffers ( Application app ) { } public static String getManagedStatus ( ) { } public Texture getColorBufferTexture ( ) { } public int getHeight ( ) { } public int getWidth ( ) { } }<BUG2FIX>FrameBuffer . defaultFramebufferHandle = intbuf . get ( 0 ) ;
public class RestMultiGetAction extends BaseRestHandler { @ Inject public RestMultiGetAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { MultiGetRequest multiGetRequest = new MultiGetRequest ( ) ; multiGetRequest . listenerThreaded ( false ) ; multiGetRequest . refresh ( request . paramAsBoolean ( "refresh" , multiGetRequest . refresh ( ) ) ) ; multiGetRequest . preference ( request . param ( "preference" ) ) ; multiGetRequest . realtime ( request . paramAsBooleanOptional ( "realtime" , null ) ) ; String [ ] sFields = null ; String sField = request . param ( "fields" ) ; if ( sField != null ) { sFields = Strings . splitStringByCommaToArray ( sField ) ; } try { multiGetRequest . add ( request . param ( "index" ) , request . param ( "type" ) , sFields , request . content ( ) ) ; } catch ( Exception e ) { try { XContentBuilder builder = restContentBuilder ( request ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . BAD_REQUEST , builder . startObject ( ) . field ( "error" , e . getMessage ( ) ) . endObject ( ) ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } return ; } client . multiGet ( multiGetRequest , new org . elasticsearch . action . ActionListener < MultiGetResponse > ( ) { @ Override public void onResponse ( MultiGetResponse response ) { try { XContentBuilder builder = restContentBuilder ( request ) ; response . toXContent ( builder , request ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class SimpleIndexShardTests { private ThreadPool threadPool ; private IndexShard indexShard ; @ BeforeMethod public void createIndexShard ( ) throws IOException { Settings settings = EMPTY_SETTINGS ; Environment environment = new Environment ( settings ) ; ShardId shardId = new ShardId ( "test" , 1 ) ; AnalysisService analysisService = new AnalysisService ( shardId . index ( ) ) ; MapperService mapperService = new MapperService ( shardId . index ( ) , settings , environment , analysisService ) ; IndexQueryParserService queryParserService = new IndexQueryParserService ( shardId . index ( ) , mapperService , new IndexCache ( shardId . index ( ) ) , new org . elasticsearch . index . engine . robin . RobinIndexEngine ( shardId . index ( ) ) , analysisService ) ; IndexCache indexCache = new IndexCache ( shardId . index ( ) ) ; SnapshotDeletionPolicy policy = new SnapshotDeletionPolicy ( new org . elasticsearch . index . deletionpolicy . KeepOnlyLastDeletionPolicy ( shardId , settings ) ) ; <START_BUG> Store store = new org . elasticsearch . index . store . ram . RamStore ( shardId , settings ) ; <END_BUG> MemoryTranslog translog = new MemoryTranslog ( shardId , settings ) ; Engine engine = new org . elasticsearch . index . engine . robin . RobinEngine ( shardId , settings , store , policy , translog , new org . elasticsearch . index . merge . policy . LogByteSizeMergePolicyProvider ( store ) , new org . elasticsearch . index . merge . scheduler . SerialMergeSchedulerProvider ( shardId , settings ) , analysisService , new org . elasticsearch . index . similarity . SimilarityService ( shardId . index ( ) ) ) ; threadPool = new ScalingThreadPool ( ) ; indexShard = new org . elasticsearch . index . shard . service . InternalIndexShard ( shardId , EMPTY_SETTINGS , store , engine , translog , threadPool , mapperService , queryParserService , indexCache ) . start ( ) ; } @ AfterMethod public void tearDown ( ) { } @ Test public void testSimpleIndexGetDelete ( ) { } }<BUG2FIX>Store store = new org . elasticsearch . index . store . ram . RamStore ( shardId , settings , null ) ;
public final class VertexAttribute { public final int usage ; public final int numComponents ; public int offset ; public String alias ; public VertexAttribute ( int usage , int numComponents , String alias ) { } public static VertexAttribute Position ( ) { } public static VertexAttribute TexCoords ( int unit ) { } public static VertexAttribute Normal ( ) { <START_BUG> return new VertexAttribute ( Usage . TextureCoordinates , 3 , ShaderProgram . NORMAL_ATTRIBUTE ) ; <END_BUG> } public static VertexAttribute Color ( ) { } }<BUG2FIX>return new VertexAttribute ( Usage . Normal , 3 , ShaderProgram . NORMAL_ATTRIBUTE ) ;
public class CircularBuffer { private final short [ ] buffer ; private int writePosition ; private int readPosition ; private int available ; public CircularBuffer ( int size ) { } public void write ( short [ ] data , int offset , int count ) { } public void combine ( short [ ] data , int offset , int count ) { } public int read ( short [ ] data , int offset , int count ) { } public int skip ( int count ) { <START_BUG> int total = count = Math . min ( available , count ) ; <END_BUG> available -= total ; readPosition = ( ( readPosition ) + total ) % ( buffer . length ) ; return total ; } public void clear ( ) { } public void setWritePosition ( int writePosition ) { } public int getWritePosition ( ) { } public void setReadPosition ( int readPosition ) { } public int getReadPosition ( ) { } public int getAvailable ( ) { } private void dump ( ) { } private static void combine ( short [ ] src , int srcPos , short [ ] dest , int destPos , int length ) { } public static void main ( String [ ] args ) throws Exception { } }<BUG2FIX>int total = Math . min ( available , count ) ;
public class TermsStringFacetCollector extends AbstractFacetCollector { static ThreadLocal < ThreadLocals . CleanableValue < Deque < TObjectIntHashMap < String > > > > cache = new ThreadLocal < ThreadLocals . CleanableValue < Deque < TObjectIntHashMap < String > > > > ( ) { @ Override protected ThreadLocals . CleanableValue < Deque < TObjectIntHashMap < String > > > initialValue ( ) { } } ; private final FieldDataCache fieldDataCache ; private final String indexFieldName ; private final ComparatorType comparatorType ; private final int size ; private final int numberOfShards ; private final FieldDataType fieldDataType ; private FieldData fieldData ; private final TermsStringFacetCollector . StaticAggregatorValueProc aggregator ; private final SearchScript script ; public TermsStringFacetCollector ( String facetName , String fieldName , int size , TermsFacet . ComparatorType comparatorType , boolean allTerms , SearchContext context , ImmutableSet < BytesRef > excluded , Pattern pattern , String scriptLang , String script , Map < String , Object > params ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override protected void doSetNextReader ( AtomicReaderContext context ) throws IOException { fieldData = fieldDataCache . cache ( fieldDataType , context . reader ( ) , indexFieldName ) ; if ( ( script ) != null ) { <START_BUG> script . setNextReader ( context . reader ( ) ) ; <END_BUG> } } @ Override protected void doCollect ( int doc ) throws IOException { } @ Override public Facet facet ( ) { } public static class AggregatorValueProc extends TermsStringFacetCollector . StaticAggregatorValueProc { private final ImmutableSet < BytesRef > excluded ; private final Matcher matcher ; private final SearchScript script ; public AggregatorValueProc ( TObjectIntHashMap < BytesRef > facets , ImmutableSet < BytesRef > excluded , Pattern pattern , SearchScript script ) { } @ Override public void onValue ( int docId , BytesRef value ) { } } public static class StaticAggregatorValueProc implements FieldData . StringValueInDocProc , FieldData . StringValueProc { private final TObjectIntHashMap < BytesRef > facets ; private int missing = 0 ; private int total = 0 ; public StaticAggregatorValueProc ( TObjectIntHashMap < BytesRef > facets ) { } @ Override public void onValue ( BytesRef value ) { } @ Override public void onValue ( int docId , BytesRef value ) { } @ Override public void onMissing ( int docId ) { } public final TObjectIntHashMap < BytesRef > facets ( ) { } public final int missing ( ) { } public int total ( ) { } } }<BUG2FIX>script . setNextReader ( context ) ;
public class CountdownEventAction < T extends Event > extends EventAction < T > { int count ; int current ; public CountdownEventAction ( Class < ? extends T > eventClass , int count ) { } public boolean handle ( T event ) { ( current ) ++ ; <START_BUG> return ( current ) >= ( count ) ; <END_BUG> } }<BUG2FIX>return ( current ) > ( count ) ;
public class StandaloneTest extends CliTool { private static final CliToolConfig CONFIG = CliToolConfig . config ( "tika" , StandaloneTest . class ) . cmds ( StandaloneTest . TikaTest . CMD ) . build ( ) ; static class TikaTest extends Command { private static final String NAME = "tika" ; private final String url ; private final Integer size ; private final String base64text ; private final DocumentMapper docMapper ; private static final Cmd CMD = cmd ( StandaloneTest . TikaTest . NAME , StandaloneTest . TikaTest . class ) . options ( option ( "u" , "url" ) . required ( false ) . hasArg ( false ) ) . options ( option ( "s" , "size" ) . required ( false ) . hasArg ( false ) ) . build ( ) ; protected TikaTest ( Terminal terminal , String url , Integer size , String base64text ) throws IOException { } @ Override public ExitStatus execute ( Settings settings , Environment env ) throws Exception { XContentBuilder builder = jsonBuilder ( ) . startObject ( ) . field ( "_id" , 1 ) . field ( "file" ) . startObject ( ) ; if ( ( base64text ) != null ) { builder . field ( "_content" , base64text ) ; } else { File file = new File ( new URL ( url ) . getFile ( ) ) ; boolean exists = file . exists ( ) ; if ( ! exists ) { return ExitStatus . IO_ERROR ; } byte [ ] bytes = copyToByteArray ( file ) ; builder . field ( "_content" , bytes ) ; } if ( ( size ) >= 0 ) { <START_BUG> builder . field ( "_indexed_chars" , 10 ) ; <END_BUG> } BytesReference json = builder . endObject ( ) . endObject ( ) . bytes ( ) ; ParseContext . Document doc = docMapper . parse ( json ) . rootDoc ( ) ; terminal . println ( "##<seq2seq4repair_space>Extracted<seq2seq4repair_space>text" ) ; terminal . println ( "---------------------<seq2seq4repair_space>BEGIN<seq2seq4repair_space>-----------------------" ) ; terminal . println ( doc . get ( docMapper . mappers ( ) . smartName ( "file" ) . mapper ( ) . names ( ) . indexName ( ) ) ) ; terminal . println ( "----------------------<seq2seq4repair_space>END<seq2seq4repair_space>------------------------" ) ; terminal . println ( "##<seq2seq4repair_space>Metadata" ) ; printMetadataContent ( doc , AUTHOR ) ; printMetadataContent ( doc , CONTENT_LENGTH ) ; printMetadataContent ( doc , CONTENT_TYPE ) ; printMetadataContent ( doc , DATE ) ; printMetadataContent ( doc , KEYWORDS ) ; printMetadataContent ( doc , LANGUAGE ) ; printMetadataContent ( doc , AttachmentMapper . FieldNames . NAME ) ; printMetadataContent ( doc , TITLE ) ; return ExitStatus . OK ; } private void printMetadataContent ( ParseContext . Document doc , String field ) { } public static Command parse ( Terminal terminal , CommandLine cli ) throws IOException { } } public StandaloneTest ( ) { } public static void main ( String [ ] args ) { } @ Override protected Command parse ( String cmdName , CommandLine cli ) throws Exception { } }<BUG2FIX>builder . field ( "_indexed_chars" , size ) ;
public class Bits { long [ ] bits = new long [ ] { 0 } ; public boolean get ( int index ) { } public void set ( int index ) { } public void flip ( int index ) { } private void checkCapacity ( int len ) { <START_BUG> if ( len > ( bits . length ) ) { <END_BUG> long [ ] newBits = new long [ len + 1 ] ; System . arraycopy ( bits , 0 , newBits , 0 , bits . length ) ; bits = newBits ; } } public void clear ( int index ) { } public void clear ( ) { } public int numBits ( ) { } }<BUG2FIX>if ( len >= ( bits . length ) ) {
public interface IReflectionCache { public Collection < Type > getKnownTypes ( ) { } public Type forName ( String name ) { } <START_BUG> public Object newArray ( Class componentType , int size ) ; <END_BUG> public int getArrayLength ( Type type , Object obj ) { } public Object getArrayElement ( Type type , Object obj , int i ) { } public void setArrayElement ( Type type , Object obj , int i , Object value ) { } public Object get ( Field field , Object obj ) throws IllegalAccessException { } public void set ( Field field , Object obj , Object value ) throws IllegalAccessException { } public Object invoke ( Method m , Object obj , Object [ ] params ) { } }<BUG2FIX>public Object newArray ( Type componentType , int size ) ;
public class TribeTests extends ElasticsearchIntegrationTest { private static TestCluster cluster2 ; private Node tribeNode ; private Client tribeClient ; @ BeforeClass public static void setupSecondCluster ( ) throws Exception { ElasticsearchIntegrationTest . beforeClass ( ) ; <START_BUG> TribeTests . cluster2 = new TestCluster ( randomLong ( ) , 2 , 2 , Strings . randomBase64UUID ( getRandom ( ) ) , 0 ) ; <END_BUG> TribeTests . cluster2 . beforeTest ( getRandom ( ) , 0.1 ) ; TribeTests . cluster2 . ensureAtLeastNumDataNodes ( 2 ) ; } @ AfterClass public static void tearDownSecondCluster ( ) { } @ After public void tearDownTribeNode ( ) { } private void setupTribeNode ( Settings settings ) { } @ Test public void testGlobalReadWriteBlocks ( ) throws Exception { } @ Test public void testIndexWriteBlocks ( ) throws Exception { } @ Test public void testOnConflictDrop ( ) throws Exception { } @ Test public void testOnConflictPrefer ( ) throws Exception { } private void testOnConflictPrefer ( String tribe ) throws Exception { } @ Test public void testTribeOnOneCluster ( ) throws Exception { } private void awaitIndicesInClusterState ( final String ... indices ) throws Exception { } private void awaitSameNodeCounts ( ) throws Exception { } private int countDataNodesForTribe ( String tribeName , DiscoveryNodes nodes ) { } }<BUG2FIX>TribeTests . cluster2 = new TestCluster ( randomLong ( ) , 2 , 2 , Strings . randomBase64UUID ( getRandom ( ) ) , 0 , false ) ;
public class TransportNodesListShardStoreMetaData extends TransportNodesOperationAction < TransportNodesListShardStoreMetaData . Request , TransportNodesListShardStoreMetaData . NodesStoreFilesMetaData , TransportNodesListShardStoreMetaData . NodeRequest , TransportNodesListShardStoreMetaData . NodeStoreFilesMetaData > { private final IndicesService indicesService ; private final NodeEnvironment nodeEnv ; @ Inject public TransportNodesListShardStoreMetaData ( Settings settings , ClusterName clusterName , ThreadPool threadPool , ClusterService clusterService , TransportService transportService , IndicesService indicesService , NodeEnvironment nodeEnv ) { } public ActionFuture < TransportNodesListShardStoreMetaData . NodesStoreFilesMetaData > list ( ShardId shardId , boolean onlyUnallocated , Set < String > nodesIds , @ Nullable TimeValue timeout ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected TransportNodesListShardStoreMetaData . Request newRequest ( ) { } @ Override protected TransportNodesListShardStoreMetaData . NodeRequest newNodeRequest ( ) { } @ Override protected TransportNodesListShardStoreMetaData . NodeRequest newNodeRequest ( String nodeId , TransportNodesListShardStoreMetaData . Request request ) { } @ Override protected TransportNodesListShardStoreMetaData . NodeStoreFilesMetaData newNodeResponse ( ) { } @ Override protected TransportNodesListShardStoreMetaData . NodesStoreFilesMetaData newResponse ( TransportNodesListShardStoreMetaData . Request request , AtomicReferenceArray responses ) { } @ Override protected TransportNodesListShardStoreMetaData . NodeStoreFilesMetaData nodeOperation ( TransportNodesListShardStoreMetaData . NodeRequest request ) throws ElasticSearchException { } private TransportNodesListShardStoreMetaData . StoreFilesMetaData listStoreMetaData ( ShardId shardId ) throws IOException { IndexService indexService = indicesService . indexService ( shardId . index ( ) . name ( ) ) ; if ( indexService != null ) { InternalIndexShard indexShard = ( ( InternalIndexShard ) ( indexService . shard ( shardId . id ( ) ) ) ) ; if ( indexShard != null ) { return new TransportNodesListShardStoreMetaData . StoreFilesMetaData ( true , shardId , indexShard . store ( ) . list ( ) ) ; } } IndexMetaData metaData = clusterService . state ( ) . metaData ( ) . index ( shardId . index ( ) . name ( ) ) ; if ( metaData == null ) { return new TransportNodesListShardStoreMetaData . StoreFilesMetaData ( false , shardId , ImmutableMap . < String , StoreFileMetaData > of ( ) ) ; } String storeType = metaData . settings ( ) . get ( "index.store.type" , "fs" ) ; if ( ! ( storeType . contains ( "fs" ) ) ) { return new TransportNodesListShardStoreMetaData . StoreFilesMetaData ( false , shardId , ImmutableMap . < String , StoreFileMetaData > of ( ) ) ; } File [ ] shardLocations = nodeEnv . shardLocations ( shardId ) ; File [ ] shardIndexLocations = new File [ shardLocations . length ] ; for ( int i = 0 ; i < ( shardLocations . length ) ; i ++ ) { shardIndexLocations [ i ] = new File ( shardLocations [ i ] , "index" ) ; } boolean exists = false ; for ( File shardIndexLocation : shardIndexLocations ) { if ( shardIndexLocation . exists ( ) ) { exists = true ; break ; } } if ( ! exists ) { return new TransportNodesListShardStoreMetaData . StoreFilesMetaData ( false , shardId , ImmutableMap . < String , StoreFileMetaData > of ( ) ) ; } Map < String , String > checksums = Store . readChecksums ( shardIndexLocations ) ; if ( checksums == null ) { checksums = ImmutableMap . of ( ) ; } Map < String , StoreFileMetaData > files = Maps . newHashMap ( ) ; for ( File shardIndexLocation : shardIndexLocations ) { File [ ] listedFiles = shardIndexLocation . listFiles ( ) ; if ( listedFiles == null ) { continue ; } for ( File file : listedFiles ) { if ( file . getName ( ) . endsWith ( ".cks" ) ) { continue ; } if ( Store . isChecksum ( file . getName ( ) ) ) { continue ; } <START_BUG> files . put ( file . getName ( ) , new StoreFileMetaData ( file . getName ( ) , file . length ( ) , file . lastModified ( ) , checksums . get ( file . getName ( ) ) ) ) ; <END_BUG> } } return new TransportNodesListShardStoreMetaData . StoreFilesMetaData ( false , shardId , files ) ; } @ Override protected boolean accumulateExceptions ( ) { } public static class StoreFilesMetaData implements Iterable < StoreFileMetaData > , Streamable { private boolean allocated ; private ShardId shardId ; private Map < String , StoreFileMetaData > files ; StoreFilesMetaData ( ) { } public StoreFilesMetaData ( boolean allocated , ShardId shardId , Map < String , StoreFileMetaData > files ) { } public boolean allocated ( ) { } public ShardId shardId ( ) { } public long totalSizeInBytes ( ) { } @ Override public Iterator < StoreFileMetaData > iterator ( ) { } public boolean fileExists ( String name ) { } public StoreFileMetaData file ( String name ) { } public static TransportNodesListShardStoreMetaData . StoreFilesMetaData readStoreFilesMetaData ( StreamInput in ) throws IOException { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } static class Request extends NodesOperationRequest < TransportNodesListShardStoreMetaData . Request > { private ShardId shardId ; private boolean unallocated ; public Request ( ) { } public Request ( ShardId shardId , boolean unallocated , Set < String > nodesIds ) { } public Request ( ShardId shardId , boolean unallocated , String ... nodesIds ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } public static class NodesStoreFilesMetaData extends NodesOperationResponse < TransportNodesListShardStoreMetaData . NodeStoreFilesMetaData > { private FailedNodeException [ ] failures ; NodesStoreFilesMetaData ( ) { } public NodesStoreFilesMetaData ( ClusterName clusterName , TransportNodesListShardStoreMetaData . NodeStoreFilesMetaData [ ] nodes , FailedNodeException [ ] failures ) { } public FailedNodeException [ ] failures ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { }<BUG2FIX>files . put ( file . getName ( ) , new StoreFileMetaData ( file . getName ( ) , file . length ( ) , checksums . get ( file . getName ( ) ) ) ) ;
public class TransportSearchScrollQueryAndFetchAction extends AbstractComponent { private final ThreadPool threadPool ; private final ClusterService clusterService ; private final SearchServiceTransportAction searchService ; private final SearchPhaseController searchPhaseController ; private final TransportSearchCache searchCache ; @ Inject public TransportSearchScrollQueryAndFetchAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportSearchCache searchCache , SearchServiceTransportAction searchService , SearchPhaseController searchPhaseController ) { } public void execute ( SearchScrollRequest request , ParsedScrollId scrollId , ActionListener < SearchResponse > listener ) { } private class AsyncAction { private final SearchScrollRequest request ; private final ActionListener < SearchResponse > listener ; private final ParsedScrollId scrollId ; private final DiscoveryNodes nodes ; private volatile Queue < ShardSearchFailure > shardFailures ; private final Map < SearchShardTarget , QueryFetchSearchResult > queryFetchResults = searchCache . obtainQueryFetchResults ( ) ; private final AtomicInteger successfulOps ; private final AtomicInteger counter ; private final long startTime = System . currentTimeMillis ( ) ; private AsyncAction ( SearchScrollRequest request , ParsedScrollId scrollId , ActionListener < SearchResponse > listener ) { } protected final ShardSearchFailure [ ] buildShardFailures ( ) { } protected final void addShardFailure ( ShardSearchFailure failure ) { } public void start ( ) { } private void executePhase ( DiscoveryNode node , final long searchId ) { } private void finishHim ( ) { try { innerFinishHim ( ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> listener . onFailure ( new ReduceSearchPhaseException ( "fetch" , "" , e , buildShardFailures ( ) ) ) ; } } private void innerFinishHim ( ) { } } }<BUG2FIX>} catch ( Throwable e ) {
public class OrthographicCamera extends Camera { public float zoom = 1 ; public OrthographicCamera ( ) { } public OrthographicCamera ( float viewportWidth , float viewportHeight ) { } private final Vector3 tmp = new Vector3 ( ) ; @ Override public void update ( ) { projection . setToOrtho ( ( ( ( zoom ) * ( - ( viewportWidth ) ) ) / 2 ) , ( ( ( zoom ) * ( viewportWidth ) ) / 2 ) , ( ( ( zoom ) * ( - ( viewportHeight ) ) ) / 2 ) , ( ( ( zoom ) * ( viewportHeight ) ) / 2 ) , Math . abs ( near ) , Math . abs ( far ) ) ; view . setToLookAt ( position , tmp . set ( position ) . add ( direction ) , up ) ; combined . set ( projection ) ; Matrix4 . mul ( val , view . val ) ; invProjectionView . set ( combined ) ; Matrix4 . inv ( invProjectionView . val ) ; <START_BUG> frustum . update ( combined ) ; <END_BUG> } }<BUG2FIX>frustum . update ( invProjectionView ) ;
public class Bootstrap { private Node node ; private static volatile Thread keepAliveThread ; private static volatile CountDownLatch keepAliveLatch ; private void setup ( boolean addShutdownHook , Tuple < Settings , Environment > tuple ) throws Exception { <START_BUG> if ( tuple . v1 ( ) . getAsBoolean ( "bootstrap.mlockall" , true ) ) { <END_BUG> Natives . tryMlockall ( ) ; } tuple = Bootstrap . setupJmx ( tuple ) ; NodeBuilder nodeBuilder = NodeBuilder . nodeBuilder ( ) . settings ( tuple . v1 ( ) ) . loadConfigSettings ( false ) ; node = nodeBuilder . build ( ) ; if ( addShutdownHook ) { Runtime . getRuntime ( ) . addShutdownHook ( new Thread ( ) { @ Override public void run ( ) { node . close ( ) ; } } ) ; } } private static Tuple < Settings , Environment > setupJmx ( Tuple < Settings , Environment > tuple ) { } private static void setupLogging ( Tuple < Settings , Environment > tuple ) { } private static Tuple < Settings , Environment > initialSettings ( ) { } public void init ( String [ ] args ) throws Exception { } public void start ( ) { } public void stop ( ) { } public void destroy ( ) { } public static void main ( String [ ] args ) { } private static String buildErrorMessage ( String stage , Throwable e ) { } }<BUG2FIX>if ( tuple . v1 ( ) . getAsBoolean ( "bootstrap.mlockall" , false ) ) {
public class RequestReader { private static final String TAG = "GHRR" ; private final File handle ; private final int version ; public RequestReader ( File file , int formatVersion ) { } @ SuppressWarnings ( "unchecked" ) public < V > V read ( ) { if ( ( ! ( handle . exists ( ) ) ) || ( ( handle . length ( ) ) == 0 ) ) return null ; RandomAccessFile dir = null ; FileLock lock = null ; ObjectInputStream input = null ; boolean delete = false ; try { dir = new RandomAccessFile ( handle , "rw" ) ; lock = dir . getChannel ( ) . lock ( ) ; <START_BUG> input = new ObjectInputStream ( new GZIPInputStream ( new FileInputStream ( dir . getFD ( ) ) , ( 8192 * 8 ) ) ) ; <END_BUG> int streamVersion = input . readInt ( ) ; if ( streamVersion != ( version ) ) { delete = true ; return null ; } return ( ( V ) ( input . readObject ( ) ) ) ; } catch ( IOException e ) { Log . d ( RequestReader . TAG , ( "Exception<seq2seq4repair_space>reading<seq2seq4repair_space>cache<seq2seq4repair_space>" + ( handle . getName ( ) ) ) , e ) ; return null ; } catch ( ClassNotFoundException e ) { Log . d ( RequestReader . TAG , ( "Exception<seq2seq4repair_space>reading<seq2seq4repair_space>cache<seq2seq4repair_space>" + ( handle . getName ( ) ) ) , e ) ; return null ; } finally { if ( input != null ) try { input . close ( ) ; } catch ( IOException e ) { Log . d ( RequestReader . TAG , "Exception<seq2seq4repair_space>closing<seq2seq4repair_space>stream" , e ) ; } if ( delete ) try { dir . setLength ( 0 ) ; } catch ( IOException e ) { Log . d ( RequestReader . TAG , "Exception<seq2seq4repair_space>truncating<seq2seq4repair_space>file" , e ) ; } if ( lock != null ) try { lock . release ( ) ; } catch ( IOException e ) { Log . d ( RequestReader . TAG , "Exception<seq2seq4repair_space>unlocking<seq2seq4repair_space>file" , e ) ; } if ( dir != null ) try { dir . close ( ) ; } catch ( IOException e ) { Log . d ( RequestReader . TAG , "Exception<seq2seq4repair_space>closing<seq2seq4repair_space>file" , e ) ; } } } }<BUG2FIX>input = new ObjectInputStream ( new GZIPInputStream ( new FileInputStream ( dir . getFD ( ) ) , 8192 ) ) ;
private void cleanContext ( SearchContext context ) { } private void parseTemplate ( ShardSearchRequest request ) { } private void parseSource ( SearchContext context , BytesReference source ) throws SearchParseException { } private static final int [ ] EMPTY_DOC_IDS = new int [ 0 ] ; private void shortcutDocIdsToLoad ( SearchContext context ) { } private void shortcutDocIdsToLoadForScanning ( SearchContext context ) { } private void processScroll ( InternalScrollSearchRequest request , SearchContext context ) { } static class NormsWarmer extends IndicesWarmer . Listener { @ Override public TerminationHandle warm ( final IndexShard indexShard , IndexMetaData indexMetaData , final WarmerContext context , ThreadPool threadPool ) { final Loading defaultLoading = Loading . parse ( indexMetaData . settings ( ) . get ( SearchService . NORMS_LOADING_KEY ) , LAZY ) ; final MapperService mapperService = indexShard . mapperService ( ) ; final ObjectSet < String > warmUp = new com . carrotsearch . hppc . ObjectOpenHashSet < String > ( ) ; for ( DocumentMapper docMapper : mapperService ) { for ( FieldMapper < ? > fieldMapper : docMapper . mappers ( ) . mappers ( ) ) { final String indexName = fieldMapper . names ( ) . indexName ( ) ; if ( ( ( fieldMapper . fieldType ( ) . indexed ( ) ) && ( ! ( fieldMapper . fieldType ( ) . omitNorms ( ) ) ) ) && ( ( fieldMapper . normsLoading ( defaultLoading ) ) == ( Loading . EAGER ) ) ) { warmUp . add ( indexName ) ; } } } final CountDownLatch latch = new CountDownLatch ( 1 ) ; threadPool . executor ( executor ( ) ) . execute ( new Runnable ( ) { @ Override public void run ( ) { try { for ( Iterator < ObjectCursor < String > > it = warmUp . iterator ( ) ; it . hasNext ( ) ; ) { final String indexName = it . next ( ) . value ; final long start = System . nanoTime ( ) ; for ( final AtomicReaderContext ctx : context . newSearcher ( ) . reader ( ) . leaves ( ) ) { final NumericDocValues values = ctx . reader ( ) . getNormValues ( indexName ) ; if ( values != null ) { values . get ( 0 ) ; } } if ( indexShard . warmerService ( ) . logger ( ) . isTraceEnabled ( ) ) { indexShard . warmerService ( ) . logger ( ) . trace ( "warmed<seq2seq4repair_space>norms<seq2seq4repair_space>for<seq2seq4repair_space>[{}],<seq2seq4repair_space>took<seq2seq4repair_space>[{}]" , indexName , TimeValue . timeValueNanos ( ( ( System . nanoTime ( ) ) - start ) ) ) ; } } } catch ( Throwable t ) { indexShard . warmerService ( ) . logger ( ) . warn ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>warm-up<seq2seq4repair_space>norms" , t ) ; } finally { latch . countDown ( ) ; } } } ) ; return new TerminationHandle ( ) { @ Override public void awaitTermination ( ) throws InterruptedException { latch . await ( ) ; } } ; } } static class FieldDataWarmer extends IndicesWarmer . Listener { @ Override public TerminationHandle warm ( final IndexShard indexShard , IndexMetaData indexMetaData , final WarmerContext context , ThreadPool threadPool ) { final MapperService mapperService = indexShard . mapperService ( ) ; final Map < String , FieldMapper < ? > > warmUp = new HashMap < String , FieldMapper < ? > > ( ) ; for ( DocumentMapper docMapper : mapperService ) { for ( FieldMapper < ? > fieldMapper : docMapper . mappers ( ) . mappers ( ) ) { final FieldDataType fieldDataType = fieldMapper . fieldDataType ( ) ; if ( fieldDataType == null ) { continue ; } final String indexName = fieldMapper . names ( ) . indexName ( ) ; if ( fieldMapper instanceof ParentFieldMapper ) { ParentFieldMapper parentFieldMapper = ( ( ParentFieldMapper ) ( fieldMapper ) ) ; if ( parentFieldMapper . active ( ) ) { warmUp . put ( indexName , parentFieldMapper ) ; } } else <START_BUG> if ( ( ( fieldDataType . getLoading ( ) ) != ( Loading . EAGER ) ) && ( warmUp . containsKey ( indexName ) ) ) { <END_BUG> warmUp . put ( indexName , fieldMapper ) ; } } } final IndexFieldDataService indexFieldDataService = indexShard . indexFieldDataService ( ) ; final Executor executor = threadPool . executor ( executor ( ) ) ; final CountDownLatch latch = new CountDownLatch ( ( ( context . newSearcher ( ) . reader ( ) . leaves ( ) . size ( ) ) * ( warmUp . size ( ) ) ) ) ; for ( final AtomicReaderContext ctx : context . newSearcher ( ) . reader ( ) . leaves ( ) ) { for ( final FieldMapper < ? > fieldMapper : warmUp . values ( ) ) { executor . execute ( new Runnable ( ) { @ Override public void run ( ) { try { final long start = System . nanoTime ( ) ; indexFieldDataService . getForField ( fieldMapper ) . load ( ctx ) ; if ( indexShard . warmerService ( ) . logger ( ) . isTraceEnabled ( ) ) { indexShard . warmerService ( ) . logger ( ) . trace ( "warmed<seq2seq4repair_space>fielddata<seq2seq4repair_space>for<seq2seq4repair_space>[{}],<seq2seq4repair_space>took<seq2seq4repair_space>[{}]" , fieldMapper . names ( ) . name ( ) , TimeValue . timeValueNanos ( ( ( System . nanoTime ( ) ) - start ) ) ) ; } } catch ( Throwable t ) { indexShard . warmerService ( ) . logger ( ) . warn ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>warm-up<seq2seq4repair_space>fielddata<seq2seq4repair_space>for<seq2seq4repair_space>[{}]" , t , fieldMapper . names ( ) . name ( ) ) ; } finally { latch . countDown ( ) ; } } } ) ; } } return new TerminationHandle ( ) { @ Override public void awaitTermination ( ) throws InterruptedException { latch . await ( ) ; } } ; }<BUG2FIX>if ( ( ( fieldDataType . getLoading ( ) ) != ( Loading . EAGER ) ) && ( ! ( warmUp . containsKey ( indexName ) ) ) ) {
public class ShardDeleteByQueryRequest extends ShardReplicationOperationRequest { private int shardId ; private BytesReference querySource ; private String [ ] types = Strings . EMPTY_ARRAY ; @ Nullable private Set < String > routing ; @ Nullable private String [ ] filteringAliases ; ShardDeleteByQueryRequest ( IndexDeleteByQueryRequest request , int shardId ) { } ShardDeleteByQueryRequest ( ) { } @ Override public ActionRequestValidationException validate ( ) { } public int shardId ( ) { } BytesReference querySource ( ) { } public String [ ] types ( ) { } public Set < String > routing ( ) { } public String [ ] filteringAliases ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { super . writeTo ( out ) ; <START_BUG> out . writeBytesReference ( querySource , true ) ; <END_BUG> out . writeVInt ( shardId ) ; out . writeVInt ( types . length ) ; for ( String type : types ) { out . writeUTF ( type ) ; } if ( ( routing ) != null ) { out . writeVInt ( routing . size ( ) ) ; for ( String r : routing ) { out . writeUTF ( r ) ; } } else { out . writeVInt ( 0 ) ; } if ( ( filteringAliases ) != null ) { out . writeVInt ( filteringAliases . length ) ; for ( String alias : filteringAliases ) { out . writeUTF ( alias ) ; } } else { out . writeVInt ( 0 ) ; } } @ Override public String toString ( ) { } }<BUG2FIX>out . writeBytesReference ( querySource ) ;
public abstract class NewsFragment extends PagedItemFragment < Event > { protected final IssueEventMatcher issueMatcher = new IssueEventMatcher ( ) ; protected final GistEventMatcher gistMatcher = new GistEventMatcher ( ) ; protected final RepositoryEventMatcher repoMatcher = new RepositoryEventMatcher ( ) ; @ Inject private AvatarLoader avatarHelper ; @ Inject protected EventService service ; @ Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; <START_BUG> setEmptyText ( getString ( no_news ) ) ; <END_BUG> } @ Override public void onListItemClick ( ListView l , View v , int position , long id ) { } private void openDownload ( Event event ) { } protected void viewRepository ( Repository repository ) { } @ Override protected ItemListAdapter < Event , ? extends ItemView > createAdapter ( List < Event > items ) { } @ Override protected int getLoadingMessage ( ) { } public void onLoadFinished ( Loader < List < Event > > loader , List < Event > items ) { } }<BUG2FIX>setEmptyText ( no_news ) ;
public class MappingUpdatedAction extends TransportMasterNodeOperationAction < MappingUpdatedAction . MappingUpdatedRequest , MappingUpdatedAction . MappingUpdatedResponse > { private final MetaDataMappingService metaDataMappingService ; @ Inject public MappingUpdatedAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool , MetaDataMappingService metaDataMappingService ) { } @ Override protected String transportAction ( ) { } @ Override protected MappingUpdatedAction . MappingUpdatedRequest newRequest ( ) { } @ Override protected MappingUpdatedAction . MappingUpdatedResponse newResponse ( ) { } @ Override protected MappingUpdatedAction . MappingUpdatedResponse masterOperation ( MappingUpdatedAction . MappingUpdatedRequest request , ClusterState state ) throws ElasticSearchException { try { metaDataMappingService . updateMapping ( request . index ( ) , request . type ( ) , request . mappingSource ( ) ) ; <START_BUG> } catch ( IOException e ) { <END_BUG> throw new ElasticSearchParseException ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>parse<seq2seq4repair_space>mapping<seq2seq4repair_space>form<seq2seq4repair_space>compressed<seq2seq4repair_space>string" , e ) ; } return new MappingUpdatedAction . MappingUpdatedResponse ( ) ; } public static class MappingUpdatedResponse implements ActionResponse { @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } public static class MappingUpdatedRequest extends MasterNodeOperationRequest { private String index ; private String type ; private CompressedString mappingSource ; MappingUpdatedRequest ( ) { } public MappingUpdatedRequest ( String index , String type , CompressedString mappingSource ) { } public String index ( ) { } public String type ( ) { } public CompressedString mappingSource ( ) { } @ Override public ActionRequestValidationException validate ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } }<BUG2FIX>} catch ( Exception e ) {
public class JsonIntegerFieldMapper extends JsonNumberFieldMapper < Integer > { public static final String JSON_TYPE = "integer" ; public static class Defaults extends JsonNumberFieldMapper . Defaults { public static final Integer NULL_VALUE = null ; } public static class Builder extends JsonNumberFieldMapper . Builder < JsonIntegerFieldMapper . Builder , JsonIntegerFieldMapper > { protected Integer nullValue = JsonIntegerFieldMapper . Defaults . NULL_VALUE ; public Builder ( String name ) { } public JsonIntegerFieldMapper . Builder nullValue ( int nullValue ) { } @ Override public JsonIntegerFieldMapper build ( BuilderContext context ) { } } public static class TypeParser implements JsonTypeParser { @ Override public JsonMapper . Builder parse ( String name , JsonNode node , ParserContext parserContext ) throws MapperParsingException { } } private final Integer nullValue ; private final String nullValueAsString ; protected JsonIntegerFieldMapper ( Names names , int precisionStep , Field . Index index , Field . Store store , float boost , boolean omitNorms , boolean omitTermFreqAndPositions , Integer nullValue ) { } @ Override protected int maxPrecisionStep ( ) { } @ Override public Integer value ( Fieldable field ) { byte [ ] value = field . getBinaryValue ( ) ; if ( value == null ) { <START_BUG> return Integer . MIN_VALUE ; <END_BUG> } return Numbers . bytesToInt ( value ) ; } @ Override public String indexedValue ( String value ) { } @ Override public String indexedValue ( Integer value ) { } @ Override public Object valueFromTerm ( String term ) { } @ Override public Object valueFromString ( String text ) { } @ Override public Query rangeQuery ( String lowerTerm , String upperTerm , boolean includeLower , boolean includeUpper ) { } @ Override public Filter rangeFilter ( String lowerTerm , String upperTerm , boolean includeLower , boolean includeUpper ) { } @ Override protected Field parseCreateField ( JsonParseContext jsonContext ) throws IOException { } @ Override public int sortType ( ) { } @ Override protected String jsonType ( ) { } @ Override protected void doJsonBody ( JsonBuilder builder ) throws IOException { } }<BUG2FIX>return null ;
public class RestMainAction extends BaseRestHandler { @ Inject public RestMainAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { ClusterStateRequest clusterStateRequest = new ClusterStateRequest ( ) ; clusterStateRequest . listenerThreaded ( false ) ; clusterStateRequest . masterNodeTimeout ( TimeValue . timeValueMillis ( 0 ) ) ; clusterStateRequest . local ( true ) ; clusterStateRequest . filterAll ( ) . filterBlocks ( false ) ; client . admin ( ) . cluster ( ) . state ( clusterStateRequest , new org . elasticsearch . action . ActionListener < ClusterStateResponse > ( ) { @ Override public void onResponse ( ClusterStateResponse response ) { RestStatus status = RestStatus . OK ; if ( response . getState ( ) . blocks ( ) . hasGlobalBlock ( SERVICE_UNAVAILABLE ) ) { status = RestStatus . SERVICE_UNAVAILABLE ; } if ( ( request . method ( ) ) == ( Method . HEAD ) ) { channel . sendResponse ( new StringRestResponse ( status ) ) ; return ; } try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) . prettyPrint ( ) ; builder . startObject ( ) ; builder . field ( "ok" , true ) ; builder . field ( "status" , status . getStatus ( ) ) ; if ( ( settings . get ( "name" ) ) != null ) { builder . field ( "name" , settings . get ( "name" ) ) ; } builder . startObject ( "version" ) . field ( "number" , CURRENT . number ( ) ) . field ( "snapshot_build" , snapshot ) . endObject ( ) ; builder . field ( "tagline" , "You<seq2seq4repair_space>Know,<seq2seq4repair_space>for<seq2seq4repair_space>Search" ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , status , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { if ( ( request . method ( ) ) == ( HEAD ) ) { channel . sendResponse ( new StringRestResponse ( ExceptionsHelper . status ( e ) ) ) ; } else { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } } catch ( Exception e1 ) { logger . warn ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>response" , e ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class RestHeadAction extends BaseRestHandler { @ Inject public RestHeadAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { final GetRequest getRequest = new GetRequest ( request . param ( "index" ) , request . param ( "type" ) , request . param ( "id" ) ) ; getRequest . listenerThreaded ( false ) ; getRequest . operationThreaded ( true ) ; getRequest . refresh ( request . paramAsBoolean ( "refresh" , getRequest . refresh ( ) ) ) ; getRequest . parent ( request . param ( "parent" ) ) ; getRequest . routing ( request . param ( "routing" ) ) ; getRequest . preference ( request . param ( "preference" ) ) ; getRequest . realtime ( request . paramAsBooleanOptional ( "realtime" , null ) ) ; getRequest . fields ( EMPTY_ARRAY ) ; client . get ( getRequest , new org . elasticsearch . action . ActionListener < GetResponse > ( ) { @ Override public void onResponse ( GetResponse response ) { try { if ( ! ( response . isExists ( ) ) ) { channel . sendResponse ( new StringRestResponse ( RestStatus . NOT_FOUND ) ) ; } else { channel . sendResponse ( new StringRestResponse ( RestStatus . OK ) ) ; } <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new StringRestResponse ( ExceptionsHelper . status ( e ) ) ) ; } catch ( Exception e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class Box2DTest implements InputListener , RenderListener { private OrthographicCamera camera ; private ImmediateModeRenderer renderer ; private SpriteBatch batch ; private Font font ; private World world ; private ArrayList < Body > boxes = new ArrayList < Body > ( ) ; private Body groundBody ; private MouseJoint mouseJoint = null ; private Body hitBody = null ; @ Override public void surfaceCreated ( Application app ) { } private void createPhysicsWorld ( ) { } private void createBoxes ( ) { } @ Override public void render ( Application app ) { long start = System . nanoTime ( ) ; world . step ( app . getGraphics ( ) . getDeltaTime ( ) , 3 , 3 ) ; float updateTime = ( ( System . nanoTime ( ) ) - start ) / 1.0E9F ; GL10 gl = app . getGraphics ( ) . getGL10 ( ) ; gl . glClear ( GL_COLOR_BUFFER_BIT ) ; <START_BUG> camera . setMatrices ( app . getGraphics ( ) ) ; <END_BUG> renderBox ( gl , groundBody , 50 , 1 ) ; for ( int i = 0 ; i < ( boxes . size ( ) ) ; i ++ ) { Body box = boxes . get ( i ) ; renderBox ( gl , box , 1 , 1 ) ; } gl . glPointSize ( 4 ) ; renderer . begin ( GL_POINTS ) ; for ( int i = 0 ; i < ( world . getContactCount ( ) ) ; i ++ ) { Contact contact = world . getContactList ( ) . get ( i ) ; if ( contact . isTouching ( ) ) { WorldManifold manifold = contact . GetWorldManifold ( ) ; int numContactPoints = manifold . getNumberOfContactPoints ( ) ; for ( int j = 0 ; j < numContactPoints ; j ++ ) { Vector2 point = manifold . getPoints ( ) [ j ] ; renderer . color ( 0 , 1 , 0 , 1 ) ; renderer . vertex ( point . x , point . y , 0 ) ; } } } renderer . end ( ) ; gl . glPointSize ( 1 ) ; batch . begin ( ) ; batch . drawText ( font , ( ( ( "fps:<seq2seq4repair_space>" + ( app . getGraphics ( ) . getFramesPerSecond ( ) ) ) + "<seq2seq4repair_space>update<seq2seq4repair_space>time:<seq2seq4repair_space>" ) + updateTime ) , 0 , app . getGraphics ( ) . getHeight ( ) , RED ) ; batch . end ( ) ; } private void renderBox ( GL10 gl , Body body , float halfWidth , float halfHeight ) { } Vector2 testPoint = new Vector2 ( ) ; QueryCallback callback = new QueryCallback ( ) { @ Override public boolean reportFixture ( Fixture fixture ) { } } ; @ Override public boolean touchDown ( int x , int y , int pointer ) { } Vector2 target = new Vector2 ( ) ; @ Override public boolean touchDragged ( int x , int y , int pointer ) { } @ Override public boolean touchUp ( int x , int y , int pointer ) { } @ Override public void surfaceChanged ( Application app , int width , int height ) { } @ Override public void dispose ( Application app ) { } @ Override public boolean keyDown ( int keycode ) { } @ Override public boolean keyTyped ( char character ) { } @ Override public boolean keyUp ( int keycode ) { } }<BUG2FIX>camera . setMatrices ( ) ;
public class BulletTestCollection extends GdxTest implements InputProcessor , GestureListener { protected final BulletTest [ ] tests = new BulletTest [ ] { new ShootTest ( ) , new KinematicTest ( ) , new ConstraintsTest ( ) , new MeshShapeTest ( ) , new ConvexHullTest ( ) , new RayCastTest ( ) , new RayPickRagdollTest ( ) , new InternalTickTest ( ) , new CollisionWorldTest ( ) , new CollisionTest ( ) , new FrustumCullingTest ( ) , new ContactCallbackTest ( ) , new SoftBodyTest ( ) , new SoftMeshTest ( ) } ; protected int testIndex = 0 ; private Application app = null ; private BitmapFont font ; private Stage hud ; private Label fpsLabel ; private Label titleLabel ; private Label instructLabel ; private int loading = 0 ; @ Override public void render ( ) { } @ Override public void create ( ) { } @ Override public void dispose ( ) { } public void next ( ) { } public void loadnext ( ) { } @ Override public boolean keyDown ( int keycode ) { } @ Override public boolean keyTyped ( char character ) { } @ Override public boolean keyUp ( int keycode ) { } @ Override public boolean touchDown ( int x , int y , int pointer , int button ) { } @ Override public boolean touchDragged ( int x , int y , int pointer ) { } @ Override public boolean touchUp ( int x , int y , int pointer , int button ) { } @ Override public boolean needsGL20 ( ) { <START_BUG> return false ; <END_BUG> } @ Override public boolean mouseMoved ( int x , int y ) { } @ Override public boolean scrolled ( int amount ) { } @ Override public boolean touchDown ( float x , float y , int pointer , int button ) { } @ Override public boolean tap ( float x , float y , int count , int button ) { } @ Override public boolean longPress ( float x , float y ) { } @ Override public boolean fling ( float velocityX , float velocityY , int button ) { } @ Override public boolean pan ( float x , float y , float deltaX , float deltaY ) { } @ Override public boolean zoom ( float originalDistance , float currentDistance ) { } @ Override public boolean pinch ( Vector2 initialFirstPointer , Vector2 initialSecondPointer , Vector2 firstPointer , Vector2 secondPointer ) { } }<BUG2FIX>return true ;
public class TideMapLoader extends SynchronousAssetLoader < TiledMap , TideMapLoader . Parameters > { public static class Parameters extends AssetLoaderParameters < TiledMap > { } private XmlReader xml = new XmlReader ( ) ; private Element root ; public TideMapLoader ( ) { } public TideMapLoader ( FileHandleResolver resolver ) { } public TiledMap load ( String fileName ) { } @ Override public TiledMap load ( AssetManager assetManager , String fileName , TideMapLoader . Parameters parameter ) { } @ Override public Array < AssetDescriptor > getDependencies ( String fileName , TideMapLoader . Parameters parameter ) { } private TiledMap loadMap ( Element root , FileHandle tmxFile , ImageResolver imageResolver ) { } private Array < FileHandle > loadTileSheets ( Element root , FileHandle tideFile ) throws IOException { } private void loadTileSheet ( TiledMap map , Element element , FileHandle tideFile , ImageResolver imageResolver ) { } private void loadLayer ( TiledMap map , Element element ) { if ( element . getName ( ) . equals ( "Layer" ) ) { String id = element . getAttribute ( "Id" ) ; String visible = element . getAttribute ( "Visible" ) ; Element dimensions = element . getChildByName ( "Dimensions" ) ; String layerSize = dimensions . getAttribute ( "LayerSize" ) ; String tileSize = dimensions . getAttribute ( "TileSize" ) ; String [ ] layerSizeParts = layerSize . split ( "<seq2seq4repair_space>x<seq2seq4repair_space>" ) ; int layerSizeX = Integer . parseInt ( layerSizeParts [ 0 ] ) ; int layerSizeY = Integer . parseInt ( layerSizeParts [ 1 ] ) ; String [ ] tileSizeParts = tileSize . split ( "<seq2seq4repair_space>x<seq2seq4repair_space>" ) ; int tileSizeX = Integer . parseInt ( tileSizeParts [ 0 ] ) ; int tileSizeY = Integer . parseInt ( tileSizeParts [ 1 ] ) ; TiledMapTileLayer layer = new TiledMapTileLayer ( layerSizeX , layerSizeY , tileSizeX , tileSizeY ) ; Element tileArray = element . getChildByName ( "TileArray" ) ; Array < Element > rows = tileArray . getChildrenByName ( "Row" ) ; TiledMapTileSets tilesets = map . getTileSets ( ) ; TiledMapTileSet currentTileSet = null ; int firstgid = 0 ; int x ; int y ; for ( int row = 0 , rowCount = rows . size ; row < rowCount ; row ++ ) { Element currentRow = rows . get ( row ) ; y = ( rowCount - 1 ) - row ; x = 0 ; for ( int child = 0 , childCount = currentRow . getChildCount ( ) ; child < childCount ; child ++ ) { Element currentChild = currentRow . getChild ( child ) ; String name = currentChild . getName ( ) ; if ( name . equals ( "TileSheet" ) ) { currentTileSet = tilesets . getTileSet ( currentChild . getAttribute ( "Ref" ) ) ; firstgid = currentTileSet . getProperties ( ) . get ( "firstgid" , Integer . class ) ; } else if ( name . equals ( "Null" ) ) { x += currentChild . getIntAttribute ( "Count" ) ; } else if ( name . equals ( "Static" ) ) { Cell cell = new Cell ( ) ; cell . setTile ( currentTileSet . getTile ( ( firstgid + ( currentChild . getIntAttribute ( "Index" ) ) ) ) ) ; layer . setCell ( ( x ++ ) , y , cell ) ; } else if ( name . equals ( "Animated" ) ) { int interval = currentChild . getInt ( "Interval" ) ; Element frames = currentChild . getChildByName ( "Frames" ) ; Array < StaticTiledMapTile > frameTiles = new Array < StaticTiledMapTile > ( ) ; for ( int frameChild = 0 , frameChildCount = frames . getChildCount ( ) ; frameChild < frameChildCount ; frameChild ++ ) { Element frame = frames . getChild ( frameChild ) ; String frameName = frame . getName ( ) ; if ( frameName . equals ( "TileSheet" ) ) { currentTileSet = tilesets . getTileSet ( frame . getAttribute ( "Ref" ) ) ; firstgid = currentTileSet . getProperties ( ) . get ( "firstgid" , Integer . class ) ; } else if ( frameName . equals ( "Static" ) ) { frameTiles . add ( ( ( StaticTiledMapTile ) ( currentTileSet . getTile ( ( firstgid + ( frame . getIntAttribute ( "Index" ) ) ) ) ) ) ) ; } } Cell cell = new Cell ( ) ; cell . setTile ( new com . badlogic . gdx . maps . tiled . tiles . AnimatedTiledMapTile ( ( interval / 1000.0F ) , frameTiles ) ) ; layer . setCell ( ( x ++ ) , y , cell ) ; } } } <START_BUG> map . getLayers ( ) . addLayer ( layer ) ; <END_BUG> } } private void loadProperties ( MapProperties properties , Element element ) { } private static FileHandle getRelativeFileHandle ( FileHandle file , String path ) { } }<BUG2FIX>map . getLayers ( ) . add ( layer ) ;
public class TermsFilterParser extends AbstractIndexComponent implements XContentFilterParser { public static final String NAME = "terms" ; @ Inject public TermsFilterParser ( Index index , @ IndexSettings Settings settings ) { } @ Override public String [ ] names ( ) { } @ Override public Filter parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; MapperService . SmartNameFieldMappers smartNameFieldMappers = null ; <START_BUG> boolean cache = false ; <END_BUG> TermsFilter termsFilter = new PublicTermsFilter ( ) ; String filterName = null ; String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_ARRAY ) ) { String fieldName = currentFieldName ; FieldMapper fieldMapper = null ; smartNameFieldMappers = parseContext . smartFieldMappers ( fieldName ) ; if ( smartNameFieldMappers != null ) { if ( smartNameFieldMappers . hasMapper ( ) ) { fieldMapper = smartNameFieldMappers . mapper ( ) ; fieldName = fieldMapper . names ( ) . indexName ( ) ; } } while ( ( token = parser . nextToken ( ) ) != ( Token . END_ARRAY ) ) { String value = parser . text ( ) ; if ( value == null ) { throw new QueryParsingException ( index , "No<seq2seq4repair_space>value<seq2seq4repair_space>specified<seq2seq4repair_space>for<seq2seq4repair_space>term<seq2seq4repair_space>filter" ) ; } if ( fieldMapper != null ) { value = fieldMapper . indexedValue ( value ) ; } termsFilter . addTerm ( new Term ( fieldName , value ) ) ; } } else if ( token . isValue ( ) ) { if ( "_name" . equals ( currentFieldName ) ) { filterName = parser . text ( ) ; } else if ( "_cache" . equals ( currentFieldName ) ) { cache = parser . booleanValue ( ) ; } } } Filter filter = termsFilter ; if ( cache ) { filter = parseContext . cacheFilter ( filter ) ; } else { filter = parseContext . cacheWeakFilter ( filter ) ; } filter = wrapSmartNameFilter ( filter , smartNameFieldMappers , parseContext ) ; if ( filterName != null ) { parseContext . addNamedFilter ( filterName , filter ) ; } return filter ; } }<BUG2FIX>boolean cache = true ;
public class ConstraintsTest extends BaseBulletTest { final Array < btTypedConstraint > constraints = new Array < btTypedConstraint > ( ) ; @ Override public void create ( ) { } @ Override public void dispose ( ) { for ( int i = 0 ; i < ( constraints . size ) ; i ++ ) { ( ( btDynamicsWorld ) ( collisionWorld ) ) . removeConstraint ( constraints . get ( i ) ) ; <START_BUG> constraints . get ( i ) . delete ( ) ; <END_BUG> } constraints . clear ( ) ; super . dispose ( ) ; } @ Override public boolean tap ( float x , float y , int count , int button ) { } }<BUG2FIX>constraints . get ( i ) . dispose ( ) ;
public abstract class WordScorer { protected final IndexReader reader ; protected final String field ; protected final Terms terms ; protected final long vocabluarySize ; protected double realWordLikelyhood ; protected final BytesRef spare = new BytesRef ( ) ; protected final BytesRef separator ; protected final TermsEnum termsEnum ; private final long numTerms ; private final boolean useTotalTermFreq ; public WordScorer ( IndexReader reader , String field , double realWordLikelyHood , BytesRef separator ) throws IOException { } public WordScorer ( IndexReader reader , Terms terms , String field , double realWordLikelyHood , BytesRef separator ) throws IOException { } public long frequency ( BytesRef term ) throws IOException { <START_BUG> if ( termsEnum . seekExact ( term , true ) ) { <END_BUG> return useTotalTermFreq ? termsEnum . totalTermFreq ( ) : termsEnum . docFreq ( ) ; } return 0 ; } protected double channelScore ( Candidate candidate , Candidate original ) throws IOException { } public double score ( Candidate [ ] path , CandidateSet [ ] candidateSet , int at , int gramSize ) throws IOException { } protected double scoreUnigram ( Candidate word ) throws IOException { } protected double scoreBigram ( Candidate word , Candidate w_1 ) throws IOException { } protected double scoreTrigram ( Candidate word , Candidate w_1 , Candidate w_2 ) throws IOException { } public static interface WordScorerFactory { public WordScorer newScorer ( IndexReader reader , Terms terms , String field , double realWordLikelyhood , BytesRef separator ) throws IOException { } } }<BUG2FIX>if ( termsEnum . seekExact ( term ) ) {
public class CustomBoostFactorQuery extends Query { private Query subQuery ; private float boostFactor ; public CustomBoostFactorQuery ( Query subQuery , float boostFactor ) { } public Query getSubQuery ( ) { } public float getBoostFactor ( ) { } @ Override public Query rewrite ( IndexReader reader ) throws IOException { } @ Override public void extractTerms ( Set < Term > terms ) { } @ Override public Weight createWeight ( Searcher searcher ) throws IOException { } private class CustomBoostFactorWeight extends Weight { Searcher searcher ; Weight subQueryWeight ; public CustomBoostFactorWeight ( Searcher searcher ) throws IOException { } public Query getQuery ( ) { } public float getValue ( ) { } @ Override public float sumOfSquaredWeights ( ) throws IOException { } @ Override public void normalize ( float norm ) { } @ Override public Scorer scorer ( IndexReader reader , boolean scoreDocsInOrder , boolean topScorer ) throws IOException { <START_BUG> Scorer subQueryScorer = subQueryWeight . scorer ( reader , true , false ) ; <END_BUG> if ( subQueryScorer == null ) { return null ; } return new CustomBoostFactorQuery . CustomBoostFactorScorer ( getSimilarity ( searcher ) , reader , this , subQueryScorer ) ; } @ Override public Explanation explain ( IndexReader reader , int doc ) throws IOException { } } private class CustomBoostFactorScorer extends Scorer { private final CustomBoostFactorQuery . CustomBoostFactorWeight weight ; private final float subQueryWeight ; private final Scorer scorer ; private final IndexReader reader ; private CustomBoostFactorScorer ( Similarity similarity , IndexReader reader , CustomBoostFactorQuery . CustomBoostFactorWeight w , Scorer scorer ) throws IOException { } @ Override public int docID ( ) { } @ Override public int advance ( int target ) throws IOException { } @ Override public int nextDoc ( ) throws IOException { } @ Override public float score ( ) throws IOException { } public Explanation explain ( int doc ) throws IOException { } } public String toString ( String field ) { } public boolean equals ( Object o ) { } public int hashCode ( ) { } }<BUG2FIX>Scorer subQueryScorer = subQueryWeight . scorer ( reader , scoreDocsInOrder , false ) ;
public class TiledMapPacker { private TexturePacker packer ; private TiledMap map ; private ArrayList < String > processedTileSets = new ArrayList < String > ( ) ; private ArrayList < Integer > blendedTiles = new ArrayList < Integer > ( ) ; private static class TmxFilter implements FilenameFilter { public TmxFilter ( ) { } @ Override public boolean accept ( File dir , String name ) { } } TiledMapPacker . TiledMapPackerSettings settings ; public TiledMapPacker ( ) { } public TiledMapPacker ( TiledMapPacker . TiledMapPackerSettings settings ) { } public void processMap ( File inputDir , File outputDir , Settings settings ) throws IOException { FileHandle inputDirHandle = new FileHandle ( inputDir . getAbsolutePath ( ) ) ; File [ ] files = inputDir . listFiles ( new TiledMapPacker . TmxFilter ( ) ) ; for ( File file : files ) { map = TiledLoader . createMap ( new FileHandle ( file . getAbsolutePath ( ) ) ) ; IntArray usedIds = null ; if ( this . settings . stripUnusedTiles ) { usedIds = new IntArray ( ( ( ( map . layers . size ( ) ) * ( map . height ) ) * ( map . width ) ) ) ; for ( TiledLayer layer : map . layers ) { for ( int y = 0 ; y < ( layer . tiles . length ) ; ++ y ) { for ( int x = 0 ; x < ( layer . tiles [ y ] . length ) ; ++ x ) { <START_BUG> usedIds . add ( ( ( layer . tiles [ y ] [ x ] ) & ( ~ - 536870912 ) ) ) ; <END_BUG> } } } } for ( TileSet set : map . tileSets ) { if ( ! ( processedTileSets . contains ( set . imageName ) ) ) { processedTileSets . add ( set . imageName ) ; packTileSet ( set , usedIds , inputDirHandle , outputDir , settings ) ; } } writeUpdatedTMX ( outputDir , map . tmxFile ) ; } } private void packTileSet ( TileSet set , IntArray usedIds , FileHandle inputDirHandle , File outputDir , Settings settings ) throws IOException { } private static String removeExtension ( String s ) { } private static String removePath ( String s ) { } private static File getRelativeFile ( File path , String relativePath ) { } private void setBlended ( int tileNum ) { } private void writeUpdatedTMX ( File outputDir , FileHandle tmxFileHandle ) throws IOException { } private static void setProperty ( Document doc , Node parent , String name , String value ) { } private static String toCSV ( ArrayList < Integer > values ) { } private static Node getFirstChildNodeByName ( Node parent , String child ) { } private static Node getFirstChildByNameAttrValue ( Node node , String childName , String attr , String value ) { } private static boolean isBlended ( BufferedImage tile ) { } private TileSetLayout getTileSetLayout ( int tileNum , FileHandle inputDirHandle ) throws IOException { } public static void main ( String [ ] args ) { } public static class TiledMapPackerSettings { public boolean stripUnusedTiles = false ; } }<BUG2FIX>usedIds . add ( layer . tiles [ y ] [ x ] ) ;
public NewsEventViewHolder ( final View view ) { } public void updateViewFor ( Event event ) { String relativeTime = Time . relativeTimeFor ( event . getCreatedAt ( ) ) . toString ( ) ; String actor = ( "<b>" + ( event . getActor ( ) . getLogin ( ) ) ) + "</b>" ; String repoName = event . getRepo ( ) . getName ( ) ; String type = event . getType ( ) ; String text = null ; if ( TYPE_COMMIT_COMMENT . equals ( type ) ) text = MessageFormat . format ( "{0}<seq2seq4repair_space>commented<seq2seq4repair_space>on<seq2seq4repair_space>commit<seq2seq4repair_space>on<seq2seq4repair_space>{1}" , actor , repoName ) ; else if ( TYPE_CREATE . equals ( type ) ) { CreatePayload payload = ( ( CreatePayload ) ( event . getPayload ( ) ) ) ; String refType = payload . getRefType ( ) ; String created ; if ( ! ( "repository" . equals ( refType ) ) ) created = ( ( payload . getRef ( ) ) + "<seq2seq4repair_space>at<seq2seq4repair_space>" ) + repoName ; else created = repoName . substring ( ( ( repoName . indexOf ( '/' ) ) + 1 ) ) ; text = MessageFormat . format ( "{0}<seq2seq4repair_space>created<seq2seq4repair_space>{1}<seq2seq4repair_space>{2}" , actor , refType , created ) ; } else if ( TYPE_DELETE . equals ( type ) ) { DeletePayload payload = ( ( DeletePayload ) ( event . getPayload ( ) ) ) ; String refType = payload . getRefType ( ) ; text = MessageFormat . format ( "{0}<seq2seq4repair_space>deleted<seq2seq4repair_space>{1}<seq2seq4repair_space>{2}<seq2seq4repair_space>at<seq2seq4repair_space>{3}" , actor , refType , payload . getRef ( ) , repoName ) ; } else if ( TYPE_DOWNLOAD . equals ( type ) ) text = MessageFormat . format ( "{0}<seq2seq4repair_space>uploaded<seq2seq4repair_space>a<seq2seq4repair_space>file<seq2seq4repair_space>to<seq2seq4repair_space>{1}" , actor , repoName ) ; else if ( TYPE_FOLLOW . equals ( type ) ) text = MessageFormat . format ( "{0}<seq2seq4repair_space>started<seq2seq4repair_space>following<seq2seq4repair_space>{1}" , actor , ( ( org . eclipse . egit . github . core . event . FollowPayload ) ( event . getPayload ( ) ) ) . getTarget ( ) . getLogin ( ) ) ; else if ( TYPE_FORK . equals ( type ) ) text = MessageFormat . format ( "{0}<seq2seq4repair_space>forked<seq2seq4repair_space>repository<seq2seq4repair_space>{1}" , actor , repoName ) ; else if ( TYPE_GIST . equals ( type ) ) { GistPayload payload = ( ( GistPayload ) ( event . getPayload ( ) ) ) ; String action ; if ( "create" . equals ( payload . getAction ( ) ) ) action = "created" ; else if ( "update" . equals ( payload . getAction ( ) ) ) action = "updated" ; else action = payload . getAction ( ) ; text = MessageFormat . format ( "{0}<seq2seq4repair_space>{1}<seq2seq4repair_space>Gist<seq2seq4repair_space>{2}" , actor , action , payload . getGist ( ) . getId ( ) ) ; } else if ( TYPE_GOLLUM . equals ( type ) ) text = MessageFormat . format ( "{0}<seq2seq4repair_space>updated<seq2seq4repair_space>the<seq2seq4repair_space>wiki<seq2seq4repair_space>in<seq2seq4repair_space>{1}" , actor , repoName ) ; else if ( TYPE_ISSUE_COMMENT . equals ( type ) ) { Issue issue = ( ( org . eclipse . egit . github . core . event . IssueCommentPayload ) ( event . getPayload ( ) ) ) . getIssue ( ) ; text = MessageFormat . format ( "{0}<seq2seq4repair_space>commented<seq2seq4repair_space>on<seq2seq4repair_space>issue<seq2seq4repair_space>{1}<seq2seq4repair_space>on<seq2seq4repair_space>{2}" , actor , Integer . toString ( issue . getNumber ( ) ) , repoName ) ; } else if ( TYPE_ISSUES . equals ( type ) ) { IssuesPayload payload = ( ( IssuesPayload ) ( event . getPayload ( ) ) ) ; text = MessageFormat . format ( "{0}<seq2seq4repair_space>{1}<seq2seq4repair_space>issue<seq2seq4repair_space>{2}<seq2seq4repair_space>on<seq2seq4repair_space>{3}" , actor , payload . getAction ( ) , Integer . toString ( payload . getIssue ( ) . getNumber ( ) ) , repoName ) ; } else if ( TYPE_MEMBER . equals ( type ) ) text = MessageFormat . format ( "{0}<seq2seq4repair_space>was<seq2seq4repair_space>added<seq2seq4repair_space>as<seq2seq4repair_space>a<seq2seq4repair_space>collaborator<seq2seq4repair_space>to<seq2seq4repair_space>{1}" , actor , repoName ) ; else if ( TYPE_PUBLIC . equals ( type ) ) text = MessageFormat . format ( "{0}<seq2seq4repair_space>open<seq2seq4repair_space>sourced<seq2seq4repair_space>repository<seq2seq4repair_space>{1}" , actor , repoName ) ; else if ( TYPE_PULL_REQUEST . equals ( type ) ) { PullRequestPayload payload = ( ( PullRequestPayload ) ( event . getPayload ( ) ) ) ; String action = payload . getAction ( ) ; if ( "synchronize" . equals ( action ) ) action = "updated" ; <START_BUG> text = MessageFormat . format ( "{0}<seq2seq4repair_space>{1}<seq2seq4repair_space>pull<seq2seq4repair_space>request<seq2seq4repair_space>{2}<seq2seq4repair_space>on<seq2seq4repair_space>{3}" , actor , action , Integer . toBinaryString ( payload . getPullRequest ( ) . getNumber ( ) ) , repoName ) ; <END_BUG> } else if ( TYPE_PULL_REQUEST_REVIEW_COMMENT . equals ( type ) ) text = MessageFormat . format ( "{0}<seq2seq4repair_space>commented<seq2seq4repair_space>on<seq2seq4repair_space>{1}" , actor , repoName ) ; else if ( TYPE_PUSH . equals ( type ) ) { PushPayload payload = ( ( PushPayload ) ( event . getPayload ( ) ) ) ; String ref = payload . getRef ( ) ; if ( ref . startsWith ( "refs/heads/" ) ) ref = ref . substring ( 11 ) ; text = MessageFormat . format ( "{0}<seq2seq4repair_space>pushed<seq2seq4repair_space>to<seq2seq4repair_space>{1}<seq2seq4repair_space>at<seq2seq4repair_space>{2}" , actor , ref , repoName ) ; } else if ( TYPE_TEAM_ADD . equals ( type ) ) { TeamAddPayload payload = ( ( TeamAddPayload ) ( event . getPayload ( ) ) ) ; Team team = payload . getTeam ( ) ; String teamName ; if ( team != null ) teamName = "<seq2seq4repair_space>" + ( team . getName ( ) ) ; else teamName = "" ; String value ; User user = payload . getUser ( ) ; if ( user != null ) value = user . getLogin ( ) ; else value = payload . getRepo ( ) . getName ( ) ; text = MessageFormat . format ( "{0}<seq2seq4repair_space>added<seq2seq4repair_space>{1}<seq2seq4repair_space>to<seq2seq4repair_space>team{2}" , actor , value , teamName ) ; } else if ( TYPE_WATCH . equals ( type ) ) text = MessageFormat . format ( "{0}<seq2seq4repair_space>started<seq2seq4repair_space>watching<seq2seq4repair_space>{1}" , actor , repoName ) ; eventText . setText ( Html . fromHtml ( ( ( text + "<seq2seq4repair_space>" ) + relativeTime ) ) ) ;<BUG2FIX>text = MessageFormat . format ( "{0}<seq2seq4repair_space>{1}<seq2seq4repair_space>pull<seq2seq4repair_space>request<seq2seq4repair_space>{2}<seq2seq4repair_space>on<seq2seq4repair_space>{3}" , actor , action , Integer . toString ( payload . getPullRequest ( ) . getNumber ( ) ) , repoName ) ;
public class Scene2dTest extends GdxTest { Stage stage ; private FloatAction meow = new FloatAction ( 10 , 5 ) ; private TiledDrawable patch ; public void create ( ) { } public void render ( ) { } public void resize ( int width , int height ) { <START_BUG> stage . getViewport ( ) . update ( width , height ) ; <END_BUG> } public void dispose ( ) { } }<BUG2FIX>stage . getViewport ( ) . update ( width , height , true ) ;
public class LongFieldMapper extends NumberFieldMapper < Long > { public static final String CONTENT_TYPE = "long" ; public static class Defaults extends NumberFieldMapper . Defaults { public static final FieldType LONG_FIELD_TYPE = new FieldType ( NumberFieldMapper . Defaults . NUMBER_FIELD_TYPE ) ; public static final Long NULL_VALUE = null ; } public static class Builder extends NumberFieldMapper . Builder < LongFieldMapper . Builder , LongFieldMapper > { protected Long nullValue = LongFieldMapper . Defaults . NULL_VALUE ; public Builder ( String name ) { } public LongFieldMapper . Builder nullValue ( long nullValue ) { } @ Override public LongFieldMapper build ( BuilderContext context ) { <START_BUG> fieldType . setOmitNorms ( ( ( fieldType . omitNorms ( ) ) || ( ( boost ) != 1.0F ) ) ) ; <END_BUG> LongFieldMapper fieldMapper = new LongFieldMapper ( buildNames ( context ) , precisionStep , fuzzyFactor , boost , fieldType , nullValue , ignoreMalformed ( context ) ) ; fieldMapper . includeInAll ( includeInAll ) ; return fieldMapper ; } } public static class TypeParser implements Mapper . TypeParser { @ Override public Mapper . Builder parse ( String name , Map < String , Object > node , ParserContext parserContext ) throws MapperParsingException { } } private Long nullValue ; private String nullValueAsString ; protected LongFieldMapper ( Names names , int precisionStep , String fuzzyFactor , float boost , FieldType fieldType , Long nullValue , Explicit < Boolean > ignoreMalformed ) { } @ Override protected int maxPrecisionStep ( ) { } @ Override public Long value ( Field field ) { } @ Override public Long valueFromString ( String value ) { } @ Override public String indexedValue ( String value ) { } @ Override public Query fuzzyQuery ( String value , String minSim , int prefixLength , int maxExpansions , boolean transpositions ) { } @ Override public Query fuzzyQuery ( String value , double minSim , int prefixLength , int maxExpansions , boolean transpositions ) { } @ Override public Query fieldQuery ( String value , @ Nullable QueryParseContext context ) { } @ Override public Query rangeQuery ( String lowerTerm , String upperTerm , boolean includeLower , boolean includeUpper , @ Nullable QueryParseContext context ) { } @ Override public Filter fieldFilter ( String value , @ Nullable QueryParseContext context ) { } @ Override public Filter rangeFilter ( String lowerTerm , String upperTerm , boolean includeLower , boolean includeUpper , @ Nullable QueryParseContext context ) { } @ Override public Filter rangeFilter ( FieldDataCache fieldDataCache , String lowerTerm , String upperTerm , boolean includeLower , boolean includeUpper , @ Nullable QueryParseContext context ) { } @ Override public Filter nullValueFilter ( ) { } @ Override protected boolean customBoost ( ) { } @ Override protected Field innerParseCreateField ( ParseContext context ) throws IOException { } @ Override public FieldDataType fieldDataType ( ) { } @ Override protected String contentType ( ) { } @ Override public void merge ( Mapper mergeWith , MergeContext mergeContext ) throws MergeMappingException { } @ Override protected void doXContentBody ( XContentBuilder builder ) throws IOException { } public static class CustomLongNumericField extends CustomNumericField { private final long number ; private final NumberFieldMapper mapper ; public CustomLongNumericField ( NumberFieldMapper mapper , long number , FieldType fieldType ) { } @ Override public TokenStream tokenStream ( Analyzer analyzer ) throws IOException { } @ Override public String numericAsString ( ) { } } }<BUG2FIX>fieldType . setOmitNorms ( ( ( fieldType . omitNorms ( ) ) && ( ( boost ) != 1.0F ) ) ) ;
public abstract class BlobStoreGateway extends SharedStorageGateway { private BlobStore blobStore ; private ByteSizeValue chunkSize ; private BlobPath basePath ; private ImmutableBlobContainer metaDataBlobContainer ; private boolean compress ; private volatile int currentIndex ; protected BlobStoreGateway ( Settings settings , ThreadPool threadPool , ClusterService clusterService ) { } protected void initialize ( BlobStore blobStore , ClusterName clusterName , @ Nullable ByteSizeValue defaultChunkSize ) throws IOException { } @ Override public String toString ( ) { } public BlobStore blobStore ( ) { } public BlobPath basePath ( ) { } public ByteSizeValue chunkSize ( ) { } @ Override public void reset ( ) throws Exception { } @ Override public MetaData read ( ) throws GatewayException { } public CommitPoint findCommitPoint ( String index , int shardId ) throws IOException { } @ Override public void write ( MetaData metaData ) throws GatewayException { } private int findLatestIndex ( ) throws IOException { } private MetaData readMetaData ( byte [ ] data ) throws IOException { XContentParser parser = null ; try { if ( LZF . isCompressed ( data ) ) { <START_BUG> BytesStreamInput siBytes = new BytesStreamInput ( data ) ; <END_BUG> LZFStreamInput siLzf = CachedStreamInput . cachedLzf ( siBytes ) ; parser = XContentFactory . xContent ( JSON ) . createParser ( siLzf ) ; } else { parser = XContentFactory . xContent ( JSON ) . createParser ( data ) ; } return Builder . fromXContent ( parser ) ; } finally { if ( parser != null ) { parser . close ( ) ; } } } }<BUG2FIX>BytesStreamInput siBytes = new BytesStreamInput ( data , false ) ;
public class Box2DTest extends GdxTest implements InputProcessor { private OrthographicCamera camera ; private ImmediateModeRenderer10 renderer ; private Box2DDebugRenderer debugRenderer ; private SpriteBatch batch ; private BitmapFont font ; private TextureRegion textureRegion ; private World world ; private ArrayList < Body > boxes = new ArrayList < Body > ( ) ; Body groundBody ; private MouseJoint mouseJoint = null ; Body hitBody = null ; @ Override public void create ( ) { } private void createPhysicsWorld ( ) { } private void createBoxes ( ) { } @ Override public void render ( ) { long start = System . nanoTime ( ) ; <START_BUG> world . step ( graphics . getDeltaTime ( ) , 3 , 3 ) ; <END_BUG> float updateTime = ( ( System . nanoTime ( ) ) - start ) / 1.0E9F ; GL10 gl = graphics . getGL10 ( ) ; gl . glClear ( GL_COLOR_BUFFER_BIT ) ; camera . update ( ) ; camera . apply ( gl ) ; renderBox ( gl , groundBody , 50 , 1 ) ; batch . getProjectionMatrix ( ) . set ( camera . combined ) ; batch . begin ( ) ; for ( int i = 0 ; i < ( boxes . size ( ) ) ; i ++ ) { Body box = boxes . get ( i ) ; Vector2 position = box . getPosition ( ) ; float angle = ( MathUtils . radiansToDegrees ) * ( box . getAngle ( ) ) ; batch . draw ( textureRegion , ( ( position . x ) - 1 ) , ( ( position . y ) - 1 ) , 1.0F , 1.0F , 2 , 2 , 1 , 1 , angle ) ; } batch . end ( ) ; camera . apply ( gl10 ) ; debugRenderer . render ( world ) ; gl . glPointSize ( 4 ) ; renderer . begin ( GL_POINTS ) ; for ( int i = 0 ; i < ( world . getContactCount ( ) ) ; i ++ ) { Contact contact = world . getContactList ( ) . get ( i ) ; if ( contact . isTouching ( ) ) { WorldManifold manifold = contact . getWorldManifold ( ) ; int numContactPoints = manifold . getNumberOfContactPoints ( ) ; for ( int j = 0 ; j < numContactPoints ; j ++ ) { Vector2 point = manifold . getPoints ( ) [ j ] ; renderer . color ( 0 , 1 , 0 , 1 ) ; renderer . vertex ( point . x , point . y , 0 ) ; } } } renderer . end ( ) ; gl . glPointSize ( 1 ) ; batch . getProjectionMatrix ( ) . setToOrtho2D ( 0 , 0 , graphics . getWidth ( ) , graphics . getHeight ( ) ) ; batch . begin ( ) ; font . draw ( batch , ( ( ( "fps:<seq2seq4repair_space>" + ( graphics . getFramesPerSecond ( ) ) ) + "<seq2seq4repair_space>update<seq2seq4repair_space>time:<seq2seq4repair_space>" ) + updateTime ) , 0 , 20 ) ; batch . end ( ) ; } private void renderBox ( GL10 gl , Body body , float halfWidth , float halfHeight ) { } Vector3 testPoint = new Vector3 ( ) ; QueryCallback callback = new QueryCallback ( ) { @ Override public boolean reportFixture ( Fixture fixture ) { } } ; @ Override public boolean touchDown ( int x , int y , int pointer , int newParam ) { } Vector2 target = new Vector2 ( ) ; @ Override public boolean touchDragged ( int x , int y , int pointer ) { } @ Override public boolean touchUp ( int x , int y , int pointer , int button ) { } @ Override public void dispose ( ) { } @ Override public boolean needsGL20 ( ) { } @ Override public boolean keyDown ( int keycode ) { } @ Override public boolean keyTyped ( char character ) { } @ Override public boolean keyUp ( int keycode ) { } @ Override public boolean touchMoved ( int x , int y ) { } @ Override public boolean scrolled ( int amount ) { } }<BUG2FIX>world . step ( graphics . getDeltaTime ( ) , 8 , 3 ) ;
public class FrameBufferTest extends GdxTest { FrameBuffer frameBuffer ; Mesh mesh ; ShaderProgram meshShader ; Texture texture ; SpriteBatch spriteBatch ; @ Override public void render ( ) { } @ Override public void create ( ) { mesh = new Mesh ( true , 3 , 0 , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . Position , 3 , "a_Position" ) , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . ColorPacked , 4 , "a_Color" ) , new com . badlogic . gdx . graphics . VertexAttribute ( Usage . TextureCoordinates , 2 , "a_texCoords" ) ) ; float c1 = Color . toFloatBits ( 255 , 0 , 0 , 255 ) ; float c2 = Color . toFloatBits ( 255 , 0 , 0 , 255 ) ; float c3 = Color . toFloatBits ( 0 , 0 , 255 , 255 ) ; mesh . setVertices ( new float [ ] { - 0.5F , - 0.5F , 0 , c1 , 0 , 0 , 0.5F , - 0.5F , 0 , c2 , 1 , 0 , 0 , 0.5F , 0 , c3 , 0.5F , 1 } ) ; texture = new Texture ( files . internal ( "data/badlogic.jpg" ) ) ; spriteBatch = new SpriteBatch ( ) ; <START_BUG> frameBuffer = new FrameBuffer ( Format . RGB565 , 128 , 128 , true ) ; <END_BUG> createShader ( graphics ) ; } private void createShader ( Graphics graphics ) { } @ Override public boolean needsGL20 ( ) { } }<BUG2FIX>frameBuffer = new FrameBuffer ( Format . RGB565 , 128 , 128 , false ) ;
public class RestAnalyzeAction extends BaseRestHandler { @ Inject public RestAnalyzeAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { String text = request . param ( "text" ) ; if ( ( text == null ) && ( request . hasContent ( ) ) ) { text = request . content ( ) . toUtf8 ( ) ; } if ( text == null ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , new ElasticSearchIllegalArgumentException ( "text<seq2seq4repair_space>is<seq2seq4repair_space>missing" ) ) ) ; } catch ( IOException e1 ) { logger . warn ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>response" , e1 ) ; } return ; } AnalyzeRequest analyzeRequest = new AnalyzeRequest ( request . param ( "index" ) , text ) ; analyzeRequest . listenerThreaded ( false ) ; analyzeRequest . preferLocal ( request . paramAsBoolean ( "prefer_local" , analyzeRequest . preferLocalShard ( ) ) ) ; analyzeRequest . analyzer ( request . param ( "analyzer" ) ) ; analyzeRequest . field ( request . param ( "field" ) ) ; analyzeRequest . tokenizer ( request . param ( "tokenizer" ) ) ; analyzeRequest . tokenFilters ( request . paramAsStringArray ( "token_filters" , request . paramAsStringArray ( "filters" , null ) ) ) ; client . admin ( ) . indices ( ) . analyze ( analyzeRequest , new org . elasticsearch . action . ActionListener < AnalyzeResponse > ( ) { @ Override public void onResponse ( AnalyzeResponse response ) { try { <START_BUG> XContentBuilder builder = restContentBuilder ( request , null ) ; <END_BUG> builder . startObject ( ) ; response . toXContent ( builder , request ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; } catch ( Throwable e ) { onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>XContentBuilder builder = restContentBuilder ( request , false ) ;
@ SuppressCodecs ( { "Lucene3x" , "Lucene40" , "Lucene41" , "Lucene42" } ) public class TestReplaceMissing extends ElasticsearchLuceneTestCase { public void test ( ) throws Exception { Directory dir = newDirectory ( ) ; <START_BUG> IndexWriterConfig iwc = newIndexWriterConfig ( TEST_VERSION_CURRENT , null ) ; <END_BUG> iwc . setMergePolicy ( newLogMergePolicy ( ) ) ; IndexWriter iw = new IndexWriter ( dir , iwc ) ; Document doc = new Document ( ) ; doc . add ( new org . apache . lucene . document . SortedDocValuesField ( "field" , new BytesRef ( "cat" ) ) ) ; iw . addDocument ( doc ) ; doc = new Document ( ) ; iw . addDocument ( doc ) ; doc = new Document ( ) ; doc . add ( new org . apache . lucene . document . SortedDocValuesField ( "field" , new BytesRef ( "dog" ) ) ) ; iw . addDocument ( doc ) ; iw . forceMerge ( 1 ) ; iw . close ( ) ; DirectoryReader reader = DirectoryReader . open ( dir ) ; AtomicReader ar = getOnlySegmentReader ( reader ) ; SortedDocValues raw = ar . getSortedDocValues ( "field" ) ; assertEquals ( 2 , raw . getValueCount ( ) ) ; SortedDocValues dv = new BytesRefFieldComparatorSource . ReplaceMissing ( raw , new BytesRef ( "cat" ) ) ; assertEquals ( 2 , dv . getValueCount ( ) ) ; assertEquals ( "cat" , dv . lookupOrd ( 0 ) . utf8ToString ( ) ) ; assertEquals ( "dog" , dv . lookupOrd ( 1 ) . utf8ToString ( ) ) ; assertEquals ( 0 , dv . getOrd ( 0 ) ) ; assertEquals ( 0 , dv . getOrd ( 1 ) ) ; assertEquals ( 1 , dv . getOrd ( 2 ) ) ; dv = new BytesRefFieldComparatorSource . ReplaceMissing ( raw , new BytesRef ( "dog" ) ) ; assertEquals ( 2 , dv . getValueCount ( ) ) ; assertEquals ( "cat" , dv . lookupOrd ( 0 ) . utf8ToString ( ) ) ; assertEquals ( "dog" , dv . lookupOrd ( 1 ) . utf8ToString ( ) ) ; assertEquals ( 0 , dv . getOrd ( 0 ) ) ; assertEquals ( 1 , dv . getOrd ( 1 ) ) ; assertEquals ( 1 , dv . getOrd ( 2 ) ) ; dv = new BytesRefFieldComparatorSource . ReplaceMissing ( raw , new BytesRef ( "apple" ) ) ; assertEquals ( 3 , dv . getValueCount ( ) ) ; assertEquals ( "apple" , dv . lookupOrd ( 0 ) . utf8ToString ( ) ) ; assertEquals ( "cat" , dv . lookupOrd ( 1 ) . utf8ToString ( ) ) ; assertEquals ( "dog" , dv . lookupOrd ( 2 ) . utf8ToString ( ) ) ; assertEquals ( 1 , dv . getOrd ( 0 ) ) ; assertEquals ( 0 , dv . getOrd ( 1 ) ) ; assertEquals ( 2 , dv . getOrd ( 2 ) ) ; dv = new BytesRefFieldComparatorSource . ReplaceMissing ( raw , new BytesRef ( "company" ) ) ; assertEquals ( 3 , dv . getValueCount ( ) ) ; assertEquals ( "cat" , dv . lookupOrd ( 0 ) . utf8ToString ( ) ) ; assertEquals ( "company" , dv . lookupOrd ( 1 ) . utf8ToString ( ) ) ; assertEquals ( "dog" , dv . lookupOrd ( 2 ) . utf8ToString ( ) ) ; assertEquals ( 0 , dv . getOrd ( 0 ) ) ; assertEquals ( 1 , dv . getOrd ( 1 ) ) ; assertEquals ( 2 , dv . getOrd ( 2 ) ) ; dv = new BytesRefFieldComparatorSource . ReplaceMissing ( raw , new BytesRef ( "ebay" ) ) ; assertEquals ( 3 , dv . getValueCount ( ) ) ; assertEquals ( "cat" , dv . lookupOrd ( 0 ) . utf8ToString ( ) ) ; assertEquals ( "dog" , dv . lookupOrd ( 1 ) . utf8ToString ( ) ) ; assertEquals ( "ebay" , dv . lookupOrd ( 2 ) . utf8ToString ( ) ) ; assertEquals ( 0 , dv . getOrd ( 0 ) ) ; assertEquals ( 2 , dv . getOrd ( 1 ) ) ; assertEquals ( 1 , dv . getOrd ( 2 ) ) ; reader . close ( ) ; dir . close ( ) ; } }<BUG2FIX>IndexWriterConfig iwc = newIndexWriterConfig ( null ) ;
public class LongArrayRef extends AbstractList < Long > implements RandomAccess { public static final LongArrayRef EMPTY = new LongArrayRef ( new long [ 0 ] ) ; public long [ ] values ; public int start ; public int end ; public LongArrayRef ( long [ ] values ) { } public LongArrayRef ( long [ ] values , int length ) { } public LongArrayRef ( long [ ] values , int start , int end ) { } public void reset ( int newLength ) { } @ Override public int size ( ) { } @ Override public boolean isEmpty ( ) { <START_BUG> return ( size ( ) ) != 0 ; <END_BUG> } @ Override public Long get ( int index ) { } @ Override public boolean contains ( Object target ) { } @ Override public int indexOf ( Object target ) { } @ Override public int lastIndexOf ( Object target ) { } @ Override public Long set ( int index , Long element ) { } @ Override public boolean equals ( Object object ) { } @ Override public int hashCode ( ) { } @ Override public String toString ( ) { } private static int indexOf ( long [ ] array , long target , int start , int end ) { } private static int lastIndexOf ( long [ ] array , long target , int start , int end ) { } }<BUG2FIX>return ( size ( ) ) == 0 ;
public final class ClassReflection { public static Class forName ( String name ) throws ReflectionException { } public static String getSimpleName ( Class c ) { <START_BUG> return c . getName ( ) ; <END_BUG> } public static boolean isInstance ( Class c , Object obj ) { } public static boolean isAssignableFrom ( Class c1 , Class c2 ) { } public static boolean isMemberClass ( Class c ) { } public static boolean isStaticClass ( Class c ) { } public static < T > T newInstance ( Class < T > c ) throws ReflectionException { } public static Constructor [ ] getConstructors ( Class c ) { } public static Constructor getConstructor ( Class c , Class ... parameterTypes ) throws ReflectionException { } public static Constructor getDeclaredConstructor ( Class c , Class ... parameterTypes ) throws ReflectionException { } public static Method [ ] getMethods ( Class c ) { } public static Method getMethod ( Class c , String name , Class ... parameterTypes ) throws ReflectionException { } public static Method [ ] getDeclaredMethods ( Class c ) { } public static Method getDeclaredMethod ( Class c , String name , Class ... parameterTypes ) throws ReflectionException { } public static Field [ ] getFields ( Class c ) { } public static Field getField ( Class c , String name ) throws ReflectionException { } public static Field [ ] getDeclaredFields ( Class c ) { } public static Field getDeclaredField ( Class c , String name ) throws ReflectionException { } }<BUG2FIX>return c . getSimpleName ( ) ;
public class TermsStatsDoubleFacetCollector extends AbstractFacetCollector { private final ComparatorType comparatorType ; private final FieldDataCache fieldDataCache ; private final String keyFieldName ; private final String valueFieldName ; private final int size ; private final int numberOfShards ; private final FieldDataType keyFieldDataType ; private NumericFieldData keyFieldData ; private final FieldDataType valueFieldDataType ; private final SearchScript script ; private final TermsStatsDoubleFacetCollector . Aggregator aggregator ; public TermsStatsDoubleFacetCollector ( String facetName , String keyFieldName , String valueFieldName , int size , TermsStatsFacet . ComparatorType comparatorType , SearchContext context , String scriptLang , String script , Map < String , Object > params ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override protected void doSetNextReader ( AtomicReaderContext context ) throws IOException { keyFieldData = ( ( NumericFieldData ) ( fieldDataCache . cache ( keyFieldDataType , context . reader ( ) , keyFieldName ) ) ) ; if ( ( script ) != null ) { <START_BUG> script . setNextReader ( context . reader ( ) ) ; <END_BUG> } else { aggregator . valueFieldData = ( ( NumericFieldData ) ( fieldDataCache . cache ( valueFieldDataType , context . reader ( ) , valueFieldName ) ) ) ; } } @ Override protected void doCollect ( int doc ) throws IOException { } @ Override public Facet facet ( ) { } public static class Aggregator implements NumericFieldData . MissingDoubleValueInDocProc { final ExtTDoubleObjectHashMap < InternalTermsStatsDoubleFacet . DoubleEntry > entries = CacheRecycler . popDoubleObjectMap ( ) ; int missing ; NumericFieldData valueFieldData ; final TermsStatsDoubleFacetCollector . Aggregator . ValueAggregator valueAggregator = new TermsStatsDoubleFacetCollector . Aggregator . ValueAggregator ( ) ; @ Override public void onValue ( int docId , double value ) { } @ Override public void onMissing ( int docId ) { } public static class ValueAggregator implements NumericFieldData . DoubleValueInDocProc { DoubleEntry doubleEntry ; @ Override public void onValue ( int docId , double value ) { } } } public static class ScriptAggregator extends TermsStatsDoubleFacetCollector . Aggregator { private final SearchScript script ; public ScriptAggregator ( SearchScript script ) { } @ Override public void onValue ( int docId , double value ) { } } }<BUG2FIX>script . setNextReader ( context ) ;
public class TermsIntFacetCollector extends AbstractFacetCollector { private final FieldDataCache fieldDataCache ; private final String indexFieldName ; private final ComparatorType comparatorType ; private final int size ; private final int numberOfShards ; private final FieldDataType fieldDataType ; private IntFieldData fieldData ; private final TermsIntFacetCollector . StaticAggregatorValueProc aggregator ; private final SearchScript script ; public TermsIntFacetCollector ( String facetName , String fieldName , int size , TermsFacet . ComparatorType comparatorType , boolean allTerms , SearchContext context , ImmutableSet < BytesRef > excluded , String scriptLang , String script , Map < String , Object > params ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override protected void doSetNextReader ( AtomicReaderContext context ) throws IOException { fieldData = ( ( IntFieldData ) ( fieldDataCache . cache ( fieldDataType , context . reader ( ) , indexFieldName ) ) ) ; if ( ( script ) != null ) { <START_BUG> script . setNextReader ( context . reader ( ) ) ; <END_BUG> } } @ Override protected void doCollect ( int doc ) throws IOException { } @ Override public Facet facet ( ) { } public static class AggregatorValueProc extends TermsIntFacetCollector . StaticAggregatorValueProc { private final SearchScript script ; private final TIntHashSet excluded ; public AggregatorValueProc ( TIntIntHashMap facets , Set < BytesRef > excluded , SearchScript script ) { } @ Override public void onValue ( int docId , int value ) { } } public static class StaticAggregatorValueProc implements IntFieldData . ValueInDocProc , IntFieldData . ValueProc { private final TIntIntHashMap facets ; private int missing ; private int total ; public StaticAggregatorValueProc ( TIntIntHashMap facets ) { } @ Override public void onValue ( int value ) { } @ Override public void onValue ( int docId , int value ) { } @ Override public void onMissing ( int docId ) { } public final TIntIntHashMap facets ( ) { } public final int missing ( ) { } public final int total ( ) { } } }<BUG2FIX>script . setNextReader ( context ) ;
public class ChildrenQuery extends Query implements ScopePhase . CollectorPhase { private final SearchContext searchContext ; private final String parentType ; private final String childType ; private final Filter parentFilter ; private final ScoreType scoreType ; private final String scope ; private final Query childQuery ; private TObjectFloatHashMap < HashedBytesArray > uidToScore ; private TObjectIntHashMap < HashedBytesArray > uidToCount ; public ChildrenQuery ( SearchContext searchContext , String parentType , String childType , Filter parentFilter , String scope , Query childQuery , ScoreType scoreType ) { } private ChildrenQuery ( ChildrenQuery unProcessedQuery , Query rewrittenChildQuery ) { } @ Override public String toString ( String field ) { } @ Override public Query rewrite ( IndexReader reader ) throws IOException { } @ Override public void extractTerms ( Set < Term > terms ) { } @ Override public boolean requiresProcessing ( ) { } @ Override public Collector collector ( ) { } @ Override public void processCollector ( Collector collector ) { } @ Override public String scope ( ) { } @ Override public void clear ( ) { } @ Override public Query query ( ) { } @ Override public Weight createWeight ( IndexSearcher searcher ) throws IOException { } class ParentWeight extends Weight { final Weight childWeight ; public ParentWeight ( Weight childWeight ) { } @ Override public Explanation explain ( AtomicReaderContext context , int doc ) throws IOException { } @ Override public Query getQuery ( ) { } @ Override public float getValueForNormalization ( ) throws IOException { } @ Override public void normalize ( float norm , float topLevelBoost ) { } @ Override public Scorer scorer ( AtomicReaderContext context , boolean scoreDocsInOrder , boolean topScorer , Bits acceptDocs ) throws IOException { } } static class ParentScorer extends Scorer { final IdReaderTypeCache idTypeCache ; final TObjectFloatMap < HashedBytesArray > uidToScore ; final DocIdSetIterator parentsIterator ; int currentDocId = - 1 ; float currentScore ; ParentScorer ( Weight weight , IdReaderTypeCache idTypeCache , TObjectFloatMap < HashedBytesArray > uidToScore , DocIdSetIterator parentsIterator ) { } @ Override public float score ( ) throws IOException { } @ Override <START_BUG> public float freq ( ) throws IOException { <END_BUG> return 1 ; } @ Override public int docID ( ) { } @ Override public int nextDoc ( ) throws IOException { } @ Override public int advance ( int target ) throws IOException { } } static class AvgParentScorer extends ChildrenQuery . ParentScorer { final TObjectIntMap < HashedBytesArray > uidToCount ; HashedBytesArray currentUid ; AvgParentScorer ( Weight weight , IdReaderTypeCache idTypeCache , TObjectFloatMap < HashedBytesArray > uidToScore , TObjectIntMap < HashedBytesArray > uidToCount , DocIdSetIterator parentsIterator ) { } @ Override public int nextDoc ( ) throws IOException { } } static class ChildUidCollector extends NoopCollector { final TObjectFloatHashMap < HashedBytesArray > uidToScore ; final ScoreType scoreType ; final SearchContext searchContext ; final String childType ; Scorer scorer ; IdReaderTypeCache typeCache ; ChildUidCollector ( ScoreType scoreType , SearchContext searchContext , String childType , TObjectFloatHashMap < HashedBytesArray > uidToScore ) { } @ Override public void collect ( int doc ) throws IOException { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override public void setNextReader ( AtomicReaderContext context ) throws IOException { } } static class AvgChildUidCollector extends ChildrenQuery . ChildUidCollector { final TObjectIntHashMap < HashedBytesArray > uidToCount ; AvgChildUidCollector ( ScoreType scoreType , SearchContext searchContext , String childType , TObjectFloatHashMap < HashedBytesArray > uidToScore , TObjectIntHashMap < HashedBytesArray > uidToCount ) { } @ Override public void collect ( int doc ) throws IOException { } } }<BUG2FIX>public int freq ( ) throws IOException {
public class Pools { private static final ObjectMap < Class , ReflectionPool > typePools = new ObjectMap ( ) ; public static < T > Pool < T > get ( Class < T > type ) { } public static < T > T obtain ( Class < T > type ) { } public static void free ( Object object ) { } public static void freeAll ( Array objects ) { if ( objects == null ) throw new IllegalArgumentException ( "objects<seq2seq4repair_space>cannot<seq2seq4repair_space>be<seq2seq4repair_space>null." ) ; for ( int i = 0 , n = objects . size ; i < n ; i ++ ) { Object object = objects . get ( i ) ; if ( object == null ) continue ; ReflectionPool pool = Pools . typePools . get ( object . getClass ( ) ) ; if ( pool == null ) <START_BUG> return ; <END_BUG> pool . free ( object ) ; } } private Pools ( ) { } }<BUG2FIX>continue ;
public class ObjTest implements InputListener , GdxTest { PerspectiveCamera cam ; Mesh mesh ; Texture texture ; float angleY = 0 ; float angleX = 0 ; float [ ] lightColor = new float [ ] { 1 , 1 , 1 , 0 } ; float [ ] lightPosition = new float [ ] { 2 , 5 , 10 , 0 } ; float touchStartX = 0 ; float touchStartY = 0 ; long frameStart ; int frames = 0 ; @ Override public void surfaceCreated ( ) { if ( ( mesh ) == null ) { input . addInputListener ( this ) ; <START_BUG> mesh = ModelLoader . loadObj ( files . readFile ( "data/cube.obj" , Internal ) , true ) ; <END_BUG> texture = graphics . newTexture ( files . getFileHandle ( "data/badlogic.jpg" , Internal ) , MipMap , Linear , ClampToEdge , ClampToEdge ) ; cam = new PerspectiveCamera ( ) ; cam . getPosition ( ) . set ( 2 , 2 , 2 ) ; cam . getDirection ( ) . set ( ( - 1 ) , ( - 1 ) , ( - 1 ) ) ; } frameStart = System . nanoTime ( ) ; } @ Override public void surfaceChanged ( int width , int height ) { } @ Override public void render ( ) { } @ Override public void dispose ( ) { } @ Override public boolean keyDown ( int keycode ) { } @ Override public boolean keyTyped ( char character ) { } @ Override public boolean keyUp ( int keycode ) { } @ Override public boolean touchDown ( int x , int y , int pointer ) { } @ Override public boolean touchDragged ( int x , int y , int pointer ) { } @ Override public boolean touchUp ( int x , int y , int pointer ) { } @ Override public boolean needsGL20 ( ) { } }<BUG2FIX>mesh = ModelLoader . loadObj ( files . readFile ( "data/cube.obj" , Internal ) ) ;
public class MultiOrdinalsTests extends ElasticsearchTestCase { protected final Ordinals creationMultiOrdinals ( OrdinalsBuilder builder ) { } protected Ordinals creationMultiOrdinals ( OrdinalsBuilder builder , ImmutableSettings . Builder settings ) { } @ Test public void testRandomValues ( ) throws IOException { Random random = getRandom ( ) ; int numDocs = 100 + ( random . nextInt ( 1000 ) ) ; int numOrdinals = 1 + ( random . nextInt ( 200 ) ) ; int numValues = 100 + ( random . nextInt ( 100000 ) ) ; OrdinalsBuilder builder = new OrdinalsBuilder ( numDocs ) ; Set < MultiOrdinalsTests . OrdAndId > ordsAndIdSet = new HashSet < > ( ) ; for ( int i = 0 ; i < numValues ; i ++ ) { ordsAndIdSet . add ( new MultiOrdinalsTests . OrdAndId ( random . nextInt ( numOrdinals ) , random . nextInt ( numDocs ) ) ) ; } List < MultiOrdinalsTests . OrdAndId > ordsAndIds = new ArrayList < > ( ordsAndIdSet ) ; Collections . sort ( ordsAndIds , new Comparator < MultiOrdinalsTests . OrdAndId > ( ) { @ Override public int compare ( MultiOrdinalsTests . OrdAndId o1 , MultiOrdinalsTests . OrdAndId o2 ) { if ( ( o1 . ord ) < ( o2 . ord ) ) { return - 1 ; } if ( ( o1 . ord ) == ( o2 . ord ) ) { if ( ( o1 . id ) < ( o2 . id ) ) { return - 1 ; } if ( ( o1 . id ) > ( o2 . id ) ) { return 1 ; } return 0 ; } return 1 ; } } ) ; long lastOrd = - 1 ; for ( MultiOrdinalsTests . OrdAndId ordAndId : ordsAndIds ) { if ( lastOrd != ( ordAndId . ord ) ) { lastOrd = ordAndId . ord ; builder . nextOrdinal ( ) ; } ordAndId . ord = builder . currentOrdinal ( ) ; builder . addDoc ( ordAndId . id ) ; } Collections . sort ( ordsAndIds , new Comparator < MultiOrdinalsTests . OrdAndId > ( ) { @ Override public int compare ( MultiOrdinalsTests . OrdAndId o1 , MultiOrdinalsTests . OrdAndId o2 ) { if ( ( o1 . id ) < ( o2 . id ) ) { return - 1 ; } if ( ( o1 . id ) == ( o2 . id ) ) { if ( ( o1 . ord ) < ( o2 . ord ) ) { return - 1 ; } if ( ( o1 . ord ) > ( o2 . ord ) ) { return 1 ; } return 0 ; } return 1 ; } } ) ; Ordinals ords = creationMultiOrdinals ( builder ) ; RandomAccessOrds docs = ords . ordinals ( ) ; <START_BUG> final SortedDocValues singleOrds = MIN . select ( docs , ( - 1 ) ) ; <END_BUG> int docId = ordsAndIds . get ( 0 ) . id ; List < Long > docOrds = new ArrayList < > ( ) ; for ( MultiOrdinalsTests . OrdAndId ordAndId : ordsAndIds ) { if ( docId == ( ordAndId . id ) ) { docOrds . add ( ordAndId . ord ) ; } else { if ( ! ( docOrds . isEmpty ( ) ) ) { assertThat ( ( ( long ) ( singleOrds . getOrd ( docId ) ) ) , equalTo ( docOrds . get ( 0 ) ) ) ; docs . setDocument ( docId ) ; final int numOrds = docs . cardinality ( ) ; assertThat ( numOrds , equalTo ( docOrds . size ( ) ) ) ; for ( int i = 0 ; i < numOrds ; i ++ ) { assertThat ( docs . nextOrd ( ) , equalTo ( docOrds . get ( i ) ) ) ; } final long [ ] array = new long [ docOrds . size ( ) ] ; for ( int i = 0 ; i < ( array . length ) ; i ++ ) { array [ i ] = docOrds . get ( i ) ; } MultiOrdinalsTests . assertIter ( docs , docId , array ) ; } for ( int i = docId + 1 ; i < ( ordAndId . id ) ; i ++ ) { assertThat ( ( ( long ) ( singleOrds . getOrd ( i ) ) ) , equalTo ( NO_MORE_ORDS ) ) ; } docId = ordAndId . id ; docOrds . clear ( ) ; docOrds . add ( ordAndId . ord ) ; } } } public static class OrdAndId { long ord ; final int id ; public OrdAndId ( long ord , int id ) { } @ Override public int hashCode ( ) { } @ Override public boolean equals ( Object obj ) { } } @ Test public void testOrdinals ( ) throws Exception { } protected static void assertIter ( RandomAccessOrds docs , int docId , long ... expectedOrdinals ) { } @ Test public void testMultiValuesDocsWithOverlappingStorageArrays ( ) throws Exception { } private void assertEquals ( RandomAccessOrds docs , long [ ] [ ] ordinalPlan ) { } }<BUG2FIX>final SortedDocValues singleOrds = MIN . select ( docs ) ;
public class TransportDeleteMappingAction extends TransportMasterNodeOperationAction < DeleteMappingRequest , DeleteMappingResponse > { private final MetaDataMappingService metaDataMappingService ; private final TransportFlushAction flushAction ; private final TransportDeleteByQueryAction deleteByQueryAction ; private final TransportRefreshAction refreshAction ; private final DestructiveOperations destructiveOperations ; @ Inject public TransportDeleteMappingAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool , MetaDataMappingService metaDataMappingService , TransportDeleteByQueryAction deleteByQueryAction , TransportRefreshAction refreshAction , TransportFlushAction flushAction , NodeSettingsService nodeSettingsService ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected DeleteMappingRequest newRequest ( ) { } @ Override protected DeleteMappingResponse newResponse ( ) { } @ Override protected void doExecute ( DeleteMappingRequest request , ActionListener < DeleteMappingResponse > listener ) { } @ Override protected ClusterBlockException checkBlock ( DeleteMappingRequest request , ClusterState state ) { } @ Override protected void masterOperation ( final DeleteMappingRequest request , final ClusterState state , final ActionListener < DeleteMappingResponse > listener ) throws ElasticsearchException { <START_BUG> request . indices ( state . metaData ( ) . concreteIndices ( request . indices ( ) , request . indicesOptions ( ) ) ) ; <END_BUG> flushAction . execute ( Requests . flushRequest ( request . indices ( ) ) , new ActionListener < FlushResponse > ( ) { @ Override public void onResponse ( FlushResponse flushResponse ) { if ( logger . isTraceEnabled ( ) ) { traceLogResponse ( "Flush" , flushResponse ) ; } ImmutableOpenMap < String , ImmutableOpenMap < String , MappingMetaData > > result = clusterService . state ( ) . metaData ( ) . findMappings ( request . indices ( ) , request . types ( ) ) ; BoolFilterBuilder filterBuilder = new BoolFilterBuilder ( ) ; Set < String > types = new HashSet < > ( ) ; for ( ObjectObjectCursor < String , ImmutableOpenMap < String , MappingMetaData > > typesMeta : result ) { for ( ObjectObjectCursor < String , MappingMetaData > type : typesMeta . value ) { filterBuilder . should ( new org . elasticsearch . index . query . TypeFilterBuilder ( type . key ) ) ; types . add ( type . key ) ; } } if ( ( types . size ( ) ) == 0 ) { throw new org . elasticsearch . indices . TypeMissingException ( new Index ( "_all" ) , request . types ( ) , "No<seq2seq4repair_space>index<seq2seq4repair_space>has<seq2seq4repair_space>the<seq2seq4repair_space>type." ) ; } request . types ( types . toArray ( new String [ types . size ( ) ] ) ) ; QuerySourceBuilder querySourceBuilder = new QuerySourceBuilder ( ) . setQuery ( QueryBuilders . filteredQuery ( QueryBuilders . matchAllQuery ( ) , filterBuilder ) ) ; deleteByQueryAction . execute ( Requests . deleteByQueryRequest ( request . indices ( ) ) . source ( querySourceBuilder ) , new ActionListener < DeleteByQueryResponse > ( ) { @ Override public void onResponse ( DeleteByQueryResponse deleteByQueryResponse ) { if ( logger . isTraceEnabled ( ) ) { for ( IndexDeleteByQueryResponse indexResponse : deleteByQueryResponse ) { logger . trace ( "Delete<seq2seq4repair_space>by<seq2seq4repair_space>query[{}]<seq2seq4repair_space>completed<seq2seq4repair_space>with<seq2seq4repair_space>total[{}],<seq2seq4repair_space>successful[{}]<seq2seq4repair_space>and<seq2seq4repair_space>failed[{}]" , indexResponse . getIndex ( ) , indexResponse . getTotalShards ( ) , indexResponse . getSuccessfulShards ( ) , indexResponse . getFailedShards ( ) ) ; if ( ( indexResponse . getFailedShards ( ) ) > 0 ) { for ( ShardOperationFailedException failure : indexResponse . getFailures ( ) ) { logger . trace ( "[{}/{}]<seq2seq4repair_space>Delete<seq2seq4repair_space>by<seq2seq4repair_space>query<seq2seq4repair_space>shard<seq2seq4repair_space>failure<seq2seq4repair_space>reason:<seq2seq4repair_space>{}" , failure . index ( ) , failure . shardId ( ) , failure . reason ( ) ) ; } } } } refreshAction . execute ( Requests . refreshRequest ( request . indices ( ) ) , new ActionListener < RefreshResponse > ( ) { @ Override public void onResponse ( RefreshResponse refreshResponse ) { if ( logger . isTraceEnabled ( ) ) { traceLogResponse ( "Refresh" , refreshResponse ) ; } removeMapping ( ) ; } @ Override public void onFailure ( Throwable e ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Refresh<seq2seq4repair_space>failed<seq2seq4repair_space>completely" , e ) ; } removeMapping ( ) ; } protected void removeMapping ( ) { DeleteMappingClusterStateUpdateRequest clusterStateUpdateRequest = new DeleteMappingClusterStateUpdateRequest ( ) . indices ( request . indices ( ) ) . types ( request . types ( ) ) . ackTimeout ( request . timeout ( ) ) . masterNodeTimeout ( request . masterNodeTimeout ( ) ) ; metaDataMappingService . removeMapping ( clusterStateUpdateRequest , new ClusterStateUpdateListener ( ) { @ Override public void onResponse ( ClusterStateUpdateResponse response ) { listener . onResponse ( new DeleteMappingResponse ( response . isAcknowledged ( ) ) ) ; } @ Override public void onFailure ( Throwable t ) { listener . onFailure ( t ) ; } } ) ; } } ) ; } @ Override public void onFailure ( Throwable t ) { listener . onFailure ( t ) ; } } ) ; } @ Override public void onFailure ( Throwable t ) { listener . onFailure ( t ) ; } } ) ; } private void traceLogResponse ( String action , BroadcastOperationResponse response ) { } }<BUG2FIX>request . indices ( state . metaData ( ) . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ) ;
public class WildcardQueryBuilder extends BaseQueryBuilder { private final String name ; private final String wildcard ; private float boost = - 1 ; private String rewrite ; public WildcardQueryBuilder ( String name , String wildcard ) { } public WildcardQueryBuilder rewrite ( String rewrite ) { } public WildcardQueryBuilder boost ( float boost ) { } @ Override public void doXContent ( XContentBuilder builder , Params params ) throws IOException { builder . startObject ( NAME ) ; <START_BUG> if ( ( ( boost ) == ( - 1 ) ) && ( ( rewrite ) != null ) ) { <END_BUG> builder . field ( name , wildcard ) ; } else { builder . startObject ( name ) ; builder . field ( "wildcard" , wildcard ) ; if ( ( boost ) != ( - 1 ) ) { builder . field ( "boost" , boost ) ; } if ( ( rewrite ) != null ) { builder . field ( "rewrite" , rewrite ) ; } builder . endObject ( ) ; } builder . endObject ( ) ; } }<BUG2FIX>if ( ( ( boost ) == ( - 1 ) ) && ( ( rewrite ) == null ) ) {
@ Inject public HasParentQueryParser ( ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; Query innerQuery = null ; boolean queryFound = false ; float boost = 1.0F ; String parentType = null ; boolean score = false ; String queryName = null ; String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_OBJECT ) ) { if ( "query" . equals ( currentFieldName ) ) { String [ ] origTypes = QueryParseContext . setTypesWithPrevious ( ( parentType == null ? null : new String [ ] { parentType } ) ) ; try { innerQuery = parseContext . parseInnerQuery ( ) ; queryFound = true ; } finally { QueryParseContext . setTypes ( origTypes ) ; } } else { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[has_parent]<seq2seq4repair_space>query<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>support<seq2seq4repair_space>[" + currentFieldName ) + "]" ) ) ; } } else if ( token . isValue ( ) ) { if ( ( ( "type" . equals ( currentFieldName ) ) || ( "parent_type" . equals ( currentFieldName ) ) ) || ( "parentType" . equals ( currentFieldName ) ) ) { parentType = parser . text ( ) ; } else if ( "_scope" . equals ( currentFieldName ) ) { throw new QueryParsingException ( parseContext . index ( ) , "the<seq2seq4repair_space>[_scope]<seq2seq4repair_space>support<seq2seq4repair_space>in<seq2seq4repair_space>[has_parent]<seq2seq4repair_space>query<seq2seq4repair_space>has<seq2seq4repair_space>been<seq2seq4repair_space>removed,<seq2seq4repair_space>use<seq2seq4repair_space>a<seq2seq4repair_space>filter<seq2seq4repair_space>as<seq2seq4repair_space>a<seq2seq4repair_space>facet_filter<seq2seq4repair_space>in<seq2seq4repair_space>the<seq2seq4repair_space>relevant<seq2seq4repair_space>global<seq2seq4repair_space>facet" ) ; } else if ( ( "score_type" . equals ( currentFieldName ) ) || ( "scoreType" . equals ( currentFieldName ) ) ) { String scoreTypeValue = parser . text ( ) ; if ( "score" . equals ( scoreTypeValue ) ) { score = true ; } else if ( "none" . equals ( scoreTypeValue ) ) { score = false ; } } else if ( ( "score_mode" . equals ( currentFieldName ) ) || ( "scoreMode" . equals ( currentFieldName ) ) ) { String scoreModeValue = parser . text ( ) ; if ( "score" . equals ( scoreModeValue ) ) { score = true ; } else if ( "none" . equals ( scoreModeValue ) ) { score = false ; } } else if ( "boost" . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } else if ( "_name" . equals ( currentFieldName ) ) { queryName = parser . text ( ) ; } else { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[has_parent]<seq2seq4repair_space>query<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>support<seq2seq4repair_space>[" + currentFieldName ) + "]" ) ) ; } } } if ( ! queryFound ) { throw new QueryParsingException ( parseContext . index ( ) , "[has_parent]<seq2seq4repair_space>query<seq2seq4repair_space>requires<seq2seq4repair_space>'query'<seq2seq4repair_space>field" ) ; } if ( innerQuery == null ) { return null ; } if ( parentType == null ) { throw new QueryParsingException ( parseContext . index ( ) , "[has_parent]<seq2seq4repair_space>query<seq2seq4repair_space>requires<seq2seq4repair_space>'parent_type'<seq2seq4repair_space>field" ) ; } DocumentMapper parentDocMapper = parseContext . mapperService ( ) . documentMapper ( parentType ) ; if ( parentDocMapper == null ) { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[has_parent]<seq2seq4repair_space>query<seq2seq4repair_space>configured<seq2seq4repair_space>'parent_type'<seq2seq4repair_space>[" + parentType ) + "]<seq2seq4repair_space>is<seq2seq4repair_space>not<seq2seq4repair_space>a<seq2seq4repair_space>valid<seq2seq4repair_space>type" ) ) ; } innerQuery . setBoost ( boost ) ; innerQuery = new org . elasticsearch . common . lucene . search . XFilteredQuery ( innerQuery , parseContext . cacheFilter ( parentDocMapper . typeFilter ( ) , null ) ) ; Set < String > parentTypes = new HashSet < String > ( 5 ) ; parentTypes . add ( parentType ) ; for ( DocumentMapper documentMapper : parseContext . mapperService ( ) ) { ParentFieldMapper parentFieldMapper = documentMapper . parentFieldMapper ( ) ; if ( parentFieldMapper . active ( ) ) { DocumentMapper parentTypeDocumentMapper = parseContext . mapperService ( ) . documentMapper ( parentFieldMapper . type ( ) ) ; if ( parentTypeDocumentMapper == null ) { parentTypes . add ( parentFieldMapper . type ( ) ) ; } } } Filter parentFilter ; if ( ( parentTypes . size ( ) ) == 1 ) { DocumentMapper documentMapper = parseContext . mapperService ( ) . documentMapper ( parentTypes . iterator ( ) . next ( ) ) ; parentFilter = parseContext . cacheFilter ( documentMapper . typeFilter ( ) , null ) ; } else { XBooleanFilter parentsFilter = new XBooleanFilter ( ) ; for ( String parentTypeStr : parentTypes ) { DocumentMapper documentMapper = parseContext . mapperService ( ) . documentMapper ( parentTypeStr ) ; Filter filter = parseContext . cacheFilter ( documentMapper . typeFilter ( ) , null ) ; parentsFilter . add ( filter , SHOULD ) ; } parentFilter = parentsFilter ; } Filter childrenFilter = parseContext . cacheFilter ( new org . elasticsearch . common . lucene . search . NotFilter ( parentFilter ) , null ) ; boolean deleteByQuery = "delete_by_query" . equals ( SearchContext . current ( ) . source ( ) ) ; Query query ; if ( ( ! deleteByQuery ) && score ) { query = new org . elasticsearch . index . search . child . ParentQuery ( innerQuery , parentType , childrenFilter ) ; } else { <START_BUG> query = new org . elasticsearch . index . search . child . ParentConstantScoreQuery ( innerQuery , parentType , childrenFilter , true ) ; <END_BUG> if ( deleteByQuery ) { query = new XConstantScoreQuery ( new org . elasticsearch . index . search . child . DeleteByQueryWrappingFilter ( query ) ) ; } } query . setBoost ( boost ) ; if ( queryName != null ) { parseContext . addNamedQuery ( queryName , query ) ; } return query ; } }<BUG2FIX>query = new org . elasticsearch . index . search . child . ParentConstantScoreQuery ( innerQuery , parentType , childrenFilter ) ;
public FullRestartStressTest clearNodeWork ( boolean clearNodeWork ) { } public void run ( ) throws Exception { long numberOfRounds = 0 ; Random random = new Random ( 0 ) ; long testStart = System . currentTimeMillis ( ) ; while ( true ) { Node [ ] nodes = new Node [ numberOfNodes ] ; for ( int i = 0 ; i < ( nodes . length ) ; i ++ ) { nodes [ i ] = org . elasticsearch . node . NodeBuilder . nodeBuilder ( ) . settings ( settings ) . node ( ) ; } Node client = org . elasticsearch . node . NodeBuilder . nodeBuilder ( ) . settings ( settings ) . client ( true ) . node ( ) ; for ( int i = 0 ; i < ( numberOfIndices ) ; i ++ ) { try { client . client ( ) . admin ( ) . indices ( ) . prepareCreate ( ( "test" + i ) ) . execute ( ) . actionGet ( ) ; } catch ( Exception e ) { } } logger . info ( "***<seq2seq4repair_space>Waiting<seq2seq4repair_space>for<seq2seq4repair_space>GREEN<seq2seq4repair_space>status" ) ; try { ClusterHealthResponse clusterHealth = client . client ( ) . admin ( ) . cluster ( ) . prepareHealth ( ) . setWaitForGreenStatus ( ) . setTimeout ( "10m" ) . execute ( ) . actionGet ( ) ; if ( clusterHealth . isTimedOut ( ) ) { logger . warn ( "timed<seq2seq4repair_space>out<seq2seq4repair_space>waiting<seq2seq4repair_space>for<seq2seq4repair_space>green<seq2seq4repair_space>status...." ) ; } } catch ( Exception e ) { logger . warn ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>execute<seq2seq4repair_space>cluster<seq2seq4repair_space>health...." ) ; } CountResponse count = client . client ( ) . prepareCount ( ) . setQuery ( matchAllQuery ( ) ) . execute ( ) . actionGet ( ) ; logger . info ( "***<seq2seq4repair_space>index_count<seq2seq4repair_space>[{}],<seq2seq4repair_space>expected_count<seq2seq4repair_space>[{}]" , count . getCount ( ) , indexCounter . get ( ) ) ; for ( int i = 0 ; i < ( ( nodes . length ) * 5 ) ; i ++ ) { count = client . client ( ) . prepareCount ( ) . setQuery ( matchAllQuery ( ) ) . execute ( ) . actionGet ( ) ; logger . debug ( "index_count<seq2seq4repair_space>[{}],<seq2seq4repair_space>expected_count<seq2seq4repair_space>[{}]" , count . getCount ( ) , indexCounter . get ( ) ) ; if ( ( count . getCount ( ) ) != ( indexCounter . get ( ) ) ) { logger . warn ( "!!!<seq2seq4repair_space>count<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>match,<seq2seq4repair_space>index_count<seq2seq4repair_space>[{}],<seq2seq4repair_space>expected_count<seq2seq4repair_space>[{}]" , count . getCount ( ) , indexCounter . get ( ) ) ; throw new Exception ( "failed<seq2seq4repair_space>test,<seq2seq4repair_space>count<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>match..." ) ; } } for ( int i = 0 ; i < ( ( nodes . length ) * 5 ) ; i ++ ) { SearchResponse search = client . client ( ) . prepareSearch ( ) . setQuery ( matchAllQuery ( ) . normsField ( "field" ) ) . execute ( ) . actionGet ( ) ; logger . debug ( "index_count<seq2seq4repair_space>[{}],<seq2seq4repair_space>expected_count<seq2seq4repair_space>[{}]" , search . getHits ( ) . totalHits ( ) , indexCounter . get ( ) ) ; if ( ( count . getCount ( ) ) != ( indexCounter . get ( ) ) ) { logger . warn ( "!!!<seq2seq4repair_space>search<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>match,<seq2seq4repair_space>index_count<seq2seq4repair_space>[{}],<seq2seq4repair_space>expected_count<seq2seq4repair_space>[{}]" , search . getHits ( ) . totalHits ( ) , indexCounter . get ( ) ) ; throw new Exception ( "failed<seq2seq4repair_space>test,<seq2seq4repair_space>count<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>match..." ) ; } } logger . info ( "***<seq2seq4repair_space>ROUND<seq2seq4repair_space>{}" , ( ++ numberOfRounds ) ) ; int numberOfBulks = ( numberOfDocsPerRound ) / ( bulkSize ) ; for ( int b = 0 ; b < numberOfBulks ; b ++ ) { BulkRequestBuilder bulk = client . client ( ) . prepareBulk ( ) ; for ( int k = 0 ; k < ( bulkSize ) ; k ++ ) { <START_BUG> StringBuffer sb = new StringBuffer ( ) ; <END_BUG> XContentBuilder json = XContentFactory . jsonBuilder ( ) . startObject ( ) . field ( "field" , ( "value" + ( ThreadLocalRandom . current ( ) . nextInt ( ) ) ) ) ; int fields = ( ThreadLocalRandom . current ( ) . nextInt ( ) ) % ( numberOfFields ) ; for ( int i = 0 ; i < fields ; i ++ ) { json . field ( ( "num_" + i ) , ThreadLocalRandom . current ( ) . nextDouble ( ) ) ; int tokens = ( ThreadLocalRandom . current ( ) . nextInt ( ) ) % ( textTokens ) ; sb . setLength ( 0 ) ; for ( int j = 0 ; j < tokens ; j ++ ) { sb . append ( Strings . randomBase64UUID ( random ) ) . append ( '<seq2seq4repair_space>' ) ; } json . field ( ( "text_" + i ) , sb . toString ( ) ) ; } json . endObject ( ) ; bulk . add ( Requests . indexRequest ( ( "test" + ( ( Math . abs ( ThreadLocalRandom . current ( ) . nextInt ( ) ) ) % ( numberOfIndices ) ) ) ) . type ( "type1" ) . source ( json ) ) ; indexCounter . incrementAndGet ( ) ; } bulk . execute ( ) . actionGet ( ) ; } client . close ( ) ; for ( Node node : nodes ) { File [ ] nodeDatas = ( ( org . elasticsearch . node . internal . InternalNode ) ( node ) ) . injector ( ) . getInstance ( NodeEnvironment . class ) . nodeDataLocations ( ) ; node . close ( ) ; if ( ( clearNodeWork ) && ( ! ( settings . get ( "gateway.type" ) . equals ( "local" ) ) ) ) { FileSystemUtils . deleteRecursively ( nodeDatas ) ; } } if ( ( ( System . currentTimeMillis ( ) ) - testStart ) > ( period . millis ( ) ) ) { logger . info ( "test<seq2seq4repair_space>finished,<seq2seq4repair_space>full_restart_rounds<seq2seq4repair_space>[{}]"<BUG2FIX>StringBuilder sb = new StringBuilder ( ) ;
public class Group extends Actor implements Cullable { private final SnapshotArray < Actor > children = new SnapshotArray ( true , 4 , Actor . class ) ; private final Matrix3 localTransform = new Matrix3 ( ) ; private final Matrix3 worldTransform = new Matrix3 ( ) ; private final Matrix4 batchTransform = new Matrix4 ( ) ; private final Matrix4 oldBatchTransform = new Matrix4 ( ) ; private boolean transform = true ; private Rectangle cullingArea ; private final Vector2 point = new Vector2 ( ) ; public void act ( float delta ) { } public void draw ( SpriteBatch batch , float parentAlpha ) { } protected void drawChildren ( SpriteBatch batch , float parentAlpha ) { } protected void applyTransform ( SpriteBatch batch , Matrix4 transform ) { } protected Matrix4 computeTransform ( ) { } protected void resetTransform ( SpriteBatch batch ) { } public void setCullingArea ( Rectangle cullingArea ) { } public Actor hit ( float x , float y ) { } protected void childrenChanged ( ) { } public void addActor ( Actor actor ) { } public void addActorAt ( int index , Actor actor ) { } public void addActorBefore ( Actor actorBefore , Actor actor ) { } public void addActorAfter ( Actor actorAfter , Actor actor ) { } public boolean removeActor ( Actor actor ) { } public void clear ( ) { } protected void setStage ( Stage stage ) { } public boolean swapActor ( int first , int second ) { } public boolean swapActor ( Actor first , Actor second ) { } <START_BUG> public Array < Actor > getChildren ( ) { <END_BUG> return children ; } public void setTransform ( boolean transform ) { } public boolean isTransform ( ) { } public void localToDescendantCoordinates ( Actor descendant , Vector2 localPoint ) { } }<BUG2FIX>public SnapshotArray < Actor > getChildren ( ) {
public class CreateIndexRequest extends MasterNodeOperationRequest { private String cause = "" ; private String index ; private Settings settings = EMPTY_SETTINGS ; private Map < String , String > mappings = newHashMap ( ) ; private TimeValue timeout = new TimeValue ( 10 , TimeUnit . SECONDS ) ; CreateIndexRequest ( ) { } public CreateIndexRequest ( String index ) { } public CreateIndexRequest ( String index , Settings settings ) { } @ Override public ActionRequestValidationException validate ( ) { } String index ( ) { } Settings settings ( ) { } String cause ( ) { } public CreateIndexRequest settings ( Settings settings ) { } public CreateIndexRequest settings ( Settings . Builder settings ) { } public CreateIndexRequest settings ( String source ) { } public CreateIndexRequest settings ( Map source ) { } public CreateIndexRequest mapping ( String type , String source ) { } public CreateIndexRequest cause ( String cause ) { } public CreateIndexRequest mapping ( String type , XContentBuilder source ) { } public CreateIndexRequest mapping ( String type , Map source ) { <START_BUG> if ( ( ( source . size ( ) ) != 1 ) || ( source . containsKey ( type ) ) ) { <END_BUG> source = MapBuilder . < String , Object > newMapBuilder ( ) . put ( type , source ) . map ( ) ; } try { XContentBuilder builder = XContentFactory . contentBuilder ( JSON ) ; builder . map ( source ) ; return mapping ( type , builder . string ( ) ) ; } catch ( IOException e ) { throw new ElasticSearchGenerationException ( ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>generate<seq2seq4repair_space>[" + source ) + "]" ) , e ) ; } } Map < String , String > mappings ( ) { } TimeValue timeout ( ) { } public CreateIndexRequest timeout ( TimeValue timeout ) { } public CreateIndexRequest timeout ( String timeout ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } }<BUG2FIX>if ( ( ( source . size ( ) ) != 1 ) || ( ! ( source . containsKey ( type ) ) ) ) {
public class FilterListFragment extends ItemListFragment < IssueFilter > implements Comparator < IssueFilter > { @ Inject private AccountDataManager cache ; @ Inject private AvatarLoader avatars ; @ Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; <START_BUG> ListViewUtils . configure ( getActivity ( ) , getListView ( ) , true ) ; <END_BUG> setEmptyText ( getString ( no_filters ) ) ; } @ Override public Loader < List < IssueFilter > > onCreateLoader ( int id , Bundle args ) { } @ Override public void onListItemClick ( ListView l , View v , int position , long id ) { } @ Override public void onResume ( ) { } @ Override protected ItemListAdapter < IssueFilter , ? extends ItemView > createAdapter ( List < IssueFilter > items ) { } @ Override public int compare ( final IssueFilter lhs , final IssueFilter rhs ) { } }<BUG2FIX>ListViewUtils . configure ( getActivity ( ) , getListView ( ) ) ;
public class FsChannelSimpleTranslogTests extends AbstractSimpleTranslogTests { @ Override protected Translog create ( ) { <START_BUG> return new FsTranslog ( shardId , EMPTY_SETTINGS , new File ( "work/fs-translog" ) , false ) ; <END_BUG> } @ AfterClass public void cleanup ( ) { } }<BUG2FIX>return new FsTranslog ( shardId , EMPTY_SETTINGS , new File ( "work/fs-translog" ) ) ;
public class BitmapFontLoader extends AsynchronousAssetLoader < BitmapFont , BitmapFontLoader . BitmapFontParameter > { public BitmapFontLoader ( FileHandleResolver resolver ) { } BitmapFontData data ; @ Override public Array < AssetDescriptor > getDependencies ( String fileName , FileHandle file , BitmapFontLoader . BitmapFontParameter parameter ) { <START_BUG> Array < AssetDescriptor > deps = new Array ( ) ; <END_BUG> if ( ( parameter != null ) && ( ( parameter . bitmapFontData ) != null ) ) { data = parameter . bitmapFontData ; return deps ; } data = new BitmapFontData ( file , ( parameter != null ? parameter . flip : false ) ) ; for ( int i = 0 ; i < ( data . getImagePaths ( ) . length ) ; i ++ ) { deps . add ( new AssetDescriptor ( data . getImagePath ( i ) , Texture . class ) ) ; } return deps ; } @ Override public void loadAsync ( AssetManager manager , String fileName , FileHandle file , BitmapFontLoader . BitmapFontParameter parameter ) { } @ Override public BitmapFont loadSync ( AssetManager manager , String fileName , FileHandle file , BitmapFontLoader . BitmapFontParameter parameter ) { } public static class BitmapFontParameter extends AssetLoaderParameters < BitmapFont > { public boolean flip = false ; public TextureFilter minFilter = TextureFilter . Nearest ; public TextureFilter magFilter = TextureFilter . Nearest ; public BitmapFontData bitmapFontData = null ; } }<BUG2FIX>Array < AssetDescriptor > deps = new Array < AssetDescriptor > ( ) ;
public class LabelScaleTest extends GdxTest { Skin skin ; Stage stage ; SpriteBatch batch ; Actor root ; @ Override public void create ( ) { } @ Override public void dispose ( ) { } @ Override public void render ( ) { } @ Override public void resize ( int width , int height ) { <START_BUG> stage . getViewport ( ) . update ( width , height ) ; <END_BUG> } }<BUG2FIX>stage . getViewport ( ) . update ( width , height , true ) ;
public class ImportTest extends BaseBulletTest { btBulletWorldImporter importer ; Model model ; public class MyImporter extends btBulletWorldImporter { public MyImporter ( btDynamicsWorld world ) { } @ Override public btRigidBody createRigidBody ( boolean isDynamic , float mass , Matrix4 startTransform , btCollisionShape shape , String bodyName ) { } } @ Override public void create ( ) { } @ Override public boolean tap ( float x , float y , int count , int button ) { } @ Override public void dispose ( ) { super . dispose ( ) ; importer . deleteAllData ( ) ; <START_BUG> importer . delete ( ) ; <END_BUG> importer = null ; } }<BUG2FIX>importer . dispose ( ) ;
public class TimerTest extends GdxTest { @ Override public void create ( ) { new Timer ( ) . scheduleTask ( new Task ( ) { @ Override public void run ( ) { app . log ( "TimerTest" , "ping" ) ; } <START_BUG> } , 0 , 1 ) ; <END_BUG> } }<BUG2FIX>} , 1 , 1 ) ;
public class RestUpdateSettingsAction extends BaseRestHandler { @ Inject public RestUpdateSettingsAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { UpdateSettingsRequest updateSettingsRequest = updateSettingsRequest ( splitIndices ( request . param ( "index" ) ) ) ; updateSettingsRequest . listenerThreaded ( false ) ; ImmutableSettings . Builder updateSettings = ImmutableSettings . settingsBuilder ( ) ; String bodySettingsStr = request . content ( ) . toUtf8 ( ) ; if ( Strings . hasText ( bodySettingsStr ) ) { try { Settings buildSettings = ImmutableSettings . settingsBuilder ( ) . loadFromSource ( bodySettingsStr ) . build ( ) ; for ( Map . Entry < String , String > entry : buildSettings . getAsMap ( ) . entrySet ( ) ) { String key = entry . getKey ( ) ; String value = entry . getValue ( ) ; if ( key . startsWith ( "settings." ) ) { key = key . substring ( "settings." . length ( ) ) ; } updateSettings . put ( key , value ) ; } } catch ( Exception e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , RestStatus . BAD_REQUEST , new SettingsException ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>parse<seq2seq4repair_space>index<seq2seq4repair_space>settings" , e ) ) ) ; } catch ( IOException e1 ) { logger . warn ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>response" , e1 ) ; } return ; } } for ( Map . Entry < String , String > entry : request . params ( ) . entrySet ( ) ) { if ( entry . getKey ( ) . equals ( "pretty" ) ) { continue ; } updateSettings . put ( entry . getKey ( ) , entry . getValue ( ) ) ; } updateSettingsRequest . settings ( updateSettings ) ; client . admin ( ) . indices ( ) . updateSettings ( updateSettingsRequest , new ActionListener < UpdateSettingsResponse > ( ) { @ Override public void onResponse ( UpdateSettingsResponse updateSettingsResponse ) { try { org . elasticsearch . common . xcontent . XContentBuilder builder = org . elasticsearch . rest . action . support . RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) . field ( "ok" , true ) . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class BulletEntity extends BaseEntity { private static final Matrix4 tmpM = new Matrix4 ( ) ; public BulletEntity . MotionState motionState ; public btCollisionObject body ; public BulletEntity ( final Model model , final btRigidBodyConstructionInfo bodyInfo , final float x , final float y , final float z ) { } public BulletEntity ( final Model model , final btRigidBodyConstructionInfo bodyInfo , final Matrix4 transform ) { } public BulletEntity ( final Model model , final btCollisionObject body , final float x , final float y , final float z ) { } public BulletEntity ( final Model model , final btCollisionObject body , final Matrix4 transform ) { } @ Override public void dispose ( ) { if ( ( motionState ) != null ) motionState . dispose ( ) ; if ( ( body ) != null ) <START_BUG> body . delete ( ) ; <END_BUG> motionState = null ; body = null ; } static class MotionState extends btMotionState implements Disposable { private final Matrix4 transform ; public MotionState ( final Matrix4 transform ) { } @ Override public void getWorldTransform ( final Matrix4 worldTrans ) { } @ Override public void setWorldTransform ( final Matrix4 worldTrans ) { } @ Override public void dispose ( ) { delete ( ) ; } } }<BUG2FIX>body . dispose ( ) ;
public class RepositoryListFragment extends ItemListFragment < Repository > implements OrganizationSelectionListener { @ Inject private AccountDataManager cache ; private final AtomicReference < User > org = new AtomicReference < User > ( ) ; private final AtomicReference < RecentRepositories > recentRepos = new AtomicReference < RecentRepositories > ( ) ; @ Override public void onAttach ( Activity activity ) { } @ Override public void onOrganizationSelected ( final User organization ) { } @ Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; <START_BUG> setEmptyText ( getString ( no_repositories ) ) ; <END_BUG> } @ Override public void onListItemClick ( ListView list , View v , int position , long id ) { } @ Override public void onStop ( ) { } @ Override public Loader < List < Repository > > onCreateLoader ( int id , final Bundle args ) { } @ Override protected ItemListAdapter < Repository , ? extends ItemView > createAdapter ( List < Repository > items ) { } @ Override public void onLoadFinished ( Loader < List < Repository > > loader , List < Repository > items ) { } }<BUG2FIX>setEmptyText ( no_repositories ) ;
public class RestClusterStateAction extends BaseRestHandler { private final SettingsFilter settingsFilter ; @ Inject public RestClusterStateAction ( Settings settings , Client client , RestController controller , SettingsFilter settingsFilter ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { final ClusterStateRequest clusterStateRequest = Requests . clusterStateRequest ( ) ; clusterStateRequest . listenerThreaded ( false ) ; clusterStateRequest . masterNodeTimeout ( request . paramAsTime ( "master_timeout" , clusterStateRequest . masterNodeTimeout ( ) ) ) ; clusterStateRequest . filterNodes ( request . paramAsBoolean ( "filter_nodes" , clusterStateRequest . filterNodes ( ) ) ) ; clusterStateRequest . filterRoutingTable ( request . paramAsBoolean ( "filter_routing_table" , clusterStateRequest . filterRoutingTable ( ) ) ) ; clusterStateRequest . filterMetaData ( request . paramAsBoolean ( "filter_metadata" , clusterStateRequest . filterMetaData ( ) ) ) ; clusterStateRequest . filterBlocks ( request . paramAsBoolean ( "filter_blocks" , clusterStateRequest . filterBlocks ( ) ) ) ; clusterStateRequest . filteredIndices ( RestActions . splitIndices ( request . param ( "filter_indices" , null ) ) ) ; clusterStateRequest . filteredIndexTemplates ( request . paramAsStringArray ( "filter_index_templates" , EMPTY_ARRAY ) ) ; clusterStateRequest . local ( request . paramAsBoolean ( "local" , clusterStateRequest . local ( ) ) ) ; client . admin ( ) . cluster ( ) . state ( clusterStateRequest , new org . elasticsearch . action . ActionListener < ClusterStateResponse > ( ) { @ Override public void onResponse ( ClusterStateResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( RestClusterStateAction . Fields . CLUSTER_NAME , response . getClusterName ( ) . value ( ) ) ; response . getState ( ) . settingsFilter ( settingsFilter ) . toXContent ( builder , request ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>handle<seq2seq4repair_space>cluster<seq2seq4repair_space>state" , e ) ; } try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } static final class Fields { static final XContentBuilderString CLUSTER_NAME = new XContentBuilderString ( "cluster_name" ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class RestCreateIndexAction extends BaseRestHandler { @ Inject public RestCreateIndexAction ( Settings settings , Client client , RestController controller ) { } @ SuppressWarnings ( { "unchecked" } ) @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { CreateIndexRequest createIndexRequest = new CreateIndexRequest ( request . param ( "index" ) ) ; createIndexRequest . listenerThreaded ( false ) ; if ( request . hasContent ( ) ) { try { createIndexRequest . source ( request . content ( ) ) ; } catch ( Exception e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . warn ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>response" , e1 ) ; } return ; } } createIndexRequest . timeout ( request . paramAsTime ( "timeout" , timeValueSeconds ( 10 ) ) ) ; client . admin ( ) . indices ( ) . create ( createIndexRequest , new org . elasticsearch . action . ActionListener < CreateIndexResponse > ( ) { @ Override public void onResponse ( CreateIndexResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) . field ( "ok" , true ) . field ( "acknowledged" , response . isAcknowledged ( ) ) . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
final class TermVectorWriter { final List < String > fields = new ArrayList < String > ( ) ; final List < Long > fieldOffset = new ArrayList < Long > ( ) ; final BytesStreamOutput output = new BytesStreamOutput ( 1 ) ; private static final String HEADER = "TV" ; private static final int CURRENT_VERSION = - 1 ; TermVectorResponse response = null ; TermVectorWriter ( TermVectorResponse termVectorResponse ) throws IOException { } void setFields ( Fields termVectorsByField , Set < String > selectedFields , EnumSet < Flag > flags , Fields topLevelFields ) throws IOException { int numFieldsWritten = 0 ; TermsEnum iterator = null ; DocsAndPositionsEnum docsAndPosEnum = null ; DocsEnum docsEnum = null ; TermsEnum topLevelIterator = null ; for ( String field : termVectorsByField ) { if ( ( selectedFields != null ) && ( ! ( selectedFields . contains ( field ) ) ) ) { continue ; } Terms fieldTermVector = termVectorsByField . terms ( field ) ; Terms topLevelTerms = topLevelFields . terms ( field ) ; topLevelIterator = topLevelTerms . iterator ( topLevelIterator ) ; boolean positions = ( flags . contains ( Positions ) ) && ( fieldTermVector . hasPositions ( ) ) ; boolean offsets = ( flags . contains ( Offsets ) ) && ( fieldTermVector . hasOffsets ( ) ) ; boolean payloads = ( flags . contains ( Payloads ) ) && ( fieldTermVector . hasPayloads ( ) ) ; startField ( field , fieldTermVector . size ( ) , positions , offsets , payloads ) ; if ( flags . contains ( FieldStatistics ) ) { writeFieldStatistics ( topLevelTerms ) ; } iterator = fieldTermVector . iterator ( iterator ) ; final boolean useDocsAndPos = ( positions || offsets ) || payloads ; while ( ( iterator . next ( ) ) != null ) { BytesRef term = iterator . term ( ) ; <START_BUG> boolean foundTerm = topLevelIterator . seekExact ( term , false ) ; <END_BUG> assert foundTerm ; startTerm ( term ) ; if ( flags . contains ( TermStatistics ) ) { writeTermStatistics ( topLevelIterator ) ; } if ( useDocsAndPos ) { docsAndPosEnum = writeTermWithDocsAndPos ( iterator , docsAndPosEnum , positions , offsets , payloads ) ; } else { docsEnum = writeTermWithDocsOnly ( iterator , docsEnum ) ; } } numFieldsWritten ++ ; } response . setTermVectorField ( output ) ; response . setHeader ( writeHeader ( numFieldsWritten , flags . contains ( TermStatistics ) , flags . contains ( FieldStatistics ) ) ) ; } private BytesReference writeHeader ( int numFieldsWritten , boolean getTermStatistics , boolean getFieldStatistics ) throws IOException { } private DocsEnum writeTermWithDocsOnly ( TermsEnum iterator , DocsEnum docsEnum ) throws IOException { } private DocsAndPositionsEnum writeTermWithDocsAndPos ( TermsEnum iterator , DocsAndPositionsEnum docsAndPosEnum , boolean positions , boolean offsets , boolean payloads ) throws IOException { } private void writePayload ( BytesRef payload ) throws IOException { } private void writeFreq ( int termFreq ) throws IOException { } private void writeOffsets ( int startOffset , int endOffset ) throws IOException { } private void writePosition ( int pos ) throws IOException { } private void startField ( String fieldName , long termsSize , boolean writePositions , boolean writeOffsets , boolean writePayloads ) throws IOException { } private void startTerm ( BytesRef term ) throws IOException { } private void writeTermStatistics ( TermsEnum topLevelIterator ) throws IOException { } private void writeFieldStatistics ( Terms topLevelTerms ) throws IOException { } private void writePotentiallyNegativeVInt ( int value ) throws IOException { } private void writePotentiallyNegativeVLong ( long value ) throws IOException { } }<BUG2FIX>boolean foundTerm = topLevelIterator . seekExact ( term ) ;
public class IntMap < V > { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; private static final int EMPTY = 0 ; public int size ; int [ ] keyTable ; V [ ] valueTable ; int capacity ; int stashSize ; V zeroValue ; boolean hasZeroValue ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private IntMap . Entries entries1 ; private IntMap . Entries entries2 ; private IntMap . Values values1 ; private IntMap . Values values2 ; private IntMap . Keys keys1 ; private IntMap . Keys keys2 ; public IntMap ( ) { } public IntMap ( int initialCapacity ) { } public IntMap ( int initialCapacity , float loadFactor ) { } public IntMap ( IntMap < ? extends V > map ) { } public V put ( int key , V value ) { } public void putAll ( IntMap < V > map ) { } private void putResize ( int key , V value ) { } private void push ( int insertKey , V insertValue , int index1 , int key1 , int index2 , int key2 , int index3 , int key3 ) { } private void putStash ( int key , V value ) { } public V get ( int key ) { } public V get ( int key , V defaultValue ) { } private V getStash ( int key , V defaultValue ) { } public V remove ( int key ) { } V removeStash ( int key ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean containsValue ( Object value , boolean identity ) { } public boolean containsKey ( int key ) { } private boolean containsKeyStash ( int key ) { } public int findKey ( Object value , boolean identity , int notFound ) { } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( int h ) { } private int hash3 ( int h ) { } public String toString ( ) { } public IntMap . Entries < V > entries ( ) { } public IntMap . Values < V > values ( ) { } public IntMap . Keys keys ( ) { } public static class Entry < V > { public int key ; public V value ; public String toString ( ) { } } private static class MapIterator < V > { static final int INDEX_ILLEGAL = - 2 ; static final int INDEX_ZERO = - 1 ; public boolean hasNext ; final IntMap < V > map ; int nextIndex ; int currentIndex ; boolean valid = true ; public MapIterator ( IntMap < V > map ) { } public void reset ( ) { } void findNextIndex ( ) { } public void remove ( ) { if ( ( ( currentIndex ) == ( IntMap . MapIterator . INDEX_ZERO ) ) && ( map . hasZeroValue ) ) { map . zeroValue = null ; map . hasZeroValue = false ; } else if ( ( currentIndex ) < 0 ) { throw new IllegalStateException ( "next<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>called<seq2seq4repair_space>before<seq2seq4repair_space>remove." ) ; } else if ( ( currentIndex ) >= ( map . capacity ) ) { map . removeStashIndex ( currentIndex ) ; <START_BUG> nextIndex = currentIndex ; <END_BUG> findNextIndex ( ) ; } else { map . keyTable [ currentIndex ] = IntMap . EMPTY ; map . valueTable [ currentIndex ] = null ; } currentIndex = IntMap . MapIterator . INDEX_ILLEGAL ; ( map . size ) -- ; } } public static class Entries < V > extends IntMap . MapIterator < V > implements Iterable < IntMap . Entry < V > > , Iterator < IntMap . Entry < V > > { private IntMap . Entry < V > entry = new IntMap . Entry ( ) ; public Entries ( IntMap map ) { } public IntMap . Entry < V > next ( ) { } public boolean hasNext ( ) { } public Iterator < IntMap . Entry < V > > iterator ( ) { } } public static class Values < V > extends IntMap . MapIterator < V > implements Iterable < V > , Iterator < V > { public Values ( IntMap < V > map ) { } public boolean hasNext ( ) { } public V next ( ) { } public Iterator < V > iterator ( ) { } public Array < V > toArray ( ) { } } public static class Keys extends IntMap . MapIterator { public Keys ( IntMap map ) { } public int next ( ) { } public IntArray toArray ( ) { } } }<BUG2FIX>nextIndex = ( currentIndex ) - 1 ;
public class Json { private static final boolean debug = false ; private JsonWriter writer ; private String typeName = "class" ; private boolean usePrototypes = true ; private OutputType outputType ; private final ObjectMap < Class , ObjectMap < String , Json . FieldMetadata > > typeToFields = new ObjectMap ( ) ; private final ObjectMap < String , Class > tagToClass = new ObjectMap ( ) ; private final ObjectMap < Class , String > classToTag = new ObjectMap ( ) ; private final ObjectMap < Class , Json . Serializer > classToSerializer = new ObjectMap ( ) ; private final ObjectMap < Class , Object [ ] > classToDefaultValues = new ObjectMap ( ) ; private Json . Serializer defaultSerializer ; private boolean ignoreUnknownFields ; public Json ( ) { } public Json ( OutputType outputType ) { } public void setIgnoreUnknownFields ( boolean ignoreUnknownFields ) { } public void setOutputType ( OutputType outputType ) { } public void addClassTag ( String tag , Class type ) { } public Class getClass ( String tag ) { } public String getTag ( Class type ) { } public void setTypeName ( String typeName ) { } public void setDefaultSerializer ( Json . Serializer defaultSerializer ) { } public < T > void setSerializer ( Class < T > type , Json . Serializer < T > serializer ) { } public < T > Json . Serializer < T > getSerializer ( Class < T > type ) { } public void setUsePrototypes ( boolean usePrototypes ) { } public void setElementType ( Class type , String fieldName , Class elementType ) { } private ObjectMap < String , Json . FieldMetadata > cacheFields ( Class type ) { } public String toJson ( Object object ) { } public String toJson ( Object object , Class knownType ) { } public String toJson ( Object object , Class knownType , Class elementType ) { } public void toJson ( Object object , FileHandle file ) { } public void toJson ( Object object , Class knownType , FileHandle file ) { } public void toJson ( Object object , Class knownType , Class elementType , FileHandle file ) { Writer writer = null ; try { <START_BUG> writer = file . writer ( false , "UTF-8" ) ; <END_BUG> toJson ( object , knownType , elementType , writer ) ; } catch ( Exception ex ) { throw new SerializationException ( ( "Error<seq2seq4repair_space>writing<seq2seq4repair_space>file:<seq2seq4repair_space>" + file ) , ex ) ; } finally { StreamUtils . closeQuietly ( writer ) ; } } public void toJson ( Object object , Writer writer ) { } public void toJson ( Object object , Class knownType , Writer writer ) { } public void toJson ( Object object , Class knownType , Class elementType , Writer writer ) { } public void setWriter ( Writer writer ) { } public JsonWriter getWriter ( ) { } public void writeFields ( Object object ) { } private Object [ ] getDefaultValues ( Class type ) { } public void writeField ( Object object , String name ) { } public void writeField ( Object object , String name , Class elementType ) { } public void writeField ( Object object , String fieldName , String jsonName ) { } public void writeField ( Object object , String fieldName , String jsonName , Class elementType ) { } public void writeValue ( String name , Object value ) { } public void writeValue ( String name , Object value , Class knownType ) { } public void writeValue ( String name , Object value , Class knownType , Class elementType ) { } public void writeValue ( Object value ) { } public void writeValue ( Object value , Class knownType ) { } public void writeValue ( Object value , Class knownType , Class elementType ) { } public void writeObjectStart ( String name ) { } public void writeObjectStart ( String name , Class actualType , Class knownType ) { } public void writeObjectStart ( ) { } public void writeObjectStart ( Class actualType , Class knownType ) { } public void writeObjectEnd ( ) { } public void writeArrayStart ( String name ) { } public void writeArrayStart ( ) { } public void writeArrayEnd ( ) { } public void writeType ( Class type ) { } public < T > T fromJson ( Class < T > type , Reader reader ) { } public < T > T fromJson ( Class < T > type , Class elementType , Reader reader ) { } public < T > T fromJson ( Class < T > type , InputStream input ) { } public < T > T fromJson ( Class < T > type , Class elementType , InputStream input ) { } public < T > T fromJson ( Class < T > type , FileHandle file ) { } public < T > T fromJson ( Class < T > type , Class elementType , FileHandle file ) { } public < T > T fromJson ( Class < T > type , char [ ] data , int offset , int length ) { } public < T > T fromJson ( Class < T > type , Class elementType , char [ ] data , int offset , int length ) { } public < T > T fromJson ( Class < T > type , String json ) { } public < T > T fromJson ( Class < T > type , Class elementType , String json ) { } public void readField ( Object object , String name , JsonValue jsonData ) { } public void readField ( Object object , String name , Class elementType , JsonValue jsonData ) { }<BUG2FIX>writer = file . writer ( false ) ;
public class TextButtonTest extends GdxTest { private Stage stage ; private Skin skin ; @ Override public void create ( ) { stage = new Stage ( 0 , 0 , false , new SpriteBatch ( ) ) ; input . setInputProcessor ( stage ) ; skin = new Skin ( files . internal ( "data/uiskin.json" ) ) ; <START_BUG> for ( int i = 0 ; i < 500 ; i ++ ) { <END_BUG> TextButton t = new TextButton ( ( "Button" + i ) , skin ) ; t . setX ( MathUtils . random ( 0 , graphics . getWidth ( ) ) ) ; t . setY ( MathUtils . random ( 0 , graphics . getHeight ( ) ) ) ; t . setWidth ( MathUtils . random ( 50 , 200 ) ) ; t . setHeight ( MathUtils . random ( 0 , 100 ) ) ; stage . addActor ( t ) ; } } @ Override public void render ( ) { } @ Override public void resize ( int width , int height ) { } @ Override public void dispose ( ) { } }<BUG2FIX>for ( int i = 0 ; i < 1 ; i ++ ) {
public class FilterPerformanceTest extends GdxTest { SpriteBatch batch ; Sprite sprite ; Sprite sprite2 ; TextureAtlas atlas ; Texture texture ; Matrix4 sceneMatrix ; Matrix4 textMatrix ; BitmapFont font ; int mode = 0 ; String modeString = "" ; int [ ] filters = new int [ ] { GL10 . GL_NEAREST , GL10 . GL_LINEAR , GL10 . GL_NEAREST_MIPMAP_NEAREST , GL10 . GL_LINEAR_MIPMAP_NEAREST , GL10 . GL_LINEAR_MIPMAP_LINEAR } ; String [ ] filterNames = new String [ ] { "nearest" , "linear" , "nearest<seq2seq4repair_space>mipmap<seq2seq4repair_space>nearest" , "linear<seq2seq4repair_space>mipmap<seq2seq4repair_space>nearest" , "linear<seq2seq4repair_space>mipmap<seq2seq4repair_space>linear" } ; void setTextureFilter ( int filter ) { } void setModeString ( ) { } public void create ( ) { batch = new SpriteBatch ( ) ; sceneMatrix = new Matrix4 ( ) . setToOrtho2D ( 0 , 0 , 480 , 320 ) ; textMatrix = new Matrix4 ( ) . setToOrtho2D ( 0 , 0 , 480 , 320 ) ; atlas = new TextureAtlas ( files . internal ( "data/issue_pack" ) , files . internal ( "data/" ) ) ; <START_BUG> texture = new Texture ( files . internal ( "data/resource1.jpg" ) ) ; <END_BUG> texture . setFilter ( MipMap , Nearest ) ; setTextureFilter ( 0 ) ; setModeString ( ) ; sprite = atlas . createSprite ( "map" ) ; sprite2 = new Sprite ( texture , 0 , 0 , 855 , 480 ) ; font = new BitmapFont ( files . internal ( "data/font.fnt" ) , files . internal ( "data/font.png" ) , false ) ; input . setInputProcessor ( new InputAdapter ( ) { public boolean touchDown ( int x , int y , int pointer , int newParam ) { ( mode ) ++ ; if ( ( mode ) == ( ( filters . length ) * 2 ) ) mode = 0 ; setTextureFilter ( ( ( mode ) / 2 ) ) ; setModeString ( ) ; return false ; } } ) ; } public void render ( ) { } public void renderSprite ( ) { } public boolean needsGL20 ( ) { } }<BUG2FIX>texture = new Texture ( files . internal ( "data/resource1.jpg" ) , true ) ;
public class IOSApplication implements Application { public static abstract class Delegate extends UIApplicationDelegate . Adapter { private IOSApplication app ; protected abstract IOSApplication createApplication ( ) { } @ Override public boolean didFinishLaunching ( UIApplication application , NSDictionary launchOptions ) { application . addStrongRef ( this ) ; this . app = createApplication ( ) ; return app . didFinishLaunching ( application , launchOptions ) ; } @ Override public void didBecomeActive ( UIApplication application ) { } @ Override public void willResignActive ( UIApplication application ) { } @ Override public void willTerminate ( UIApplication application ) { } } UIApplication uiApp ; UIWindow uiWindow ; ApplicationListener listener ; IOSApplicationConfiguration config ; IOSGraphics graphics ; IOSAudio audio ; IOSFiles files ; IOSInput input ; IOSNet net ; int logLevel = Application . LOG_DEBUG ; float displayScaleFactor ; Array < Runnable > runnables = new Array < Runnable > ( ) ; Array < Runnable > executedRunnables = new Array < Runnable > ( ) ; Array < LifecycleListener > lifecycleListeners = new Array < LifecycleListener > ( ) ; public IOSApplication ( ApplicationListener listener , IOSApplicationConfiguration config ) { } final boolean didFinishLaunching ( UIApplication uiApp , NSDictionary options ) { Gdx . app = this ; this . uiApp = uiApp ; UIApplication . getSharedApplication ( ) . setIdleTimerDisabled ( config . preventScreenDimming ) ; if ( ( UIScreen . getMainScreen ( ) . getScale ( ) ) == 2.0F ) { if ( ( UIDevice . getCurrentDevice ( ) . getUserInterfaceIdiom ( ) ) == ( UIUserInterfaceIdiom . Pad ) ) { displayScaleFactor = ( config . displayScaleLargeScreenIfRetina ) * 2.0F ; } else { displayScaleFactor = ( config . displayScaleSmallScreenIfRetina ) * 2.0F ; } } else { if ( ( UIDevice . getCurrentDevice ( ) . getUserInterfaceIdiom ( ) ) == ( UIUserInterfaceIdiom . Pad ) ) { displayScaleFactor = config . displayScaleLargeScreenIfNonRetina ; } else { displayScaleFactor = config . displayScaleSmallScreenIfNonRetina ; } } GL20 gl20 = new IOSGLES20 ( ) ; Gdx . gl = gl20 ; Gdx . gl20 = gl20 ; this . input = new IOSInput ( this ) ; this . graphics = new IOSGraphics ( getBounds ( null ) , this , config , input , gl20 ) ; this . files = new IOSFiles ( ) ; <START_BUG> this . audio = new IOSAudio ( config ) ; <END_BUG> this . net = new IOSNet ( this ) ; Gdx . files = this . files ; Gdx . graphics = this . graphics ; Gdx . audio = this . audio ; Gdx . input = this . input ; Gdx . net = this . net ; this . input . setupPeripherals ( ) ; this . uiWindow = new UIWindow ( UIScreen . getMainScreen ( ) . getBounds ( ) ) ; this . uiWindow . setRootViewController ( this . graphics . viewController ) ; this . uiWindow . makeKeyAndVisible ( ) ; app . debug ( "IOSApplication" , "created" ) ; return true ; } public UIViewController getUIViewController ( ) { } CGSize getBounds ( UIViewController viewController ) { } final void didBecomeActive ( UIApplication uiApp ) { } final void willResignActive ( UIApplication uiApp ) { } final void willTerminate ( UIApplication uiApp ) { } @ Override public ApplicationListener getApplicationListener ( ) { } @ Override public Graphics getGraphics ( ) { } @ Override public Audio getAudio ( ) { } @ Override public Input getInput ( ) { } @ Override public Files getFiles ( ) { } @ Override public Net getNet ( ) { } @ Override public void log ( String tag , String message ) { } @ Override public void log ( String tag , String message , Throwable exception ) { } @ Override public void error ( String tag , String message ) { } @ Override public void error ( String tag , String message , Throwable exception ) { } @ Override public void debug ( String tag , String message ) { } @ Override public void debug ( String tag , String message , Throwable exception ) { } @ Override public void setLogLevel ( int logLevel ) { } @ Override public int getLogLevel ( ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } @ Override public Preferences getPreferences ( String name ) { } @ Override public void postRunnable ( Runnable runnable ) { } public void processRunnables ( ) { } @ Override public void exit ( ) { } @ Override public Clipboard getClipboard ( ) { } @ Override public void addLifecycleListener ( LifecycleListener listener ) { } @ Override public void removeLifecycleListener ( LifecycleListener listener ) { } }<BUG2FIX>this . audio = new IOSAudio ( ) ;
public class ViewIssueActivity extends DialogFragmentActivity { private static final String TAG = "VIA" ; private static final String ARG_COMMENTS = "comments" ; private static final int REQUEST_CODE_COMMENT = 1 ; private static final int REQUEST_CODE_LABELS = 2 ; private static final int REQUEST_CODE_MILESTONE = 3 ; private static final int REQUEST_CODE_ASSIGNEE = 4 ; private static final int REQUEST_CODE_CLOSE = 5 ; private static final int REQUEST_CODE_REOPEN = 6 ; private static final int REQUEST_CODE_EDIT = 7 ; public static Intent createIntent ( Issue issue ) { } @ Inject private ContextScopedProvider < IssueService > service ; @ Inject private IssueStore store ; @ Inject private LabelService labelService ; @ Inject private MilestoneService milestoneService ; @ Inject private CollaboratorService collaboratorService ; @ Inject private AvatarHelper avatarHelper ; private RepositoryId repositoryId ; @ InjectExtra ( value = EXTRA_REPOSITORY_NAME , optional = true ) private String repository ; private RefreshAnimation refreshAnimation = new RefreshAnimation ( ) ; @ InjectExtra ( value = EXTRA_REPOSITORY_OWNER , optional = true ) private String repositoryOwner ; @ InjectExtra ( value = EXTRA_ISSUE_NUMBER , optional = true ) private int issueNumber ; private Issue issue ; @ InjectExtra ( value = ViewIssueActivity . ARG_COMMENTS , optional = true ) private List < Comment > comments ; private LabelsDialog labelsDialog ; private MilestoneDialog milestoneDialog ; private AssigneeDialog assigneeDialog ; @ InjectView ( id . list ) private ListView list ; private IssueHeaderViewHolder header ; private View loadingView ; private boolean destroyed = false ; @ Override protected void onDestroy ( ) { } protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; setContentView ( issue_view ) ; View headerView = getLayoutInflater ( ) . inflate ( issue_header , null ) ; headerView . findViewById ( ll_milestone ) . setOnClickListener ( new OnClickListener ( ) { public void onClick ( View v ) { if ( ( issue ) != null ) milestoneDialog . show ( issue . getMilestone ( ) ) ; } } ) ; headerView . findViewById ( ll_assignee ) . setOnClickListener ( new OnClickListener ( ) { public void onClick ( View v ) { if ( ( issue ) != null ) { User assignee = issue . getAssignee ( ) ; assigneeDialog . show ( ( assignee != null ? assignee . getLogin ( ) : null ) ) ; } } } ) ; headerView . findViewById ( ll_state ) . setOnClickListener ( new OnClickListener ( ) { public void onClick ( View v ) { if ( ( issue ) != null ) confirmEditState ( STATE_OPEN . equals ( issue . getState ( ) ) ) ; } } ) ; headerView . findViewById ( ll_labels ) . setOnClickListener ( new OnClickListener ( ) { public void onClick ( View v ) { if ( ( issue ) != null ) labelsDialog . show ( issue . getLabels ( ) ) ; } } ) ; <START_BUG> header = new IssueHeaderViewHolder ( headerView , avatarHelper , getResources ( ) ) ; <END_BUG> list . setFastScrollEnabled ( true ) ; list . addHeaderView ( headerView ) ; loadingView = getLayoutInflater ( ) . inflate ( comment_load_item , null ) ; } @ Override public void onNewIntent ( Intent intent ) { } @ Override public void onResume ( ) { } private void refreshIssue ( ) { } private void updateList ( Issue issue , List < Comment > comments ) { } @ SuppressWarnings ( "unchecked" ) private ViewHoldingListAdapter < Comment > getRootAdapter ( ) { } @ Override public boolean onCreateOptionsMenu ( Menu options ) { } @ Override public boolean onPrepareOptionsMenu ( Menu menu ) { } @ Override public boolean onOptionsItemSelected ( MenuItem item ) { } protected void onActivityResult ( int requestCode , int resultCode , Intent data ) { } private void createComment ( final String comment ) { } @ Override public void onDialogResult ( int requestCode , int resultCode , Bundle arguments ) { } private void confirmEditState ( boolean close ) { } private void editState ( final boolean close ) { } private void editLabels ( final String [ ] labels ) { } private void editMilestone ( final String title ) { } private void editAssignee ( final String user ) { } private void editBody ( final String title , final String body ) { } }<BUG2FIX>header = new IssueHeaderViewHolder ( headerView , avatarHelper ) ;
public class UxAndroid extends AndroidApplication { String IP = null ; int PORT = 0 ; RemoteSender sender ; @ Override public void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; Bundle bundle = getIntent ( ) . getExtras ( ) ; IP = bundle . getString ( "ip" ) ; PORT = Integer . parseInt ( bundle . getString ( "port" ) ) ; Log . d ( "UxAndroid" , ( ( ( "ip:<seq2seq4repair_space>" + ( IP ) ) + ",<seq2seq4repair_space>port:<seq2seq4repair_space>" ) + ( PORT ) ) ) ; initialize ( new ApplicationListener ( ) { BitmapFont font ; SpriteBatch batch ; @ Override public void create ( ) { new Thread ( new Runnable ( ) { @ Override public void run ( ) { try { RemoteSender sender = new RemoteSender ( IP , PORT ) ; synchronized ( UxAndroid . this ) { UxAndroid . this . sender = sender ; } } catch ( GdxRuntimeException e ) { } } } ) . start ( ) ; batch = new SpriteBatch ( ) ; font = new BitmapFont ( ) ; } @ Override public void resume ( ) { } @ Override public void resize ( int width , int height ) { batch . getProjectionMatrix ( ) . setToOrtho2D ( 0 , 0 , width , height ) ; } @ Override public void render ( ) { boolean connected = false ; synchronized ( UxAndroid . this ) { if ( ( sender ) != null ) { sender . sendUpdate ( ) ; connected = sender . isConnected ( ) ; } } gl . glClear ( GL_COLOR_BUFFER_BIT ) ; batch . begin ( ) ; if ( connected ) { font . draw ( batch , ( ( ( ( ( ( ( "accel:" + ( input . getAccelerometerX ( ) ) ) + ",<seq2seq4repair_space>" ) + ( input . getAccelerometerY ( ) ) ) + ",<seq2seq4repair_space>" ) + ( input . getAccelerometerZ ( ) ) ) + ",<seq2seq4repair_space>fps:<seq2seq4repair_space>" ) + ( graphics . getFramesPerSecond ( ) ) ) , 10 , 20 ) ; } else { font . draw ( batch , ( ( ( "No<seq2seq4repair_space>connection<seq2seq4repair_space>to<seq2seq4repair_space>" + ( IP ) ) + ":" ) + ( PORT ) ) , 10 , 20 ) ; } batch . end ( ) ; } @ Override public void pause ( ) { } @ Override public void dispose ( ) { } <START_BUG> } ) ; <END_BUG> } }<BUG2FIX>} , false ) ;
public class TransportSearchScanAction extends TransportSearchTypeAction { @ Inject public TransportSearchScanAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportSearchCache transportSearchCache , SearchServiceTransportAction searchService , SearchPhaseController searchPhaseController ) { } @ Override protected void doExecute ( SearchRequest searchRequest , ActionListener < SearchResponse > listener ) { } private class AsyncAction extends BaseAsyncAction < QuerySearchResult > { private final Map < SearchShardTarget , QuerySearchResultProvider > queryResults = searchCache . obtainQueryResults ( ) ; private AsyncAction ( SearchRequest request , ActionListener < SearchResponse > listener ) { } @ Override protected String firstPhaseName ( ) { } @ Override protected void sendExecuteFirstPhase ( DiscoveryNode node , InternalSearchRequest request , SearchServiceListener < QuerySearchResult > listener ) { } @ Override protected void processFirstPhaseResult ( ShardRouting shard , QuerySearchResult result ) { } @ Override protected void moveToSecondPhase ( ) throws Exception { long totalHits = 0 ; final InternalSearchResponse internalResponse = searchPhaseController . merge ( TransportSearchScanAction . EMPTY_DOCS , queryResults , ImmutableMap . < SearchShardTarget , FetchSearchResultProvider > of ( ) ) ; String scrollId = null ; if ( ( request . scroll ( ) ) != null ) { <START_BUG> scrollId = buildScrollId ( request . searchType ( ) , queryResults . values ( ) ) ; <END_BUG> } listener . onResponse ( new SearchResponse ( internalResponse , scrollId , expectedSuccessfulOps , successulOps . get ( ) , buildTookInMillis ( ) , buildShardFailures ( ) ) ) ; searchCache . releaseQueryResults ( queryResults ) ; } } private static ShardDoc [ ] EMPTY_DOCS = new ShardDoc [ 0 ] ; }<BUG2FIX>scrollId = buildScrollId ( request . searchType ( ) , queryResults . values ( ) , null ) ;
public class LongArray { public long [ ] items ; public int size ; public boolean ordered ; public LongArray ( ) { } public LongArray ( int capacity ) { } public LongArray ( boolean ordered , int capacity ) { } public LongArray ( LongArray array ) { } public LongArray ( long [ ] array ) { } public LongArray ( boolean ordered , long [ ] array , int startIndex , int count ) { } public void add ( long value ) { } public void addAll ( LongArray array ) { } public void addAll ( LongArray array , int offset , int length ) { } public void addAll ( long [ ] array ) { } public void addAll ( long [ ] array , int offset , int length ) { long [ ] items = this . items ; <START_BUG> int sizeNeeded = ( ( size ) + length ) - offset ; <END_BUG> if ( sizeNeeded >= ( items . length ) ) items = resize ( Math . max ( 8 , ( ( int ) ( sizeNeeded * 1.75F ) ) ) ) ; System . arraycopy ( array , offset , items , size , length ) ; size += length ; } public long get ( int index ) { } public void set ( int index , long value ) { } public void insert ( int index , long value ) { } public void swap ( int first , int second ) { } public boolean contains ( long value ) { } public int indexOf ( long value ) { } public int lastIndexOf ( char value ) { } public boolean removeValue ( long value ) { } public long removeIndex ( int index ) { } public boolean removeAll ( LongArray array ) { } public long pop ( ) { } public long peek ( ) { } public long first ( ) { } public void clear ( ) { } public void shrink ( ) { } public long [ ] ensureCapacity ( int additionalCapacity ) { } protected long [ ] resize ( int newSize ) { } public void sort ( ) { } public void reverse ( ) { } public void shuffle ( ) { } public void truncate ( int newSize ) { } public long random ( ) { } public long [ ] toArray ( ) { } public boolean equals ( Object object ) { } public String toString ( ) { } public String toString ( String separator ) { } }<BUG2FIX>int sizeNeeded = ( size ) + length ;
public class MD5Test extends GdxTest implements InputProcessor { PerspectiveCamera camera ; MD5Model model ; MD5Animation anim ; MD5AnimationInfo animInfo ; MD5Joints skeleton ; MD5Renderer renderer ; SpriteBatch batch ; BitmapFont font ; @ Override public void create ( ) { app . log ( "MD5<seq2seq4repair_space>Test" , "created" ) ; model = MD5Loader . loadModel ( files . internal ( "data/zfat.md5mesh" ) . read ( ) , false ) ; anim = MD5Loader . loadAnimation ( files . internal ( "data/walk1.md5anim" ) . read ( ) ) ; skeleton = new MD5Joints ( ) ; skeleton . joints = new float [ anim . frames [ 0 ] . joints . length ] ; animInfo = new MD5AnimationInfo ( anim . frames . length , anim . secondsPerFrame ) ; <START_BUG> renderer = new MD5Renderer ( model , false , true ) ; <END_BUG> renderer . setSkeleton ( model . baseSkeleton ) ; camera = new PerspectiveCamera ( 60 , graphics . getWidth ( ) , graphics . getHeight ( ) ) ; camera . position . set ( 0 , 25 , 100 ) ; camera . near = 1 ; camera . far = 1000 ; batch = new SpriteBatch ( ) ; font = new BitmapFont ( ) ; graphics . getGL10 ( ) . glViewport ( 0 , 0 , graphics . getWidth ( ) , graphics . getHeight ( ) ) ; input . setInputProcessor ( this ) ; } float angle = 0 ; @ Override public void render ( ) { } @ Override public void dispose ( ) { } @ Override public boolean keyDown ( int keycode ) { } @ Override public boolean keyTyped ( char character ) { } @ Override public boolean keyUp ( int keycode ) { } @ Override public boolean touchDown ( int x , int y , int pointer , int newParam ) { } @ Override public boolean touchDragged ( int x , int y , int pointer ) { } @ Override public boolean touchUp ( int x , int y , int pointer , int button ) { } @ Override public boolean needsGL20 ( ) { } @ Override public boolean touchMoved ( int x , int y ) { } @ Override public boolean scrolled ( int amount ) { } }<BUG2FIX>renderer = new MD5Renderer ( model , true , false ) ;
public class XContentIndexQueryParser extends AbstractIndexComponent implements IndexQueryParser { public static final class Defaults { public static final String QUERY_PREFIX = "index.queryparser.query" ; public static final String FILTER_PREFIX = "index.queryparser.filter" ; } private ThreadLocal < ThreadLocals . CleanableValue < QueryParseContext > > cache = new ThreadLocal < ThreadLocals . CleanableValue < QueryParseContext > > ( ) { @ Override protected ThreadLocals . CleanableValue < QueryParseContext > initialValue ( ) { } } ; private final String name ; final ScriptService scriptService ; final MapperService mapperService ; final SimilarityService similarityService ; final IndexCache indexCache ; final IndexEngine indexEngine ; private final Map < String , XContentQueryParser > queryParsers ; private final Map < String , XContentFilterParser > filterParsers ; @ Inject public XContentIndexQueryParser ( Index index , @ IndexSettings Settings indexSettings , ScriptService scriptService , MapperService mapperService , IndexCache indexCache , IndexEngine indexEngine , @ Nullable SimilarityService similarityService , @ Nullable Map < String , XContentQueryParserFactory > namedQueryParsers , @ Nullable Map < String , XContentFilterParserFactory > namedFilterParsers , @ Assisted String name , @ Assisted @ Nullable Settings settings ) { } @ Override public String name ( ) { } public XContentQueryParser queryParser ( String name ) { } public XContentFilterParser filterParser ( String name ) { } @ Override public ParsedQuery parse ( QueryBuilder queryBuilder ) throws ElasticSearchException { } @ Override public ParsedQuery parse ( byte [ ] source ) throws ElasticSearchException { } @ Override public ParsedQuery parse ( byte [ ] source , int offset , int length ) throws ElasticSearchException { } @ Override public ParsedQuery parse ( String source ) throws QueryParsingException { } public ParsedQuery parse ( XContentParser parser ) { } public Filter parseInnerFilter ( XContentParser parser ) throws IOException { } public Query parseInnerQuery ( XContentParser parser ) throws IOException { } private ParsedQuery parse ( QueryParseContext parseContext , XContentParser parser ) throws IOException , QueryParsingException { parseContext . reset ( parser ) ; Query query = parseContext . parseInnerQuery ( ) ; <START_BUG> return new ParsedQuery ( query , parseContext . copyNamedFilters ( ) , parseContext . copyScopePhases ( ) ) ; <END_BUG> } private void add ( Map < String , XContentFilterParser > map , XContentFilterParser filterParser ) { } private void add ( Map < String , XContentQueryParser > map , XContentQueryParser queryParser ) { } }<BUG2FIX>return new ParsedQuery ( query , parseContext . copyNamedFilters ( ) ) ;
public class AndroidMultiTouchHandler implements AndroidTouchHandler { public void onTouch ( MotionEvent event , AndroidInput input ) { } private void postTouchEvent ( AndroidInput input , int type , int x , int y , int pointer ) { synchronized ( input ) { TouchEvent event = input . freeTouchEvents . newObject ( ) ; <START_BUG> event . pointer = 0 ; <END_BUG> event . x = x ; event . y = y ; event . type = type ; input . touchEvents . add ( event ) ; } } public boolean supportsMultitouch ( AndroidApplication activity ) { } }<BUG2FIX>event . pointer = pointer ;
public class CubocDesktop { public static void main ( String [ ] argv ) { <START_BUG> new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new Cubocy ( ) , "Cubocy" , 480 , 320 , false ) ; <END_BUG> } }<BUG2FIX>new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new Cubocy ( ) , "Cubocy" , 480 , 320 , true ) ;
public class CharArray { public char [ ] items ; public int size ; public boolean ordered ; public CharArray ( ) { } public CharArray ( int capacity ) { } public CharArray ( boolean ordered , int capacity ) { } public CharArray ( CharArray array ) { } public CharArray ( char [ ] array ) { } public CharArray ( boolean ordered , char [ ] array ) { } public void add ( char value ) { } public void addAll ( CharArray array ) { } public void addAll ( CharArray array , int offset , int length ) { } public void addAll ( char [ ] array ) { } public void addAll ( char [ ] array , int offset , int length ) { } public char get ( int index ) { } public void set ( int index , char value ) { } public void insert ( int index , char value ) { } public void swap ( int first , int second ) { } public boolean contains ( char value ) { } public int indexOf ( char value ) { } public int lastIndexOf ( char value ) { } public boolean removeValue ( char value ) { } public char removeIndex ( int index ) { } public boolean removeAll ( CharArray array ) { int size = this . size ; int startSize = size ; char [ ] items = this . items ; for ( int i = 0 , n = array . size ; i < n ; i ++ ) { char item = array . get ( i ) ; <START_BUG> for ( int ii = 0 , nn = size ; ii < nn ; ii ++ ) { <END_BUG> if ( item == ( items [ ii ] ) ) { removeIndex ( ii ) ; size -- ; break ; } } } return size != startSize ; } public char pop ( ) { } public char peek ( ) { } public char first ( ) { } public void clear ( ) { } public void shrink ( ) { } public char [ ] ensureCapacity ( int additionalCapacity ) { } protected char [ ] resize ( int newSize ) { } public void sort ( ) { } public void reverse ( ) { } public void shuffle ( ) { } public void truncate ( int newSize ) { } public char random ( ) { } public char [ ] toArray ( ) { } public boolean equals ( Object object ) { } public String toString ( ) { } public String toString ( String separator ) { } }<BUG2FIX>for ( int ii = 0 ; ii < size ; ii ++ ) {
public class GeoDistanceFacetParser extends AbstractComponent implements FacetParser { @ Inject public GeoDistanceFacetParser ( Settings settings ) { } @ Override public String [ ] types ( ) { } @ Override public Mode defaultMainMode ( ) { } @ Override public Mode defaultGlobalMode ( ) { } @ Override public FacetExecutor parse ( String facetName , XContentParser parser , SearchContext context ) throws IOException { String fieldName = null ; String valueFieldName = null ; String valueScript = null ; String scriptLang = null ; Map < String , Object > params = null ; GeoPoint point = new GeoPoint ( ) ; <START_BUG> DistanceUnit unit = DistanceUnit . KILOMETERS ; <END_BUG> GeoDistance geoDistance = GeoDistance . DEFAULT ; List < GeoDistanceFacet . Entry > entries = Lists . newArrayList ( ) ; boolean normalizeLon = true ; boolean normalizeLat = true ; XContentParser . Token token ; String currentName = parser . currentName ( ) ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentName = parser . currentName ( ) ; } else if ( token == ( Token . START_ARRAY ) ) { if ( ( "ranges" . equals ( currentName ) ) || ( "entries" . equals ( currentName ) ) ) { while ( ( token = parser . nextToken ( ) ) != ( Token . END_ARRAY ) ) { double from = Double . NEGATIVE_INFINITY ; double to = Double . POSITIVE_INFINITY ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentName = parser . currentName ( ) ; } else if ( token . isValue ( ) ) { if ( "from" . equals ( currentName ) ) { from = parser . doubleValue ( ) ; } else if ( "to" . equals ( currentName ) ) { to = parser . doubleValue ( ) ; } } } entries . add ( new GeoDistanceFacet . Entry ( from , to , 0 , 0 , 0 , Double . POSITIVE_INFINITY , Double . NEGATIVE_INFINITY ) ) ; } } else { GeoPoint . parse ( parser , point ) ; fieldName = currentName ; } } else if ( token == ( Token . START_OBJECT ) ) { if ( "params" . equals ( currentName ) ) { params = parser . map ( ) ; } else { fieldName = currentName ; GeoPoint . parse ( parser , point ) ; } } else if ( token . isValue ( ) ) { if ( currentName . equals ( "unit" ) ) { unit = DistanceUnit . fromString ( parser . text ( ) ) ; } else if ( ( currentName . equals ( "distance_type" ) ) || ( currentName . equals ( "distanceType" ) ) ) { geoDistance = GeoDistance . fromString ( parser . text ( ) ) ; } else if ( ( "value_field" . equals ( currentName ) ) || ( "valueField" . equals ( currentName ) ) ) { valueFieldName = parser . text ( ) ; } else if ( ( "value_script" . equals ( currentName ) ) || ( "valueScript" . equals ( currentName ) ) ) { valueScript = parser . text ( ) ; } else if ( "lang" . equals ( currentName ) ) { scriptLang = parser . text ( ) ; } else if ( "normalize" . equals ( currentName ) ) { normalizeLat = parser . booleanValue ( ) ; normalizeLon = parser . booleanValue ( ) ; } else { point . resetFromString ( parser . text ( ) ) ; fieldName = currentName ; } } } if ( entries . isEmpty ( ) ) { throw new FacetPhaseExecutionException ( facetName , "no<seq2seq4repair_space>ranges<seq2seq4repair_space>defined<seq2seq4repair_space>for<seq2seq4repair_space>geo_distance<seq2seq4repair_space>facet" ) ; } if ( normalizeLat || normalizeLon ) { GeoUtils . normalizePoint ( point , normalizeLat , normalizeLon ) ; } FieldMapper keyFieldMapper = context . smartNameFieldMapper ( fieldName ) ; if ( keyFieldMapper == null ) { throw new FacetPhaseExecutionException ( facetName , ( ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>find<seq2seq4repair_space>mapping<seq2seq4repair_space>for<seq2seq4repair_space>[" + fieldName ) + "]" ) ) ; } IndexGeoPointFieldData keyIndexFieldData = context . fieldData ( ) . getForField ( keyFieldMapper ) ; if ( valueFieldName != null ) { FieldMapper valueFieldMapper = context . smartNameFieldMapper ( valueFieldName ) ; if ( valueFieldMapper == null ) { throw new FacetPhaseExecutionException ( facetName , ( ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>find<seq2seq4repair_space>mapping<seq2seq4repair_space>for<seq2seq4repair_space>[" + valueFieldName ) + "]" ) ) ; } IndexNumericFieldData valueIndexFieldData = context . fieldData ( ) . getForField ( valueFieldMapper ) ; return new ValueGeoDistanceFacetExecutor ( keyIndexFieldData , point . lat ( ) , point . lon ( ) , unit , geoDistance , entries . toArray ( new GeoDistanceFacet . Entry [ entries . size ( ) ] ) , context , valueIndexFieldData ) ; } if ( valueScript != null ) { return new ScriptGeoDistanceFacetExecutor ( keyIndexFieldData , point . lat ( ) , point . lon ( ) , unit , geoDistance , entries . toArray ( new GeoDistanceFacet . Entry [ entries . size ( ) ] ) , context , scriptLang , valueScript , params ) ; } return new GeoDistanceFacetExecutor ( keyIndexFieldData , point . lat ( ) , point . lon ( ) , unit , geoDistance , entries . toArray ( new GeoDistanceFacet . Entry [ entries . size ( ) ] ) , context ) ; } }<BUG2FIX>DistanceUnit unit = DistanceUnit . DEFAULT ;
public final class NoisyChannelSpellChecker { public static final double REAL_WORD_LIKELYHOOD = 0.95 ; private final double realWordLikelihood ; private final boolean requireUnigram ; public NoisyChannelSpellChecker ( ) { } public NoisyChannelSpellChecker ( double nonErrorLikelihood ) { } public NoisyChannelSpellChecker ( double nonErrorLikelihood , boolean requireUnigram ) { } public Correction [ ] getCorrections ( TokenStream stream , final CandidateGenerator generator , final int numCandidates , float maxErrors , int numCorrections , IndexReader reader , WordScorer wordScorer , BytesRef separator , float confidence , int gramSize ) throws IOException { final List < CandidateSet > candidateSetsList = new ArrayList < DirectCandidateGenerator . CandidateSet > ( ) ; SuggestUtils . analyze ( stream , new SuggestUtils . TokenConsumer ( ) { CandidateSet currentSet = null ; private TypeAttribute typeAttribute ; private final BytesRef termsRef = new BytesRef ( ) ; private boolean anyUnigram = false ; private boolean anyTokens = false ; @ Override public void reset ( TokenStream stream ) { super . reset ( stream ) ; typeAttribute = stream . addAttribute ( TypeAttribute . class ) ; } @ Override public void nextToken ( ) throws IOException { anyTokens = true ; BytesRef term = fillBytesRef ( termsRef ) ; if ( ( requireUnigram ) && ( ( typeAttribute . type ( ) ) == ( ShingleFilter . DEFAULT_TOKEN_TYPE ) ) ) { return ; } anyUnigram = true ; if ( ( ( posIncAttr . getPositionIncrement ( ) ) == 0 ) && ( ( typeAttribute . type ( ) ) == ( SynonymFilter . TYPE_SYNONYM ) ) ) { assert ( currentSet ) != null ; <START_BUG> int freq = 0 ; <END_BUG> if ( ( freq = generator . frequency ( term ) ) > 0 ) { currentSet . addOneCandidate ( generator . createCandidate ( BytesRef . deepCopyOf ( term ) , freq , realWordLikelihood ) ) ; } } else { if ( ( currentSet ) != null ) { candidateSetsList . add ( currentSet ) ; } currentSet = new CandidateSet ( Candidate . EMPTY , generator . createCandidate ( BytesRef . deepCopyOf ( term ) ) ) ; } } @ Override public void end ( ) { if ( ( currentSet ) != null ) { candidateSetsList . add ( currentSet ) ; } if ( ( ( requireUnigram ) && ( ! ( anyUnigram ) ) ) && ( anyTokens ) ) { throw new IllegalStateException ( "At<seq2seq4repair_space>least<seq2seq4repair_space>one<seq2seq4repair_space>unigram<seq2seq4repair_space>is<seq2seq4repair_space>required<seq2seq4repair_space>but<seq2seq4repair_space>all<seq2seq4repair_space>tokens<seq2seq4repair_space>were<seq2seq4repair_space>ngrams" ) ; } } } ) ; for ( CandidateSet candidateSet : candidateSetsList ) { generator . drawCandidates ( candidateSet , numCandidates ) ; } double cutoffScore = Double . MIN_VALUE ; CandidateScorer scorer = new CandidateScorer ( wordScorer , numCorrections , gramSize ) ; CandidateSet [ ] candidateSets = candidateSetsList . toArray ( new CandidateSet [ candidateSetsList . size ( ) ] ) ; if ( confidence > 0.0 ) { Candidate [ ] candidates = new Candidate [ candidateSets . length ] ; for ( int i = 0 ; i < ( candidates . length ) ; i ++ ) { candidates [ i ] = candidateSets [ i ] . originalTerm ; } cutoffScore = scorer . score ( candidates , candidateSets ) ; } Correction [ ] findBestCandiates = scorer . findBestCandiates ( candidateSets , maxErrors , ( cutoffScore * confidence ) ) ; return findBestCandiates ; } public Correction [ ] getCorrections ( Analyzer analyzer , BytesRef query , CandidateGenerator generator , int numCandidates , float maxErrors , int numCorrections , IndexReader reader , String analysisField , WordScorer scorer , float confidence , int gramSize ) throws IOException { } public TokenStream tokenStream ( Analyzer analyzer , BytesRef query , CharsRef spare , String field ) throws IOException { } }<BUG2FIX>long freq = 0 ;
public class ScrollPaneScrollBarsTest extends GdxTest { private Stage stage ; Array < ScrollPane > scrollPanes = new Array < ScrollPane > ( ) ; boolean doFade = true ; boolean doOnTop = true ; private Table bottomLeft ; private Table bottomRight ; private Table topLeft ; private Table topRight ; private Table horizOnlyTop ; private Table horizOnlyBottom ; private Table vertOnlyLeft ; private Table vertOnlyRight ; public void create ( ) { } public void render ( ) { } public void resize ( int width , int height ) { <START_BUG> stage . getViewport ( ) . update ( width , height ) ; <END_BUG> } public void dispose ( ) { } }<BUG2FIX>stage . getViewport ( ) . update ( width , height , true ) ;
public class LwjglAWTCanvas implements Application { final LwjglGraphics graphics ; final OpenALAudio audio ; final LwjglFiles files ; final LwjglAWTInput input ; final LwjglNet net ; final ApplicationListener listener ; final AWTGLCanvas canvas ; final List < Runnable > runnables = new ArrayList ( ) ; final List < Runnable > executedRunnables = new ArrayList ( ) ; final Array < LifecycleListener > lifecycleListeners = new Array < LifecycleListener > ( ) ; boolean running = true ; int lastWidth ; int lastHeight ; int logLevel = LOG_INFO ; private Cursor cursor ; public LwjglAWTCanvas ( ApplicationListener listener , boolean useGL2 ) { } public LwjglAWTCanvas ( ApplicationListener listener , boolean useGL2 , LwjglAWTCanvas sharedContextCanvas ) { } protected void setDisplayMode ( int width , int height ) { } protected void setTitle ( String title ) { } @ Override public ApplicationListener getApplicationListener ( ) { } public Canvas getCanvas ( ) { } @ Override public Audio getAudio ( ) { } @ Override public Files getFiles ( ) { } @ Override public Graphics getGraphics ( ) { } @ Override public Input getInput ( ) { } @ Override public Net getNet ( ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } void setGlobals ( ) { } void create ( ) { } void render ( ) { } protected void start ( ) { } protected void resize ( int width , int height ) { } protected void stopped ( ) { } public void stop ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } Map < String , Preferences > preferences = new HashMap < String , Preferences > ( ) ; @ Override public Preferences getPreferences ( String name ) { } @ Override public Clipboard getClipboard ( ) { } @ Override public void postRunnable ( Runnable runnable ) { } @ Override public void debug ( String tag , String message ) { } @ Override public void debug ( String tag , String message , Throwable exception ) { } public void log ( String tag , String message ) { } @ Override <START_BUG> public void log ( String tag , String message , Exception exception ) { <END_BUG> if ( ( logLevel ) >= ( LOG_INFO ) ) { System . out . println ( ( ( tag + ":<seq2seq4repair_space>" ) + message ) ) ; exception . printStackTrace ( System . out ) ; } } @ Override public void error ( String tag , String message ) { } @ Override public void error ( String tag , String message , Throwable exception ) { } @ Override public void setLogLevel ( int logLevel ) { } @ Override public int getLogLevel ( ) { } @ Override public void exit ( ) { } public void makeCurrent ( ) { } public boolean isCurrent ( ) { } public void setCursor ( Cursor cursor ) { } @ Override public void addLifecycleListener ( LifecycleListener listener ) { } @ Override public void removeLifecycleListener ( LifecycleListener listener ) { } }<BUG2FIX>public void log ( String tag , String message , Throwable exception ) {
public class OrgViewHolder implements ViewHolder < User > { private final AvatarHelper avatarHelper ; private final TextView nameText ; private final ImageView avatarView ; public OrgViewHolder ( final View view , final AvatarHelper avatarHelper ) { } @ Override <START_BUG> public void updateViewFor ( User user ) { <END_BUG> nameText . setText ( user . getLogin ( ) ) ; avatarView . setBackgroundDrawable ( null ) ; avatarHelper . bind ( avatarView , user ) ; } }<BUG2FIX>public void updateViewFor ( final User user ) {
private ParticleEmitter . GradientColorValue tintValue = new ParticleEmitter . GradientColorValue ( ) ; private ParticleEmitter . RangedNumericValue xOffsetValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . RangedNumericValue yOffsetValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue spawnWidthValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . ScaledNumericValue spawnHeightValue = new ParticleEmitter . ScaledNumericValue ( ) ; private ParticleEmitter . SpawnShapeValue spawnShapeValue = new ParticleEmitter . SpawnShapeValue ( ) ; private float accumulator ; private Sprite sprite ; private ParticleEmitter . Particle [ ] particles ; private int minParticleCount ; private int maxParticleCount = 4 ; private float x ; private float y ; private String name ; private String imagePath ; private int activeCount ; private boolean [ ] active ; private boolean firstUpdate ; private boolean flipX ; private boolean flipY ; private int updateFlags ; private boolean allowCompletion ; private int emission ; private int emissionDiff ; private int emissionDelta ; private int lifeOffset ; private int lifeOffsetDiff ; private int life ; private int lifeDiff ; private float spawnWidth ; private float spawnWidthDiff ; private float spawnHeight ; private float spawnHeightDiff ; public float duration = 1 ; public float durationTimer ; private float delay ; private float delayTimer ; private boolean attached ; private boolean continuous ; private boolean aligned ; private boolean behind ; private boolean additive = true ; public ParticleEmitter ( ) { } public ParticleEmitter ( BufferedReader reader ) throws IOException { } public ParticleEmitter ( ParticleEmitter emitter ) { } private void initialize ( ) { } public void setMaxParticleCount ( int maxParticleCount ) { } public void addParticle ( ) { } public void addParticles ( int count ) { } public void update ( float delta ) { } public void draw ( SpriteBatch spriteBatch ) { } public void draw ( SpriteBatch spriteBatch , float delta ) { } public void start ( ) { } public void reset ( ) { } private void restart ( ) { delay = ( delayValue . active ) ? delayValue . newLowValue ( ) : 0 ; delayTimer = 0 ; durationTimer -= duration ; duration = durationValue . newLowValue ( ) ; emission = ( ( int ) ( emissionValue . newLowValue ( ) ) ) ; emissionDiff = ( ( int ) ( emissionValue . newHighValue ( ) ) ) ; if ( ! ( emissionValue . isRelative ( ) ) ) emissionDiff -= emission ; life = ( ( int ) ( lifeValue . newLowValue ( ) ) ) ; lifeDiff = ( ( int ) ( lifeValue . newHighValue ( ) ) ) ; if ( ! ( lifeValue . isRelative ( ) ) ) lifeDiff -= life ; lifeOffset = ( lifeOffsetValue . active ) ? ( ( int ) ( lifeOffsetValue . newLowValue ( ) ) ) : 0 ; lifeOffsetDiff = ( ( int ) ( lifeOffsetValue . newHighValue ( ) ) ) ; if ( ! ( lifeOffsetValue . isRelative ( ) ) ) lifeOffsetDiff -= lifeOffset ; spawnWidth = spawnWidthValue . newLowValue ( ) ; spawnWidthDiff = spawnWidthValue . newHighValue ( ) ; if ( ! ( spawnWidthValue . isRelative ( ) ) ) spawnWidthDiff -= spawnWidth ; spawnHeight = spawnHeightValue . newLowValue ( ) ; spawnHeightDiff = spawnHeightValue . newHighValue ( ) ; if ( ! ( spawnHeightValue . isRelative ( ) ) ) spawnHeightDiff -= spawnHeight ; updateFlags = 0 ; if ( ( angleValue . active ) && ( ( angleValue . timeline . length ) > 1 ) ) updateFlags |= ParticleEmitter . UPDATE_ANGLE ; <START_BUG> if ( ( velocityValue . active ) && ( velocityValue . active ) ) <END_BUG> updateFlags |= ParticleEmitter . UPDATE_VELOCITY ; if ( ( scaleValue . timeline . length ) > 1 ) updateFlags |= ParticleEmitter . UPDATE_SCALE ; if ( ( rotationValue . active ) && ( ( rotationValue . timeline . length ) > 1 ) ) updateFlags |= ParticleEmitter . UPDATE_ROTATION ; if ( windValue . active ) updateFlags |= ParticleEmitter . UPDATE_WIND ; if ( gravityValue . active ) updateFlags |= ParticleEmitter . UPDATE_GRAVITY ; if ( ( tintValue . timeline . length ) > 1 ) updateFlags |= ParticleEmitter . UPDATE_TINT ; } protected ParticleEmitter . Particle newParticle ( Sprite sprite ) { } private void activateParticle ( int index ) { } private boolean updateParticle ( ParticleEmitter . Particle particle , float delta , int deltaMillis ) { } public void setPosition ( float x , float y ) { } public void setSprite ( Sprite sprite ) { } public void allowCompletion ( ) { } public Sprite getSprite ( ) { } public String getName ( ) { } public void setName ( String name ) { } public ParticleEmitter . ScaledNumericValue getLife ( ) { } public ParticleEmitter . ScaledNumericValue getScale ( ) { } public ParticleEmitter . ScaledNumericValue getRotation ( ) { } public ParticleEmitter . GradientColorValue getTint ( ) { } public ParticleEmitter . ScaledNumericValue getVelocity ( ) { } public ParticleEmitter . ScaledNumericValue getWind ( ) { } public ParticleEmitter . ScaledNumericValue getGravity ( ) { } public ParticleEmitter . ScaledNumericValue getAngle ( ) { } public ParticleEmitter . ScaledNumericValue getEmission ( ) { } public ParticleEmitter . ScaledNumericValue getTransparency ( ) { } public ParticleEmitter . RangedNumericValue getDuration ( ) { } public ParticleEmitter . RangedNumericValue getDelay ( ) { } public ParticleEmitter . ScaledNumericValue getLifeOffset ( ) { } public ParticleEmitter . RangedNumericValue getXOffsetValue ( ) { } public ParticleEmitter . RangedNumericValue getYOffsetValue ( ) { } public ParticleEmitter . ScaledNumericValue getSpawnWidth ( ) { } public ParticleEmitter . ScaledNumericValue getSpawnHeight ( ) { } public ParticleEmitter . SpawnShapeValue getSpawnShape ( ) { } public boolean isAttached ( ) { } public void setAttached ( boolean attached ) { } public boolean isContinuous ( ) { } public void setContinuous ( boolean continuous ) { }<BUG2FIX>if ( velocityValue . active )
public class LocalGateway extends AbstractLifecycleComponent < Gateway > implements ClusterStateListener , Gateway { private final ClusterService clusterService ; private final NodeEnvironment nodeEnv ; private final LocalGatewayShardsState shardsState ; private final LocalGatewayMetaState metaState ; private final TransportNodesListGatewayMetaState listGatewayMetaState ; private final String initialMeta ; @ Inject public LocalGateway ( Settings settings , ClusterService clusterService , NodeEnvironment nodeEnv , LocalGatewayShardsState shardsState , LocalGatewayMetaState metaState , TransportNodesListGatewayMetaState listGatewayMetaState ) { } @ Override public String type ( ) { } @ Override protected void doStart ( ) throws ElasticsearchException { } @ Override protected void doStop ( ) throws ElasticsearchException { } @ Override protected void doClose ( ) throws ElasticsearchException { } @ Override public void performStateRecovery ( final GatewayStateRecoveredListener listener ) throws GatewayException { ObjectOpenHashSet < String > nodesIds = ObjectOpenHashSet . from ( clusterService . state ( ) . nodes ( ) . masterNodes ( ) . keys ( ) ) ; logger . trace ( "performing<seq2seq4repair_space>state<seq2seq4repair_space>recovery<seq2seq4repair_space>from<seq2seq4repair_space>{}" , nodesIds ) ; TransportNodesListGatewayMetaState . NodesLocalGatewayMetaState nodesState = listGatewayMetaState . list ( nodesIds . toArray ( String . class ) , null ) . actionGet ( ) ; int requiredAllocation = 1 ; try { if ( "quorum" . equals ( initialMeta ) ) { if ( ( nodesIds . size ( ) ) > 2 ) { requiredAllocation = ( ( nodesIds . size ( ) ) / 2 ) + 1 ; } } else if ( ( "quorum-1" . equals ( initialMeta ) ) || ( "half" . equals ( initialMeta ) ) ) { if ( ( nodesIds . size ( ) ) > 2 ) { requiredAllocation = ( 1 + ( nodesIds . size ( ) ) ) / 2 ; } } else if ( "one" . equals ( initialMeta ) ) { requiredAllocation = 1 ; } else if ( ( "full" . equals ( initialMeta ) ) || ( "all" . equals ( initialMeta ) ) ) { requiredAllocation = nodesIds . size ( ) ; } else if ( ( "full-1" . equals ( initialMeta ) ) || ( "all-1" . equals ( initialMeta ) ) ) { if ( ( nodesIds . size ( ) ) > 1 ) { requiredAllocation = ( nodesIds . size ( ) ) - 1 ; } } else { requiredAllocation = Integer . parseInt ( initialMeta ) ; } } catch ( Exception e ) { logger . warn ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>derived<seq2seq4repair_space>initial_meta<seq2seq4repair_space>from<seq2seq4repair_space>value<seq2seq4repair_space>{}" , initialMeta ) ; } if ( ( nodesState . failures ( ) . length ) > 0 ) { for ( FailedNodeException failedNodeException : nodesState . failures ( ) ) { logger . warn ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>fetch<seq2seq4repair_space>state<seq2seq4repair_space>from<seq2seq4repair_space>node" , failedNodeException ) ; } } <START_BUG> ObjectFloatOpenHashMap < String > indices = new ObjectFloatOpenHashMap < String > ( ) ; <END_BUG> MetaData electedGlobalState = null ; int found = 0 ; for ( TransportNodesListGatewayMetaState . NodeLocalGatewayMetaState nodeState : nodesState ) { if ( ( nodeState . metaData ( ) ) == null ) { continue ; } found ++ ; if ( electedGlobalState == null ) { electedGlobalState = nodeState . metaData ( ) ; } else if ( ( nodeState . metaData ( ) . version ( ) ) > ( electedGlobalState . version ( ) ) ) { electedGlobalState = nodeState . metaData ( ) ; } for ( ObjectCursor < IndexMetaData > cursor : nodeState . metaData ( ) . indices ( ) . values ( ) ) { indices . addTo ( cursor . value . index ( ) , 1 ) ; } } if ( found < requiredAllocation ) { listener . onFailure ( ( ( ( ( "found<seq2seq4repair_space>[" + found ) + "]<seq2seq4repair_space>metadata<seq2seq4repair_space>states,<seq2seq4repair_space>required<seq2seq4repair_space>[" ) + requiredAllocation ) + "]" ) ) ; return ; } MetaData . Builder metaDataBuilder = MetaData . builder ( electedGlobalState ) . removeAllIndices ( ) ; final boolean [ ] states = indices . allocated ; final Object [ ] keys = indices . keys ; for ( int i = 0 ; i < ( states . length ) ; i ++ ) { if ( states [ i ] ) { String index = ( ( String ) ( keys [ i ] ) ) ; IndexMetaData electedIndexMetaData = null ; int indexMetaDataCount = 0 ; for ( TransportNodesListGatewayMetaState . NodeLocalGatewayMetaState nodeState : nodesState ) { if ( ( nodeState . metaData ( ) ) == null ) { continue ; } IndexMetaData indexMetaData = nodeState . metaData ( ) . index ( index ) ; if ( indexMetaData == null ) { continue ; } if ( electedIndexMetaData == null ) { electedIndexMetaData = indexMetaData ; } else if ( ( indexMetaData . version ( ) ) > ( electedIndexMetaData . version ( ) ) ) { electedIndexMetaData = indexMetaData ; } indexMetaDataCount ++ ; } if ( electedIndexMetaData != null ) { if ( indexMetaDataCount < requiredAllocation ) { logger . debug ( "[{}]<seq2seq4repair_space>found<seq2seq4repair_space>[{}],<seq2seq4repair_space>required<seq2seq4repair_space>[{}],<seq2seq4repair_space>not<seq2seq4repair_space>adding" , index , indexMetaDataCount , requiredAllocation ) ; } metaDataBuilder . put ( electedIndexMetaData , false ) ; } } } ClusterState . Builder builder = ClusterState . builder ( ) ; builder . metaData ( metaDataBuilder ) ; listener . onSuccess ( builder . build ( ) ) ; } @ Override public Class < ? extends Module > suggestIndexGateway ( ) { } @ Override public void reset ( ) throws Exception { } @ Override public void clusterChanged ( final ClusterChangedEvent event ) { } }<BUG2FIX>ObjectFloatOpenHashMap < String > indices = new ObjectFloatOpenHashMap ( ) ;
if ( node == null ) { logger . debug ( "delaying<seq2seq4repair_space>recovery<seq2seq4repair_space>of<seq2seq4repair_space>{}<seq2seq4repair_space>as<seq2seq4repair_space>source<seq2seq4repair_space>node<seq2seq4repair_space>{}<seq2seq4repair_space>is<seq2seq4repair_space>unknown" , request . shardId ( ) , request . targetNode ( ) ) ; throw new DelayRecoveryException ( ( ( "source<seq2seq4repair_space>node<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>have<seq2seq4repair_space>the<seq2seq4repair_space>node<seq2seq4repair_space>[" + ( request . targetNode ( ) ) ) + "]<seq2seq4repair_space>in<seq2seq4repair_space>its<seq2seq4repair_space>state<seq2seq4repair_space>yet.." ) ) ; } ShardRouting targetShardRouting = null ; for ( ShardRouting shardRouting : node ) { if ( shardRouting . shardId ( ) . equals ( request . shardId ( ) ) ) { targetShardRouting = shardRouting ; break ; } } if ( targetShardRouting == null ) { logger . debug ( "delaying<seq2seq4repair_space>recovery<seq2seq4repair_space>of<seq2seq4repair_space>{}<seq2seq4repair_space>as<seq2seq4repair_space>it<seq2seq4repair_space>is<seq2seq4repair_space>not<seq2seq4repair_space>listed<seq2seq4repair_space>as<seq2seq4repair_space>assigned<seq2seq4repair_space>to<seq2seq4repair_space>target<seq2seq4repair_space>node<seq2seq4repair_space>{}" , request . shardId ( ) , request . targetNode ( ) ) ; throw new DelayRecoveryException ( "source<seq2seq4repair_space>node<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>have<seq2seq4repair_space>the<seq2seq4repair_space>shard<seq2seq4repair_space>listed<seq2seq4repair_space>in<seq2seq4repair_space>its<seq2seq4repair_space>state<seq2seq4repair_space>as<seq2seq4repair_space>allocated<seq2seq4repair_space>on<seq2seq4repair_space>the<seq2seq4repair_space>node" ) ; } if ( ! ( targetShardRouting . initializing ( ) ) ) { logger . debug ( "delaying<seq2seq4repair_space>recovery<seq2seq4repair_space>of<seq2seq4repair_space>{}<seq2seq4repair_space>as<seq2seq4repair_space>it<seq2seq4repair_space>is<seq2seq4repair_space>not<seq2seq4repair_space>listed<seq2seq4repair_space>as<seq2seq4repair_space>initializing<seq2seq4repair_space>on<seq2seq4repair_space>the<seq2seq4repair_space>target<seq2seq4repair_space>node<seq2seq4repair_space>{}.<seq2seq4repair_space>known<seq2seq4repair_space>shards<seq2seq4repair_space>state<seq2seq4repair_space>is<seq2seq4repair_space>[{}]" , request . shardId ( ) , request . targetNode ( ) , targetShardRouting . state ( ) ) ; throw new DelayRecoveryException ( ( ( "source<seq2seq4repair_space>node<seq2seq4repair_space>has<seq2seq4repair_space>the<seq2seq4repair_space>state<seq2seq4repair_space>of<seq2seq4repair_space>the<seq2seq4repair_space>target<seq2seq4repair_space>shard<seq2seq4repair_space>to<seq2seq4repair_space>be<seq2seq4repair_space>[" + ( targetShardRouting . state ( ) ) ) + "],<seq2seq4repair_space>expecting<seq2seq4repair_space>to<seq2seq4repair_space>be<seq2seq4repair_space>[initializing]" ) ) ; } logger . trace ( "[{}][{}]<seq2seq4repair_space>starting<seq2seq4repair_space>recovery<seq2seq4repair_space>to<seq2seq4repair_space>{},<seq2seq4repair_space>mark_as_relocated<seq2seq4repair_space>{}" , request . shardId ( ) . index ( ) . name ( ) , request . shardId ( ) . id ( ) , request . targetNode ( ) , request . markAsRelocated ( ) ) ; final RecoveryResponse response = new RecoveryResponse ( ) ; shard . recover ( new Engine . RecoveryHandler ( ) { @ Override public void phase1 ( final SnapshotIndexCommit snapshot ) throws ElasticsearchException { long totalSize = 0 ; long existingTotalSize = 0 ; final Store store = shard . store ( ) ; store . incRef ( ) ; try { StopWatch stopWatch = new StopWatch ( ) . start ( ) ; final Store . MetadataSnapshot metadata ; <START_BUG> metadata = store . getMetadata ( ) ; <END_BUG><BUG2FIX>metadata = store . getMetadata ( snapshot ) ;
public class TemplateQueryParser implements QueryParser { public static final String NAME = "template" ; public static final String QUERY = "query" ; public static final String PARAMS = "params" ; private final ScriptService scriptService ; private static final Map < String , ScriptService . ScriptType > parametersToTypes = new HashMap < > ( ) ; @ Inject public TemplateQueryParser ( ScriptService scriptService ) { } @ Override public String [ ] names ( ) { } @ Override @ Nullable public Query parse ( QueryParseContext parseContext ) throws IOException { } public static TemplateQueryParser . TemplateContext parse ( XContentParser parser , String paramsFieldname , String ... parameters ) throws IOException { } public static TemplateQueryParser . TemplateContext parse ( XContentParser parser , String paramsFieldname ) throws IOException { } public static TemplateQueryParser . TemplateContext parse ( XContentParser parser , String paramsFieldname , Map < String , ScriptService . ScriptType > parameterMap ) throws IOException { Map < String , Object > params = null ; String templateNameOrTemplateContent = null ; String currentFieldName = null ; XContentParser . Token token ; ScriptService . ScriptType type = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( parameterMap . containsKey ( currentFieldName ) ) { type = parameterMap . get ( currentFieldName ) ; <START_BUG> if ( ( token == ( Token . START_OBJECT ) ) && ( ! ( parser . hasTextCharacters ( ) ) ) ) { <END_BUG> XContentBuilder builder = XContentBuilder . builder ( parser . contentType ( ) . xContent ( ) ) ; builder . copyCurrentStructure ( parser ) ; templateNameOrTemplateContent = builder . string ( ) ; } else { templateNameOrTemplateContent = parser . text ( ) ; } } else if ( paramsFieldname . equals ( currentFieldName ) ) { params = parser . map ( ) ; } } return new TemplateQueryParser . TemplateContext ( type , templateNameOrTemplateContent , params ) ; } public static class TemplateContext { private Map < String , Object > params ; private String template ; private ScriptType type ; public TemplateContext ( ScriptService . ScriptType type , String template , Map < String , Object > params ) { } public Map < String , Object > params ( ) { } public String template ( ) { } public ScriptType scriptType ( ) { } @ Override public String toString ( ) { } } }<BUG2FIX>if ( token == ( Token . START_OBJECT ) ) {
public class BufferUtils { static Array < ByteBuffer > unsafeBuffers = new Array < ByteBuffer > ( ) ; static int allocatedUnsafe = 0 ; public static void copy ( float [ ] src , Buffer dst , int numFloats , int offset ) { } public static void copy ( byte [ ] src , int srcOffset , Buffer dst , int numElements ) { } public static void copy ( short [ ] src , int srcOffset , Buffer dst , int numElements ) { } public static void copy ( char [ ] src , int srcOffset , Buffer dst , int numElements ) { } public static void copy ( int [ ] src , int srcOffset , Buffer dst , int numElements ) { } public static void copy ( long [ ] src , int srcOffset , Buffer dst , int numElements ) { } public static void copy ( float [ ] src , int srcOffset , Buffer dst , int numElements ) { } public static void copy ( double [ ] src , int srcOffset , Buffer dst , int numElements ) { } public static void copy ( Buffer src , Buffer dst , int numElements ) { } private static int positionInBytes ( Buffer dst ) { } private static int bytesToElements ( Buffer dst , int bytes ) { } private static int elementsToBytes ( Buffer dst , int elements ) { } public static FloatBuffer newFloatBuffer ( int numFloats ) { } public static DoubleBuffer newDoubleBuffer ( int numDoubles ) { } public static ByteBuffer newByteBuffer ( int numBytes ) { } public static ShortBuffer newShortBuffer ( int numShorts ) { } public static CharBuffer newCharBuffer ( int numChars ) { } public static IntBuffer newIntBuffer ( int numInts ) { } public static LongBuffer newLongBuffer ( int numLongs ) { } public static void disposeUnsafeByteBuffer ( ByteBuffer buffer ) { } public static ByteBuffer newUnsafeByteBuffer ( int numBytes ) { } public static long getUnsafeByteBufferAddress ( ByteBuffer buffer ) { synchronized ( BufferUtils . unsafeBuffers ) { <START_BUG> if ( BufferUtils . unsafeBuffers . contains ( buffer , true ) ) <END_BUG> return 0 ; } return BufferUtils . getByteBufferAddress ( buffer ) ; } public static ByteBuffer newUnsafeByteBuffer ( ByteBuffer buffer ) { } public static int getAllocatedBytesUnsafe ( ) { } private static native void freeMemory ( ByteBuffer buffer ) { } private static native ByteBuffer newDisposableByteBuffer ( int numBytes ) { } private static native long getByteBufferAddress ( ByteBuffer buffer ) { } public static native void clear ( ByteBuffer buffer , int numBytes ) { } private static native void copyJni ( float [ ] src , Buffer dst , int numFloats , int offset ) { } private static native void copyJni ( byte [ ] src , int srcOffset , Buffer dst , int dstOffset , int numBytes ) { } private static native void copyJni ( char [ ] src , int srcOffset , Buffer dst , int dstOffset , int numBytes ) { } private static native void copyJni ( short [ ] src , int srcOffset , Buffer dst , int dstOffset , int numBytes ) { } private static native void copyJni ( int [ ] src , int srcOffset , Buffer dst , int dstOffset , int numBytes ) { } private static native void copyJni ( long [ ] src , int srcOffset , Buffer dst , int dstOffset , int numBytes ) { } private static native void copyJni ( float [ ] src , int srcOffset , Buffer dst , int dstOffset , int numBytes ) { } private static native void copyJni ( double [ ] src , int srcOffset , Buffer dst , int dstOffset , int numBytes ) { } private static native void copyJni ( Buffer src , int srcOffset , Buffer dst , int dstOffset , int numBytes ) { } }<BUG2FIX>if ( ! ( BufferUtils . unsafeBuffers . contains ( buffer , true ) ) )
public class RestSpec { Map < String , RestApi > restApiMap = Maps . newHashMap ( ) ; private RestSpec ( ) { } void addApi ( RestApi restApi ) { } public RestApi getApi ( String api ) { } public static RestSpec parseFrom ( String optionalPathPrefix , String ... paths ) throws IOException { RestSpec restSpec = new RestSpec ( ) ; for ( String path : paths ) { for ( File jsonFile : FileUtils . findJsonSpec ( optionalPathPrefix , path ) ) { try { XContentParser parser = jsonXContent . createParser ( new FileInputStream ( jsonFile ) ) ; RestApi restApi = new RestApiParser ( ) . parse ( parser ) ; restSpec . addApi ( restApi ) ; <START_BUG> } catch ( IOException ex ) { <END_BUG> throw new IOException ( ( ( "Can't<seq2seq4repair_space>parse<seq2seq4repair_space>rest<seq2seq4repair_space>spec<seq2seq4repair_space>file:<seq2seq4repair_space>[" + jsonFile ) + "]" ) , ex ) ; } } } return restSpec ; } }<BUG2FIX>} catch ( Throwable ex ) {
public class Polygon { private final float [ ] localVertices ; private float [ ] worldVertices ; private float x ; private float y ; private float originX ; private float originY ; private float rotation ; private float scaleX = 1 ; private float scaleY = 1 ; private boolean dirty = true ; private Rectangle bounds ; public Polygon ( float [ ] vertices ) { } public float [ ] getLocalVertices ( ) { } public float [ ] getWorldVertices ( ) { if ( ! ( dirty ) ) <START_BUG> return localVertices ; <END_BUG> dirty = false ; final float [ ] localVertices = this . localVertices ; if ( ( ( worldVertices ) == null ) || ( ( worldVertices . length ) < ( localVertices . length ) ) ) worldVertices = new float [ localVertices . length ] ; final float [ ] worldVertices = this . worldVertices ; final float positionX = x ; final float positionY = y ; final float originX = this . originX ; final float originY = this . originY ; final float scaleX = this . scaleX ; final float scaleY = this . scaleY ; final boolean scale = ( scaleX != 1 ) || ( scaleY != 1 ) ; final float rotation = this . rotation ; final float cos = MathUtils . cosDeg ( rotation ) ; final float sin = MathUtils . sinDeg ( rotation ) ; for ( int i = 0 , n = localVertices . length ; i < n ; i += 2 ) { float x = ( localVertices [ i ] ) - originX ; float y = ( localVertices [ ( i + 1 ) ] ) - originY ; if ( scale ) { x *= scaleX ; y *= scaleY ; } if ( rotation != 0 ) { float oldX = x ; x = ( cos * x ) - ( sin * y ) ; y = ( sin * oldX ) + ( cos * y ) ; } worldVertices [ i ] = ( positionX + x ) + originX ; worldVertices [ ( i + 1 ) ] = ( positionY + y ) + originY ; } return worldVertices ; } public void setOrigin ( float originX , float originY ) { } public void setPosition ( float x , float y ) { } public void translate ( float x , float y ) { } public void setRotation ( float degrees ) { } public void rotate ( float degrees ) { } public void setScale ( float scaleX , float scaleY ) { } public void scale ( float amount ) { } public float area ( ) { } public Rectangle getBoundingRectangle ( ) { } public boolean contains ( float x , float y ) { } public float getX ( ) { } public float getY ( ) { } public float getOriginX ( ) { } public float getOriginY ( ) { } public float getRotation ( ) { } public float getScaleX ( ) { } public float getScaleY ( ) { } }<BUG2FIX>return worldVertices ;
public class MissingParser implements Aggregator . Parser { @ Override public String type ( ) { } @ Override public AggregatorFactory parse ( String aggregationName , XContentParser parser , SearchContext context ) throws IOException { <START_BUG> ValuesSourceConfig < ValuesSource > config = new ValuesSourceConfig < ValuesSource > ( ValuesSource . class ) ; <END_BUG> String field = null ; XContentParser . Token token ; String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . VALUE_STRING ) ) { if ( "field" . equals ( currentFieldName ) ) { field = parser . text ( ) ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( ( ( "Unknown<seq2seq4repair_space>key<seq2seq4repair_space>for<seq2seq4repair_space>a<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>[" ) + aggregationName ) + "]:<seq2seq4repair_space>[" ) + currentFieldName ) + "]." ) ) ; } } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( "Unexpected<seq2seq4repair_space>token<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>[" ) + aggregationName ) + "]." ) ) ; } } if ( field == null ) { return new MissingAggregator . Factory ( aggregationName , config ) ; } FieldMapper < ? > mapper = context . smartNameFieldMapper ( field ) ; if ( mapper == null ) { config . unmapped ( true ) ; return new MissingAggregator . Factory ( aggregationName , config ) ; } config . fieldContext ( new org . elasticsearch . search . aggregations . support . FieldContext ( field , context . fieldData ( ) . getForField ( mapper ) ) ) ; return new MissingAggregator . Factory ( aggregationName , config ) ; } }<BUG2FIX>ValuesSourceConfig < ValuesSource > config = new ValuesSourceConfig ( ValuesSource . class ) ;
public class TransportUpdateAction extends TransportInstanceSingleOperationAction < UpdateRequest , UpdateResponse > { private final IndicesService indicesService ; private final TransportDeleteAction deleteAction ; private final TransportIndexAction indexAction ; private final ScriptService scriptService ; private final AutoCreateIndex autoCreateIndex ; private final TransportCreateIndexAction createIndexAction ; @ Inject public TransportUpdateAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportService transportService , IndicesService indicesService , TransportIndexAction indexAction , TransportDeleteAction deleteAction , ScriptService scriptService , TransportCreateIndexAction createIndexAction ) { } @ Override protected String transportAction ( ) { } @ Override protected String executor ( ) { } @ Override protected UpdateRequest newRequest ( ) { } @ Override protected UpdateResponse newResponse ( ) { } @ Override protected ClusterBlockException checkGlobalBlock ( ClusterState state , UpdateRequest request ) { } @ Override protected ClusterBlockException checkRequestBlock ( ClusterState state , UpdateRequest request ) { } @ Override protected boolean retryOnFailure ( Throwable e ) { } @ Override protected boolean resolveRequest ( ClusterState state , UpdateRequest request , ActionListener < UpdateResponse > listener ) { } @ Override protected void doExecute ( final UpdateRequest request , final ActionListener < UpdateResponse > listener ) { if ( autoCreateIndex . shouldAutoCreate ( request . index ( ) , clusterService . state ( ) ) ) { request . beforeLocalFork ( ) ; createIndexAction . execute ( new org . elasticsearch . action . admin . indices . create . CreateIndexRequest ( request . index ( ) ) . cause ( "auto(update<seq2seq4repair_space>api)" ) . masterNodeTimeout ( request . timeout ( ) ) , new ActionListener < CreateIndexResponse > ( ) { @ Override public void onResponse ( CreateIndexResponse result ) { innerExecute ( request , listener ) ; } @ Override public void onFailure ( Throwable e ) { if ( ( ExceptionsHelper . unwrapCause ( e ) ) instanceof IndexAlreadyExistsException ) { try { innerExecute ( request , listener ) ; <START_BUG> } catch ( Exception e1 ) { <END_BUG> listener . onFailure ( e1 ) ; } } else { listener . onFailure ( e ) ; } } } ) ; } else { innerExecute ( request , listener ) ; } } private void innerExecute ( final UpdateRequest request , final ActionListener < UpdateResponse > listener ) { } @ Override protected ShardIterator shards ( ClusterState clusterState , UpdateRequest request ) throws ElasticSearchException { } @ Override protected void shardOperation ( final UpdateRequest request , final ActionListener < UpdateResponse > listener ) throws ElasticSearchException { } protected void shardOperation ( final UpdateRequest request , final ActionListener < UpdateResponse > listener , final int retryCount ) throws ElasticSearchException { } @ Nullable protected GetResult extractGetResult ( final UpdateRequest request , long version , final Map < String , Object > source , XContentType sourceContentType , @ Nullable final BytesReference sourceAsBytes ) { } }<BUG2FIX>} catch ( Throwable e1 ) {
@ LuceneTestCase . Slow @ ClusterScope ( scope = Scope . TEST , numNodes = 0 ) public class ZenUnicastDiscoveryTests extends ElasticsearchIntegrationTest { @ Test @ TestLogging ( "discovery.zen:TRACE" ) public void testMasterElectionNotMissed ( ) throws Exception { final Settings settings = settingsBuilder ( ) . put ( "discovery.zen.ping.multicast.ping.enabled" , false ) . put ( "discovery.zen.minimum_master_nodes" , 2 ) . put ( "discovery.zen.ping.unicast.hosts" , "localhost:15300,localhost:15301,localhost:15302" ) . put ( "transport.tcp.port" , "15300-15400" ) . build ( ) ; final CountDownLatch latch = new CountDownLatch ( 3 ) ; <START_BUG> final AtomicArray < String > nodes = new AtomicArray < String > ( 3 ) ; <END_BUG> Runnable r1 = new Runnable ( ) { @ Override public void run ( ) { logger . info ( "--><seq2seq4repair_space>start<seq2seq4repair_space>first<seq2seq4repair_space>node" ) ; nodes . set ( 0 , cluster ( ) . startNode ( settings ) ) ; latch . countDown ( ) ; } } ; new Thread ( r1 ) . start ( ) ; sleep ( between ( 500 , 3000 ) ) ; Runnable r2 = new Runnable ( ) { @ Override public void run ( ) { logger . info ( "--><seq2seq4repair_space>start<seq2seq4repair_space>second<seq2seq4repair_space>node" ) ; nodes . set ( 1 , cluster ( ) . startNode ( settings ) ) ; latch . countDown ( ) ; } } ; new Thread ( r2 ) . start ( ) ; sleep ( between ( 500 , 3000 ) ) ; Runnable r3 = new Runnable ( ) { @ Override public void run ( ) { logger . info ( "--><seq2seq4repair_space>start<seq2seq4repair_space>third<seq2seq4repair_space>node" ) ; nodes . set ( 2 , cluster ( ) . startNode ( settings ) ) ; latch . countDown ( ) ; } } ; new Thread ( r3 ) . start ( ) ; latch . await ( ) ; ClusterHealthResponse clusterHealthResponse = client ( ) . admin ( ) . cluster ( ) . prepareHealth ( ) . setWaitForEvents ( LANGUID ) . setWaitForNodes ( "3" ) . execute ( ) . actionGet ( ) ; assertThat ( clusterHealthResponse . isTimedOut ( ) , equalTo ( false ) ) ; DiscoveryNode masterDiscoNode = null ; for ( String node : nodes . toArray ( new String [ 3 ] ) ) { ClusterState state = cluster ( ) . client ( node ) . admin ( ) . cluster ( ) . prepareState ( ) . setLocal ( true ) . execute ( ) . actionGet ( ) . getState ( ) ; assertThat ( state . nodes ( ) . size ( ) , equalTo ( 3 ) ) ; if ( masterDiscoNode == null ) { masterDiscoNode = state . nodes ( ) . masterNode ( ) ; } else { assertThat ( masterDiscoNode . equals ( state . nodes ( ) . masterNode ( ) ) , equalTo ( true ) ) ; } } } }<BUG2FIX>final AtomicArray < String > nodes = new AtomicArray ( 3 ) ;
public class Cube { static final int FOLLOW = 0 ; static final int FIXED = 1 ; static final int CONTROLLED = 2 ; static final int DEAD = 3 ; static final float ACCELERATION = 20 ; static final float MAX_VELOCITY = 4 ; static final float DAMP = 0.8F ; Map map ; Vector2 pos = new Vector2 ( ) ; Vector2 accel = new Vector2 ( ) ; Vector2 vel = new Vector2 ( ) ; Rectangle bounds = new Rectangle ( ) ; int state = Cube . FOLLOW ; float stateTime = 0 ; Rectangle controllButtonRect = new Rectangle ( ( 480 - 64 ) , ( 320 - 64 ) , 64 , 64 ) ; Rectangle followButtonRect = new Rectangle ( ( 480 - 64 ) , ( 320 - 138 ) , 64 , 64 ) ; Rectangle dpadRect = new Rectangle ( 0 , 0 , 128 , 128 ) ; public Cube ( Map map , float x , float y ) { } Vector2 target = new Vector2 ( ) ; public void update ( float deltaTime ) { } private void processKeys ( ) { float x0 = ( ( input . getX ( 0 ) ) / ( ( float ) ( graphics . getWidth ( ) ) ) ) * 480 ; float x1 = ( ( input . getX ( 1 ) ) / ( ( float ) ( graphics . getWidth ( ) ) ) ) * 480 ; float y0 = 320 - ( ( ( input . getY ( 0 ) ) / ( ( float ) ( graphics . getHeight ( ) ) ) ) * 320 ) ; float y1 = 320 - ( ( ( input . getY ( 1 ) ) / ( ( float ) ( graphics . getHeight ( ) ) ) ) * 320 ) ; boolean controlButton = ( ( input . isTouched ( 0 ) ) && ( controllButtonRect . contains ( x0 , y0 ) ) ) || ( ( input . isTouched ( 1 ) ) && ( controllButtonRect . contains ( x1 , y1 ) ) ) ; boolean followButton = ( ( input . isTouched ( 0 ) ) && ( followButtonRect . contains ( x0 , y0 ) ) ) || ( ( input . isTouched ( 1 ) ) && ( followButtonRect . contains ( x1 , y1 ) ) ) ; if ( ( ( ( input . isKeyPressed ( SPACE ) ) || controlButton ) && ( ( state ) == ( Cube . FOLLOW ) ) ) && ( ( stateTime ) > 0.5F ) ) { stateTime = 0 ; state = Cube . CONTROLLED ; return ; } if ( ( ( ( input . isKeyPressed ( SPACE ) ) || controlButton ) && ( ( state ) == ( Cube . CONTROLLED ) ) ) && ( ( stateTime ) > 0.5F ) ) { stateTime = 0 ; state = Cube . FIXED ; return ; } if ( ( ( ( input . isKeyPressed ( SPACE ) ) || controlButton ) && ( ( state ) == ( Cube . FIXED ) ) ) && ( ( stateTime ) > 0.5F ) ) { stateTime = 0 ; state = Cube . CONTROLLED ; return ; } <START_BUG> if ( ( ( ( input . isKeyPressed ( SPACE ) ) || followButton ) && ( ( state ) == ( Cube . FIXED ) ) ) && ( ( stateTime ) > 0.5F ) ) { <END_BUG> stateTime = 0 ; state = Cube . FOLLOW ; return ; } boolean touch0 = input . isTouched ( 0 ) ; boolean touch1 = input . isTouched ( 1 ) ; boolean left = ( touch0 && ( x0 < 60 ) ) || ( touch1 && ( x1 < 60 ) ) ; boolean right = ( touch0 && ( ( x0 > 80 ) && ( x0 < 128 ) ) ) || ( touch1 && ( ( x1 > 80 ) && ( x1 < 128 ) ) ) ; boolean down = ( touch0 && ( y0 < 60 ) ) || ( touch1 && ( y1 < 60 ) ) ; boolean up = ( touch0 && ( ( y0 > 80 ) && ( x0 < 128 ) ) ) || ( touch1 && ( ( y1 > 80 ) && ( y1 < 128 ) ) ) ; if ( ( state ) == ( Cube . CONTROLLED ) ) { if ( input . isKeyPressed ( A ) ) { accel . x = - ( Cube . ACCELERATION ) ; } else if ( ( input . isKeyPressed ( D ) ) || right ) { accel . x = Cube . ACCELERATION ; } else { accel . x = 0 ; } if ( ( input . isKeyPressed ( W ) ) || up ) { accel . y = Cube . ACCELERATION ; } else if ( ( input . isKeyPressed ( S ) ) || down ) { accel . y = - ( Cube . ACCELERATION ) ; } else { accel . y = 0 ; } if ( touch0 ) { if ( dpadRect . contains ( x0 , y0 ) ) { float x = ( x0 - 64 ) / 64 ; float y = ( y0 - 64 ) / 64 ; float len = ( ( float ) ( Math . sqrt ( ( ( x * x ) + ( y * y ) ) ) ) ) ; if ( len != 0 ) { x /= len ; y /= len ; } else { x = 0 ; y = 0 ; } vel . x = x * ( Cube . MAX_VELOCITY ) ;<BUG2FIX>if ( ( ( input . isKeyPressed ( SPACE ) ) || followButton ) && ( ( stateTime ) > 0.5F ) ) {
builder . field ( RestClusterHealthAction . Fields . STATUS , response . getStatus ( ) . name ( ) . toLowerCase ( ) ) ; builder . field ( RestClusterHealthAction . Fields . TIMED_OUT , response . isTimedOut ( ) ) ; builder . field ( RestClusterHealthAction . Fields . NUMBER_OF_NODES , response . getNumberOfNodes ( ) ) ; builder . field ( RestClusterHealthAction . Fields . NUMBER_OF_DATA_NODES , response . getNumberOfDataNodes ( ) ) ; builder . field ( RestClusterHealthAction . Fields . ACTIVE_PRIMARY_SHARDS , response . getActivePrimaryShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . ACTIVE_SHARDS , response . getActiveShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . RELOCATING_SHARDS , response . getRelocatingShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . INITIALIZING_SHARDS , response . getInitializingShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . UNASSIGNED_SHARDS , response . getUnassignedShards ( ) ) ; if ( ! ( response . getValidationFailures ( ) . isEmpty ( ) ) ) { builder . startArray ( RestClusterHealthAction . Fields . VALIDATION_FAILURES ) ; for ( String validationFailure : response . getValidationFailures ( ) ) { builder . value ( validationFailure ) ; } if ( fLevel == 0 ) { for ( ClusterIndexHealth indexHealth : response ) { builder . startObject ( indexHealth . getIndex ( ) ) ; if ( ! ( indexHealth . getValidationFailures ( ) . isEmpty ( ) ) ) { builder . startArray ( RestClusterHealthAction . Fields . VALIDATION_FAILURES ) ; for ( String validationFailure : indexHealth . getValidationFailures ( ) ) { builder . value ( validationFailure ) ; } builder . endArray ( ) ; } builder . endObject ( ) ; } } builder . endArray ( ) ; } if ( fLevel > 0 ) { builder . startObject ( RestClusterHealthAction . Fields . INDICES ) ; for ( ClusterIndexHealth indexHealth : response ) { builder . startObject ( indexHealth . getIndex ( ) , NONE ) ; builder . field ( RestClusterHealthAction . Fields . STATUS , indexHealth . getStatus ( ) . name ( ) . toLowerCase ( ) ) ; builder . field ( RestClusterHealthAction . Fields . NUMBER_OF_SHARDS , indexHealth . getNumberOfShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . NUMBER_OF_REPLICAS , indexHealth . getNumberOfReplicas ( ) ) ; builder . field ( RestClusterHealthAction . Fields . ACTIVE_PRIMARY_SHARDS , indexHealth . getActivePrimaryShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . ACTIVE_SHARDS , indexHealth . getActiveShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . RELOCATING_SHARDS , indexHealth . getRelocatingShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . INITIALIZING_SHARDS , indexHealth . getInitializingShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . UNASSIGNED_SHARDS , indexHealth . getUnassignedShards ( ) ) ; if ( ! ( indexHealth . getValidationFailures ( ) . isEmpty ( ) ) ) { builder . startArray ( RestClusterHealthAction . Fields . VALIDATION_FAILURES ) ; for ( String validationFailure : indexHealth . getValidationFailures ( ) ) { builder . value ( validationFailure ) ; } builder . endArray ( ) ; } if ( fLevel > 1 ) { builder . startObject ( RestClusterHealthAction . Fields . SHARDS ) ; for ( ClusterShardHealth shardHealth : indexHealth ) { builder . startObject ( Integer . toString ( shardHealth . getId ( ) ) ) ; builder . field ( RestClusterHealthAction . Fields . STATUS , shardHealth . getStatus ( ) . name ( ) . toLowerCase ( ) ) ; builder . field ( RestClusterHealthAction . Fields . PRIMARY_ACTIVE , shardHealth . isPrimaryActive ( ) ) ; builder . field ( RestClusterHealthAction . Fields . ACTIVE_SHARDS , shardHealth . getActiveShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . RELOCATING_SHARDS , shardHealth . getRelocatingShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . INITIALIZING_SHARDS , shardHealth . getInitializingShards ( ) ) ; builder . field ( RestClusterHealthAction . Fields . UNASSIGNED_SHARDS , shardHealth . getUnassignedShards ( ) ) ; builder . endObject ( ) ; } builder . endObject ( ) ; } builder . endObject ( ) ; } builder . endObject ( ) ; } builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , status , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } static final class Fields { static final XContentBuilderString CLUSTER_NAME = new XContentBuilderString ( "cluster_name" ) ; static final XContentBuilderString STATUS = new XContentBuilderString ( "status" ) ; static final XContentBuilderString TIMED_OUT = new XContentBuilderString ( "timed_out" ) ; static final XContentBuilderString NUMBER_OF_SHARDS = new XContentBuilderString ( "number_of_shards" ) ; static final XContentBuilderString NUMBER_OF_REPLICAS = new XContentBuilderString ( "number_of_replicas" ) ; static final XContentBuilderString NUMBER_OF_NODES = new XContentBuilderString ( "number_of_nodes" ) ; static final XContentBuilderString NUMBER_OF_DATA_NODES = new XContentBuilderString ( "number_of_data_nodes" ) ; static final XContentBuilderString ACTIVE_PRIMARY_SHARDS = new XContentBuilderString ( "active_primary_shards" ) ; static final XContentBuilderString ACTIVE_SHARDS = new XContentBuilderString ( "active_shards" ) ; static final XContentBuilderString RELOCATING_SHARDS = new XContentBuilderString ( "relocating_shards" ) ; static final XContentBuilderString INITIALIZING_SHARDS = new XContentBuilderString ( "initializing_shards" ) ; static final XContentBuilderString UNASSIGNED_SHARDS = new XContentBuilderString ( "unassigned_shards" ) ; static final XContentBuilderString VALIDATION_FAILURES = new XContentBuilderString ( "validation_failures" ) ; static final XContentBuilderString INDICES = new XContentBuilderString ( "indices" ) ; static final XContentBuilderString SHARDS = new XContentBuilderString ( "shards" ) ; static final XContentBuilderString PRIMARY_ACTIVE = new XContentBuilderString ( "primary_active" ) ; }<BUG2FIX>} catch ( Throwable e ) {
public class TransportGatewaySnapshotAction extends TransportBroadcastOperationAction < GatewaySnapshotRequest , GatewaySnapshotResponse , ShardGatewaySnapshotRequest , ShardGatewaySnapshotResponse > { private final IndicesService indicesService ; @ Inject public TransportGatewaySnapshotAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportService transportService , IndicesService indicesService ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected GatewaySnapshotRequest newRequest ( ) { } @ Override protected boolean ignoreNonActiveExceptions ( ) { } @ Override protected GatewaySnapshotResponse newResponse ( GatewaySnapshotRequest request , AtomicReferenceArray shardsResponses , ClusterState clusterState ) { } @ Override protected ShardGatewaySnapshotRequest newShardRequest ( ) { } @ Override protected ShardGatewaySnapshotRequest newShardRequest ( ShardRouting shard , GatewaySnapshotRequest request ) { <START_BUG> return new ShardGatewaySnapshotRequest ( shard . index ( ) , shard . id ( ) ) ; <END_BUG> } @ Override protected ShardGatewaySnapshotResponse newShardResponse ( ) { } @ Override protected ShardGatewaySnapshotResponse shardOperation ( ShardGatewaySnapshotRequest request ) throws ElasticSearchException { } @ Override protected GroupShardsIterator shards ( ClusterState clusterState , GatewaySnapshotRequest request , String [ ] concreteIndices ) { } @ Override protected ClusterBlockException checkGlobalBlock ( ClusterState state , GatewaySnapshotRequest request ) { } @ Override protected ClusterBlockException checkRequestBlock ( ClusterState state , GatewaySnapshotRequest request , String [ ] concreteIndices ) { } }<BUG2FIX>return new ShardGatewaySnapshotRequest ( shard . index ( ) , shard . id ( ) , request ) ;
public abstract class TransportShardReplicationOperationAction < Request extends ShardReplicationOperationRequest , Response extends ActionResponse > extends BaseAction < Request , Response > { protected final TransportService transportService ; protected final ClusterService clusterService ; protected final IndicesService indicesService ; protected final ThreadPool threadPool ; protected final ShardStateAction shardStateAction ; protected TransportShardReplicationOperationAction ( Settings settings , TransportService transportService , ClusterService clusterService , IndicesService indicesService , ThreadPool threadPool , ShardStateAction shardStateAction ) { } @ Override protected void doExecute ( Request request , ActionListener < Response > listener ) { } protected abstract Request newRequestInstance ( ) { } protected abstract Response newResponseInstance ( ) { } protected abstract String transportAction ( ) { } protected abstract Response shardOperationOnPrimary ( TransportShardReplicationOperationAction < Request , Response > . ShardOperationRequest shardRequest ) { } protected abstract void shardOperationOnBackup ( TransportShardReplicationOperationAction < Request , Response > . ShardOperationRequest shardRequest ) { } protected abstract ShardsIterator shards ( Request request ) throws ElasticSearchException { } protected boolean ignoreBackups ( ) { } private String transportBackupAction ( ) { } protected IndexShard indexShard ( TransportShardReplicationOperationAction < Request , Response > . ShardOperationRequest shardRequest ) { } private class OperationTransportHandler extends BaseTransportRequestHandler < Request > { @ Override public Request newInstance ( ) { } @ Override public void messageReceived ( final Request request , final TransportChannel channel ) throws Exception { } @ Override public boolean spawn ( ) { } } private class BackupOperationTransportHandler extends BaseTransportRequestHandler < TransportShardReplicationOperationAction < Request , Response > . ShardOperationRequest > { @ Override public TransportShardReplicationOperationAction < Request , Response > . ShardOperationRequest newInstance ( ) { } @ Override public void messageReceived ( TransportShardReplicationOperationAction < Request , Response > . ShardOperationRequest request , TransportChannel channel ) throws Exception { } } protected class ShardOperationRequest implements Streamable { public int shardId ; public Request request ; public ShardOperationRequest ( ) { } public ShardOperationRequest ( int shardId , Request request ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } private class AsyncShardOperationAction { private final ActionListener < Response > listener ; private final Request request ; private Nodes nodes ; private ShardsIterator shards ; private final AtomicBoolean primaryOperationStarted = new AtomicBoolean ( ) ; private AsyncShardOperationAction ( Request request , ActionListener < Response > listener ) { } public void start ( ) { } public boolean start ( final boolean fromClusterEvent ) throws ElasticSearchException { ClusterState clusterState = clusterService . state ( ) ; nodes = clusterState . nodes ( ) ; try { shards = shards ( request ) ; } catch ( Exception e ) { <START_BUG> listener . onFailure ( new ReplicationShardOperationFailedException ( shards . shardId ( ) , e ) ) ; <END_BUG> return true ; } boolean foundPrimary = false ; for ( final ShardRouting shard : shards ) { if ( shard . primary ( ) ) { if ( ! ( shard . active ( ) ) ) { retryPrimary ( fromClusterEvent , shard ) ; return false ; } if ( ! ( primaryOperationStarted . compareAndSet ( false , true ) ) ) { return false ; } foundPrimary = true ; if ( shard . currentNodeId ( ) . equals ( nodes . localNodeId ( ) ) ) { if ( request . operationThreaded ( ) ) { threadPool . execute ( new Runnable ( ) { @ Override public void run ( ) { performOnPrimary ( shard . id ( ) , fromClusterEvent , true , shard ) ; } } ) ; } else { performOnPrimary ( shard . id ( ) , fromClusterEvent , false , shard ) ; } } else { Node node = nodes . get ( shard . currentNodeId ( ) ) ; transportService . sendRequest ( node , transportAction ( ) , request , new BaseTransportResponseHandler < Response > ( ) { @ Override public Response newInstance ( ) { return newResponseInstance ( ) ; } @ Override public void handleResponse ( Response response ) { listener . onResponse ( response ) ; } @ Override public void handleException ( RemoteTransportException exp ) { listener . onFailure ( exp ) ; } @ Override public boolean spawn ( ) { return request . listenerThreaded ( ) ; } } ) ; } break ; } } if ( ! foundPrimary ) { final PrimaryNotStartedActionException failure = new PrimaryNotStartedActionException ( shards . shardId ( ) , "Primary<seq2seq4repair_space>not<seq2seq4repair_space>found" ) ; if ( request . listenerThreaded ( ) ) { threadPool . execute ( new Runnable ( ) { @ Override public void run ( ) { listener . onFailure ( failure ) ; } } ) ; } else { listener . onFailure ( failure ) ; } } return true ; } private void retryPrimary ( boolean fromClusterEvent , final ShardRouting shard ) { } private void performOnPrimary ( int primaryShardId , boolean fromDiscoveryListener , boolean alreadyThreaded , final ShardRouting shard ) { } private void performBackups ( final Response response , boolean alreadyThreaded ) { } private void performOnBackup ( final Response response , final AtomicInteger counter , final ShardRouting shard , String nodeId ) { } private boolean ignoreBackupException ( Throwable e ) { } } }<BUG2FIX>listener . onFailure ( e ) ;
public class ShardTermVectorService extends AbstractIndexShardComponent { private IndexShard indexShard ; private MapperService mapperService ; @ Inject public ShardTermVectorService ( ShardId shardId , @ IndexSettings Settings indexSettings , MapperService mapperService ) { } public ShardTermVectorService setIndexShard ( IndexShard indexShard ) { } public TermVectorResponse getTermVector ( TermVectorRequest request ) { final Engine . Searcher searcher = indexShard . acquireSearcher ( "term_vector" ) ; IndexReader topLevelReader = searcher . reader ( ) ; final TermVectorResponse termVectorResponse = new TermVectorResponse ( request . index ( ) , request . type ( ) , request . id ( ) ) ; final Term uidTerm = new Term ( UidFieldMapper . NAME , Uid . createUidAsBytes ( request . type ( ) , request . id ( ) ) ) ; try { Fields topLevelFields = MultiFields . getFields ( topLevelReader ) ; Versions . DocIdAndVersion docIdAndVersion = Versions . loadDocIdAndVersion ( topLevelReader , uidTerm ) ; if ( docIdAndVersion != null ) { Fields termVectorsByField = docIdAndVersion . context . reader ( ) . getTermVectors ( docIdAndVersion . docId ) ; termVectorResponse . setFields ( termVectorsByField , request . selectedFields ( ) , request . getFlags ( ) , topLevelFields ) ; termVectorResponse . setExists ( true ) ; termVectorResponse . setDocVersion ( docIdAndVersion . version ) ; } else { termVectorResponse . setExists ( false ) ; } } catch ( Throwable ex ) { throw new ElasticsearchException ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>execute<seq2seq4repair_space>term<seq2seq4repair_space>vector<seq2seq4repair_space>request" , ex ) ; } finally { <START_BUG> searcher . release ( ) ; <END_BUG> } return termVectorResponse ; } }<BUG2FIX>searcher . close ( ) ;
public class GeoPointCompressedIndexFieldData extends AbstractGeoPointIndexFieldData { private static final String PRECISION_KEY = "precision" ; private static final Distance DEFAULT_PRECISION_VALUE = new Distance ( 1 , DistanceUnit . CENTIMETERS ) ; private final CircuitBreakerService breakerService ; public static class Builder implements IndexFieldData . Builder { @ Override public IndexFieldData < ? > build ( Index index , @ IndexSettings Settings indexSettings , FieldMapper < ? > mapper , IndexFieldDataCache cache , CircuitBreakerService breakerService ) { FieldDataType type = mapper . fieldDataType ( ) ; final String precisionAsString = type . getSettings ( ) . get ( GeoPointCompressedIndexFieldData . PRECISION_KEY ) ; final Distance precision ; if ( precisionAsString != null ) { <START_BUG> precision = Distance . parseDistance ( precisionAsString , METERS ) ; <END_BUG> } else { precision = GeoPointCompressedIndexFieldData . DEFAULT_PRECISION_VALUE ; } return new GeoPointCompressedIndexFieldData ( index , indexSettings , mapper . names ( ) , mapper . fieldDataType ( ) , cache , precision , breakerService ) ; } } private final Encoding encoding ; public GeoPointCompressedIndexFieldData ( Index index , @ IndexSettings Settings indexSettings , FieldMapper . Names fieldNames , FieldDataType fieldDataType , IndexFieldDataCache cache , Distance precision , CircuitBreakerService breakerService ) { } @ Override public AtomicGeoPointFieldData < ScriptDocValues > loadDirect ( AtomicReaderContext context ) throws Exception { } }<BUG2FIX>precision = Distance . parseDistance ( precisionAsString ) ;
public class ScrollPaneTest extends GdxTest { private Stage stage ; private Table container ; public void create ( ) { stage = new Stage ( 0 , 0 , false ) ; Skin skin = new Skin ( files . internal ( "data/uiskin.json" ) ) ; input . setInputProcessor ( stage ) ; container = new Table ( ) ; stage . addActor ( container ) ; container . setFillParent ( true ) ; Table table = new Table ( ) ; final ScrollPane scroll = new ScrollPane ( table , skin ) ; InputListener stopTouchDown = new InputListener ( ) { public boolean touchDown ( InputEvent event , float x , float y , int pointer , int button ) { event . stop ( ) ; return false ; } } ; table . pad ( 10 ) . defaults ( ) . expandX ( ) . space ( 4 ) ; for ( int i = 0 ; i < 100 ; i ++ ) { table . row ( ) ; table . add ( new com . badlogic . gdx . scenes . scene2d . ui . Label ( ( i + "uno" ) , skin ) ) . expandX ( ) . fillX ( ) ; TextButton button = new TextButton ( ( i + "dos" ) , skin ) ; table . add ( button ) ; button . addListener ( new ClickListener ( ) { public void clicked ( InputEvent event , float x , float y ) { System . out . println ( ( ( ( "click<seq2seq4repair_space>" + x ) + ",<seq2seq4repair_space>" ) + y ) ) ; } } ) ; <START_BUG> Slider slider = new Slider ( 0 , 100 , 1 , false , skin ) ; <END_BUG> slider . addListener ( stopTouchDown ) ; table . add ( slider ) ; table . add ( new com . badlogic . gdx . scenes . scene2d . ui . Label ( ( i + "tres<seq2seq4repair_space>long0<seq2seq4repair_space>long1<seq2seq4repair_space>long2<seq2seq4repair_space>long3<seq2seq4repair_space>long4<seq2seq4repair_space>long5<seq2seq4repair_space>long6<seq2seq4repair_space>long7<seq2seq4repair_space>long8<seq2seq4repair_space>long9<seq2seq4repair_space>long10<seq2seq4repair_space>long11<seq2seq4repair_space>long12" ) , skin ) ) ; } final TextButton flickButton = new TextButton ( "Flick<seq2seq4repair_space>Scroll" , skin . get ( "toggle" , TextButtonStyle . class ) ) ; flickButton . setChecked ( true ) ; flickButton . addListener ( new ChangeListener ( ) { public void changed ( ChangeEvent event , Actor actor ) { scroll . setFlickScroll ( flickButton . isChecked ( ) ) ; } } ) ; final TextButton fadeButton = new TextButton ( "Fade<seq2seq4repair_space>Scrollbars" , skin . get ( "toggle" , TextButtonStyle . class ) ) ; fadeButton . setChecked ( true ) ; fadeButton . addListener ( new ChangeListener ( ) { public void changed ( ChangeEvent event , Actor actor ) { scroll . setFadeScrollBars ( fadeButton . isChecked ( ) ) ; } } ) ; final TextButton smoothButton = new TextButton ( "Smooth<seq2seq4repair_space>Scrolling" , skin . get ( "toggle" , TextButtonStyle . class ) ) ; smoothButton . setChecked ( true ) ; smoothButton . addListener ( new ChangeListener ( ) { public void changed ( ChangeEvent event , Actor actor ) { scroll . setSmoothScrolling ( smoothButton . isChecked ( ) ) ; } } ) ; final TextButton onTopButton = new TextButton ( "Scrollbars<seq2seq4repair_space>On<seq2seq4repair_space>Top" , skin . get ( "toggle" , TextButtonStyle . class ) ) ; onTopButton . addListener ( new ChangeListener ( ) { public void changed ( ChangeEvent event , Actor actor ) { scroll . setScrollbarsOnTop ( onTopButton . isChecked ( ) ) ; } } ) ; container . add ( scroll ) . expand ( ) . fill ( ) . colspan ( 4 ) ; container . row ( ) . space ( 10 ) . padBottom ( 10 ) ; container . add ( flickButton ) . right ( ) . expandX ( ) ; container . add ( onTopButton ) ; container . add ( smoothButton ) ; container . add ( fadeButton ) . left ( ) . expandX ( ) ; } public void render ( ) { } public void resize ( int width , int height ) { } public void dispose ( ) { } public boolean needsGL20 ( ) { } }<BUG2FIX>Slider slider = new Slider ( 0 , 100 , 100 , false , skin ) ;
public abstract class AbstractIndexStore extends AbstractIndexComponent implements IndexStore { public static final String INDEX_STORE_THROTTLE_TYPE = "index.store.throttle.type" ; public static final String INDEX_STORE_THROTTLE_MAX_BYTES_PER_SEC = "index.store.throttle.max_bytes_per_sec" ; class ApplySettings implements IndexSettingsService . Listener { @ Override public void onRefreshSettings ( Settings settings ) { <START_BUG> String rateLimitingType = indexSettings . get ( AbstractIndexStore . INDEX_STORE_THROTTLE_TYPE , AbstractIndexStore . this . rateLimitingType ) ; <END_BUG> if ( ! ( rateLimitingType . equals ( AbstractIndexStore . this . rateLimitingType ) ) ) { logger . info ( "updating<seq2seq4repair_space>index.store.throttle.type<seq2seq4repair_space>from<seq2seq4repair_space>[{}]<seq2seq4repair_space>to<seq2seq4repair_space>[{}]" , AbstractIndexStore . this . rateLimitingType , rateLimitingType ) ; if ( rateLimitingType . equalsIgnoreCase ( "node" ) ) { AbstractIndexStore . this . rateLimitingType = rateLimitingType ; AbstractIndexStore . this . nodeRateLimiting = true ; } else { Type . fromString ( rateLimitingType ) ; AbstractIndexStore . this . rateLimitingType = rateLimitingType ; AbstractIndexStore . this . nodeRateLimiting = false ; AbstractIndexStore . this . rateLimiting . setType ( rateLimitingType ) ; } } ByteSizeValue rateLimitingThrottle = settings . getAsBytesSize ( AbstractIndexStore . INDEX_STORE_THROTTLE_MAX_BYTES_PER_SEC , AbstractIndexStore . this . rateLimitingThrottle ) ; if ( ! ( rateLimitingThrottle . equals ( AbstractIndexStore . this . rateLimitingThrottle ) ) ) { logger . info ( "updating<seq2seq4repair_space>index.store.throttle.max_bytes_per_sec<seq2seq4repair_space>from<seq2seq4repair_space>[{}]<seq2seq4repair_space>to<seq2seq4repair_space>[{}],<seq2seq4repair_space>note,<seq2seq4repair_space>type<seq2seq4repair_space>is<seq2seq4repair_space>[{}]" , AbstractIndexStore . this . rateLimitingThrottle , rateLimitingThrottle , AbstractIndexStore . this . rateLimitingType ) ; AbstractIndexStore . this . rateLimitingThrottle = rateLimitingThrottle ; AbstractIndexStore . this . rateLimiting . setMaxRate ( rateLimitingThrottle ) ; } } } protected final IndexService indexService ; protected final IndicesStore indicesStore ; private volatile String rateLimitingType ; private volatile ByteSizeValue rateLimitingThrottle ; private volatile boolean nodeRateLimiting ; private final StoreRateLimiting rateLimiting = new StoreRateLimiting ( ) ; private final AbstractIndexStore . ApplySettings applySettings = new AbstractIndexStore . ApplySettings ( ) ; protected AbstractIndexStore ( Index index , @ IndexSettings Settings indexSettings , IndexService indexService , IndicesStore indicesStore ) { } @ Override public void close ( ) throws ElasticsearchException { } @ Override public boolean canDeleteUnallocated ( ShardId shardId ) { } @ Override public void deleteUnallocated ( ShardId shardId ) throws IOException { } @ Override public IndicesStore indicesStore ( ) { } @ Override public StoreRateLimiting rateLimiting ( ) { } }<BUG2FIX>String rateLimitingType = settings . get ( AbstractIndexStore . INDEX_STORE_THROTTLE_TYPE , AbstractIndexStore . this . rateLimitingType ) ;
public class MD5Test extends GdxTest implements InputProcessor { PerspectiveCamera camera ; MD5Model model ; MD5Animation anim ; MD5AnimationInfo animInfo ; MD5Joints skeleton ; MD5Renderer renderer ; SpriteBatch batch ; BitmapFont font ; @ Override public void create ( ) { app . log ( "MD5<seq2seq4repair_space>Test" , "created" ) ; <START_BUG> model = MD5Loader . loadModel ( files . internal ( "data/zfat.md5mesh" ) . read ( ) , true ) ; <END_BUG> anim = MD5Loader . loadAnimation ( files . internal ( "data/walk1.md5anim" ) . read ( ) ) ; skeleton = new MD5Joints ( ) ; skeleton . joints = new float [ anim . frames [ 0 ] . joints . length ] ; animInfo = new MD5AnimationInfo ( anim . frames . length , anim . secondsPerFrame ) ; renderer = new MD5Renderer ( model , false , true ) ; renderer . setSkeleton ( model . baseSkeleton ) ; camera = new PerspectiveCamera ( ) ; camera . getPosition ( ) . set ( 0 , 25 , 100 ) ; camera . setFov ( 60 ) ; camera . setNear ( 1 ) ; camera . setFar ( 1000 ) ; camera . setViewport ( graphics . getWidth ( ) , graphics . getHeight ( ) ) ; batch = new SpriteBatch ( ) ; font = new BitmapFont ( ) ; graphics . getGL10 ( ) . glViewport ( 0 , 0 , graphics . getWidth ( ) , graphics . getHeight ( ) ) ; input . setInputProcessor ( this ) ; } float angle = 0 ; @ Override public void render ( ) { } @ Override public void dispose ( ) { } @ Override public boolean keyDown ( int keycode ) { } @ Override public boolean keyTyped ( char character ) { } @ Override public boolean keyUp ( int keycode ) { } @ Override public boolean touchDown ( int x , int y , int pointer ) { } @ Override public boolean touchDragged ( int x , int y , int pointer ) { } @ Override public boolean touchUp ( int x , int y , int pointer ) { } @ Override public boolean needsGL20 ( ) { } }<BUG2FIX>model = MD5Loader . loadModel ( files . internal ( "data/zfat.md5mesh" ) . read ( ) , false ) ;
public class DeleteByQueryWrappingFilter extends Filter { private final Query query ; private IndexSearcher searcher ; private Weight weight ; public DeleteByQueryWrappingFilter ( Query query ) { } public final Query getQuery ( ) { } @ Override public DocIdSet getDocIdSet ( final AtomicReaderContext context , final Bits acceptDocs ) throws IOException { SearchContext searchContext = SearchContext . current ( ) ; if ( ( weight ) == null ) { assert ( searcher ) == null ; searcher = searchContext . searcher ( ) ; IndexReader indexReader = SearchContext . current ( ) . searcher ( ) . getIndexReader ( ) ; IndexReader multiReader = null ; try { if ( ! ( DeleteByQueryWrappingFilter . contains ( indexReader , context ) ) ) { multiReader = new org . apache . lucene . index . MultiReader ( new IndexReader [ ] { indexReader , context . reader ( ) } , false ) ; Similarity similarity = searcher . getSimilarity ( ) ; searcher = new IndexSearcher ( new org . apache . lucene . index . MultiReader ( indexReader , context . reader ( ) ) ) ; searcher . setSimilarity ( similarity ) ; } weight = searcher . createNormalizedWeight ( query ) ; } finally { if ( multiReader != null ) { multiReader . close ( ) ; } } } else { IndexReader indexReader = searcher . getIndexReader ( ) ; if ( ! ( DeleteByQueryWrappingFilter . contains ( indexReader , context ) ) ) { try ( IndexReader multiReader = new org . apache . lucene . index . MultiReader ( new IndexReader [ ] { indexReader , context . reader ( ) } , false ) ) { Similarity similarity = searcher . getSimilarity ( ) ; searcher = new IndexSearcher ( multiReader ) ; searcher . setSimilarity ( similarity ) ; weight = searcher . createNormalizedWeight ( query ) ; } } } return new DocIdSet ( ) { @ Override public DocIdSetIterator iterator ( ) throws IOException { <START_BUG> return weight . scorer ( context , true , false , acceptDocs ) ; <END_BUG> } @ Override public boolean isCacheable ( ) { return false ; } } ; } @ Override public String toString ( ) { } @ Override public boolean equals ( Object o ) { } @ Override public int hashCode ( ) { } static boolean contains ( IndexReader indexReader , AtomicReaderContext context ) { } }<BUG2FIX>return weight . scorer ( context , acceptDocs ) ;
public class TermsStatsStringFacetExecutor extends FacetExecutor { private final ComparatorType comparatorType ; final IndexFieldData keyIndexFieldData ; final IndexNumericFieldData valueIndexFieldData ; final SearchScript script ; private final int size ; private final int shardSize ; final V < ObjectObjectOpenHashMap < HashedBytesRef , InternalTermsStatsStringFacet . StringEntry > > entries ; long missing ; public TermsStatsStringFacetExecutor ( IndexFieldData keyIndexFieldData , IndexNumericFieldData valueIndexFieldData , SearchScript valueScript , int size , int shardSize , TermsStatsFacet . ComparatorType comparatorType , SearchContext context ) { } @ Override public TermsStatsStringFacetExecutor . Collector collector ( ) { } @ Override public InternalFacet buildFacet ( String facetName ) { } class Collector extends FacetExecutor . Collector { private final TermsStatsStringFacetExecutor . Aggregator aggregator ; private BytesValues keyValues ; public Collector ( ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override public void setNextReader ( AtomicReaderContext context ) throws IOException { <START_BUG> keyValues = keyIndexFieldData . load ( context ) . getBytesValues ( true ) ; <END_BUG> if ( ( script ) != null ) { script . setNextReader ( context ) ; } else { aggregator . valueValues = valueIndexFieldData . load ( context ) . getDoubleValues ( ) ; } } @ Override public void collect ( int doc ) throws IOException { } @ Override public void postCollection ( ) { } } public static class Aggregator extends HashedAggregator { final ObjectObjectOpenHashMap < HashedBytesRef , InternalTermsStatsStringFacet . StringEntry > entries ; final HashedBytesRef spare = new HashedBytesRef ( ) ; int missing = 0 ; DoubleValues valueValues ; TermsStatsStringFacetExecutor . Aggregator . ValueAggregator valueAggregator = new TermsStatsStringFacetExecutor . Aggregator . ValueAggregator ( ) ; public Aggregator ( ObjectObjectOpenHashMap < HashedBytesRef , InternalTermsStatsStringFacet . StringEntry > entries ) { } @ Override public void onValue ( int docId , BytesRef value , int hashCode , BytesValues values ) { } public static class ValueAggregator extends DoubleFacetAggregatorBase { StringEntry stringEntry ; @ Override public void onValue ( int docId , double value ) { } } } public static class ScriptAggregator extends TermsStatsStringFacetExecutor . Aggregator { private final SearchScript script ; public ScriptAggregator ( ObjectObjectOpenHashMap < HashedBytesRef , InternalTermsStatsStringFacet . StringEntry > entries , SearchScript script ) { } @ Override public void onValue ( int docId , BytesRef value , int hashCode , BytesValues values ) { } } }<BUG2FIX>keyValues = keyIndexFieldData . load ( context ) . getBytesValues ( ) ;
public class TermsDoubleFacetCollector extends AbstractFacetCollector { private final FieldDataCache fieldDataCache ; private final String indexFieldName ; private final ComparatorType comparatorType ; private final int size ; private final int numberOfShards ; private final FieldDataType fieldDataType ; private DoubleFieldData fieldData ; private final TermsDoubleFacetCollector . StaticAggregatorValueProc aggregator ; private final SearchScript script ; public TermsDoubleFacetCollector ( String facetName , String fieldName , int size , TermsFacet . ComparatorType comparatorType , boolean allTerms , SearchContext context , ImmutableSet < BytesRef > excluded , String scriptLang , String script , Map < String , Object > params ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override protected void doSetNextReader ( AtomicReaderContext context ) throws IOException { fieldData = ( ( DoubleFieldData ) ( fieldDataCache . cache ( fieldDataType , context . reader ( ) , indexFieldName ) ) ) ; if ( ( script ) != null ) { <START_BUG> script . setNextReader ( context . reader ( ) ) ; <END_BUG> } } @ Override protected void doCollect ( int doc ) throws IOException { } @ Override public Facet facet ( ) { } public static class AggregatorValueProc extends TermsDoubleFacetCollector . StaticAggregatorValueProc { private final SearchScript script ; private final TDoubleHashSet excluded ; public AggregatorValueProc ( TDoubleIntHashMap facets , Set < BytesRef > excluded , SearchScript script ) { } @ Override public void onValue ( int docId , double value ) { } } public static class StaticAggregatorValueProc implements DoubleFieldData . ValueInDocProc , DoubleFieldData . ValueProc { private final TDoubleIntHashMap facets ; private int missing ; private int total ; public StaticAggregatorValueProc ( TDoubleIntHashMap facets ) { } @ Override public void onValue ( double value ) { } @ Override public void onValue ( int docId , double value ) { } @ Override public void onMissing ( int docId ) { } public final TDoubleIntHashMap facets ( ) { } public final int missing ( ) { } public int total ( ) { } } }<BUG2FIX>script . setNextReader ( context ) ;
public class RobinEngine extends AbstractIndexShardComponent implements Engine , ScheduledRefreshableEngine { private volatile ByteSizeValue indexingBufferSize ; private final boolean compoundFormat ; private final int termIndexInterval ; private final int termIndexDivisor ; private final TimeValue refreshInterval ; private final ReadWriteLock rwl = new ReentrantReadWriteLock ( ) ; private final AtomicBoolean optimizeMutex = new AtomicBoolean ( ) ; private final Store store ; private final SnapshotDeletionPolicy deletionPolicy ; private final Translog translog ; private final MergePolicyProvider mergePolicyProvider ; private final MergeSchedulerProvider mergeScheduler ; private final AnalysisService analysisService ; private final SimilarityService similarityService ; private final BloomCache bloomCache ; private final boolean asyncLoadBloomFilter ; private IndexWriter indexWriter ; private volatile AcquirableResource < ReaderSearcherHolder > nrtResource ; private volatile boolean closed = false ; private volatile boolean dirty = false ; private volatile int disableFlushCounter = 0 ; private final AtomicReference < Searcher > indexingSearcher = new AtomicReference < Searcher > ( ) ; private final AtomicBoolean flushing = new AtomicBoolean ( ) ; private final ConcurrentMap < String , RobinEngine . VersionValue > versionMap ; private final Object [ ] dirtyLocks ; @ Inject public RobinEngine ( ShardId shardId , @ IndexSettings Settings indexSettings , Store store , SnapshotDeletionPolicy deletionPolicy , Translog translog , MergePolicyProvider mergePolicyProvider , MergeSchedulerProvider mergeScheduler , AnalysisService analysisService , SimilarityService similarityService , BloomCache bloomCache ) throws EngineException { } @ Override public void updateIndexingBufferSize ( ByteSizeValue indexingBufferSize ) { } @ Override public void start ( ) throws EngineException { } @ Override public TimeValue refreshInterval ( ) { } @ Override public EngineException [ ] bulk ( Bulk bulk ) throws EngineException { } @ Override public void create ( Create create ) throws EngineException { } private void innerCreate ( Create create , IndexWriter writer ) throws IOException { } @ Override public void index ( Index index ) throws EngineException { } private void innerIndex ( Index index , IndexWriter writer ) throws IOException { } @ Override public void delete ( Delete delete ) throws EngineException { } private void innerDelete ( Delete delete , IndexWriter writer ) throws IOException { } @ Override public void delete ( DeleteByQuery delete ) throws EngineException { } @ Override public Searcher searcher ( ) throws EngineException { } @ Override public ByteSizeValue estimateFlushableMemorySize ( ) { } @ Override public boolean refreshNeeded ( ) { } @ Override public void refresh ( Refresh refresh ) throws EngineException { } @ Override public void flush ( Flush flush ) throws EngineException { } @ Override public void optimize ( Optimize optimize ) throws EngineException { } @ Override public < T > T snapshot ( SnapshotHandler < T > snapshotHandler ) throws EngineException { } @ Override public void recover ( RecoveryHandler recoveryHandler ) throws EngineException { rwl . writeLock ( ) . lock ( ) ; try { ( disableFlushCounter ) ++ ; } finally { rwl . writeLock ( ) . unlock ( ) ; } SnapshotIndexCommit phase1Snapshot ; try { phase1Snapshot = deletionPolicy . snapshot ( ) ; <START_BUG> } catch ( IOException e ) { <END_BUG> -- ( disableFlushCounter ) ; throw new RecoveryEngineException ( shardId , 1 , "Snapshot<seq2seq4repair_space>failed" , e ) ; } try { recoveryHandler . phase1 ( phase1Snapshot ) ; } catch ( Exception e ) { -- ( disableFlushCounter ) ; phase1Snapshot . release ( ) ; throw new RecoveryEngineException ( shardId , 1 , "Execution<seq2seq4repair_space>failed" , e ) ; } Translog . Snapshot phase2Snapshot ; try { phase2Snapshot = translog . snapshot ( ) ; } catch ( Exception e ) { -- ( disableFlushCounter ) ; phase1Snapshot . release ( ) ; throw new RecoveryEngineException ( shardId , 2 , "Snapshot<seq2seq4repair_space>failed" , e ) ; } try { recoveryHandler . phase2 ( phase2Snapshot ) ; } catch ( Exception e ) { -- ( disableFlushCounter ) ; phase1Snapshot . release ( ) ; phase2Snapshot . release ( ) ; throw new RecoveryEngineException ( shardId , 2 , "Execution<seq2seq4repair_space>failed" , e ) ; } rwl . writeLock ( ) . lock ( ) ; Translog . Snapshot phase3Snapshot ; try { phase3Snapshot = translog . snapshot ( phase2Snapshot ) ; } catch ( Exception e ) { -- ( disableFlushCounter ) ; rwl . writeLock ( ) . unlock ( ) ; phase1Snapshot . release ( ) ; phase2Snapshot . release ( ) ; throw new RecoveryEngineException ( shardId , 3 , "Snapshot<seq2seq4repair_space>failed" , e ) ; } try { recoveryHandler . phase3 ( phase3Snapshot ) ; } catch ( Exception e ) { throw new RecoveryEngineException ( shardId , 3 , "Execution<seq2seq4repair_space>failed" , e ) ; } finally { -- ( disableFlushCounter ) ; rwl . writeLock ( ) . unlock ( ) ; phase1Snapshot . release ( ) ; phase2Snapshot . release ( ) ; phase3Snapshot . release ( ) ; } } @ Override public void close ( ) throws ElasticSearchException { } private Object dirtyLock ( Term uid ) { } private long loadCurrentVersionFromIndex ( Term uid ) { } private IndexWriter createWriter ( ) throws IOException { } private AcquirableResource < ReaderSearcherHolder > buildNrtResource ( IndexWriter indexWriter ) throws IOException { } private long newTransactionLogId ( ) throws IOException { } private static class RobinSearchResult implements Searcher { private final AcquirableResource < ReaderSearcherHolder > nrtHolder ; private RobinSearchResult ( AcquirableResource < ReaderSearcherHolder > nrtHolder ) { } @ Override public IndexReader reader ( ) { } @ Override public ExtendedIndexSearcher searcher ( ) { } @ Override public boolean release ( ) throws ElasticSearchException { } } static class VersionValue { private long version ; private final boolean delete ; VersionValue ( long version , boolean delete ) { } public long version ( ) { } public boolean delete ( ) { } } }<BUG2FIX>} catch ( Exception e ) {
public class TransportFlushAction extends TransportBroadcastOperationAction < FlushRequest , FlushResponse , ShardFlushRequest , ShardFlushResponse > { private final IndicesService indicesService ; @ Inject public TransportFlushAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportService transportService , IndicesService indicesService ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected FlushRequest newRequest ( ) { } @ Override protected FlushResponse newResponse ( FlushRequest request , AtomicReferenceArray shardsResponses , ClusterState clusterState ) { } @ Override protected ShardFlushRequest newShardRequest ( ) { } @ Override protected ShardFlushRequest newShardRequest ( int numShards , ShardRouting shard , FlushRequest request ) { } @ Override protected ShardFlushResponse newShardResponse ( ) { } @ Override protected ShardFlushResponse shardOperation ( ShardFlushRequest request ) throws ElasticsearchException { } @ Override protected GroupShardsIterator shards ( ClusterState clusterState , FlushRequest request , String [ ] concreteIndices ) { <START_BUG> return clusterState . routingTable ( ) . allActiveShardsGrouped ( concreteIndices , true ) ; <END_BUG> } @ Override protected ClusterBlockException checkGlobalBlock ( ClusterState state , FlushRequest request ) { } @ Override protected ClusterBlockException checkRequestBlock ( ClusterState state , FlushRequest countRequest , String [ ] concreteIndices ) { } }<BUG2FIX>return clusterState . routingTable ( ) . allActiveShardsGrouped ( concreteIndices , true , true ) ;
@ Override public Number getTermAsNumber ( ) { } @ Override public int count ( ) { } @ Override public int getCount ( ) { } @ Override public double min ( ) { } @ Override public double getMin ( ) { } @ Override public double max ( ) { } @ Override public double getMax ( ) { } @ Override public double total ( ) { } @ Override public double getTotal ( ) { } @ Override public double mean ( ) { } @ Override public double getMean ( ) { } @ Override public int compareTo ( Entry o ) { } } private String name ; int requiredSize ; long missing ; Collection < InternalTermsStatsLongFacet . LongEntry > entries = ImmutableList . of ( ) ; ComparatorType comparatorType ; public InternalTermsStatsLongFacet ( String name , ComparatorType comparatorType , int requiredSize , Collection < InternalTermsStatsLongFacet . LongEntry > entries , long missing ) { } @ Override public String name ( ) { } @ Override public String getName ( ) { } @ Override public String type ( ) { } @ Override public String getType ( ) { } @ Override public List < InternalTermsStatsLongFacet . LongEntry > entries ( ) { } List < InternalTermsStatsLongFacet . LongEntry > mutableList ( ) { } @ Override public List < InternalTermsStatsLongFacet . LongEntry > getEntries ( ) { } @ SuppressWarnings ( { "unchecked" } ) @ Override public Iterator < Entry > iterator ( ) { } @ Override public long missingCount ( ) { } @ Override public long getMissingCount ( ) { } private static ThreadLocal < ThreadLocals . CleanableValue < ExtTLongObjectHashMap < InternalTermsStatsLongFacet . LongEntry > > > aggregateCache = new ThreadLocal < ThreadLocals . CleanableValue < ExtTLongObjectHashMap < InternalTermsStatsLongFacet . LongEntry > > > ( ) { @ Override protected ThreadLocals . CleanableValue < ExtTLongObjectHashMap < LongEntry > > initialValue ( ) { } } ; @ Override public Facet reduce ( String name , List < Facet > facets ) { if ( ( facets . size ( ) ) == 1 ) { if ( ( requiredSize ) == 0 ) { InternalTermsStatsLongFacet tsFacet = ( ( InternalTermsStatsLongFacet ) ( facets . get ( 0 ) ) ) ; if ( ! ( tsFacet . entries . isEmpty ( ) ) ) { List < InternalTermsStatsLongFacet . LongEntry > entries = tsFacet . mutableList ( ) ; Collections . sort ( entries , comparatorType . comparator ( ) ) ; } } return facets . get ( 0 ) ; } int missing = 0 ; ExtTLongObjectHashMap < InternalTermsStatsLongFacet . LongEntry > map = aggregateCache . get ( ) . get ( ) ; map . clear ( ) ; for ( Facet facet : facets ) { InternalTermsStatsLongFacet tsFacet = ( ( InternalTermsStatsLongFacet ) ( facet ) ) ; missing += tsFacet . missing ; for ( Entry entry : tsFacet ) { InternalTermsStatsLongFacet . LongEntry longEntry = ( ( InternalTermsStatsLongFacet . LongEntry ) ( entry ) ) ; InternalTermsStatsLongFacet . LongEntry current = map . get ( longEntry . term ) ; if ( current != null ) { current . count += longEntry . count ; current . total += longEntry . total ; if ( ( ( longEntry . min ) < ( current . min ) ) || ( Double . isNaN ( current . min ) ) ) { current . min = longEntry . min ; } if ( ( ( longEntry . max ) > ( current . max ) ) || ( Double . isNaN ( current . max ) ) ) { current . max = longEntry . max ; } } else { map . put ( longEntry . term , longEntry ) ; } } } if ( ( requiredSize ) == 0 ) { InternalTermsStatsLongFacet . LongEntry [ ] entries1 = map . values ( new InternalTermsStatsLongFacet . LongEntry [ map . size ( ) ] ) ; Arrays . sort ( entries1 , comparatorType . comparator ( ) ) ; return new InternalTermsStatsLongFacet ( name , comparatorType , requiredSize , Arrays . asList ( entries1 ) , missing ) ; } else { Object [ ] values = map . internalValues ( ) ; Arrays . sort ( values , ( ( Comparator ) ( comparatorType . comparator ( ) ) ) ) ; <START_BUG> List < InternalTermsStatsLongFacet . LongEntry > ordered = new ArrayList < InternalTermsStatsLongFacet . LongEntry > ( ) ; <END_BUG> for ( int i = 0 ; i < ( requiredSize ) ; i ++ ) { InternalTermsStatsLongFacet . LongEntry value = ( ( InternalTermsStatsLongFacet . LongEntry ) ( values [ i ] ) ) ; if ( value == null ) { break ; } ordered . add ( value ) ; } return new InternalTermsStatsLongFacet ( name , comparatorType , requiredSize , ordered , missing ) ; } } static final class Fields { static final XContentBuilderString _TYPE = new XContentBuilderString ( "_type" ) ; static final XContentBuilderString MISSING = new XContentBuilderString ( "missing" ) ; static final XContentBuilderString TERMS = new XContentBuilderString ( "terms" ) ; static final XContentBuilderString TERM = new XContentBuilderString ( "term" ) ; static final XContentBuilderString COUNT = new XContentBuilderString ( "count" ) ; static final XContentBuilderString MIN = new XContentBuilderString ( "min" ) ; static final XContentBuilderString MAX = new XContentBuilderString ( "max" ) ; static final XContentBuilderString TOTAL = new XContentBuilderString ( "total" ) ; static final XContentBuilderString MEAN = new XContentBuilderString ( "mean" ) ; } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } public static InternalTermsStatsLongFacet readTermsStatsFacet ( StreamInput in ) throws IOException { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } }<BUG2FIX>List < InternalTermsStatsLongFacet . LongEntry > ordered = new ArrayList < InternalTermsStatsLongFacet . LongEntry > ( map . size ( ) ) ;
public class TransportSearchDfsQueryThenFetchAction extends TransportSearchTypeAction { @ Inject public TransportSearchDfsQueryThenFetchAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportSearchCache transportSearchCache , SearchServiceTransportAction searchService , SearchPhaseController searchPhaseController ) { } @ Override protected void doExecute ( SearchRequest searchRequest , ActionListener < SearchResponse > listener ) { } private class AsyncAction extends BaseAsyncAction < DfsSearchResult > { private final Collection < DfsSearchResult > dfsResults = searchCache . obtainDfsResults ( ) ; private final Map < SearchShardTarget , QuerySearchResultProvider > queryResults = searchCache . obtainQueryResults ( ) ; private final Map < SearchShardTarget , FetchSearchResult > fetchResults = searchCache . obtainFetchResults ( ) ; private volatile Map < SearchShardTarget , ExtTIntArrayList > docIdsToLoad ; private AsyncAction ( SearchRequest request , ActionListener < SearchResponse > listener ) { } @ Override protected String firstPhaseName ( ) { } @ Override protected void sendExecuteFirstPhase ( DiscoveryNode node , InternalSearchRequest request , SearchServiceListener < DfsSearchResult > listener ) { } @ Override protected void processFirstPhaseResult ( ShardRouting shard , DfsSearchResult result ) { } @ Override protected void moveToSecondPhase ( ) { } private void executeQuery ( final DfsSearchResult dfsResult , final AtomicInteger counter , final QuerySearchRequest querySearchRequest , DiscoveryNode node ) { } private void executeFetchPhase ( ) { } private void innerExecuteFetchPhase ( ) { } private void executeFetch ( final SearchShardTarget shardTarget , final AtomicInteger counter , final FetchSearchRequest fetchSearchRequest , DiscoveryNode node ) { } private void finishHim ( ) { } private void innerFinishHim ( ) throws Exception { final InternalSearchResponse internalResponse = searchPhaseController . merge ( sortedShardList , queryResults , fetchResults ) ; String scrollId = null ; if ( ( request . scroll ( ) ) != null ) { <START_BUG> scrollId = TransportSearchHelper . buildScrollId ( request . searchType ( ) , dfsResults ) ; <END_BUG> } listener . onResponse ( new SearchResponse ( internalResponse , scrollId , expectedSuccessfulOps , successulOps . get ( ) , buildTookInMillis ( ) , buildShardFailures ( ) ) ) ; } } }<BUG2FIX>scrollId = TransportSearchHelper . buildScrollId ( request . searchType ( ) , dfsResults , null ) ;
public class LocalTransport extends AbstractLifecycleComponent < Transport > implements Transport { private final ThreadPool threadPool ; private volatile TransportServiceAdapter transportServiceAdapter ; private volatile BoundTransportAddress boundAddress ; private volatile LocalTransportAddress localAddress ; private static final ConcurrentMap < TransportAddress , LocalTransport > transports = newConcurrentMap ( ) ; private static final AtomicLong transportAddressIdGenerator = new AtomicLong ( ) ; private final ConcurrentMap < DiscoveryNode , LocalTransport > connectedNodes = newConcurrentMap ( ) ; public LocalTransport ( ThreadPool threadPool ) { } @ Inject public LocalTransport ( Settings settings , ThreadPool threadPool ) { } @ Override public TransportAddress [ ] addressesFromString ( String address ) { } @ Override public boolean addressSupported ( Class < ? extends TransportAddress > address ) { } @ Override protected void doStart ( ) throws ElasticSearchException { } @ Override protected void doStop ( ) throws ElasticSearchException { } @ Override protected void doClose ( ) throws ElasticSearchException { } @ Override public void transportServiceAdapter ( TransportServiceAdapter transportServiceAdapter ) { } @ Override public BoundTransportAddress boundAddress ( ) { } @ Override public boolean nodeConnected ( DiscoveryNode node ) { } @ Override public void connectToNodeLight ( DiscoveryNode node ) throws ConnectTransportException { } @ Override public void connectToNode ( DiscoveryNode node ) throws ConnectTransportException { } @ Override public void disconnectFromNode ( DiscoveryNode node ) { } @ Override public long serverOpen ( ) { } @ Override public < T extends Streamable > void sendRequest ( final DiscoveryNode node , final long requestId , final String action , final Streamable message , TransportRequestOptions options ) throws IOException , TransportException { } ThreadPool threadPool ( ) { } void messageReceived ( byte [ ] data , String action , LocalTransport sourceTransport , @ Nullable final Long sendRequestId ) { transportServiceAdapter . received ( data . length ) ; <START_BUG> StreamInput stream = new BytesStreamInput ( data ) ; <END_BUG> stream = CachedStreamInput . cachedHandles ( stream ) ; try { long requestId = stream . readLong ( ) ; byte status = stream . readByte ( ) ; boolean isRequest = TransportStreams . statusIsRequest ( status ) ; if ( isRequest ) { handleRequest ( stream , requestId , sourceTransport ) ; } else { final TransportResponseHandler handler = transportServiceAdapter . remove ( requestId ) ; if ( handler != null ) { if ( TransportStreams . statusIsError ( status ) ) { handlerResponseError ( stream , handler ) ; } else { handleResponse ( stream , handler ) ; } } } } catch ( Exception e ) { if ( sendRequestId != null ) { TransportResponseHandler handler = transportServiceAdapter . remove ( sendRequestId ) ; if ( handler != null ) { handler . handleException ( new RemoteTransportException ( nodeName ( ) , localAddress , action , e ) ) ; } } else { logger . warn ( ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>receive<seq2seq4repair_space>message<seq2seq4repair_space>for<seq2seq4repair_space>action<seq2seq4repair_space>[" + action ) + "]" ) , e ) ; } } } private void handleRequest ( StreamInput stream , long requestId , LocalTransport sourceTransport ) throws Exception { } private void handleResponse ( StreamInput buffer , final TransportResponseHandler handler ) { } private void handlerResponseError ( StreamInput buffer , final TransportResponseHandler handler ) { } private void handleException ( final TransportResponseHandler handler , Throwable error ) { } }<BUG2FIX>StreamInput stream = new BytesStreamInput ( data , false ) ;
public class SinglePackedOrdinals implements Ordinals { private final Reader reader ; private final int numOrds ; private long size = - 1 ; public SinglePackedOrdinals ( PackedInts . Reader reader , int numOrds ) { } @ Override public Object getBackingStorage ( ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override public boolean isMultiValued ( ) { } @ Override public int getNumDocs ( ) { } @ Override public int getNumOrds ( ) { } @ Override public SinglePackedOrdinals . Docs ordinals ( ) { } public static class Docs implements Ordinals . Docs { private final SinglePackedOrdinals parent ; private final Reader reader ; private final IntArrayRef intsScratch = new IntArrayRef ( new int [ 1 ] ) ; private final SingleValueIter iter = new SingleValueIter ( ) ; public Docs ( SinglePackedOrdinals parent , PackedInts . Reader reader ) { } @ Override public Ordinals ordinals ( ) { } @ Override public int getNumDocs ( ) { } @ Override public int getNumOrds ( ) { } @ Override public boolean isMultiValued ( ) { } @ Override public int getOrd ( int docId ) { } @ Override public IntArrayRef getOrds ( int docId ) { int ordinal = ( ( int ) ( reader . get ( docId ) ) ) ; if ( ordinal == 0 ) return IntArrayRef . EMPTY ; <START_BUG> intsScratch . values [ 0 ] = docId ; <END_BUG> return intsScratch ; } @ Override public Iter getIter ( int docId ) { } @ Override public void forEachOrdinalInDoc ( int docId , OrdinalInDocProc proc ) { } } }<BUG2FIX>intsScratch . values [ 0 ] = ordinal ;
final class JoglAudio implements Audio , Runnable { private SourceDataLine line ; private final List < JoglAudio . JoglSoundBuffer > buffers = new ArrayList < JoglAudio . JoglSoundBuffer > ( ) ; private Thread thread ; private volatile boolean run = false ; class JoglSoundBuffer { private final float [ ] samples ; private final AudioFormat format ; private final float volume ; private int writtenSamples = 0 ; public JoglSoundBuffer ( JoglSound sound , float volume ) throws Exception { } public boolean writeSamples ( int numSamples , float [ ] buffer ) { } } JoglAudio ( ) { } @ Override public AudioDevice newAudioDevice ( boolean isMono ) { } @ Override public Music newMusic ( FileHandle file ) { try { JoglMusic music = new JoglMusic ( ( ( JoglFileHandle ) ( file ) ) ) ; return music ; <START_BUG> } catch ( Exception e ) { <END_BUG> throw new com . badlogic . gdx . utils . GdxRuntimeException ( ( ( "Couldn't<seq2seq4repair_space>create<seq2seq4repair_space>Music<seq2seq4repair_space>instance<seq2seq4repair_space>from<seq2seq4repair_space>file<seq2seq4repair_space>'" + file ) + "'" ) , e ) ; } } @ Override public Sound newSound ( FileHandle file ) { } protected void enqueueSound ( JoglSound sound , float volume ) { } @ Override public void run ( ) { } private void fillBuffer ( float [ ] buffer , byte [ ] bytes , int samplesToWrite ) { } @ Override public AudioRecorder newAudioRecoder ( int samplingRate , boolean isMono ) { } void dispose ( ) { } }<BUG2FIX>} catch ( Throwable e ) {
public class InternalFilterFacet extends InternalFacet implements FilterFacet { private static final BytesReference STREAM_TYPE = new org . elasticsearch . common . bytes . HashedBytesArray ( Strings . toUTF8Bytes ( "filter" ) ) ; public static void registerStreams ( ) { } static Stream STREAM = new Stream ( ) { @ Override public Facet readFacet ( StreamInput in ) throws IOException { } } ; @ Override public BytesReference streamType ( ) { } private long count ; InternalFilterFacet ( ) { } public InternalFilterFacet ( String name , long count ) { } @ Override public String getType ( ) { } public long getCount ( ) { } @ Override public Facet reduce ( ReduceContext context ) { List < Facet > facets = context . facets ( ) ; if ( ( facets . size ( ) ) == 1 ) { return facets . get ( 0 ) ; } <START_BUG> int count = 0 ; <END_BUG> for ( Facet facet : facets ) { count += ( ( FilterFacet ) ( facet ) ) . getCount ( ) ; } return new InternalFilterFacet ( getName ( ) , count ) ; } static final class Fields { static final XContentBuilderString _TYPE = new XContentBuilderString ( "_type" ) ; static final XContentBuilderString COUNT = new XContentBuilderString ( "count" ) ; } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } public static FilterFacet readFilterFacet ( StreamInput in ) throws IOException { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } }<BUG2FIX>long count = 0 ;
public class RestTypesExistsAction extends BaseRestHandler { @ Inject public RestTypesExistsAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { TypesExistsRequest typesExistsRequest = new TypesExistsRequest ( splitIndices ( request . param ( "index" ) ) , splitTypes ( request . param ( "type" ) ) ) ; typesExistsRequest . listenerThreaded ( false ) ; if ( request . hasParam ( "ignore_indices" ) ) { typesExistsRequest . ignoreIndices ( IgnoreIndices . fromString ( request . param ( "ignore_indices" ) ) ) ; } client . admin ( ) . indices ( ) . typesExists ( typesExistsRequest , new org . elasticsearch . action . ActionListener < TypesExistsResponse > ( ) { @ Override public void onResponse ( TypesExistsResponse response ) { try { if ( response . isExists ( ) ) { channel . sendResponse ( new StringRestResponse ( RestStatus . OK ) ) ; } else { channel . sendResponse ( new StringRestResponse ( RestStatus . NOT_FOUND ) ) ; } <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new StringRestResponse ( ExceptionsHelper . status ( e ) ) ) ; } catch ( Exception e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class RestAnalyzeAction extends BaseRestHandler { @ Inject public RestAnalyzeAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { String text = request . param ( "text" ) ; if ( ( text == null ) && ( request . hasContent ( ) ) ) { text = request . content ( ) . toUtf8 ( ) ; } if ( text == null ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , new ElasticSearchIllegalArgumentException ( "text<seq2seq4repair_space>is<seq2seq4repair_space>missing" ) ) ) ; } catch ( IOException e1 ) { logger . warn ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>response" , e1 ) ; } return ; } AnalyzeRequest analyzeRequest = new AnalyzeRequest ( request . param ( "index" ) , text ) ; analyzeRequest . listenerThreaded ( false ) ; analyzeRequest . preferLocal ( request . paramAsBoolean ( "prefer_local" , analyzeRequest . preferLocalShard ( ) ) ) ; analyzeRequest . analyzer ( request . param ( "analyzer" ) ) ; analyzeRequest . field ( request . param ( "field" ) ) ; analyzeRequest . tokenizer ( request . param ( "tokenizer" ) ) ; analyzeRequest . tokenFilters ( request . paramAsStringArray ( "token_filters" , request . paramAsStringArray ( "filters" , null ) ) ) ; client . admin ( ) . indices ( ) . analyze ( analyzeRequest , new org . elasticsearch . action . ActionListener < AnalyzeResponse > ( ) { @ Override public void onResponse ( AnalyzeResponse response ) { try { XContentBuilder builder = restContentBuilder ( request , false ) ; builder . startObject ( ) ; response . toXContent ( builder , request ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class WildcardQueryParser extends AbstractIndexComponent implements XContentQueryParser { public static final String NAME = "wildcard" ; @ Inject public WildcardQueryParser ( Index index , @ IndexSettings Settings settings ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; XContentParser . Token token = parser . nextToken ( ) ; assert token == ( Token . FIELD_NAME ) ; String fieldName = parser . currentName ( ) ; String value = null ; float boost = 1.0F ; token = parser . nextToken ( ) ; if ( token == ( Token . START_OBJECT ) ) { String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else { if ( "wildcard" . equals ( currentFieldName ) ) { value = parser . text ( ) ; } else if ( "boost" . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } } } parser . nextToken ( ) ; } else { value = parser . text ( ) ; parser . nextToken ( ) ; } if ( value == null ) { throw new QueryParsingException ( index , "No<seq2seq4repair_space>value<seq2seq4repair_space>specified<seq2seq4repair_space>for<seq2seq4repair_space>prefix<seq2seq4repair_space>query" ) ; } MapperService . SmartNameFieldMappers smartNameFieldMappers = parseContext . smartFieldMappers ( fieldName ) ; if ( smartNameFieldMappers != null ) { if ( smartNameFieldMappers . hasMapper ( ) ) { fieldName = smartNameFieldMappers . mapper ( ) . names ( ) . indexName ( ) ; value = smartNameFieldMappers . mapper ( ) . indexedValue ( value ) ; } } WildcardQuery query = new WildcardQuery ( new Term ( fieldName , value ) ) ; query . setRewriteMethod ( CONSTANT_SCORE_AUTO_REWRITE_DEFAULT ) ; query . setBoost ( boost ) ; <START_BUG> return wrapSmartNameQuery ( query , smartNameFieldMappers , parseContext . indexCache ( ) ) ; <END_BUG> } }<BUG2FIX>return wrapSmartNameQuery ( query , smartNameFieldMappers , parseContext ) ;
public class ImportTest extends BaseBulletTest { btBulletWorldImporter importer ; Model model ; public class MyImporter extends btBulletWorldImporter { public MyImporter ( btDynamicsWorld world ) { } @ Override public btRigidBody createRigidBody ( boolean isDynamic , float mass , Matrix4 startTransform , btCollisionShape shape , String bodyName ) { Vector3 localInertia = new Vector3 ( ) ; if ( mass > 0.0F ) shape . calculateLocalInertia ( mass , localInertia ) ; btRigidBody result = new btRigidBody ( mass , null , shape , localInertia ) ; String nodeName = ( bodyName . split ( "_" , 2 ) [ 0 ] ) + "_model" ; <START_BUG> ModelInstance instance = new ModelInstance ( model , nodeName , true , true , true ) ; <END_BUG> instance . transform . set ( startTransform ) ; BulletEntity entity = new BulletEntity ( instance , result ) ; ImportTest . this . world . add ( entity ) ; return result ; } } @ Override public void create ( ) { } @ Override public boolean tap ( float x , float y , int count , int button ) { } @ Override public void dispose ( ) { } }<BUG2FIX>ModelInstance instance = new ModelInstance ( model , nodeName , true , true ) ;
public class BinaryLoader { private final LoaderCallback < BinaryLoader . Blob > callback ; public BinaryLoader ( String url , LoaderCallback < BinaryLoader . Blob > callback ) { } private native void overrideMimeType ( XMLHttpRequest req , String mimeType ) { } public static final class Blob { final String data ; public Blob ( String data ) { } public int length ( ) { } public byte get ( int i ) { } private native byte get ( String s , int i ) { } public InputStream read ( ) { return new BinaryLoader . BlobInputStream ( this ) ; } } private static class BlobInputStream extends InputStream { BinaryLoader . Blob blob ; int pos ; public BlobInputStream ( BinaryLoader . Blob blob ) { } @ Override public int read ( ) throws IOException { if ( ( pos ) == ( blob . length ( ) ) ) return - 1 ; <START_BUG> return blob . get ( ( ( pos ) ++ ) ) ; <END_BUG> } } }<BUG2FIX>return ( blob . get ( ( ( pos ) ++ ) ) ) & 255 ;
public final class DirectCandidateGenerator extends CandidateGenerator { private final DirectSpellChecker spellchecker ; private final String field ; private final SuggestMode suggestMode ; private final TermsEnum termsEnum ; private final IndexReader reader ; private final long dictSize ; private final double logBase = 5 ; private final long frequencyPlateau ; private final Analyzer preFilter ; private final Analyzer postFilter ; private final double nonErrorLikelihood ; private final boolean useTotalTermFrequency ; private final CharsRef spare = new CharsRef ( ) ; private final BytesRef byteSpare = new BytesRef ( ) ; private final int numCandidates ; public DirectCandidateGenerator ( DirectSpellChecker spellchecker , String field , SuggestMode suggestMode , IndexReader reader , double nonErrorLikelihood , int numCandidates ) throws IOException { } public DirectCandidateGenerator ( DirectSpellChecker spellchecker , String field , SuggestMode suggestMode , IndexReader reader , double nonErrorLikelihood , int numCandidates , Analyzer preFilter , Analyzer postFilter , Terms terms ) throws IOException { } @ Override public boolean isKnownWord ( BytesRef term ) throws IOException { } @ Override public long frequency ( BytesRef term ) throws IOException { } public long internalFrequency ( BytesRef term ) throws IOException { <START_BUG> if ( termsEnum . seekExact ( term , true ) ) { <END_BUG> return useTotalTermFrequency ? termsEnum . totalTermFreq ( ) : termsEnum . docFreq ( ) ; } return 0 ; } public String getField ( ) { } @ Override public DirectCandidateGenerator . CandidateSet drawCandidates ( DirectCandidateGenerator . CandidateSet set ) throws IOException { } protected BytesRef preFilter ( final BytesRef term , final CharsRef spare , final BytesRef byteSpare ) throws IOException { } protected void postFilter ( final DirectCandidateGenerator . Candidate candidate , final CharsRef spare , BytesRef byteSpare , final List < DirectCandidateGenerator . Candidate > candidates ) throws IOException { } private double score ( long frequency , double errorScore , long dictionarySize ) { } protected long thresholdFrequency ( long termFrequency , long dictionarySize ) { } public static class CandidateSet { public DirectCandidateGenerator . Candidate [ ] candidates ; public final DirectCandidateGenerator . Candidate originalTerm ; public CandidateSet ( DirectCandidateGenerator . Candidate [ ] candidates , DirectCandidateGenerator . Candidate originalTerm ) { } public void addCandidates ( List < DirectCandidateGenerator . Candidate > candidates ) { } public void addOneCandidate ( DirectCandidateGenerator . Candidate candidate ) { } } public static class Candidate { public static final DirectCandidateGenerator . Candidate [ ] EMPTY = new DirectCandidateGenerator . Candidate [ 0 ] ; public final BytesRef term ; public final double stringDistance ; public final long frequency ; public final double score ; public final boolean userInput ; public Candidate ( BytesRef term , long frequency , double stringDistance , double score , boolean userInput ) { } @ Override public String toString ( ) { } @ Override public int hashCode ( ) { } @ Override public boolean equals ( Object obj ) { } } @ Override public DirectCandidateGenerator . Candidate createCandidate ( BytesRef term , long frequency , double channelScore , boolean userInput ) throws IOException { } }<BUG2FIX>if ( termsEnum . seekExact ( term ) ) {
public class RestNodesStatsAction extends BaseRestHandler { @ Inject public RestNodesStatsAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } void executeNodeStats ( final RestRequest request , final RestChannel channel , final NodesStatsRequest nodesStatsRequest ) { nodesStatsRequest . listenerThreaded ( false ) ; client . admin ( ) . cluster ( ) . nodesStats ( nodesStatsRequest , new org . elasticsearch . action . ActionListener < NodesStatsResponse > ( ) { @ Override public void onResponse ( NodesStatsResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; response . toXContent ( builder , request ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } class RestIndicesHandler implements RestHandler { @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } } class RestOsHandler implements RestHandler { @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } } class RestProcessHandler implements RestHandler { @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } } class RestJvmHandler implements RestHandler { @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } } class RestThreadPoolHandler implements RestHandler { @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } } class RestNetworkHandler implements RestHandler { @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } } class RestFsHandler implements RestHandler { @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } } class RestTransportHandler implements RestHandler { @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } } class RestHttpHandler implements RestHandler { @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } } }<BUG2FIX>} catch ( Throwable e ) {
public class CircularFloatBuffer { private final float [ ] buffer ; private int writePosition ; private int readPosition ; private int available ; public final int size ; public CircularFloatBuffer ( int size ) { } public void write ( float [ ] data , int offset , int count ) { } public void combine ( float [ ] data , int offset , int count ) { } public int read ( float [ ] data , int offset , int count ) { } public int skip ( int count ) { <START_BUG> int total = count = Math . min ( available , count ) ; <END_BUG> available -= total ; readPosition = ( ( readPosition ) + total ) % ( buffer . length ) ; return total ; } public void clear ( ) { } public void setWritePosition ( int writePosition ) { } public int getWritePosition ( ) { } public void setReadPosition ( int readPosition ) { } public int getReadPosition ( ) { } public int getAvailable ( ) { } private void dump ( ) { } private static void combine ( float [ ] src , int srcPos , float [ ] dest , int destPos , int length ) { } }<BUG2FIX>int total = Math . min ( available , count ) ;
public class CharArray { public char [ ] items ; public int size ; public boolean ordered ; public CharArray ( ) { } public CharArray ( int capacity ) { } public CharArray ( boolean ordered , int capacity ) { } public CharArray ( CharArray array ) { } public CharArray ( char [ ] array ) { } public CharArray ( boolean ordered , char [ ] array , int startIndex , int count ) { } public void add ( char value ) { } public void addAll ( CharArray array ) { } public void addAll ( CharArray array , int offset , int length ) { } public void addAll ( char [ ] array ) { } public void addAll ( char [ ] array , int offset , int length ) { char [ ] items = this . items ; <START_BUG> int sizeNeeded = ( ( size ) + length ) - offset ; <END_BUG> if ( sizeNeeded >= ( items . length ) ) items = resize ( Math . max ( 8 , ( ( int ) ( sizeNeeded * 1.75F ) ) ) ) ; System . arraycopy ( array , offset , items , size , length ) ; size += length ; } public char get ( int index ) { } public void set ( int index , char value ) { } public void insert ( int index , char value ) { } public void swap ( int first , int second ) { } public boolean contains ( char value ) { } public int indexOf ( char value ) { } public int lastIndexOf ( char value ) { } public boolean removeValue ( char value ) { } public char removeIndex ( int index ) { } public boolean removeAll ( CharArray array ) { } public char pop ( ) { } public char peek ( ) { } public char first ( ) { } public void clear ( ) { } public void shrink ( ) { } public char [ ] ensureCapacity ( int additionalCapacity ) { } protected char [ ] resize ( int newSize ) { } public void sort ( ) { } public void reverse ( ) { } public void shuffle ( ) { } public void truncate ( int newSize ) { } public char random ( ) { } public char [ ] toArray ( ) { } public boolean equals ( Object object ) { } public String toString ( ) { } public String toString ( String separator ) { } }<BUG2FIX>int sizeNeeded = ( size ) + length ;
public class DummyCircuitBreakerService implements CircuitBreakerService { private final ESLogger logger = Loggers . getLogger ( DummyCircuitBreakerService . class ) ; private final MemoryCircuitBreaker breaker = new MemoryCircuitBreaker ( new ByteSizeValue ( Long . MAX_VALUE ) , 0.0 , logger ) ; public DummyCircuitBreakerService ( ) { } @ Override public MemoryCircuitBreaker getBreaker ( ) { } @ Override public FieldDataBreakerStats stats ( ) { <START_BUG> return new FieldDataBreakerStats ( ( - 1 ) , ( - 1 ) , 0 ) ; <END_BUG> } }<BUG2FIX>return new FieldDataBreakerStats ( ( - 1 ) , ( - 1 ) , 0 , 0 ) ;
class InternalOrder extends Terms . Order { public static final InternalOrder COUNT_DESC = new InternalOrder ( ( ( byte ) ( 1 ) ) , "_count" , false , new Comparator < Terms . Bucket > ( ) { @ Override public int compare ( Terms . Bucket o1 , Terms . Bucket o2 ) { } } ) ; public static final InternalOrder COUNT_ASC = new InternalOrder ( ( ( byte ) ( 2 ) ) , "_count" , true , new Comparator < Terms . Bucket > ( ) { @ Override public int compare ( Terms . Bucket o1 , Terms . Bucket o2 ) { } } ) ; public static final InternalOrder TERM_DESC = new InternalOrder ( ( ( byte ) ( 3 ) ) , "_term" , false , new Comparator < Terms . Bucket > ( ) { @ Override public int compare ( Terms . Bucket o1 , Terms . Bucket o2 ) { } } ) ; public static final InternalOrder TERM_ASC = new InternalOrder ( ( ( byte ) ( 4 ) ) , "_term" , true , new Comparator < Terms . Bucket > ( ) { @ Override public int compare ( Terms . Bucket o1 , Terms . Bucket o2 ) { } } ) ; final byte id ; final String key ; final boolean asc ; protected final Comparator < Terms . Bucket > comparator ; InternalOrder ( byte id , String key , boolean asc , Comparator < Terms . Bucket > comparator ) { } byte id ( ) { } @ Override protected Comparator < Terms . Bucket > comparator ( Aggregator aggregator ) { return comparator ; } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } public static InternalOrder validate ( InternalOrder order , Aggregator termsAggregator ) { } static class Aggregation extends InternalOrder { static final byte ID = 0 ; Aggregation ( String key , boolean asc ) { } OrderPath path ( ) { } @ Override protected Comparator < Terms . Bucket > comparator ( Aggregator termsAggregator ) { if ( termsAggregator == null ) { return comparator ; } OrderPath path = path ( ) ; <START_BUG> final Aggregator aggregator = path . resolveAggregator ( termsAggregator , false ) ; <END_BUG> final String key = path . tokens [ ( ( path . tokens . length ) - 1 ) ] . key ; if ( aggregator instanceof SingleBucketAggregator ) { assert key == null : "this<seq2seq4repair_space>should<seq2seq4repair_space>be<seq2seq4repair_space>picked<seq2seq4repair_space>up<seq2seq4repair_space>before<seq2seq4repair_space>the<seq2seq4repair_space>aggregation<seq2seq4repair_space>is<seq2seq4repair_space>executed<seq2seq4repair_space>-<seq2seq4repair_space>on<seq2seq4repair_space>validate" ; return new Comparator < Terms . Bucket > ( ) { @ Override public int compare ( Terms . Bucket o1 , Terms . Bucket o2 ) { int mul = ( asc ) ? 1 : - 1 ; int v1 = ( ( SingleBucketAggregator ) ( aggregator ) ) . bucketDocCount ( ( ( InternalTerms . Bucket ) ( o1 ) ) . bucketOrd ) ; int v2 = ( ( SingleBucketAggregator ) ( aggregator ) ) . bucketDocCount ( ( ( InternalTerms . Bucket ) ( o2 ) ) . bucketOrd ) ; return mul * ( v1 - v2 ) ; } } ; } assert ! ( aggregator instanceof BucketsAggregator ) : "this<seq2seq4repair_space>should<seq2seq4repair_space>be<seq2seq4repair_space>picked<seq2seq4repair_space>up<seq2seq4repair_space>before<seq2seq4repair_space>the<seq2seq4repair_space>aggregation<seq2seq4repair_space>is<seq2seq4repair_space>executed<seq2seq4repair_space>-<seq2seq4repair_space>on<seq2seq4repair_space>validate" ; if ( aggregator instanceof NumericMetricsAggregator . MultiValue ) { assert key != null : "this<seq2seq4repair_space>should<seq2seq4repair_space>be<seq2seq4repair_space>picked<seq2seq4repair_space>up<seq2seq4repair_space>before<seq2seq4repair_space>the<seq2seq4repair_space>aggregation<seq2seq4repair_space>is<seq2seq4repair_space>executed<seq2seq4repair_space>-<seq2seq4repair_space>on<seq2seq4repair_space>validate" ; return new Comparator < Terms . Bucket > ( ) { @ Override public int compare ( Terms . Bucket o1 , Terms . Bucket o2 ) { double v1 = ( ( NumericMetricsAggregator . MultiValue ) ( aggregator ) ) . metric ( key , ( ( InternalTerms . Bucket ) ( o1 ) ) . bucketOrd ) ; double v2 = ( ( NumericMetricsAggregator . MultiValue ) ( aggregator ) ) . metric ( key , ( ( InternalTerms . Bucket ) ( o2 ) ) . bucketOrd ) ; return Comparators . compareDiscardNaN ( v1 , v2 , asc ) ; } } ; } return new Comparator < Terms . Bucket > ( ) { @ Override public int compare ( Terms . Bucket o1 , Terms . Bucket o2 ) { double v1 = ( ( NumericMetricsAggregator . SingleValue ) ( aggregator ) ) . metric ( ( ( InternalTerms . Bucket ) ( o1 ) ) . bucketOrd ) ; double v2 = ( ( NumericMetricsAggregator . SingleValue ) ( aggregator ) ) . metric ( ( ( InternalTerms . Bucket ) ( o2 ) ) . bucketOrd ) ; return Comparators . compareDiscardNaN ( v1 , v2 , asc ) ; } } ; } } public static class Streams { public static void writeOrder ( InternalOrder order , StreamOutput out ) throws IOException { } public static InternalOrder readOrder ( StreamInput in ) throws IOException { } } }<BUG2FIX>final Aggregator aggregator = path . resolveAggregator ( termsAggregator ) ;
public class LwjglAWTCanvas implements Application { final LwjglGraphics graphics ; final OpenALAudio audio ; final LwjglFiles files ; final LwjglAWTInput input ; final LwjglNet net ; final ApplicationListener listener ; final AWTGLCanvas canvas ; final List < Runnable > runnables = new ArrayList ( ) ; final List < Runnable > executedRunnables = new ArrayList ( ) ; final Array < LifecycleListener > lifecycleListeners = new Array < LifecycleListener > ( ) ; boolean running = true ; int lastWidth ; int lastHeight ; int logLevel = LOG_INFO ; private Cursor cursor ; public LwjglAWTCanvas ( ApplicationListener listener , boolean useGL2 ) { } public LwjglAWTCanvas ( ApplicationListener listener , boolean useGL2 , LwjglAWTCanvas sharedContextCanvas ) { } protected void setDisplayMode ( int width , int height ) { } protected void setTitle ( String title ) { } @ Override public ApplicationListener getApplicationListener ( ) { } public Canvas getCanvas ( ) { } @ Override public Audio getAudio ( ) { } @ Override public Files getFiles ( ) { } @ Override public Graphics getGraphics ( ) { } @ Override public Input getInput ( ) { } @ Override public Net getNet ( ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } void setGlobals ( ) { } void create ( ) { } void render ( ) { } protected void start ( ) { } protected void resize ( int width , int height ) { } protected void stopped ( ) { } public void stop ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } Map < String , Preferences > preferences = new HashMap < String , Preferences > ( ) ; @ Override public Preferences getPreferences ( String name ) { if ( preferences . containsKey ( name ) ) { return preferences . get ( name ) ; } else { <START_BUG> Preferences prefs = new LwjglPreferences ( name , ".prefs/" ) ; <END_BUG> preferences . put ( name , prefs ) ; return prefs ; } } @ Override public Clipboard getClipboard ( ) { } @ Override public void postRunnable ( Runnable runnable ) { } @ Override public void debug ( String tag , String message ) { } @ Override public void debug ( String tag , String message , Throwable exception ) { } public void log ( String tag , String message ) { } @ Override public void log ( String tag , String message , Throwable exception ) { } @ Override public void error ( String tag , String message ) { } @ Override public void error ( String tag , String message , Throwable exception ) { } @ Override public void setLogLevel ( int logLevel ) { } @ Override public int getLogLevel ( ) { } @ Override public void exit ( ) { } public void makeCurrent ( ) { } public boolean isCurrent ( ) { } public void setCursor ( Cursor cursor ) { } @ Override public void addLifecycleListener ( LifecycleListener listener ) { } @ Override public void removeLifecycleListener ( LifecycleListener listener ) { } }<BUG2FIX>Preferences prefs = new LwjglPreferences ( name ) ;
public class LwjglApplication implements Application { LwjglGraphics graphics ; OpenALAudio audio ; LwjglFiles files ; LwjglInput input ; final ApplicationListener listener ; Thread mainLoopThread ; boolean running = true ; List < Runnable > runnables = new ArrayList < Runnable > ( ) ; public LwjglApplication ( ApplicationListener listener , String title , int width , int height , boolean useGL2 ) { } public LwjglApplication ( ApplicationListener listener , boolean useGL2 , Canvas canvas ) { } private void initialize ( ) { } private void mainLoop ( ) { try { graphics . setupDisplay ( ) ; } catch ( LWJGLException e ) { throw new com . badlogic . gdx . utils . GdxRuntimeException ( e ) ; } Keyboard . enableRepeatEvents ( true ) ; listener . create ( ) ; listener . resize ( graphics . getWidth ( ) , graphics . getHeight ( ) ) ; int lastWidth = graphics . getWidth ( ) ; int lastHeight = graphics . getHeight ( ) ; graphics . lastTime = System . nanoTime ( ) ; while ( ( running ) && ( ! ( Display . isCloseRequested ( ) ) ) ) { graphics . updateTime ( ) ; synchronized ( runnables ) { for ( int i = 0 ; i < ( runnables . size ( ) ) ; i ++ ) { runnables . get ( i ) . run ( ) ; } runnables . clear ( ) ; } input . update ( ) ; if ( ( graphics . canvas ) != null ) { int width = graphics . canvas . getWidth ( ) ; int height = graphics . canvas . getHeight ( ) ; if ( ( lastWidth != width ) || ( lastHeight != height ) ) { lastWidth = width ; lastHeight = height ; listener . resize ( lastWidth , lastHeight ) ; } } <START_BUG> ( ( LwjglInput ) ( Gdx . input ) ) . processEvents ( ) ; <END_BUG> listener . render ( ) ; audio . update ( ) ; Display . update ( ) ; Display . sync ( 60 ) ; } listener . pause ( ) ; listener . dispose ( ) ; Display . destroy ( ) ; audio . dispose ( ) ; } @ Override public Audio getAudio ( ) { } @ Override public Files getFiles ( ) { } @ Override public Graphics getGraphics ( ) { } @ Override public Input getInput ( ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } @ Override public void log ( String tag , String message ) { } public void stop ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } Map < String , Preferences > preferences = new HashMap < String , Preferences > ( ) ; @ Override public Preferences getPreferences ( String name ) { } @ Override public void postRunnable ( Runnable runnable ) { } }<BUG2FIX>input . processEvents ( ) ;
public class ImageProcessor { private static final BufferedImage emptyImage = new BufferedImage ( 1 , 1 , BufferedImage . TYPE_4BYTE_ABGR ) ; private static Pattern indexPattern = Pattern . compile ( "(.+)_(\\d+)$" ) ; private String rootPath ; private final Settings settings ; private final HashMap < String , Rect > crcs = new HashMap ( ) ; private final Array < Rect > rects = new Array ( ) ; public ImageProcessor ( File rootDir , Settings settings ) { } public void addImage ( File file ) { BufferedImage image ; try { image = ImageIO . read ( file ) ; } catch ( IOException ex ) { throw new RuntimeException ( ( "Error<seq2seq4repair_space>reading<seq2seq4repair_space>image:<seq2seq4repair_space>" + file ) , ex ) ; } if ( image == null ) throw new RuntimeException ( ( "Unable<seq2seq4repair_space>to<seq2seq4repair_space>read<seq2seq4repair_space>image:<seq2seq4repair_space>" + file ) ) ; String name = file . getAbsolutePath ( ) . replace ( '\\' , '/' ) ; if ( ! ( name . startsWith ( rootPath ) ) ) throw new RuntimeException ( ( ( ( "Path<seq2seq4repair_space>'" + name ) + "'<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>start<seq2seq4repair_space>with<seq2seq4repair_space>root:<seq2seq4repair_space>" ) + ( rootPath ) ) ) ; name = name . substring ( rootPath . length ( ) ) ; int dotIndex = name . lastIndexOf ( '.' ) ; if ( dotIndex != ( - 1 ) ) name = name . substring ( 0 , dotIndex ) ; Rect rect = null ; int [ ] splits = null ; int [ ] pads = null ; if ( name . endsWith ( ".9" ) ) { name = name . substring ( 0 , ( ( name . length ( ) ) - 2 ) ) ; splits = getSplits ( image , name ) ; pads = getPads ( image , name , splits ) ; BufferedImage newImage = new BufferedImage ( ( ( image . getWidth ( ) ) - 2 ) , ( ( image . getHeight ( ) ) - 2 ) , BufferedImage . TYPE_4BYTE_ABGR ) ; newImage . getGraphics ( ) . drawImage ( image , 0 , 0 , newImage . getWidth ( ) , newImage . getHeight ( ) , 1 , 1 , ( ( image . getWidth ( ) ) - 1 ) , ( ( image . getHeight ( ) ) - 1 ) , null ) ; image = newImage ; rect = new Rect ( image , 0 , 0 , image . getWidth ( ) , image . getHeight ( ) ) ; rect . splits = splits ; rect . pads = pads ; rect . canRotate = false ; } Matcher matcher = ImageProcessor . indexPattern . matcher ( name ) ; int index = - 1 ; if ( matcher . matches ( ) ) { name = matcher . group ( 1 ) ; index = Integer . parseInt ( matcher . group ( 2 ) ) ; } if ( rect == null ) { rect = createRect ( image ) ; if ( rect == null ) { System . out . println ( ( "Ignoring<seq2seq4repair_space>blank<seq2seq4repair_space>input<seq2seq4repair_space>image:<seq2seq4repair_space>" + name ) ) ; return ; } } rect . name = name ; rect . index = index ; if ( settings . alias ) { String crc = ImageProcessor . hash ( rect . image ) ; Rect existing = crcs . get ( crc ) ; if ( existing != null ) { System . out . println ( ( ( ( ( rect . name ) + "<seq2seq4repair_space>(alias<seq2seq4repair_space>of<seq2seq4repair_space>" ) + ( existing . name ) ) + ")" ) ) ; <START_BUG> existing . aliases . add ( rect . name ) ; <END_BUG> return ; } crcs . put ( crc , rect ) ; } rects . add ( rect ) ; } public Array < Rect > getImages ( ) { } private Rect createRect ( BufferedImage source ) { } private String splitError ( int x , int y , int [ ] rgba , String name ) { } private int [ ] getSplits ( BufferedImage image , String name ) { } private int [ ] getPads ( BufferedImage image , String name , int [ ] splits ) { } private int getSplitPoint ( WritableRaster raster , String name , int startX , int startY , boolean startPoint , boolean xAxis ) { } private static String hash ( BufferedImage image ) { } }<BUG2FIX>existing . aliases . add ( rect ) ;
public class IdsFilterParser implements FilterParser { public static final String NAME = "ids" ; @ Inject public IdsFilterParser ( ) { } @ Override public String [ ] names ( ) { } @ Override public Filter parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; List < String > ids = new ArrayList < String > ( ) ; Collection < String > types = null ; String filterName = null ; String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_ARRAY ) ) { if ( "values" . equals ( currentFieldName ) ) { while ( ( token = parser . nextToken ( ) ) != ( Token . END_ARRAY ) ) { String value = parser . textOrNull ( ) ; if ( value == null ) { throw new QueryParsingException ( parseContext . index ( ) , "No<seq2seq4repair_space>value<seq2seq4repair_space>specified<seq2seq4repair_space>for<seq2seq4repair_space>term<seq2seq4repair_space>filter" ) ; } ids . add ( value ) ; } } else if ( ( "types" . equals ( currentFieldName ) ) || ( "type" . equals ( currentFieldName ) ) ) { types = new ArrayList < String > ( ) ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_ARRAY ) ) { String value = parser . textOrNull ( ) ; if ( value == null ) { throw new QueryParsingException ( parseContext . index ( ) , "No<seq2seq4repair_space>type<seq2seq4repair_space>specified<seq2seq4repair_space>for<seq2seq4repair_space>term<seq2seq4repair_space>filter" ) ; } types . add ( value ) ; } } else { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[ids]<seq2seq4repair_space>filter<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>support<seq2seq4repair_space>[" + currentFieldName ) + "]" ) ) ; } } else if ( token . isValue ( ) ) { if ( ( "type" . equals ( currentFieldName ) ) || ( "_type" . equals ( currentFieldName ) ) ) { types = ImmutableList . of ( parser . text ( ) ) ; } else if ( "_name" . equals ( currentFieldName ) ) { filterName = parser . text ( ) ; } else { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[ids]<seq2seq4repair_space>filter<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>support<seq2seq4repair_space>[" + currentFieldName ) + "]" ) ) ; } } } if ( ( ids . size ( ) ) == 0 ) { throw new QueryParsingException ( parseContext . index ( ) , "[ids]<seq2seq4repair_space>filter,<seq2seq4repair_space>no<seq2seq4repair_space>ids<seq2seq4repair_space>values<seq2seq4repair_space>provided" ) ; } if ( ( types == null ) || ( types . isEmpty ( ) ) ) { types = parseContext . queryTypes ( ) ; } else if ( ( ( types . size ( ) ) == 1 ) && ( Iterables . getFirst ( types , null ) . equals ( "_all" ) ) ) { types = parseContext . mapperService ( ) . types ( ) ; } <START_BUG> UidFilter filter = new UidFilter ( types , ids , parseContext . indexCache ( ) . bloomCache ( ) ) ; <END_BUG> if ( filterName != null ) { parseContext . addNamedFilter ( filterName , filter ) ; } return filter ; } }<BUG2FIX>UidFilter filter = new UidFilter ( types , ids ) ;
public class TouchpadTest extends GdxTest { Stage stage ; Touchpad touchpad ; public void create ( ) { } public void render ( ) { } public void resize ( int width , int height ) { <START_BUG> stage . getViewport ( ) . update ( width , height ) ; <END_BUG> } public void dispose ( ) { } }<BUG2FIX>stage . getViewport ( ) . update ( width , height , true ) ;
public class RestNodesHotThreadsAction extends BaseRestHandler { @ Inject public RestNodesHotThreadsAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { String [ ] nodesIds = RestActions . splitNodes ( request . param ( "nodeId" ) ) ; NodesHotThreadsRequest nodesHotThreadsRequest = new NodesHotThreadsRequest ( nodesIds ) ; nodesHotThreadsRequest . threads ( request . paramAsInt ( "threads" , nodesHotThreadsRequest . threads ( ) ) ) ; nodesHotThreadsRequest . type ( request . param ( "type" , nodesHotThreadsRequest . type ( ) ) ) ; nodesHotThreadsRequest . interval ( TimeValue . parseTimeValue ( request . param ( "interval" ) , nodesHotThreadsRequest . interval ( ) ) ) ; nodesHotThreadsRequest . snapshots ( request . paramAsInt ( "snapshots" , nodesHotThreadsRequest . snapshots ( ) ) ) ; client . admin ( ) . cluster ( ) . nodesHotThreads ( nodesHotThreadsRequest , new org . elasticsearch . action . ActionListener < NodesHotThreadsResponse > ( ) { @ Override public void onResponse ( NodesHotThreadsResponse response ) { try { StringBuilder sb = new StringBuilder ( ) ; for ( NodeHotThreads node : response ) { sb . append ( ":::<seq2seq4repair_space>" ) . append ( node . getNode ( ) . toString ( ) ) . append ( "\n" ) ; Strings . spaceify ( 3 , node . getHotThreads ( ) , sb ) ; sb . append ( '\n' ) ; } channel . sendResponse ( new StringRestResponse ( RestStatus . OK , sb . toString ( ) ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class JsonShortFieldMapper extends JsonNumberFieldMapper < Short > { public static final String JSON_TYPE = "short" ; public static class Defaults extends JsonNumberFieldMapper . Defaults { public static final Short NULL_VALUE = null ; } public static class Builder extends JsonNumberFieldMapper . Builder < JsonShortFieldMapper . Builder , JsonShortFieldMapper > { protected Short nullValue = JsonShortFieldMapper . Defaults . NULL_VALUE ; public Builder ( String name ) { } public JsonShortFieldMapper . Builder nullValue ( short nullValue ) { } @ Override public JsonShortFieldMapper build ( BuilderContext context ) { } } public static class TypeParser implements JsonTypeParser { @ Override public JsonMapper . Builder parse ( String name , JsonNode node , ParserContext parserContext ) throws MapperParsingException { } } private final Short nullValue ; private final String nullValueAsString ; protected JsonShortFieldMapper ( Names names , int precisionStep , Field . Index index , Field . Store store , float boost , boolean omitNorms , boolean omitTermFreqAndPositions , Short nullValue ) { } @ Override protected int maxPrecisionStep ( ) { } @ Override public Short value ( Fieldable field ) { byte [ ] value = field . getBinaryValue ( ) ; if ( value == null ) { <START_BUG> return Short . MIN_VALUE ; <END_BUG> } return Numbers . bytesToShort ( value ) ; } @ Override public String indexedValue ( String value ) { } @ Override public String indexedValue ( Short value ) { } @ Override public Object valueFromTerm ( String term ) { } @ Override public Object valueFromString ( String text ) { } @ Override public Query rangeQuery ( String lowerTerm , String upperTerm , boolean includeLower , boolean includeUpper ) { } @ Override public Filter rangeFilter ( String lowerTerm , String upperTerm , boolean includeLower , boolean includeUpper ) { } @ Override protected Field parseCreateField ( JsonParseContext jsonContext ) throws IOException { } @ Override public int sortType ( ) { } @ Override protected String jsonType ( ) { } @ Override protected void doJsonBody ( JsonBuilder builder ) throws IOException { } }<BUG2FIX>return null ;
public class RestIndicesExistsAction extends BaseRestHandler { private final SettingsFilter settingsFilter ; @ Inject public RestIndicesExistsAction ( Settings settings , Client client , RestController controller , SettingsFilter settingsFilter ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { IndicesExistsRequest indicesExistsRequest = new IndicesExistsRequest ( splitIndices ( request . param ( "index" ) ) ) ; indicesExistsRequest . listenerThreaded ( false ) ; client . admin ( ) . indices ( ) . exists ( indicesExistsRequest , new org . elasticsearch . action . ActionListener < IndicesExistsResponse > ( ) { @ Override public void onResponse ( IndicesExistsResponse response ) { try { if ( response . isExists ( ) ) { channel . sendResponse ( new StringRestResponse ( RestStatus . OK ) ) ; } else { channel . sendResponse ( new StringRestResponse ( RestStatus . NOT_FOUND ) ) ; } <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new StringRestResponse ( ExceptionsHelper . status ( e ) ) ) ; } catch ( Exception e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class MembersFragment extends ItemListFragment < User > implements OrganizationSelectionListener { private User org ; @ Inject private OrganizationService service ; @ Inject private AvatarLoader avatarHelper ; @ Override public void onAttach ( Activity activity ) { } @ Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; <START_BUG> setEmptyText ( getString ( no_members ) ) ; <END_BUG> } @ Override public Loader < List < User > > onCreateLoader ( int id , Bundle args ) { } @ Override protected ItemListAdapter < User , ? extends ItemView > createAdapter ( List < User > items ) { } @ Override public void onOrganizationSelected ( User organization ) { } @ Override public void onListItemClick ( ListView l , View v , int position , long id ) { } }<BUG2FIX>setEmptyText ( no_members ) ;
class TmxMapHelper { static final int FLAG_FLIP_HORIZONTALLY = - 2147483648 ; static final int FLAG_FLIP_VERTICALLY = 1073741824 ; static final int FLAG_FLIP_DIAGONALLY = 536870912 ; static final int MASK_CLEAR = - 536870912 ; private TmxMapHelper ( ) { } static int [ ] getTileIds ( Element element , int width , int height ) { Element data = element . getChildByName ( "data" ) ; String encoding = data . getAttribute ( "encoding" , null ) ; if ( encoding == null ) { throw new GdxRuntimeException ( "Unsupported<seq2seq4repair_space>encoding<seq2seq4repair_space>(XML)<seq2seq4repair_space>for<seq2seq4repair_space>TMX<seq2seq4repair_space>Layer<seq2seq4repair_space>Data" ) ; } int [ ] ids = new int [ width * height ] ; if ( encoding . equals ( "csv" ) ) { String [ ] array = data . getText ( ) . split ( "," ) ; for ( int i = 0 ; i < ( array . length ) ; i ++ ) <START_BUG> ids [ i ] = ( ( int ) ( Long . parseLong ( array [ i ] . trim ( ) ) ) ) ; <END_BUG> } else { if ( true ) if ( encoding . equals ( "base64" ) ) { InputStream is = null ; try { String compression = data . getAttribute ( "compression" , null ) ; byte [ ] bytes = Base64Coder . decode ( data . getText ( ) ) ; if ( compression == null ) is = new ByteArrayInputStream ( bytes ) ; else if ( compression . equals ( "gzip" ) ) is = new GZIPInputStream ( new ByteArrayInputStream ( bytes ) , bytes . length ) ; else if ( compression . equals ( "zlib" ) ) is = new InflaterInputStream ( new ByteArrayInputStream ( bytes ) ) ; else throw new GdxRuntimeException ( ( ( "Unrecognised<seq2seq4repair_space>compression<seq2seq4repair_space>(" + compression ) + ")<seq2seq4repair_space>for<seq2seq4repair_space>TMX<seq2seq4repair_space>Layer<seq2seq4repair_space>Data" ) ) ; byte [ ] temp = new byte [ 4 ] ; for ( int y = 0 ; y < height ; y ++ ) { for ( int x = 0 ; x < width ; x ++ ) { if ( ( is . read ( temp ) ) != ( temp . length ) ) throw new GdxRuntimeException ( "Error<seq2seq4repair_space>Reading<seq2seq4repair_space>TMX<seq2seq4repair_space>Layer<seq2seq4repair_space>Data:<seq2seq4repair_space>Premature<seq2seq4repair_space>end<seq2seq4repair_space>of<seq2seq4repair_space>tile<seq2seq4repair_space>data" ) ; ids [ ( ( y * width ) + x ) ] = ( ( ( TmxMapHelper . unsignedByteToInt ( temp [ 0 ] ) ) | ( ( TmxMapHelper . unsignedByteToInt ( temp [ 1 ] ) ) << 8 ) ) | ( ( TmxMapHelper . unsignedByteToInt ( temp [ 2 ] ) ) << 16 ) ) | ( ( TmxMapHelper . unsignedByteToInt ( temp [ 3 ] ) ) << 24 ) ; } } } catch ( IOException e ) { throw new GdxRuntimeException ( ( "Error<seq2seq4repair_space>Reading<seq2seq4repair_space>TMX<seq2seq4repair_space>Layer<seq2seq4repair_space>Data<seq2seq4repair_space>-<seq2seq4repair_space>IOException:<seq2seq4repair_space>" + ( e . getMessage ( ) ) ) ) ; } finally { StreamUtils . closeQuietly ( is ) ; } } else { throw new GdxRuntimeException ( ( ( "Unrecognised<seq2seq4repair_space>encoding<seq2seq4repair_space>(" + encoding ) + ")<seq2seq4repair_space>for<seq2seq4repair_space>TMX<seq2seq4repair_space>Layer<seq2seq4repair_space>Data" ) ) ; } } return ids ; } static int unsignedByteToInt ( byte b ) { } }<BUG2FIX>ids [ i ] = ( ( int ) ( Long . parseLong ( array [ i ] ) ) ) ;
public class MultiValueByteFieldData extends ByteFieldData { private static final int VALUE_CACHE_SIZE = 10 ; private ThreadLocal < ThreadLocals . CleanableValue < double [ ] [ ] > > doublesValuesCache = new ThreadLocal < ThreadLocals . CleanableValue < double [ ] [ ] > > ( ) { @ Override protected ThreadLocals . CleanableValue < double [ ] [ ] > initialValue ( ) { } } ; private ThreadLocal < ThreadLocals . CleanableValue < byte [ ] [ ] > > valuesCache = new ThreadLocal < ThreadLocals . CleanableValue < byte [ ] [ ] > > ( ) { @ Override protected ThreadLocals . CleanableValue < byte [ ] [ ] > initialValue ( ) { } } ; private final int [ ] [ ] ordinals ; public MultiValueByteFieldData ( String fieldName , int [ ] [ ] ordinals , byte [ ] values ) { } @ Override protected long computeSizeInBytes ( ) { } @ Override public boolean multiValued ( ) { } @ Override public boolean hasValue ( int docId ) { } @ Override public void forEachValueInDoc ( int docId , StringValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , DoubleValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , LongValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , MissingDoubleValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , MissingLongValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , ValueInDocProc proc ) { } @ Override public void forEachOrdinalInDoc ( int docId , OrdinalInDocProc proc ) { boolean found = false ; for ( int [ ] ordinal : ordinals ) { int loc = ordinal [ docId ] ; if ( loc != 0 ) { found = true ; <START_BUG> proc . onOrdinal ( docId , ordinal [ docId ] ) ; <END_BUG> } } if ( ! found ) { proc . onOrdinal ( docId , 0 ) ; } } @ Override public double [ ] doubleValues ( int docId ) { } @ Override public byte value ( int docId ) { } @ Override public byte [ ] values ( int docId ) { } }<BUG2FIX>proc . onOrdinal ( docId , loc ) ;
public class RangeFacetProcessor extends AbstractComponent implements FacetProcessor { @ Inject public RangeFacetProcessor ( Settings settings ) { } @ Override public String [ ] types ( ) { } @ Override public FacetCollector parse ( String facetName , XContentParser parser , SearchContext context ) throws IOException { String keyField = null ; String valueField = null ; String scriptLang = null ; String keyScript = null ; String valueScript = null ; Map < String , Object > params = null ; XContentParser . Token token ; String fieldName = null ; List < RangeFacet . Entry > entries = Lists . newArrayList ( ) ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { fieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_ARRAY ) ) { if ( ! ( "ranges" . equals ( fieldName ) ) ) { keyField = fieldName ; } while ( ( token = parser . nextToken ( ) ) != ( Token . END_ARRAY ) ) { RangeFacet . Entry entry = new RangeFacet . Entry ( ) ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { fieldName = parser . currentName ( ) ; } else if ( token == ( Token . VALUE_STRING ) ) { if ( "from" . equals ( fieldName ) ) { entry . fromAsString = parser . text ( ) ; } else if ( "to" . equals ( fieldName ) ) { entry . toAsString = parser . text ( ) ; } } else if ( token . isValue ( ) ) { if ( "from" . equals ( fieldName ) ) { entry . from = parser . doubleValue ( ) ; } else if ( "to" . equals ( fieldName ) ) { entry . to = parser . doubleValue ( ) ; } } } entries . add ( entry ) ; } } else if ( token == ( Token . START_OBJECT ) ) { if ( "params" . equals ( fieldName ) ) { params = parser . map ( ) ; } } else if ( token . isValue ( ) ) { if ( "field" . equals ( fieldName ) ) { keyField = parser . text ( ) ; } else if ( ( "key_field" . equals ( fieldName ) ) || ( "keyField" . equals ( fieldName ) ) ) { keyField = parser . text ( ) ; } else if ( ( "value_field" . equals ( fieldName ) ) || ( "valueField" . equals ( fieldName ) ) ) { valueField = parser . text ( ) ; } else if ( ( "key_script" . equals ( fieldName ) ) || ( "keyScript" . equals ( fieldName ) ) ) { keyScript = parser . text ( ) ; } else if ( ( "value_script" . equals ( fieldName ) ) || ( "valueScript" . equals ( fieldName ) ) ) { valueScript = parser . text ( ) ; } else if ( "lang" . equals ( fieldName ) ) { scriptLang = parser . text ( ) ; } } } if ( entries . isEmpty ( ) ) { throw new FacetPhaseExecutionException ( facetName , "no<seq2seq4repair_space>ranges<seq2seq4repair_space>defined<seq2seq4repair_space>for<seq2seq4repair_space>range<seq2seq4repair_space>facet" ) ; } RangeFacet [ ] rangeEntries = entries . toArray ( new RangeFacet . Entry [ entries . size ( ) ] ) ; if ( keyField != null ) { <START_BUG> FieldMapper mapper = context . mapperService ( ) . smartNameFieldMapper ( keyField ) ; <END_BUG> if ( mapper == null ) { throw new FacetPhaseExecutionException ( facetName , ( ( "No<seq2seq4repair_space>mapping<seq2seq4repair_space>found<seq2seq4repair_space>for<seq2seq4repair_space>key_field<seq2seq4repair_space>[" + keyField ) + "]" ) ) ; } for ( RangeFacet . Entry entry : rangeEntries ) { if ( ( entry . fromAsString ) != null ) { entry . from = ( ( Number ) ( mapper . valueFromString ( entry . fromAsString ) ) ) . doubleValue ( ) ; } if ( ( entry . toAsString ) != null ) { entry . to = ( ( Number ) ( mapper . valueFromString ( entry . toAsString ) ) ) . doubleValue ( ) ; } } } if ( ( keyScript != null ) && ( valueScript != null ) ) { return new ScriptRangeFacetCollector ( facetName , scriptLang , keyScript , valueScript , params , rangeEntries , context ) ; } if ( keyField == null ) { throw new FacetPhaseExecutionException ( facetName , "key<seq2seq4repair_space>field<seq2seq4repair_space>is<seq2seq4repair_space>required<seq2seq4repair_space>to<seq2seq4repair_space>be<seq2seq4repair_space>set<seq2seq4repair_space>for<seq2seq4repair_space>range<seq2seq4repair_space>facet,<seq2seq4repair_space>either<seq2seq4repair_space>using<seq2seq4repair_space>[field]<seq2seq4repair_space>or<seq2seq4repair_space>using<seq2seq4repair_space>[key_field]" ) ; } if ( ( valueField == null ) || ( keyField . equals ( valueField ) ) ) { return new RangeFacetCollector ( facetName , keyField , rangeEntries , context ) ; } else { return new KeyValueRangeFacetCollector ( facetName , keyField , valueField , rangeEntries , context ) ; } } @ Override public Facet reduce ( String name , List < Facet > facets ) { } }<BUG2FIX>FieldMapper mapper = context . smartNameFieldMapper ( keyField ) ;
public class TransportDeleteWarmerAction extends TransportMasterNodeOperationAction < DeleteWarmerRequest , DeleteWarmerResponse > { @ Inject public TransportDeleteWarmerAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected DeleteWarmerRequest newRequest ( ) { } @ Override protected DeleteWarmerResponse newResponse ( ) { } @ Override protected void doExecute ( DeleteWarmerRequest request , ActionListener < DeleteWarmerResponse > listener ) { <START_BUG> request . indices ( clusterService . state ( ) . metaData ( ) . concreteIndices ( request . indices ( ) , request . indicesOptions ( ) ) ) ; <END_BUG> super . doExecute ( request , listener ) ; } @ Override protected ClusterBlockException checkBlock ( DeleteWarmerRequest request , ClusterState state ) { } @ Override protected void masterOperation ( final DeleteWarmerRequest request , final ClusterState state , final ActionListener < DeleteWarmerResponse > listener ) throws ElasticsearchException { } }<BUG2FIX>request . indices ( clusterService . state ( ) . metaData ( ) . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ) ;
public class FieldQueryParser extends AbstractIndexComponent implements XContentQueryParser { public static final String NAME = "field" ; private final AnalysisService analysisService ; @ Inject public FieldQueryParser ( Index index , @ IndexSettings Settings settings , AnalysisService analysisService ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; XContentParser . Token token = parser . nextToken ( ) ; assert token == ( Token . FIELD_NAME ) ; String fieldName = parser . currentName ( ) ; String queryString = null ; float boost = 1.0F ; MapperQueryParser . Operator defaultOperator = Operator . OR ; boolean lowercaseExpandedTerms = true ; boolean enablePositionIncrements = true ; int phraseSlop = 0 ; float fuzzyMinSim = FuzzyQuery . defaultMinSimilarity ; int fuzzyPrefixLength = FuzzyQuery . defaultPrefixLength ; boolean escape = false ; Analyzer analyzer = null ; token = parser . nextToken ( ) ; if ( token == ( Token . START_OBJECT ) ) { String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token . isValue ( ) ) { if ( "query" . equals ( currentFieldName ) ) { queryString = parser . text ( ) ; } else if ( "boost" . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } else if ( ( "enable_position_increments" . equals ( currentFieldName ) ) || ( "enablePositionIncrements" . equals ( currentFieldName ) ) ) { enablePositionIncrements = parser . booleanValue ( ) ; } else if ( ( "lowercase_expanded_terms" . equals ( currentFieldName ) ) || ( "lowercaseExpandedTerms" . equals ( currentFieldName ) ) ) { lowercaseExpandedTerms = parser . booleanValue ( ) ; } else if ( ( "phrase_slop" . equals ( currentFieldName ) ) || ( "phraseSlop" . equals ( currentFieldName ) ) ) { phraseSlop = parser . intValue ( ) ; } else if ( "analyzer" . equals ( currentFieldName ) ) { analyzer = analysisService . analyzer ( parser . text ( ) ) ; } else if ( ( "default_operator" . equals ( currentFieldName ) ) || ( "defaultOperator" . equals ( currentFieldName ) ) ) { String op = parser . text ( ) ; if ( "or" . equalsIgnoreCase ( op ) ) { defaultOperator = Operator . OR ; } else if ( "and" . equalsIgnoreCase ( op ) ) { defaultOperator = Operator . AND ; } else { throw new QueryParsingException ( index , ( ( "Query<seq2seq4repair_space>default<seq2seq4repair_space>operator<seq2seq4repair_space>[" + op ) + "]<seq2seq4repair_space>is<seq2seq4repair_space>not<seq2seq4repair_space>allowed" ) ) ; } } else if ( ( "fuzzy_min_sim" . equals ( currentFieldName ) ) || ( "fuzzyMinSim" . equals ( currentFieldName ) ) ) { fuzzyMinSim = parser . floatValue ( ) ; } else if ( ( "fuzzy_prefix_length" . equals ( currentFieldName ) ) || ( "fuzzyPrefixLength" . equals ( currentFieldName ) ) ) { fuzzyPrefixLength = parser . intValue ( ) ; } else if ( "escape" . equals ( currentFieldName ) ) { escape = parser . booleanValue ( ) ; } } } parser . nextToken ( ) ; } else { queryString = parser . text ( ) ; parser . nextToken ( ) ; } if ( analyzer == null ) { analyzer = parseContext . mapperService ( ) . searchAnalyzer ( ) ; } if ( queryString == null ) { throw new QueryParsingException ( index , "No<seq2seq4repair_space>value<seq2seq4repair_space>specified<seq2seq4repair_space>for<seq2seq4repair_space>term<seq2seq4repair_space>query" ) ; } <START_BUG> MapperQueryParser queryParser = new MapperQueryParser ( fieldName , analyzer , parseContext . mapperService ( ) , parseContext . indexCache ( ) ) ; <END_BUG> queryParser . setEnablePositionIncrements ( enablePositionIncrements ) ; queryParser . setLowercaseExpandedTerms ( lowercaseExpandedTerms ) ; queryParser . setPhraseSlop ( phraseSlop ) ; queryParser . setDefaultOperator ( defaultOperator ) ; queryParser . setFuzzyMinSim ( fuzzyMinSim ) ; queryParser . setFuzzyPrefixLength ( fuzzyPrefixLength ) ; if ( escape ) { queryString = QueryParser . escape ( queryString ) ; } try { Query query = queryParser . parse ( queryString ) ; query . setBoost ( boost ) ; return optimizeQuery ( fixNegativeQueryIfNeeded ( query ) ) ; } catch ( ParseException e ) { throw new QueryParsingException ( index , ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>parse<seq2seq4repair_space>query<seq2seq4repair_space>[" + queryString ) + "]" ) , e ) ; } } }<BUG2FIX>MapperQueryParser queryParser = new MapperQueryParser ( fieldName , analyzer , parseContext ) ;
@ Test public class MoreLikeThisQueryTests { @ Test public void testSimple ( ) throws Exception { Directory dir = new RAMDirectory ( ) ; IndexWriter indexWriter = new IndexWriter ( dir , new org . apache . lucene . index . IndexWriterConfig ( Lucene . VERSION , Lucene . STANDARD_ANALYZER ) ) ; indexWriter . commit ( ) ; indexWriter . addDocument ( doc ( ) . add ( field ( "_id" , "1" ) ) . add ( field ( "text" , "lucene" ) ) . build ( ) ) ; indexWriter . addDocument ( doc ( ) . add ( field ( "_id" , "2" ) ) . add ( field ( "text" , "lucene<seq2seq4repair_space>release" ) ) . build ( ) ) ; IndexReader reader = IndexReader . open ( indexWriter , true ) ; IndexSearcher searcher = new IndexSearcher ( reader ) ; MoreLikeThisQuery mltQuery = new MoreLikeThisQuery ( "lucene" , new String [ ] { "text" } , Lucene . STANDARD_ANALYZER ) ; mltQuery . setLikeText ( "lucene" ) ; mltQuery . setMinTermFrequency ( 1 ) ; mltQuery . setMinDocFreq ( 1 ) ; <START_BUG> long count = Lucene . count ( searcher , mltQuery , ( - 1 ) ) ; <END_BUG> assertThat ( count , equalTo ( 2L ) ) ; reader . close ( ) ; indexWriter . close ( ) ; } }<BUG2FIX>long count = Lucene . count ( searcher , mltQuery ) ;
public class BooleanArray { public boolean [ ] items ; public int size ; public boolean ordered ; public BooleanArray ( ) { } public BooleanArray ( int capacity ) { } public BooleanArray ( boolean ordered , int capacity ) { } public BooleanArray ( BooleanArray array ) { } public BooleanArray ( boolean [ ] array ) { } public BooleanArray ( boolean ordered , boolean [ ] array ) { } public void add ( boolean value ) { } public void addAll ( BooleanArray array ) { } public void addAll ( BooleanArray array , int offset , int length ) { } public void addAll ( boolean [ ] array ) { } public void addAll ( boolean [ ] array , int offset , int length ) { } public boolean get ( int index ) { } public void set ( int index , boolean value ) { } public void insert ( int index , boolean value ) { } public void swap ( int first , int second ) { } public boolean removeIndex ( int index ) { } public boolean removeAll ( BooleanArray array ) { int size = this . size ; int startSize = size ; boolean [ ] items = this . items ; for ( int i = 0 , n = array . size ; i < n ; i ++ ) { boolean item = array . get ( i ) ; <START_BUG> for ( int ii = 0 , nn = size ; ii < nn ; ii ++ ) { <END_BUG> if ( item == ( items [ ii ] ) ) { removeIndex ( ii ) ; size -- ; break ; } } } return size != startSize ; } public boolean pop ( ) { } public boolean peek ( ) { } public boolean first ( ) { } public void clear ( ) { } public void shrink ( ) { } public boolean [ ] ensureCapacity ( int additionalCapacity ) { } protected boolean [ ] resize ( int newSize ) { } public void reverse ( ) { } public void shuffle ( ) { } public void truncate ( int newSize ) { } public boolean random ( ) { } public boolean [ ] toArray ( ) { } public boolean equals ( Object object ) { } public String toString ( ) { } public String toString ( String separator ) { } }<BUG2FIX>for ( int ii = 0 ; ii < size ; ii ++ ) {
public class IssuesFragment extends PagedItemFragment < Issue > { @ Inject private AccountDataManager cache ; @ Inject private IssueService service ; @ Inject private IssueStore store ; @ InjectExtra ( value = Intents . EXTRA_ISSUE_FILTER , optional = true ) private IssueFilter filter ; @ InjectExtra ( Intents . EXTRA_REPOSITORY ) private Repository repository ; private View filterHeader ; private TextView state ; private ImageView assigneeAvatar ; private View assigneeArea ; private TextView assignee ; private TextView labels ; private TextView milestone ; @ Inject private AvatarLoader avatars ; @ Override public void onCreate ( Bundle savedInstanceState ) { } @ Override public void onViewCreated ( View view , Bundle savedInstanceState ) { } @ Override protected void configureList ( Activity activity , ListView listView ) { super . configureList ( activity , listView ) ; <START_BUG> getListAdapter ( ) . addHeader ( filterHeader , null , false ) ; <END_BUG> } private void updateFilterSummary ( ) { } @ Override public void onActivityCreated ( Bundle savedInstanceState ) { } @ Override public void onListItemClick ( ListView l , View v , int position , long id ) { } @ Override public void onCreateOptionsMenu ( Menu optionsMenu , MenuInflater inflater ) { } @ Override public boolean onOptionsItemSelected ( MenuItem item ) { } @ Override public void onActivityResult ( int requestCode , int resultCode , Intent data ) { } @ Override protected ResourcePager < Issue > createPager ( ) { } @ Override protected int getLoadingMessage ( ) { } @ Override protected int getErrorMessage ( Exception exception ) { } @ Override protected SingleTypeAdapter < Issue > createAdapter ( List < Issue > items ) { } }<BUG2FIX>getListAdapter ( ) . addHeader ( filterHeader ) ;
public class CustomScoreQueryBuilder extends BaseQueryBuilder { private final XContentQueryBuilder queryBuilder ; private String script ; private String lang ; private float boost = - 1 ; private Map < String , Object > params = null ; public CustomScoreQueryBuilder ( XContentQueryBuilder queryBuilder ) { } public CustomScoreQueryBuilder script ( String script ) { } public CustomScoreQueryBuilder lang ( String lang ) { } public CustomScoreQueryBuilder params ( Map < String , Object > params ) { <START_BUG> if ( params == null ) { <END_BUG> this . params = params ; } else { this . params . putAll ( params ) ; } return this ; } public CustomScoreQueryBuilder param ( String key , Object value ) { } public CustomScoreQueryBuilder boost ( float boost ) { } @ Override protected void doXContent ( XContentBuilder builder , Params params ) throws IOException { } }<BUG2FIX>if ( ( this . params ) == null ) {
public class IndicesTTLService extends AbstractLifecycleComponent < IndicesTTLService > { private final ClusterService clusterService ; private final IndicesService indicesService ; private final Client client ; private volatile TimeValue interval ; private final int bulkSize ; private IndicesTTLService . PurgerThread purgerThread ; @ Inject public IndicesTTLService ( Settings settings , ClusterService clusterService , IndicesService indicesService , NodeSettingsService nodeSettingsService , Client client ) { } @ Override protected void doStart ( ) throws ElasticSearchException { } @ Override protected void doStop ( ) throws ElasticSearchException { } @ Override protected void doClose ( ) throws ElasticSearchException { } private class PurgerThread extends Thread { volatile boolean running = true ; public PurgerThread ( String name ) { } public void doStop ( ) { } public void run ( ) { } private List < IndexShard > getShardsToPurge ( ) { } } private void purgeShards ( List < IndexShard > shardsToPurge ) { } private static class DocToPurge { public final String type ; public final String id ; public final long version ; public final String routing ; public DocToPurge ( String type , String id , long version , String routing ) { } } private class ExpiredDocsCollector extends Collector { private AtomicReaderContext context ; private List < IndicesTTLService . DocToPurge > docsToPurge = new ArrayList < IndicesTTLService . DocToPurge > ( ) ; public ExpiredDocsCollector ( ) { } public void setScorer ( Scorer scorer ) { } public boolean acceptsDocsOutOfOrder ( ) { } public void collect ( int doc ) { try { UidAndRoutingFieldVisitor fieldVisitor = new UidAndRoutingFieldVisitor ( ) ; <START_BUG> context . reader ( ) . document ( doc , new UidAndRoutingFieldVisitor ( ) ) ; <END_BUG> String uid = fieldVisitor . uid ( ) ; long version = UidField . loadVersion ( context , new org . apache . lucene . index . Term ( UidFieldMapper . NAME , uid ) ) ; docsToPurge . add ( new IndicesTTLService . DocToPurge ( Uid . typeFromUid ( uid ) , Uid . idFromUid ( uid ) , version , fieldVisitor . routing ( ) ) ) ; } catch ( Exception e ) { logger . trace ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>collect<seq2seq4repair_space>doc" , e ) ; } } public void setNextReader ( AtomicReaderContext context ) throws IOException { } public List < IndicesTTLService . DocToPurge > getDocsToPurge ( ) { } } private BulkRequestBuilder processBulkIfNeeded ( BulkRequestBuilder bulkRequest , boolean force ) { } class ApplySettings implements NodeSettingsService . Listener { @ Override public void onRefreshSettings ( Settings settings ) { } } }<BUG2FIX>context . reader ( ) . document ( doc , fieldVisitor ) ;
public class TransportIndexAction extends TransportShardReplicationOperationAction < IndexRequest , IndexRequest , IndexResponse > { private final AutoCreateIndex autoCreateIndex ; private final boolean allowIdGeneration ; private final TransportCreateIndexAction createIndexAction ; private final MappingUpdatedAction mappingUpdatedAction ; private final boolean waitForMappingChange ; @ Inject public TransportIndexAction ( Settings settings , TransportService transportService , ClusterService clusterService , IndicesService indicesService , ThreadPool threadPool , ShardStateAction shardStateAction , TransportCreateIndexAction createIndexAction , MappingUpdatedAction mappingUpdatedAction ) { } @ Override protected void doExecute ( final IndexRequest request , final ActionListener < IndexResponse > listener ) { } @ Override protected boolean resolveRequest ( ClusterState state , IndexRequest request , ActionListener < IndexResponse > indexResponseActionListener ) { } private void innerExecute ( final IndexRequest request , final ActionListener < IndexResponse > listener ) { } @ Override protected boolean checkWriteConsistency ( ) { } @ Override protected IndexRequest newRequestInstance ( ) { } @ Override protected IndexRequest newReplicaRequestInstance ( ) { } @ Override protected IndexResponse newResponseInstance ( ) { } @ Override protected String transportAction ( ) { } @ Override protected String executor ( ) { } @ Override protected ClusterBlockException checkGlobalBlock ( ClusterState state , IndexRequest request ) { } @ Override protected ClusterBlockException checkRequestBlock ( ClusterState state , IndexRequest request ) { } @ Override protected ShardIterator shards ( ClusterState clusterState , IndexRequest request ) { } @ Override protected PrimaryResponse < IndexResponse , IndexRequest > shardOperationOnPrimary ( ClusterState clusterState , PrimaryOperationRequest shardRequest ) { final IndexRequest request = shardRequest . request ; MappingMetaData mappingMd = clusterState . metaData ( ) . index ( request . index ( ) ) . mappingOrDefault ( request . type ( ) ) ; if ( ( mappingMd != null ) && ( mappingMd . routing ( ) . required ( ) ) ) { if ( ( request . routing ( ) ) == null ) { throw new org . elasticsearch . action . RoutingMissingException ( request . index ( ) , request . type ( ) , request . id ( ) ) ; } } IndexShard indexShard = indicesService . indexServiceSafe ( shardRequest . request . index ( ) ) . shardSafe ( shardRequest . shardId ) ; SourceToParse sourceToParse = SourceToParse . source ( PRIMARY , request . source ( ) ) . type ( request . type ( ) ) . id ( request . id ( ) ) . routing ( request . routing ( ) ) . parent ( request . parent ( ) ) . timestamp ( request . timestamp ( ) ) . ttl ( request . ttl ( ) ) ; long version ; boolean created ; Engine . IndexingOperation op ; if ( ( request . opType ( ) ) == ( OpType . INDEX ) ) { Engine . Index index = indexShard . prepareIndex ( sourceToParse ) . version ( request . version ( ) ) . versionType ( request . versionType ( ) ) . origin ( Engine . Operation . Origin . PRIMARY ) ; indexShard . index ( index ) ; version = index . version ( ) ; op = index ; created = index . created ( ) ; } else { Engine . Create create = indexShard . prepareCreate ( sourceToParse ) . version ( request . version ( ) ) . versionType ( request . versionType ( ) ) . origin ( Engine . Operation . Origin . PRIMARY ) ; indexShard . create ( create ) ; version = create . version ( ) ; op = create ; created = true ; } if ( request . refresh ( ) ) { try { indexShard . refresh ( new Engine . Refresh ( ) . force ( false ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> } } if ( op . parsedDoc ( ) . mappingsModified ( ) ) { updateMappingOnMaster ( request ) ; } request . version ( version ) ; IndexResponse response = new IndexResponse ( request . index ( ) , request . type ( ) , request . id ( ) , version , created ) ; return new PrimaryResponse < IndexResponse , IndexRequest > ( shardRequest . request , response , op ) ; } @ Override protected void shardOperationOnReplica ( ReplicaOperationRequest shardRequest ) { } private void updateMappingOnMaster ( final IndexRequest request ) { } }<BUG2FIX>} catch ( Throwable e ) {
public class TransportMultiSearchAction extends TransportAction < MultiSearchRequest , MultiSearchResponse > { private final ClusterService clusterService ; private final TransportSearchAction searchAction ; @ Inject public TransportMultiSearchAction ( Settings settings , ThreadPool threadPool , TransportService transportService , ClusterService clusterService , TransportSearchAction searchAction ) { } @ Override protected void doExecute ( final MultiSearchRequest request , final ActionListener < MultiSearchResponse > listener ) { ClusterState clusterState = clusterService . state ( ) ; clusterState . blocks ( ) . globalBlockedRaiseException ( READ ) ; <START_BUG> final AtomicArray < MultiSearchResponse . Item > responses = new AtomicArray < MultiSearchResponse . Item > ( request . requests ( ) . size ( ) ) ; <END_BUG> final AtomicInteger counter = new AtomicInteger ( responses . length ( ) ) ; for ( int i = 0 ; i < ( responses . length ( ) ) ; i ++ ) { final int index = i ; searchAction . execute ( request . requests ( ) . get ( i ) , new ActionListener < SearchResponse > ( ) { @ Override public void onResponse ( SearchResponse searchResponse ) { responses . set ( index , new MultiSearchResponse . Item ( searchResponse , null ) ) ; if ( ( counter . decrementAndGet ( ) ) == 0 ) { finishHim ( ) ; } } @ Override public void onFailure ( Throwable e ) { responses . set ( index , new MultiSearchResponse . Item ( null , ExceptionsHelper . detailedMessage ( e ) ) ) ; if ( ( counter . decrementAndGet ( ) ) == 0 ) { finishHim ( ) ; } } private void finishHim ( ) { listener . onResponse ( new MultiSearchResponse ( responses . toArray ( new MultiSearchResponse . Item [ responses . length ( ) ] ) ) ) ; } } ) ; } } class TransportHandler extends BaseTransportRequestHandler < MultiSearchRequest > { @ Override public MultiSearchRequest newInstance ( ) { } @ Override public void messageReceived ( final MultiSearchRequest request , final TransportChannel channel ) throws Exception { } @ Override public String executor ( ) { } } }<BUG2FIX>final AtomicArray < MultiSearchResponse . Item > responses = new AtomicArray ( request . requests ( ) . size ( ) ) ;
public abstract class FieldDataTermsFilter extends Filter { final IndexFieldData fieldData ; protected FieldDataTermsFilter ( IndexFieldData fieldData ) { } public static FieldDataTermsFilter newBytes ( IndexFieldData fieldData , ObjectOpenHashSet < BytesRef > terms ) { } public static FieldDataTermsFilter newLongs ( IndexNumericFieldData fieldData , LongOpenHashSet terms ) { } public static FieldDataTermsFilter newDoubles ( IndexNumericFieldData fieldData , DoubleOpenHashSet terms ) { } @ Override public boolean equals ( Object obj ) { } @ Override public abstract int hashCode ( ) { } @ Override public abstract String toString ( ) { } protected static class BytesFieldDataFilter extends FieldDataTermsFilter { final ObjectOpenHashSet < BytesRef > terms ; protected BytesFieldDataFilter ( IndexFieldData fieldData , ObjectOpenHashSet < BytesRef > terms ) { } @ Override public int hashCode ( ) { } @ Override public String toString ( ) { } @ Override public DocIdSet getDocIdSet ( AtomicReaderContext context , Bits acceptDocs ) throws IOException { if ( ( ( terms ) == null ) || ( terms . isEmpty ( ) ) ) return null ; <START_BUG> final BytesValues values = fieldData . load ( context ) . getBytesValues ( false ) ; <END_BUG> return new MatchDocIdSet ( context . reader ( ) . maxDoc ( ) , acceptDocs ) { @ Override protected boolean matchDoc ( int doc ) { final int numVals = values . setDocument ( doc ) ; for ( int i = 0 ; i < numVals ; i ++ ) { if ( terms . contains ( values . nextValue ( ) ) ) { return true ; } } return false ; } } ; } } protected static class LongsFieldDataFilter extends FieldDataTermsFilter { final LongOpenHashSet terms ; protected LongsFieldDataFilter ( IndexNumericFieldData fieldData , LongOpenHashSet terms ) { } @ Override public int hashCode ( ) { } @ Override public String toString ( ) { } @ Override public DocIdSet getDocIdSet ( AtomicReaderContext context , Bits acceptDocs ) throws IOException { if ( ( ( terms ) == null ) || ( terms . isEmpty ( ) ) ) return null ; IndexNumericFieldData numericFieldData = ( ( IndexNumericFieldData ) ( fieldData ) ) ; if ( ! ( numericFieldData . getNumericType ( ) . isFloatingPoint ( ) ) ) { final LongValues values = numericFieldData . load ( context ) . getLongValues ( ) ; return new MatchDocIdSet ( context . reader ( ) . maxDoc ( ) , acceptDocs ) { @ Override protected boolean matchDoc ( int doc ) { final int numVals = values . setDocument ( doc ) ; for ( int i = 0 ; i < numVals ; i ++ ) { if ( terms . contains ( values . nextValue ( ) ) ) { return true ; } } return false ; } } ; } return null ; } } protected static class DoublesFieldDataFilter extends FieldDataTermsFilter { final DoubleOpenHashSet terms ; protected DoublesFieldDataFilter ( IndexNumericFieldData fieldData , DoubleOpenHashSet terms ) { } @ Override public int hashCode ( ) { } @ Override public String toString ( ) { } @ Override public DocIdSet getDocIdSet ( AtomicReaderContext context , Bits acceptDocs ) throws IOException { if ( ( ( terms ) == null ) || ( terms . isEmpty ( ) ) ) return null ; IndexNumericFieldData indexNumericFieldData = ( ( IndexNumericFieldData ) ( fieldData ) ) ; if ( indexNumericFieldData . getNumericType ( ) . isFloatingPoint ( ) ) { final DoubleValues values = indexNumericFieldData . load ( context ) . getDoubleValues ( ) ; return new MatchDocIdSet ( context . reader ( ) . maxDoc ( ) , acceptDocs ) { @ Override protected boolean matchDoc ( int doc ) { final int numVals = values . setDocument ( doc ) ; for ( int i = 0 ; i < numVals ; i ++ ) { if ( terms . contains ( values . nextValue ( ) ) ) { return true ; } } return false ; } } ; } return null ; } } }<BUG2FIX>final BytesValues values = fieldData . load ( context ) . getBytesValues ( ) ;
public class TWL implements InputProcessor { private final GdxRenderer renderer ; private final GUI gui ; private boolean mouseDown ; private boolean ignoreMouse ; private boolean lastPressConsumed ; public Widget root ; public TWL ( SpriteBatch batch , String themeFile , FileType fileType , Widget widget ) { } public TWL ( SpriteBatch batch , String themeFile , FileType fileType ) { } public GUI getGUI ( ) { } public void setWidget ( Widget widget ) { } public void clear ( ) { } public void render ( ) { } public boolean keyDown ( int keycode ) { } public boolean keyUp ( int keycode ) { } public boolean keyTyped ( char character ) { } public boolean touchDown ( int x , int y , int pointer , int button ) { } public boolean touchUp ( int x , int y , int pointer , int button ) { mouseDown = false ; if ( ignoreMouse ) { ignoreMouse = false ; return false ; } <START_BUG> boolean handled = gui . handleMouse ( x , y , 0 , false ) ; <END_BUG> if ( ( app . getType ( ) ) == ( ApplicationType . Android ) ) { gui . handleMouse ( ( - 9999 ) , ( - 9999 ) , ( - 1 ) , false ) ; } return handled ; } public boolean touchDragged ( int x , int y , int pointer ) { } public boolean touchMoved ( int x , int y ) { } public boolean scrolled ( int amount ) { } public void dispose ( ) { } public static int getTwlKeyCode ( int gdxKeyCode ) { } public static URL getThemeURL ( String themeFile , final FileType fileType ) throws MalformedURLException { } }<BUG2FIX>boolean handled = gui . handleMouse ( x , y , button , false ) ;
public class ShadowMappingTest extends GdxTest { @ Override public boolean needsGL20 ( ) { } Stage ui ; PerspectiveCamera cam ; PerspectiveCamera lightCam ; PerspectiveCamera currCam ; Mesh plane ; Mesh cube ; ShaderProgram flatShader ; ShaderProgram shadowGenShader ; ShaderProgram shadowMapShader ; ShaderProgram currShader ; FrameBuffer shadowMap ; InputMultiplexer multiplexer ; PerspectiveCamController camController ; @ Override public void create ( ) { } private void setupScene ( ) { } private void setupShadowMap ( ) { } private void setupUI ( ) { ui = new Stage ( graphics . getWidth ( ) , graphics . getHeight ( ) , false ) ; Skin skin = new Skin ( files . internal ( "data/uiskin.json" ) , files . internal ( "data/uiskin.png" ) ) ; Label label = new Label ( "Camera:" , skin . getStyle ( LabelStyle . class ) ) ; ComboBox cameraCombo = new ComboBox ( new String [ ] { "Scene" , "Light" } , ui , skin . getStyle ( ComboBoxStyle . class ) ) ; Label label2 = new Label ( "Shader" , skin . getStyle ( LabelStyle . class ) , "cameraCombo" ) ; ComboBox shaderCombo = new ComboBox ( new String [ ] { "flat" , "shadow-gen" , "shadow-map" } , ui , skin . getStyle ( ComboBoxStyle . class ) , "shaderCombo" ) ; Label fpsLabel = new Label ( "fps:" , skin . getStyle ( LabelStyle . class ) , "fps" ) ; <START_BUG> Table table = new Table ( "toolbar" ) ; <END_BUG> table . width = graphics . getWidth ( ) ; table . height = 100 ; table . top ( ) . padTop ( 12 ) ; table . defaults ( ) . spaceRight ( 5 ) ; table . add ( label ) ; table . add ( cameraCombo ) ; table . add ( label2 ) ; table . add ( shaderCombo ) ; table . add ( fpsLabel ) ; table . y = ( ui . top ( ) ) - 100 ; ui . addActor ( table ) ; cameraCombo . setSelectionListener ( new ComboBox . SelectionListener ( ) { @ Override public void selected ( ComboBox comboBox , int selectionIndex , String selection ) { if ( selectionIndex == 0 ) currCam = cam ; else currCam = lightCam ; camController . cam = currCam ; } } ) ; shaderCombo . setSelectionListener ( new ComboBox . SelectionListener ( ) { @ Override public void selected ( ComboBox comboBox , int selectionIndex , String selection ) { if ( selectionIndex == 0 ) currShader = flatShader ; else if ( selectionIndex == 1 ) currShader = shadowGenShader ; else currShader = shadowMapShader ; } } ) ; } @ Override public void render ( ) { } }<BUG2FIX>Table table = new Table ( ) ;
public class ScriptGeoDistanceFacetCollector extends GeoDistanceFacetCollector { private final SearchScript script ; private ScriptGeoDistanceFacetCollector . Aggregator scriptAggregator ; public ScriptGeoDistanceFacetCollector ( String facetName , String fieldName , double lat , double lon , DistanceUnit unit , GeoDistance geoDistance , GeoDistanceFacet [ ] entries , SearchContext context , String scriptLang , String script , Map < String , Object > params ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override protected void doSetNextReader ( AtomicReaderContext context ) throws IOException { super . doSetNextReader ( context ) ; <START_BUG> script . setNextReader ( context . reader ( ) ) ; <END_BUG> } @ Override protected void doCollect ( int doc ) throws IOException { } public static class Aggregator implements GeoPointFieldData . ValueInDocProc { private final FixedSourceDistance fixedSourceDistance ; private final Entry [ ] entries ; double scriptValue ; public Aggregator ( GeoDistance . FixedSourceDistance fixedSourceDistance , GeoDistanceFacet [ ] entries ) { } @ Override public void onValue ( int docId , double lat , double lon ) { } } }<BUG2FIX>script . setNextReader ( context ) ;
public class ClusterBlock implements Serializable , Streamable , ToXContent { private int id ; private String description ; private ClusterBlockLevel [ ] levels ; private ClusterBlock ( ) { } public ClusterBlock ( int id , String description , ClusterBlockLevel ... levels ) { } public int id ( ) { } public String description ( ) { } public ClusterBlockLevel [ ] levels ( ) { <START_BUG> return this . levels ( ) ; <END_BUG> } public boolean contains ( ClusterBlockLevel level ) { } @ Override public void toXContent ( XContentBuilder builder , Params params ) throws IOException { } public static ClusterBlock readClusterBlock ( StreamInput in ) throws IOException { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } public String toString ( ) { } @ Override public boolean equals ( Object o ) { } @ Override public int hashCode ( ) { } }<BUG2FIX>return this . levels ;
public class PrefixFilterParser extends AbstractIndexComponent implements XContentFilterParser { public static final String NAME = "prefix" ; @ Inject public PrefixFilterParser ( Index index , @ IndexSettings Settings settings ) { } @ Override public String [ ] names ( ) { } @ Override public Filter parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; <START_BUG> boolean cache = false ; <END_BUG> String fieldName = null ; String value = null ; String filterName = null ; String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token . isValue ( ) ) { if ( "_name" . equals ( currentFieldName ) ) { filterName = parser . text ( ) ; } else if ( "_cache" . equals ( currentFieldName ) ) { cache = parser . booleanValue ( ) ; } else { fieldName = currentFieldName ; value = parser . text ( ) ; } } } if ( value == null ) { throw new QueryParsingException ( index , "No<seq2seq4repair_space>value<seq2seq4repair_space>specified<seq2seq4repair_space>for<seq2seq4repair_space>prefix<seq2seq4repair_space>filter" ) ; } MapperService . SmartNameFieldMappers smartNameFieldMappers = parseContext . smartFieldMappers ( fieldName ) ; if ( smartNameFieldMappers != null ) { if ( smartNameFieldMappers . hasMapper ( ) ) { fieldName = smartNameFieldMappers . mapper ( ) . names ( ) . indexName ( ) ; value = smartNameFieldMappers . mapper ( ) . indexedValue ( value ) ; } } Filter filter = new org . apache . lucene . search . PrefixFilter ( new Term ( fieldName , value ) ) ; if ( cache ) { filter = parseContext . cacheFilter ( filter ) ; } else { filter = parseContext . cacheWeakFilter ( filter ) ; } filter = wrapSmartNameFilter ( filter , smartNameFieldMappers , parseContext ) ; if ( filterName != null ) { parseContext . addNamedFilter ( filterName , filter ) ; } return filter ; } }<BUG2FIX>boolean cache = true ;
public class TermsByteFacetCollector extends AbstractFacetCollector { private final FieldDataCache fieldDataCache ; private final String indexFieldName ; private final ComparatorType comparatorType ; private final int size ; private final int numberOfShards ; private final FieldDataType fieldDataType ; private ByteFieldData fieldData ; private final TermsByteFacetCollector . StaticAggregatorValueProc aggregator ; private final SearchScript script ; public TermsByteFacetCollector ( String facetName , String fieldName , int size , TermsFacet . ComparatorType comparatorType , boolean allTerms , SearchContext context , ImmutableSet < BytesRef > excluded , String scriptLang , String script , Map < String , Object > params ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override protected void doSetNextReader ( AtomicReaderContext context ) throws IOException { fieldData = ( ( ByteFieldData ) ( fieldDataCache . cache ( fieldDataType , context . reader ( ) , indexFieldName ) ) ) ; if ( ( script ) != null ) { <START_BUG> script . setNextReader ( context . reader ( ) ) ; <END_BUG> } } @ Override protected void doCollect ( int doc ) throws IOException { } @ Override public Facet facet ( ) { } public static class AggregatorValueProc extends TermsByteFacetCollector . StaticAggregatorValueProc { private final SearchScript script ; private final TByteHashSet excluded ; public AggregatorValueProc ( TByteIntHashMap facets , Set < BytesRef > excluded , SearchScript script ) { } @ Override public void onValue ( int docId , byte value ) { } } public static class StaticAggregatorValueProc implements ByteFieldData . ValueInDocProc , ByteFieldData . ValueProc { private final TByteIntHashMap facets ; private int missing ; private int total ; public StaticAggregatorValueProc ( TByteIntHashMap facets ) { } @ Override public void onValue ( byte value ) { } @ Override public void onValue ( int docId , byte value ) { } @ Override public void onMissing ( int docID ) { } public final TByteIntHashMap facets ( ) { } public final int missing ( ) { } public final int total ( ) { } } }<BUG2FIX>script . setNextReader ( context ) ;
public class EmptyScorer extends Scorer { public EmptyScorer ( Weight weight ) { } @ Override public float score ( ) throws IOException { } @ Override <START_BUG> public float freq ( ) throws IOException { <END_BUG> return 0 ; } @ Override public int docID ( ) { } @ Override public int nextDoc ( ) throws IOException { } @ Override public int advance ( int target ) throws IOException { } }<BUG2FIX>public int freq ( ) throws IOException {
public class MembersFragment extends ItemListFragment < User > implements OrganizationSelectionListener { private User org ; @ Inject private OrganizationService service ; @ Inject private AvatarLoader avatarHelper ; @ Override public void onAttach ( Activity activity ) { } @ Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; setEmptyText ( getString ( no_members ) ) ; <START_BUG> ListViewUtils . configure ( getActivity ( ) , getListView ( ) , true ) ; <END_BUG> } @ Override public Loader < List < User > > onCreateLoader ( int id , Bundle args ) { } @ Override protected ItemListAdapter < User , ? extends ItemView > createAdapter ( List < User > items ) { } @ Override public void onOrganizationSelected ( User organization ) { } @ Override public void onListItemClick ( ListView l , View v , int position , long id ) { } }<BUG2FIX>ListViewUtils . configure ( getActivity ( ) , getListView ( ) ) ;
public class InterpolationTest extends GdxTest { private static final String [ ] interpolators = new String [ ] { "bounce" , "bounceIn" , "bounceOut" , "circle" , "circleIn" , "circleOut" , "elastic" , "elasticIn" , "elasticOut" , "exp10" , "exp10In" , "exp10Out" , "exp5" , "exp5In" , "exp5Out" , "fade" , "linear" , "pow2" , "pow2In" , "pow2Out" , "pow3" , "pow3In" , "pow3Out" , "pow4" , "pow4In" , "pow4Out" , "pow5" , "pow5In" , "pow5Out" , "sine" , "sineIn" , "sineOut" , "swing" , "swingIn" , "swingOut" } ; private Stage stage ; private Table root ; private List list ; private ShapeRenderer renderer ; Vector2 position = new Vector2 ( 300 , 20 ) ; Vector2 targetPosition = new Vector2 ( position ) ; Vector2 temp = new Vector2 ( ) ; float timer ; public void create ( ) { renderer = new ShapeRenderer ( ) ; stage = new Stage ( 0 , 0 , true ) ; input . setInputProcessor ( new com . badlogic . gdx . InputMultiplexer ( stage , new InputAdapter ( ) { public boolean touchDown ( int x , int y , int pointer , int button ) { Vector2 current = getCurrentPosition ( ) ; position . set ( current ) ; targetPosition . set ( ( x - 10 ) , ( ( ( graphics . getHeight ( ) ) - y ) - 10 ) ) ; timer = 0 ; return true ; } } ) ) ; root = new Table ( ) ; stage . addActor ( root ) ; root . pad ( 10 ) . top ( ) . left ( ) ; Skin skin = new Skin ( files . internal ( "data/uiskin.json" ) ) ; list = new List ( InterpolationTest . interpolators , skin ) ; ScrollPane scrollPane = new ScrollPane ( list , skin ) ; <START_BUG> scrollPane . setOverscroll ( false , false ) ; <END_BUG> scrollPane . setFadeScrollBars ( false ) ; root . add ( scrollPane ) . expandY ( ) . fillY ( ) . prefWidth ( 110 ) ; } public void resize ( int width , int height ) { } public void render ( ) { } Vector2 getCurrentPosition ( ) { } private Interpolation getInterpolation ( ) { } public boolean needsGL20 ( ) { } }<BUG2FIX>scrollPane . setOverscroll ( false ) ;
public class GroupTest extends GdxTest { Stage stage ; SpriteBatch batch ; BitmapFont font ; ShapeRenderer renderer ; TextureRegion region ; GroupTest . TestGroup group1 ; GroupTest . TestGroup group2 ; public void create ( ) { } public void render ( ) { } public void resize ( int width , int height ) { <START_BUG> stage . getViewport ( ) . update ( width , height ) ; <END_BUG> } public boolean needsGL20 ( ) { } class TestGroup extends Group { private String name ; Vector2 toScreenCoordinates = new Vector2 ( ) ; Vector2 localToParentCoordinates = new Vector2 ( ) ; float testX = 25 ; float testY = 25 ; public TestGroup ( String name ) { } public void draw ( Batch batch , float parentAlpha ) { } } }<BUG2FIX>stage . getViewport ( ) . update ( width , height , true ) ;
public class LwjglCanvas implements Application { LwjglGraphics graphics ; OpenALAudio audio ; LwjglFiles files ; LwjglInput input ; LwjglNet net ; ApplicationListener listener ; Canvas canvas ; final List < Runnable > runnables = new ArrayList ( ) ; final List < Runnable > executedRunnables = new ArrayList ( ) ; final Array < LifecycleListener > lifecycleListeners = new Array < LifecycleListener > ( ) ; boolean running = true ; int logLevel = LOG_INFO ; Cursor cursor ; public LwjglCanvas ( ApplicationListener listener , boolean useGL2 ) { } public LwjglCanvas ( ApplicationListener listener , LwjglApplicationConfiguration config ) { } private void initialize ( ApplicationListener listener , LwjglApplicationConfiguration config ) { } protected void setDisplayMode ( int width , int height ) { } protected void setTitle ( String title ) { } @ Override public ApplicationListener getApplicationListener ( ) { } public Canvas getCanvas ( ) { } @ Override public Audio getAudio ( ) { } @ Override public Files getFiles ( ) { } @ Override public Graphics getGraphics ( ) { } @ Override public Input getInput ( ) { } @ Override public Net getNet ( ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } void create ( ) { } protected int getFrameRate ( ) { int frameRate = ( Display . isActive ( ) ) ? graphics . config . foregroundFPS : graphics . config . backgroundFPS ; if ( frameRate == ( - 1 ) ) frameRate = 10 ; if ( frameRate == 0 ) frameRate = graphics . config . backgroundFPS ; if ( frameRate == 0 ) frameRate = 30 ; <START_BUG> return 0 ; <END_BUG> } protected void exception ( Throwable ex ) { } protected void start ( ) { } protected void resize ( int width , int height ) { } protected void stopped ( ) { } public void stop ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } Map < String , Preferences > preferences = new HashMap < String , Preferences > ( ) ; @ Override public Preferences getPreferences ( String name ) { } @ Override public Clipboard getClipboard ( ) { } @ Override public void postRunnable ( Runnable runnable ) { } @ Override public void debug ( String tag , String message ) { } @ Override public void debug ( String tag , String message , Throwable exception ) { } public void log ( String tag , String message ) { } @ Override public void log ( String tag , String message , Exception exception ) { } @ Override public void error ( String tag , String message ) { } @ Override public void error ( String tag , String message , Throwable exception ) { } @ Override public void setLogLevel ( int logLevel ) { } @ Override public void exit ( ) { } public void setCursor ( Cursor cursor ) { } @ Override public void addLifecycleListener ( LifecycleListener listener ) { } @ Override public void removeLifecycleListener ( LifecycleListener listener ) { } }<BUG2FIX>return frameRate ;
public class HighlightPhase implements SearchPhase { @ Override public Map < String , ? extends SearchParseElement > parseElements ( ) { } @ Override public void preProcess ( SearchContext context ) { } @ Override public void execute ( SearchContext context ) throws ElasticSearchException { if ( ( context . highlight ( ) ) == null ) { return ; } FragListBuilder fragListBuilder = new SimpleFragListBuilder ( ) ; FragmentsBuilder fragmentsBuilder ; if ( context . highlight ( ) . scoreOrdered ( ) ) { fragmentsBuilder = new ScoreOrderFragmentsBuilder ( context . highlight ( ) . preTags ( ) , context . highlight ( ) . postTags ( ) ) ; } else { fragmentsBuilder = new SimpleFragmentsBuilder ( context . highlight ( ) . preTags ( ) , context . highlight ( ) . postTags ( ) ) ; } FastVectorHighlighter highlighter = new FastVectorHighlighter ( true , false , fragListBuilder , fragmentsBuilder ) ; reader . set ( context . searcher ( ) . getIndexReader ( ) ) ; highlightFilters . set ( context . highlight ( ) . highlightFilter ( ) ) ; FieldQuery fieldQuery = new CustomFieldQuery ( context . query ( ) , highlighter ) ; for ( SearchHit hit : context . fetchResult ( ) . hits ( ) . hits ( ) ) { InternalSearchHit internalHit = ( ( InternalSearchHit ) ( hit ) ) ; DocumentMapper documentMapper = context . mapperService ( ) . type ( internalHit . type ( ) ) ; int docId = internalHit . docId ( ) ; Map < String , HighlightField > highlightFields = new HashMap < String , HighlightField > ( ) ; for ( SearchContextHighlight . ParsedHighlightField parsedHighlightField : context . highlight ( ) . fields ( ) ) { String indexName = parsedHighlightField . field ( ) ; FieldMapper mapper = documentMapper . mappers ( ) . smartNameFieldMapper ( parsedHighlightField . field ( ) ) ; if ( mapper != null ) { indexName = mapper . names ( ) . indexName ( ) ; } <START_BUG> String [ ] fragments = null ; <END_BUG> try { fragments = highlighter . getBestFragments ( fieldQuery , context . searcher ( ) . getIndexReader ( ) , docId , indexName , parsedHighlightField . fragmentCharSize ( ) , parsedHighlightField . numberOfFragments ( ) ) ; } catch ( IOException e ) { throw new org . elasticsearch . search . fetch . FetchPhaseExecutionException ( context , ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>highlight<seq2seq4repair_space>field<seq2seq4repair_space>[" + ( parsedHighlightField . field ( ) ) ) + "]" ) , e ) ; } HighlightField highlightField = new HighlightField ( parsedHighlightField . field ( ) , fragments ) ; highlightFields . put ( highlightField . name ( ) , highlightField ) ; } internalHit . highlightFields ( highlightFields ) ; } } }<BUG2FIX>String [ ] fragments ;
public class RestAllocationAction extends AbstractCatAction { @ Inject public RestAllocationAction ( Settings settings , Client client , RestController controller ) { } @ Override void documentation ( StringBuilder sb ) { } @ Override public void doRequest ( final RestRequest request , final RestChannel channel ) { } @ Override Table getTableWithHeader ( final RestRequest request ) { } private Table buildTable ( RestRequest request , final ClusterStateResponse state , final NodesStatsResponse stats ) { final ObjectIntOpenHashMap < String > allocs = new ObjectIntOpenHashMap < String > ( ) ; for ( ShardRouting shard : state . getState ( ) . routingTable ( ) . allShards ( ) ) { String nodeId = "UNASSIGNED" ; if ( shard . assignedToNode ( ) ) { nodeId = shard . currentNodeId ( ) ; } allocs . addTo ( nodeId , 1 ) ; } Table table = getTableWithHeader ( request ) ; for ( NodeStats nodeStats : stats . getNodes ( ) ) { DiscoveryNode node = nodeStats . getNode ( ) ; int shardCount = 0 ; if ( allocs . containsKey ( node . id ( ) ) ) { shardCount = allocs . lget ( ) ; } long used = ( nodeStats . getFs ( ) . getTotal ( ) . getTotal ( ) . bytes ( ) ) - ( nodeStats . getFs ( ) . getTotal ( ) . getAvailable ( ) . bytes ( ) ) ; long avail = nodeStats . getFs ( ) . getTotal ( ) . getAvailable ( ) . bytes ( ) ; short diskPercent = - 1 ; <START_BUG> if ( ( used >= 0 ) && ( avail > 0 ) ) { <END_BUG> diskPercent = ( ( short ) ( ( used * 100 ) / ( used + avail ) ) ) ; } table . startRow ( ) ; table . addCell ( shardCount ) ; table . addCell ( ( used < 0 ? null : new ByteSizeValue ( used ) ) ) ; table . addCell ( ( avail < 0 ? null : new ByteSizeValue ( avail ) ) ) ; table . addCell ( nodeStats . getFs ( ) . getTotal ( ) . getTotal ( ) ) ; table . addCell ( ( diskPercent < 0 ? null : diskPercent ) ) ; table . addCell ( ( node == null ? null : node . getHostName ( ) ) ) ; table . addCell ( ( node == null ? null : node . getHostAddress ( ) ) ) ; table . addCell ( ( node == null ? "UNASSIGNED" : node . name ( ) ) ) ; table . endRow ( ) ; } if ( allocs . containsKey ( "UNASSIGNED" ) ) { table . startRow ( ) ; table . addCell ( allocs . lget ( ) ) ; table . addCell ( null ) ; table . addCell ( null ) ; table . addCell ( null ) ; table . addCell ( null ) ; table . addCell ( null ) ; table . addCell ( null ) ; table . addCell ( "UNASSIGNED" ) ; table . endRow ( ) ; } return table ; } }<BUG2FIX>if ( ( used >= 0 ) && ( avail >= 0 ) ) {
public class FunctionScoreQuery extends Query { Query subQuery ; final ScoreFunction function ; public FunctionScoreQuery ( Query subQuery , ScoreFunction function ) { } public Query getSubQuery ( ) { } public ScoreFunction getFunction ( ) { } @ Override public Query rewrite ( IndexReader reader ) throws IOException { } @ Override public void extractTerms ( Set < Term > terms ) { } @ Override public Weight createWeight ( IndexSearcher searcher ) throws IOException { } class CustomBoostFactorWeight extends Weight { final Weight subQueryWeight ; public CustomBoostFactorWeight ( Weight subQueryWeight ) throws IOException { } public Query getQuery ( ) { } @ Override public float getValueForNormalization ( ) throws IOException { } @ Override public void normalize ( float norm , float topLevelBoost ) { } @ Override public Scorer scorer ( AtomicReaderContext context , boolean scoreDocsInOrder , boolean topScorer , Bits acceptDocs ) throws IOException { } @ Override public Explanation explain ( AtomicReaderContext context , int doc ) throws IOException { } } static class CustomBoostFactorScorer extends Scorer { private final float subQueryBoost ; private final Scorer scorer ; private final ScoreFunction function ; private CustomBoostFactorScorer ( FunctionScoreQuery . CustomBoostFactorWeight w , Scorer scorer , ScoreFunction function ) throws IOException { } @ Override public int docID ( ) { } @ Override public int advance ( int target ) throws IOException { } @ Override public int nextDoc ( ) throws IOException { } @ Override public float score ( ) throws IOException { } @ Override <START_BUG> public float freq ( ) throws IOException { <END_BUG> return scorer . freq ( ) ; } } public String toString ( String field ) { } public boolean equals ( Object o ) { } public int hashCode ( ) { } }<BUG2FIX>public int freq ( ) throws IOException {
public void glBlendFunc ( int sfactor , int dfactor ) { } public void glBlendFuncSeparate ( int srcRGB , int dstRGB , int srcAlpha , int dstAlpha ) { } public void glBufferData ( int target , int size , Buffer data , int usage ) { } public void glBufferSubData ( int target , int offset , int size , Buffer data ) { } public int glCheckFramebufferStatus ( int target ) { } public void glClear ( int mask ) { } public void glClearColor ( float red , float green , float blue , float alpha ) { } public void glClearDepthf ( float depth ) { } public void glClearStencil ( int s ) { } public void glColorMask ( boolean red , boolean green , boolean blue , boolean alpha ) { } public void glCompileShader ( int shader ) { } public void glCompressedTexImage2D ( int target , int level , int internalformat , int width , int height , int border , int imageSize , Buffer data ) { } public void glCompressedTexSubImage2D ( int target , int level , int xoffset , int yoffset , int width , int height , int format , int imageSize , Buffer data ) { } public void glCopyTexImage2D ( int target , int level , int internalformat , int x , int y , int width , int height , int border ) { } public void glCopyTexSubImage2D ( int target , int level , int xoffset , int yoffset , int x , int y , int width , int height ) { } public int glCreateProgram ( ) { } public int glCreateShader ( int type ) { } public void glCullFace ( int mode ) { } public void glDeleteBuffers ( int n , IntBuffer buffers ) { } public void glDeleteFramebuffers ( int n , IntBuffer framebuffers ) { } public void glDeleteProgram ( int program ) { } public void glDeleteRenderbuffers ( int n , IntBuffer renderbuffers ) { } public void glDeleteShader ( int shader ) { } public void glDeleteTextures ( int n , IntBuffer textures ) { } public void glDepthFunc ( int func ) { } public void glDepthMask ( boolean flag ) { } public void glDepthRangef ( float zNear , float zFar ) { } public void glDetachShader ( int program , int shader ) { } public void glDisable ( int cap ) { } public void glDisableVertexAttribArray ( int index ) { } public void glDrawArrays ( int mode , int first , int count ) { } public void glDrawElements ( int mode , int count , int type , Buffer indices ) { } public void glEnable ( int cap ) { } public void glEnableVertexAttribArray ( int index ) { } public void glFinish ( ) { } public void glFlush ( ) { } public void glFramebufferRenderbuffer ( int target , int attachment , int renderbuffertarget , int renderbuffer ) { } public void glFramebufferTexture2D ( int target , int attachment , int textarget , int texture , int level ) { } public void glFrontFace ( int mode ) { } public void glGenBuffers ( int n , IntBuffer buffers ) { } public void glGenFramebuffers ( int n , IntBuffer framebuffers ) { } public void glGenRenderbuffers ( int n , IntBuffer renderbuffers ) { } public void glGenTextures ( int n , IntBuffer textures ) { } public void glGenerateMipmap ( int target ) { } public String glGetActiveAttrib ( int program , int index , IntBuffer size , Buffer type ) { } public String glGetActiveUniform ( int program , int index , IntBuffer size , Buffer type ) { IntBuffer typeTmp = BufferUtils . createIntBuffer ( 2 ) ; String name = org . lwjgl . opengl . GL20 . glGetActiveUniform ( program , index , 256 , typeTmp ) ; size . put ( typeTmp . get ( 0 ) ) ; if ( type instanceof IntBuffer ) <START_BUG> ( ( IntBuffer ) ( type ) ) . put ( typeTmp . get ( 1 ) ) ; <END_BUG> return name ; } public void glGetAttachedShaders ( int program , int maxcount , Buffer count , IntBuffer shaders ) { } public int glGetAttribLocation ( int program , String name ) { } public void glGetBooleanv ( int pname , Buffer params ) { } public void glGetBufferParameteriv ( int target , int pname , IntBuffer params ) { } public int glGetError ( ) { } public void glGetFloatv ( int pname , FloatBuffer params ) { } public void glGetFramebufferAttachmentParameteriv ( int target , int attachment , int pname , IntBuffer params ) { } public void glGetIntegerv ( int pname , IntBuffer params ) { } public String glGetProgramInfoLog ( int program ) { } public void glGetProgramiv ( int program , int pname , IntBuffer params ) { } public void glGetRenderbufferParameteriv ( int target , int pname , IntBuffer params ) { } public String glGetShaderInfoLog ( int shader ) { } public void glGetShaderPrecisionFormat ( int shadertype , int precisiontype , IntBuffer range , IntBuffer precision ) { } public void glGetShaderiv ( int shader , int pname , IntBuffer params ) { } public String glGetString ( int name ) { } public void glGetTexParameterfv ( int target , int pname , FloatBuffer params ) { } public void glGetTexParameteriv ( int target , int pname , IntBuffer params ) { } public int glGetUniformLocation ( int program , String name ) { } public void glGetUniformfv ( int program , int location , FloatBuffer params ) { } public void glGetUniformiv ( int program , int location , IntBuffer params ) { } public void glGetVertexAttribPointerv ( int index , int pname , Buffer pointer ) { } public void glGetVertexAttribfv ( int index , int pname , FloatBuffer params ) { }<BUG2FIX>( ( IntBuffer ) ( type ) ) . put ( typeTmp . get ( 0 ) ) ;
if ( ( ( ( rgba [ 0 ] ) != 0 ) || ( ( rgba [ 1 ] ) != 0 ) ) || ( ( rgba [ 2 ] ) != 0 ) ) throw new RuntimeException ( ( ( ( "Unknown<seq2seq4repair_space>pixel:<seq2seq4repair_space>0," + y ) + ":<seq2seq4repair_space>" ) + name ) ) ; startY = y ; break ; } int endY ; for ( endY = startY ; endY < ( ( raster . getHeight ( ) ) - 1 ) ; endY ++ ) { raster . getPixel ( 0 , endY , rgba ) ; if ( ( rgba [ 3 ] ) == 0 ) break ; if ( ( ( ( rgba [ 0 ] ) != 0 ) || ( ( rgba [ 1 ] ) != 0 ) ) || ( ( rgba [ 2 ] ) != 0 ) ) throw new RuntimeException ( ( ( ( "Unknown<seq2seq4repair_space>pixel<seq2seq4repair_space>0," + endY ) + ":<seq2seq4repair_space>" ) + name ) ) ; } for ( int y = endY + 1 ; y < ( ( raster . getHeight ( ) ) - 1 ) ; y ++ ) { raster . getPixel ( 0 , y , rgba ) ; if ( ( rgba [ 3 ] ) != 0 ) throw new RuntimeException ( ( ( ( "Unknown<seq2seq4repair_space>pixel<seq2seq4repair_space>0," + y ) + ":<seq2seq4repair_space>" ) + name ) ) ; } boolean singleRegion = ( ( ( startX == 1 ) && ( endX == 1 ) ) && ( startY == 1 ) ) && ( endY == 1 ) ; if ( singleRegion ) { endX = raster . getWidth ( ) ; endY = raster . getHeight ( ) ; } int [ ] splits = new int [ 5 ] ; splits [ 0 ] = startX - 1 ; splits [ 1 ] = endX - 1 ; splits [ 2 ] = startY - 1 ; splits [ 3 ] = endY - 1 ; splits [ 4 ] = ( singleRegion ) ? 1 : 0 ; nameToSplits . put ( name , splits ) ; BufferedImage newImage = new BufferedImage ( ( ( raster . getWidth ( ) ) - 2 ) , ( ( raster . getHeight ( ) ) - 2 ) , BufferedImage . TYPE_4BYTE_ABGR ) ; newImage . getGraphics ( ) . drawImage ( image , 0 , 0 , newImage . getWidth ( ) , newImage . getHeight ( ) , 1 , 1 , ( ( raster . getWidth ( ) ) - 1 ) , ( ( raster . getHeight ( ) ) - 1 ) , null ) ; return newImage ; } } ; ninePatchProcessor . setRecursive ( false ) ; ninePatchProcessor . addInputSuffix ( ".9.png" ) ; ninePatchProcessor . setOutputSuffix ( "" ) ; ninePatchProcessor . process ( inputDir , inputDir ) ; texturePacker . process ( packedDir , new File ( packedDir , "pack" ) , "skin" ) ; LwjglApplicationConfiguration config = new LwjglApplicationConfiguration ( ) ; config . forceExit = false ; config . width = 1 ; config . height = 1 ; config . title = "SkinPacker" ; new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new ApplicationListener ( ) { public void create ( ) { Skin skin = new Skin ( ) ; TextureAtlasData atlas = new TextureAtlasData ( new FileHandle ( new File ( packedDir , "pack" ) ) , new FileHandle ( packedDir ) , true ) ; <START_BUG> if ( ( atlas . getPages ( ) . size ) != 1 ) <END_BUG> throw new GdxRuntimeException ( "Skin<seq2seq4repair_space>images<seq2seq4repair_space>could<seq2seq4repair_space>not<seq2seq4repair_space>be<seq2seq4repair_space>packed<seq2seq4repair_space>on<seq2seq4repair_space>to<seq2seq4repair_space>a<seq2seq4repair_space>single<seq2seq4repair_space>image!" ) ; Texture texture = new Texture ( 1 , 1 , Format . Alpha ) ; for ( Region region : atlas . getRegions ( ) ) { int [ ] split = nameToSplits . get ( region . name ) ; TextureRegion textureRegion = new TextureRegion ( texture , region . left , region . top , region . width , region . height ) ; if ( split == null ) { skin . addResource ( region . name , textureRegion ) ; } else { if ( ( split [ 4 ] ) == 1 ) skin . addResource ( region . name , new NinePatch ( textureRegion ) ) ; else skin . addResource ( region . name , new NinePatch ( textureRegion , split [ 0 ] , ( ( region . width ) - ( split [ 1 ] ) ) , split [ 2 ] , ( ( region . height ) - ( split [ 3 ] ) ) ) ) ; } } FileHandle newSkinFile = new FileHandle ( new File ( inputDir , "temp-skin" ) ) ; skin . save ( newSkinFile ) ; atlas . getPages ( ) . get ( 0 ) . textureFile . copyTo ( new FileHandle ( imageFile ) ) ; new FileHandle ( packedDir ) . deleteDirectory ( ) ; Json json = new Json ( ) ; if ( skinFile != null ) { FileHandle oldSkinFile = new FileHandle ( skinFile ) ; ObjectMap oldSkin = json . fromJson ( ObjectMap . class , new FileHandle ( skinFile ) ) ; ObjectMap newSkin = json . fromJson ( ObjectMap . class , newSkinFile ) ; ObjectMap oldResources = ( ( ObjectMap ) ( oldSkin . get ( "resources" ) ) ) ; ObjectMap newResources = ( ( ObjectMap ) ( newSkin . get ( "resources" ) ) ) ; oldResources . put ( NinePatch . class . getName ( ) , newResources . get ( NinePatch . class . getName ( ) ) ) ; oldResources . put ( TextureRegion . class . getName ( ) , newResources . get ( TextureRegion . class . getName ( ) ) ) ; Writer writer = oldSkinFile . writer ( false ) ;<BUG2FIX>if ( ( atlas . getPages ( ) . size ) > 1 )
public class Button extends Table implements Disableable { private Button . ButtonStyle style ; boolean isChecked ; boolean isDisabled ; ButtonGroup buttonGroup ; private ClickListener clickListener ; public Button ( Skin skin ) { } public Button ( Skin skin , String styleName ) { } public Button ( Actor child , Skin skin , String styleName ) { } public Button ( Actor child , Button . ButtonStyle style ) { } public Button ( Button . ButtonStyle style ) { } public Button ( ) { } private void initialize ( ) { } public Button ( Drawable up ) { } public Button ( Drawable up , Drawable down ) { } public Button ( Drawable up , Drawable down , Drawable checked ) { } public Button ( Actor child , Skin skin ) { } public void setChecked ( boolean isChecked ) { } public void toggle ( ) { } public boolean isChecked ( ) { } public boolean isPressed ( ) { <START_BUG> return clickListener . isVisualPressed ( ) ; <END_BUG> } public boolean isOver ( ) { } public ClickListener getClickListener ( ) { } public boolean isDisabled ( ) { } public void setDisabled ( boolean isDisabled ) { } public void setStyle ( Button . ButtonStyle style ) { } public Button . ButtonStyle getStyle ( ) { } public void draw ( Batch batch , float parentAlpha ) { } public float getPrefWidth ( ) { } public float getPrefHeight ( ) { } public float getMinWidth ( ) { } public float getMinHeight ( ) { } public static class ButtonStyle { public Drawable up ; public Drawable down ; public Drawable over ; public Drawable checked ; public Drawable checkedOver ; public Drawable disabled ; public float pressedOffsetX ; public float pressedOffsetY ; public float unpressedOffsetX ; public float unpressedOffsetY ; public ButtonStyle ( ) { } public ButtonStyle ( Drawable up , Drawable down , Drawable checked ) { } public ButtonStyle ( Button . ButtonStyle style ) { } } }<BUG2FIX>return clickListener . isPressed ( ) ;
public class ByteValuesComparatorSource extends IndexFieldData . XFieldComparatorSource { private final IndexNumericFieldData indexFieldData ; private final Object missingValue ; public ByteValuesComparatorSource ( IndexNumericFieldData indexFieldData , @ Nullable Object missingValue ) { } @ Override public Type reducedType ( ) { } @ Override public FieldComparator < ? > newComparator ( String fieldname , int numHits , int sortPos , boolean reversed ) throws IOException { assert fieldname . equals ( indexFieldData . getFieldNames ( ) . indexName ( ) ) ; byte dMissingValue ; if ( ( ( missingValue ) == null ) || ( "_last" . equals ( missingValue ) ) ) { dMissingValue = ( reversed ) ? Byte . MIN_VALUE : Byte . MAX_VALUE ; } else if ( "_first" . equals ( missingValue ) ) { dMissingValue = ( reversed ) ? Byte . MAX_VALUE : Byte . MIN_VALUE ; } else { dMissingValue = ( ( missingValue ) instanceof Number ) ? ( ( Number ) ( missingValue ) ) . byteValue ( ) : Byte . parseByte ( missingValue . toString ( ) ) ; } <START_BUG> return new ByteValuesComparator ( indexFieldData , dMissingValue , numHits ) ; <END_BUG> } }<BUG2FIX>return new ByteValuesComparator ( indexFieldData , dMissingValue , numHits , reversed ) ;
public class Sequence implements Action { static final Pool < Sequence > pool = new Pool < Sequence > ( new com . badlogic . gdx . utils . Pool . PoolObjectFactory < Sequence > ( ) { @ Override public Sequence createObject ( ) { } } , 100 ) ; protected final List < Action > actions = new ArrayList < Action > ( ) ; protected Actor target ; protected int currAction = 0 ; public static Sequence $ ( Action ... actions ) { } @ Override public void setTarget ( Actor actor ) { } @ Override public void act ( float delta ) { } @ Override public boolean isDone ( ) { <START_BUG> return ( currAction ) == ( actions . size ( ) ) ; <END_BUG> } @ Override public void finish ( ) { } @ Override public Action copy ( ) { } }<BUG2FIX>return ( currAction ) >= ( actions . size ( ) ) ;
public class PercolatorQueriesRegistry extends AbstractIndexShardComponent { private final IndexQueryParserService queryParserService ; private final MapperService mapperService ; private final IndicesLifecycle indicesLifecycle ; private final IndexCache indexCache ; private final IndexFieldDataService indexFieldDataService ; private final ShardIndexingService indexingService ; private final ShardPercolateService shardPercolateService ; private final ConcurrentMap < HashedBytesRef , Query > percolateQueries = ConcurrentCollections . newConcurrentMapWithAggressiveConcurrency ( ) ; private final PercolatorQueriesRegistry . ShardLifecycleListener shardLifecycleListener = new PercolatorQueriesRegistry . ShardLifecycleListener ( ) ; private final PercolatorQueriesRegistry . RealTimePercolatorOperationListener realTimePercolatorOperationListener = new PercolatorQueriesRegistry . RealTimePercolatorOperationListener ( ) ; private final PercolatorQueriesRegistry . PercolateTypeListener percolateTypeListener = new PercolatorQueriesRegistry . PercolateTypeListener ( ) ; private final AtomicBoolean realTimePercolatorEnabled = new AtomicBoolean ( false ) ; @ Inject public PercolatorQueriesRegistry ( ShardId shardId , @ IndexSettings Settings indexSettings , IndexQueryParserService queryParserService , ShardIndexingService indexingService , IndicesLifecycle indicesLifecycle , MapperService mapperService , IndexCache indexCache , IndexFieldDataService indexFieldDataService , ShardPercolateService shardPercolateService ) { } public ConcurrentMap < HashedBytesRef , Query > percolateQueries ( ) { } public void close ( ) { } public void clear ( ) { } void enableRealTimePercolator ( ) { } void disableRealTimePercolator ( ) { } public void addPercolateQuery ( String idAsString , BytesReference source ) { } public void removePercolateQuery ( String idAsString ) { } Query parsePercolatorDocument ( String id , BytesReference source ) { } private Query parseQuery ( String type , BytesReference querySource , XContentParser parser ) { } private class PercolateTypeListener implements DocumentTypeListener { @ Override public void beforeCreate ( DocumentMapper mapper ) { } @ Override public void afterRemove ( DocumentMapper mapper ) { } } private class ShardLifecycleListener extends IndicesLifecycle . Listener { @ Override public void afterIndexShardCreated ( IndexShard indexShard ) { } @ Override public void afterIndexShardPostRecovery ( IndexShard indexShard ) { } private boolean hasPercolatorType ( IndexShard indexShard ) { } private void loadQueries ( IndexShard shard ) { try { shard . refresh ( new Engine . Refresh ( "percolator_load_queries" ) . force ( true ) ) ; Engine . Searcher searcher = shard . acquireSearcher ( "percolator_load_queries" , WRITE ) ; try { Query query = new org . elasticsearch . common . lucene . search . XConstantScoreQuery ( indexCache . filter ( ) . cache ( new TermFilter ( new org . apache . lucene . index . Term ( TypeFieldMapper . NAME , PercolatorService . TYPE_NAME ) ) ) ) ; QueriesLoaderCollector queryCollector = new QueriesLoaderCollector ( PercolatorQueriesRegistry . this , logger , mapperService , indexFieldDataService ) ; searcher . searcher ( ) . search ( query , queryCollector ) ; Map < HashedBytesRef , Query > queries = queryCollector . queries ( ) ; for ( Map . Entry < HashedBytesRef , Query > entry : queries . entrySet ( ) ) { Query previousQuery = percolateQueries . put ( entry . getKey ( ) , entry . getValue ( ) ) ; shardPercolateService . addedQuery ( entry . getKey ( ) , previousQuery , entry . getValue ( ) ) ; } } finally { <START_BUG> searcher . release ( ) ; <END_BUG> } } catch ( Exception e ) { throw new PercolatorException ( shardId . index ( ) , "failed<seq2seq4repair_space>to<seq2seq4repair_space>load<seq2seq4repair_space>queries<seq2seq4repair_space>from<seq2seq4repair_space>percolator<seq2seq4repair_space>index" , e ) ; } } } private class RealTimePercolatorOperationListener extends IndexingOperationListener { @ Override public Create preCreate ( Engine . Create create ) { } @ Override public void postCreateUnderLock ( Engine . Create create ) { } @ Override public Index preIndex ( Engine . Index index ) { } @ Override public void postIndexUnderLock ( Engine . Index index ) { } @ Override public void postDeleteUnderLock ( Engine . Delete delete ) { } } }<BUG2FIX>searcher . close ( ) ;
public class TransportClientNodesService extends AbstractComponent { private final TimeValue nodesSamplerInterval ; private final long pingTimeout ; private final ClusterName clusterName ; private final TransportService transportService ; private final ThreadPool threadPool ; private volatile ImmutableList < DiscoveryNode > listedNodes = ImmutableList . of ( ) ; private final Object transportMutex = new Object ( ) ; private volatile ImmutableList < DiscoveryNode > nodes = ImmutableList . of ( ) ; private final AtomicInteger tempNodeIdGenerator = new AtomicInteger ( ) ; private final TransportClientNodesService . NodeSampler nodesSampler ; private volatile ScheduledFuture nodesSamplerFuture ; private final AtomicInteger randomNodeGenerator = new AtomicInteger ( ) ; private final boolean ignoreClusterName ; private volatile boolean closed ; @ Inject public TransportClientNodesService ( Settings settings , ClusterName clusterName , TransportService transportService , ThreadPool threadPool ) { } public ImmutableList < TransportAddress > transportAddresses ( ) { } public ImmutableList < DiscoveryNode > connectedNodes ( ) { } public ImmutableList < DiscoveryNode > listedNodes ( ) { } public TransportClientNodesService addTransportAddresses ( TransportAddress ... transportAddresses ) { } public TransportClientNodesService removeTransportAddress ( TransportAddress transportAddress ) { } public < T > T execute ( TransportClientNodesService . NodeCallback < T > callback ) throws ElasticSearchException { } public < Response > void execute ( TransportClientNodesService . NodeListenerCallback < Response > callback , ActionListener < Response > listener ) throws ElasticSearchException { } public static class RetryListener < Response > implements ActionListener < Response > { private final TransportClientNodesService . NodeListenerCallback < Response > callback ; private final ActionListener < Response > listener ; private final ImmutableList < DiscoveryNode > nodes ; private final int index ; private volatile int i ; public RetryListener ( TransportClientNodesService . NodeListenerCallback < Response > callback , ActionListener < Response > listener , ImmutableList < DiscoveryNode > nodes , int index ) { } @ Override public void onResponse ( Response response ) { } @ Override public void onFailure ( Throwable e ) { if ( ( ExceptionsHelper . unwrapCause ( e ) ) instanceof ConnectTransportException ) { int i = ++ ( this . i ) ; if ( i == ( nodes . size ( ) ) ) { listener . onFailure ( new NoNodeAvailableException ( ) ) ; } else { try { callback . doWithNode ( nodes . get ( ( ( ( index ) + i ) % ( nodes . size ( ) ) ) ) , this ) ; <START_BUG> } catch ( Exception e1 ) { <END_BUG> onFailure ( e ) ; } } } else { listener . onFailure ( e ) ; } } } public void close ( ) { } interface NodeSampler { void sample ( ) { } } class ScheduledNodeSampler implements Runnable { @ Override public void run ( ) { } } class SimpleNodeSampler implements TransportClientNodesService . NodeSampler { @ Override public synchronized void sample ( ) { } } class SniffNodesSampler implements TransportClientNodesService . NodeSampler { @ Override public synchronized void sample ( ) { } } public static interface NodeCallback < T > { T doWithNode ( DiscoveryNode node ) throws ElasticSearchException { } } public static interface NodeListenerCallback < Response > { void doWithNode ( DiscoveryNode node , ActionListener < Response > listener ) throws ElasticSearchException { } } }<BUG2FIX>} catch ( Throwable e1 ) {
public class CountdownEventAction < T extends Event > extends EventAction < T > { int count ; int current ; public CountdownEventAction ( Class < ? extends T > eventClass , int count ) { } public boolean handle ( T event ) { ( current ) ++ ; <START_BUG> return ( current ) > ( count ) ; <END_BUG> } }<BUG2FIX>return ( current ) >= ( count ) ;
public class InternalQueryFacet extends InternalFacet implements QueryFacet { private static final BytesReference STREAM_TYPE = new org . elasticsearch . common . bytes . HashedBytesArray ( Strings . toUTF8Bytes ( "query" ) ) ; public static void registerStreams ( ) { } static Stream STREAM = new Stream ( ) { @ Override public Facet readFacet ( StreamInput in ) throws IOException { } } ; @ Override public BytesReference streamType ( ) { } private long count ; private InternalQueryFacet ( ) { } public InternalQueryFacet ( String name , long count ) { } @ Override public String getType ( ) { } public long getCount ( ) { } @ Override public Facet reduce ( ReduceContext context ) { List < Facet > facets = context . facets ( ) ; if ( ( facets . size ( ) ) == 1 ) { return facets . get ( 0 ) ; } <START_BUG> int count = 0 ; <END_BUG> for ( Facet facet : facets ) { count += ( ( QueryFacet ) ( facet ) ) . getCount ( ) ; } return new InternalQueryFacet ( getName ( ) , count ) ; } static final class Fields { static final XContentBuilderString _TYPE = new XContentBuilderString ( "_type" ) ; static final XContentBuilderString COUNT = new XContentBuilderString ( "count" ) ; } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } public static QueryFacet readQueryFacet ( StreamInput in ) throws IOException { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } }<BUG2FIX>long count = 0 ;
public class BitmapFontLoader extends AsynchronousAssetLoader < BitmapFont , BitmapFontLoader . BitmapFontParameter > { public BitmapFontLoader ( FileHandleResolver resolver ) { } BitmapFontData data ; @ Override public Array < AssetDescriptor > getDependencies ( String fileName , FileHandle file , BitmapFontLoader . BitmapFontParameter parameter ) { <START_BUG> Array < AssetDescriptor > deps = new Array < AssetDescriptor > ( ) ; <END_BUG> if ( ( parameter != null ) && ( ( parameter . bitmapFontData ) != null ) ) { data = parameter . bitmapFontData ; return deps ; } data = new BitmapFontData ( file , ( parameter != null ? parameter . flip : false ) ) ; for ( int i = 0 ; i < ( data . getImagePaths ( ) . length ) ; i ++ ) { deps . add ( new AssetDescriptor ( data . getImagePath ( i ) , Texture . class ) ) ; } return deps ; } @ Override public void loadAsync ( AssetManager manager , String fileName , FileHandle file , BitmapFontLoader . BitmapFontParameter parameter ) { } @ Override public BitmapFont loadSync ( AssetManager manager , String fileName , FileHandle file , BitmapFontLoader . BitmapFontParameter parameter ) { } public static class BitmapFontParameter extends AssetLoaderParameters < BitmapFont > { public boolean flip = false ; public TextureFilter minFilter = TextureFilter . Nearest ; public TextureFilter magFilter = TextureFilter . Nearest ; public BitmapFontData bitmapFontData = null ; } }<BUG2FIX>Array < AssetDescriptor > deps = new Array ( ) ;
@ LuceneTestCase . Slow @ TestLogging ( "discovery.zen:TRACE" ) @ ClusterScope ( scope = Scope . TEST , numDataNodes = 0 , transportClientRatio = 0 ) public class DiscoveryWithServiceDisruptions extends ElasticsearchIntegrationTest { private static final TimeValue DISRUPTION_HEALING_OVERHEAD = TimeValue . timeValueSeconds ( 40 ) ; private ClusterDiscoveryConfiguration discoveryConfig ; @ Override protected Settings nodeSettings ( int nodeOrdinal ) { } @ Before public void clearConfig ( ) { } @ Override protected int numberOfShards ( ) { } @ Override protected int numberOfReplicas ( ) { } private List < String > startCluster ( int numberOfNodes ) throws InterruptedException , ExecutionException { } private List < String > startCluster ( int numberOfNodes , int minimumMasterNode ) throws InterruptedException , ExecutionException { } private List < String > startUnicastCluster ( int numberOfNodes , @ Nullable int [ ] unicastHostsOrdinals , int minimumMasterNode ) throws InterruptedException , ExecutionException { } static final Settings DEFAULT_SETTINGS = ImmutableSettings . builder ( ) . put ( SETTING_PING_TIMEOUT , "1s" ) . put ( SETTING_PING_RETRIES , "1" ) . put ( "discovery.zen.join_timeout" , "10s" ) . put ( PUBLISH_TIMEOUT , "1s" ) . put ( "http.enabled" , false ) . put ( "gateway.local.list_timeout" , "10s" ) . put ( TRANSPORT_SERVICE_TYPE_KEY , MockTransportService . class . getName ( ) ) . build ( ) ; private void configureCluster ( int numberOfNodes , int minimumMasterNode ) throws InterruptedException , ExecutionException { } private void configureMulticastCluster ( int numberOfNodes , int minimumMasterNode ) throws InterruptedException , ExecutionException { } private void configureUnicastCluster ( int numberOfNodes , @ Nullable int [ ] unicastHostsOrdinals , int minimumMasterNode ) throws InterruptedException , ExecutionException { } @ Test public void failWithMinimumMasterNodesConfigured ( ) throws Exception { } @ Test @ TestLogging ( "cluster.service:TRACE,indices.recovery:TRACE" ) public void testNodesFDAfterMasterReelection ( ) throws Exception { } @ Test @ TestLogging ( "cluster.service:TRACE,indices.recovery:TRACE" ) public void testVerifyApiBlocksDuringPartition ( ) throws Exception { } @ Test @ TestLogging ( "discovery.zen:TRACE,action:TRACE,cluster.service:TRACE,indices.recovery:TRACE,indices.cluster:TRACE" ) public void testIsolateMasterAndVerifyClusterStateConsensus ( ) throws Exception { } @ Test @ AwaitsFix ( bugUrl = "needs<seq2seq4repair_space>some<seq2seq4repair_space>more<seq2seq4repair_space>work<seq2seq4repair_space>to<seq2seq4repair_space>stabilize" ) @ TestLogging ( "action.index:TRACE,action.get:TRACE,discovery:TRACE,cluster.service:TRACE,indices.recovery:TRACE,indices.cluster:TRACE" ) public void testAckedIndexing ( ) throws Exception { } @ Test @ TestLogging ( "discovery.zen:TRACE,action:TRACE,cluster.service:TRACE,indices.recovery:TRACE,indices.cluster:TRACE" ) public void testMasterNodeGCs ( ) throws Exception { } @ Test @ TestLogging ( "discovery.zen:TRACE,action:TRACE,cluster.service:TRACE,indices.recovery:TRACE,indices.cluster:TRACE" ) public void testRejoinDocumentExistsInAllShardCopies ( ) throws Exception { } @ Test @ TestLogging ( "discovery.zen:TRACE,action:TRACE" ) public void unicastSinglePingResponseContainsMaster ( ) throws Exception { } @ Test @ TestLogging ( "discovery.zen:TRACE,action:TRACE" ) public void isolatedUnicastNodes ( ) throws Exception { } @ Test @ TestLogging ( "discovery.zen:TRACE,action:TRACE" ) public void testClusterJoinDespiteOfPublishingIssues ( ) throws Exception { } @ Test @ TestLogging ( "discovery.zen:TRACE,action:TRACE" ) public void testClusterFormingWithASlowNode ( ) throws Exception { } @ Test @ TestLogging ( "discovery.zen:TRACE,action:TRACE" ) public void testNodeNotReachableFromMaster ( ) throws Exception { startCluster ( 3 ) ; String masterNode = internalCluster ( ) . getMasterName ( ) ; String nonMasterNode = null ; while ( nonMasterNode == null ) { nonMasterNode = randomFrom ( internalCluster ( ) . getNodeNames ( ) ) ; if ( nonMasterNode . equals ( masterNode ) ) { <START_BUG> masterNode = null ; <END_BUG> } } logger . info ( "blocking<seq2seq4repair_space>request<seq2seq4repair_space>from<seq2seq4repair_space>master<seq2seq4repair_space>[{}]<seq2seq4repair_space>to<seq2seq4repair_space>[{}]" , masterNode , nonMasterNode ) ; MockTransportService masterTransportService = ( ( MockTransportService ) ( internalCluster ( ) . getInstance ( TransportService . class , masterNode ) ) ) ; if ( randomBoolean ( ) ) { masterTransportService . addUnresponsiveRule ( internalCluster ( ) . getInstance ( ClusterService . class , nonMasterNode ) . localNode ( ) ) ; } else { masterTransportService . addFailToSendNoConnectRule ( internalCluster ( ) . getInstance ( ClusterService . class , nonMasterNode ) . localNode ( ) ) ; } logger . info ( "waiting<seq2seq4repair_space>for<seq2seq4repair_space>[{}]<seq2seq4repair_space>to<seq2seq4repair_space>be<seq2seq4repair_space>removed<seq2seq4repair_space>from<seq2seq4repair_space>cluster" , nonMasterNode ) ; ensureStableCluster ( 2 , masterNode ) ; logger . info ( "waiting<seq2seq4repair_space>for<seq2seq4repair_space>[{}]<seq2seq4repair_space>to<seq2seq4repair_space>have<seq2seq4repair_space>no<seq2seq4repair_space>master" , nonMasterNode ) ; assertNoMaster ( nonMasterNode ) ; logger . info ( "healing<seq2seq4repair_space>partition<seq2seq4repair_space>and<seq2seq4repair_space>checking<seq2seq4repair_space>cluster<seq2seq4repair_space>reforms" ) ; masterTransportService . clearAllRules ( ) ; ensureStableCluster ( 3 ) ; } protected NetworkPartition addRandomPartition ( ) { } protected NetworkPartition addRandomIsolation ( String isolatedNode ) { } private ServiceDisruptionScheme addRandomDisruptionScheme ( ) { } private void ensureStableCluster ( int nodeCount ) { } private void ensureStableCluster ( int nodeCount , TimeValue timeValue ) { } private void ensureStableCluster ( int nodeCount , @ Nullable String viaNode ) { } private void ensureStableCluster ( int nodeCount , TimeValue timeValue , @ Nullable String viaNode ) { } private ClusterState getNodeClusterState ( String node ) { } private void assertNoMaster ( final String node ) throws Exception { } private void assertNoMaster ( final String node , TimeValue maxWaitTime ) throws Exception { } private void assertNoMaster ( final String node , @ Nullable final ClusterBlock expectedBlocks , TimeValue maxWaitTime ) throws Exception { } private void assertDifferentMaster ( final String node , final String oldMasterNode ) throws Exception { } private void assertMaster ( String masterNode , List < String > nodes ) { } }<BUG2FIX>nonMasterNode = null ;
public class MetaDataIndexAliasesService extends AbstractComponent { private final ClusterService clusterService ; private final IndicesService indicesService ; private final NodeAliasesUpdatedAction aliasOperationPerformedAction ; @ Inject public MetaDataIndexAliasesService ( Settings settings , ClusterService clusterService , IndicesService indicesService , NodeAliasesUpdatedAction aliasOperationPerformedAction ) { } public void indicesAliases ( final MetaDataIndexAliasesService . Request request , final MetaDataIndexAliasesService . Listener listener ) { clusterService . submitStateUpdateTask ( "index-aliases" , URGENT , new ProcessedClusterStateUpdateTask ( ) { @ Override public ClusterState execute ( ClusterState currentState ) { for ( AliasAction aliasAction : request . actions ) { if ( ! ( currentState . metaData ( ) . hasIndex ( aliasAction . index ( ) ) ) ) { listener . onFailure ( new IndexMissingException ( new org . elasticsearch . index . Index ( aliasAction . index ( ) ) ) ) ; return currentState ; } if ( currentState . metaData ( ) . hasIndex ( aliasAction . alias ( ) ) ) { listener . onFailure ( new org . elasticsearch . indices . InvalidAliasNameException ( new org . elasticsearch . index . Index ( aliasAction . index ( ) ) , aliasAction . alias ( ) , "an<seq2seq4repair_space>index<seq2seq4repair_space>exists<seq2seq4repair_space>with<seq2seq4repair_space>the<seq2seq4repair_space>same<seq2seq4repair_space>name<seq2seq4repair_space>as<seq2seq4repair_space>the<seq2seq4repair_space>alias" ) ) ; return currentState ; } if ( ( ( aliasAction . indexRouting ( ) ) != null ) && ( ( aliasAction . indexRouting ( ) . indexOf ( ',' ) ) != ( - 1 ) ) ) { listener . onFailure ( new org . elasticsearch . ElasticSearchIllegalArgumentException ( ( ( "alias<seq2seq4repair_space>[" + ( aliasAction . alias ( ) ) ) + "]<seq2seq4repair_space>has<seq2seq4repair_space>several<seq2seq4repair_space>routing<seq2seq4repair_space>values<seq2seq4repair_space>associated<seq2seq4repair_space>with<seq2seq4repair_space>it" ) ) ) ; return currentState ; } } List < String > indicesToClose = Lists . newArrayList ( ) ; Map < String , IndexService > indices = Maps . newHashMap ( ) ; try { boolean changed = false ; MetaData . Builder builder = MetaData . newMetaDataBuilder ( ) . metaData ( currentState . metaData ( ) ) ; for ( AliasAction aliasAction : request . actions ) { IndexMetaData indexMetaData = builder . get ( aliasAction . index ( ) ) ; if ( indexMetaData == null ) { throw new IndexMissingException ( new org . elasticsearch . index . Index ( aliasAction . index ( ) ) ) ; } IndexMetaData . Builder indexMetaDataBuilder = IndexMetaData . newIndexMetaDataBuilder ( indexMetaData ) ; if ( ( aliasAction . actionType ( ) ) == ( Type . ADD ) ) { String filter = aliasAction . filter ( ) ; if ( Strings . hasLength ( filter ) ) { IndexService indexService = indices . get ( indexMetaData . index ( ) ) ; if ( indexService == null ) { indexService = indicesService . indexService ( indexMetaData . index ( ) ) ; if ( indexService == null ) { try { indexService = indicesService . createIndex ( indexMetaData . index ( ) , indexMetaData . settings ( ) , currentState . nodes ( ) . localNode ( ) . id ( ) ) ; } catch ( Exception e ) { logger . warn ( "[{}]<seq2seq4repair_space>failed<seq2seq4repair_space>to<seq2seq4repair_space>temporary<seq2seq4repair_space>create<seq2seq4repair_space>in<seq2seq4repair_space>order<seq2seq4repair_space>to<seq2seq4repair_space>apply<seq2seq4repair_space>alias<seq2seq4repair_space>action" , e , indexMetaData . index ( ) ) ; continue ; } indicesToClose . add ( indexMetaData . index ( ) ) ; } indices . put ( indexMetaData . index ( ) , indexService ) ; } IndexQueryParserService indexQueryParser = indexService . queryParserService ( ) ; try { XContentParser parser = XContentFactory . xContent ( filter ) . createParser ( filter ) ; try { indexQueryParser . parseInnerFilter ( parser ) ; } finally { parser . close ( ) ; } <START_BUG> } catch ( Exception e ) { <END_BUG> listener . onFailure ( new org . elasticsearch . ElasticSearchIllegalArgumentException ( ( ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>parse<seq2seq4repair_space>filter<seq2seq4repair_space>for<seq2seq4repair_space>[" + ( aliasAction . alias ( ) ) ) + "]" ) , e ) ) ; return currentState ; } } AliasMetaData newAliasMd = AliasMetaData . newAliasMetaDataBuilder ( aliasAction . alias ( ) ) . filter ( filter ) . indexRouting ( aliasAction . indexRouting ( ) ) . searchRouting ( aliasAction . searchRouting ( ) ) . build ( ) ; AliasMetaData aliasMd = indexMetaData . aliases ( ) . get ( aliasAction . alias ( ) ) ; if ( ( aliasMd != null ) && ( aliasMd . equals ( newAliasMd ) ) ) { continue ; } indexMetaDataBuilder . putAlias ( newAliasMd ) ; } else if ( ( aliasAction . actionType ( ) ) == ( Type . REMOVE ) ) { if ( ! ( indexMetaData . aliases ( ) . containsKey ( aliasAction . alias ( ) ) ) ) { continue ; } indexMetaDataBuilder . removerAlias ( aliasAction . alias ( ) ) ; } changed = true ; builder . put ( indexMetaDataBuilder ) ; } if ( changed ) { ClusterState updatedState = ClusterState . newClusterStateBuilder ( ) . state ( currentState ) . metaData ( builder ) . build ( ) ; if ( updatedState . metaData ( ) . aliases ( ) . equals ( currentState . metaData ( ) . aliases ( ) ) ) { listener . onResponse ( new MetaDataIndexAliasesService . Response ( true ) ) ; return currentState ; } int responseCount = updatedState . nodes ( ) . size ( ) ; long version = ( updatedState . version ( ) ) + 1 ; logger . trace ( "waiting<seq2seq4repair_space>for<seq2seq4repair_space>[{}]<seq2seq4repair_space>notifications<seq2seq4repair_space>with<seq2seq4repair_space>version<seq2seq4repair_space>[{}]" , responseCount , version ) ; aliasOperationPerformedAction . add ( new MetaDataIndexAliasesService . CountDownListener ( responseCount , listener , version ) , request . timeout ) ; return updatedState ; } else { listener . onResponse ( new MetaDataIndexAliasesService . Response ( true ) ) ; return currentState ; } } finally { for ( String index : indicesToClose ) { indicesService . removeIndex ( index , "created<seq2seq4repair_space>for<seq2seq4repair_space>alias<seq2seq4repair_space>processing" ) ; } } } @ Override public void clusterStateProcessed ( ClusterState clusterState ) { } } ) ; } public static interface Listener { void onResponse ( MetaDataIndexAliasesService . Response response ) { }<BUG2FIX>} catch ( Throwable e ) {
public class TransportClusterStatsAction extends TransportNodesOperationAction < ClusterStatsRequest , ClusterStatsResponse , TransportClusterStatsAction . ClusterStatsNodeRequest , ClusterStatsNodeResponse > { private static final CommonStatsFlags SHARD_STATS_FLAGS = new CommonStatsFlags ( Flag . Docs , Flag . Store , Flag . FieldData , Flag . FilterCache , Flag . IdCache , Flag . Completion , Flag . Segments , Flag . Percolate ) ; private final NodeService nodeService ; private final IndicesService indicesService ; @ Inject public TransportClusterStatsAction ( Settings settings , ClusterName clusterName , ThreadPool threadPool , ClusterService clusterService , TransportService transportService , NodeService nodeService , IndicesService indicesService ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected ClusterStatsResponse newResponse ( ClusterStatsRequest clusterStatsRequest , AtomicReferenceArray responses ) { } @ Override protected ClusterStatsRequest newRequest ( ) { } @ Override protected TransportClusterStatsAction . ClusterStatsNodeRequest newNodeRequest ( ) { } @ Override protected TransportClusterStatsAction . ClusterStatsNodeRequest newNodeRequest ( String nodeId , ClusterStatsRequest request ) { } @ Override protected ClusterStatsNodeResponse newNodeResponse ( ) { } @ Override protected ClusterStatsNodeResponse nodeOperation ( TransportClusterStatsAction . ClusterStatsNodeRequest nodeRequest ) throws ElasticSearchException { NodeInfo nodeInfo = nodeService . info ( false , true , false , true , false , false , true , false , true ) ; <START_BUG> NodeStats nodeStats = nodeService . stats ( NONE , false , true , true , false , false , true , false , false ) ; <END_BUG> List < ShardStats > shardsStats = new ArrayList < ShardStats > ( ) ; for ( String index : indicesService . indices ( ) ) { IndexService indexService = indicesService . indexService ( index ) ; if ( indexService == null ) { continue ; } for ( IndexShard indexShard : indexService ) { if ( indexShard . routingEntry ( ) . active ( ) ) { shardsStats . add ( new ShardStats ( indexShard , TransportClusterStatsAction . SHARD_STATS_FLAGS ) ) ; } } } ClusterHealthStatus clusterStatus = null ; if ( clusterService . state ( ) . nodes ( ) . localNodeMaster ( ) ) { clusterStatus = ClusterHealthStatus . GREEN ; for ( IndexRoutingTable indexRoutingTable : clusterService . state ( ) . routingTable ( ) ) { IndexMetaData indexMetaData = clusterService . state ( ) . metaData ( ) . index ( indexRoutingTable . index ( ) ) ; if ( indexRoutingTable == null ) { continue ; } ClusterIndexHealth indexHealth = new ClusterIndexHealth ( indexMetaData , indexRoutingTable ) ; switch ( indexHealth . getStatus ( ) ) { case RED : clusterStatus = ClusterHealthStatus . RED ; break ; case YELLOW : if ( clusterStatus != ( ClusterHealthStatus . RED ) ) { clusterStatus = ClusterHealthStatus . YELLOW ; } break ; } } } return new ClusterStatsNodeResponse ( nodeInfo . getNode ( ) , clusterStatus , nodeInfo , nodeStats , shardsStats . toArray ( new ShardStats [ shardsStats . size ( ) ] ) ) ; } @ Override protected boolean accumulateExceptions ( ) { } static class ClusterStatsNodeRequest extends NodeOperationRequest { ClusterStatsRequest request ; ClusterStatsNodeRequest ( ) { } ClusterStatsNodeRequest ( String nodeId , ClusterStatsRequest request ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } }<BUG2FIX>NodeStats nodeStats = nodeService . stats ( NONE , false , true , true , false , false , true , false , false , false ) ;
public abstract class PagedUserFragment extends PagedItemFragment < User > { @ Inject protected AvatarLoader avatars ; @ Inject protected UserService service ; @ Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; <START_BUG> ListViewUtils . configure ( getActivity ( ) , getListView ( ) , true ) ; <END_BUG> } @ Override protected ItemListAdapter < User , ? extends ItemView > createAdapter ( List < User > items ) { } @ Override public void onListItemClick ( ListView l , View v , int position , long id ) { } }<BUG2FIX>ListViewUtils . configure ( getActivity ( ) , getListView ( ) ) ;
public class GdxInvadersAndroid extends AndroidApplication { @ Override public void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; setRequestedOrientation ( SCREEN_ORIENTATION_LANDSCAPE ) ; AndroidApplicationConfiguration config = new AndroidApplicationConfiguration ( ) ; config . useWakelock = true ; <START_BUG> config . useGL20 = false ; <END_BUG> initialize ( new GdxInvaders ( ) , config ) ; } }<BUG2FIX>config . useGL20 = true ;
public class Scene2dTest extends GdxTest { Stage stage ; private FloatAction meow = new FloatAction ( 10 , 5 ) ; private TiledDrawable patch ; public void create ( ) { stage = new Stage ( ) ; input . setInputProcessor ( stage ) ; final TextureRegion region = new TextureRegion ( new Texture ( "data/badlogic.jpg" ) ) ; final Actor actor = new Actor ( ) { public void draw ( SpriteBatch batch , float parentAlpha ) { Color color = getColor ( ) ; batch . setColor ( color . r , color . g , color . b , parentAlpha ) ; batch . draw ( region , getX ( ) , getY ( ) , getOriginX ( ) , getOriginY ( ) , getWidth ( ) , getHeight ( ) , getScaleX ( ) , getScaleY ( ) , getRotation ( ) ) ; } } ; actor . setBounds ( 15 , 15 , 100 , 100 ) ; actor . setOrigin ( 50 , 50 ) ; stage . addActor ( actor ) ; actor . addListener ( new InputListener ( ) { public boolean touchDown ( InputEvent event , float x , float y , int pointer , int button ) { System . out . println ( "down" ) ; return true ; } public void touchUp ( InputEvent event , float x , float y , int pointer , int button ) { System . out . println ( ( "up<seq2seq4repair_space>" + ( event . getTarget ( ) ) ) ) ; } } ) ; Skin skin = new Skin ( files . internal ( "data/uiskin.json" ) ) ; VerticalGroup g = new VerticalGroup ( ) ; g . setPosition ( 100 , 100 ) ; g . setReverse ( true ) ; stage . addActor ( g ) ; for ( int i = 0 ; i < 10 ; i ++ ) { g . addActor ( new TextButton ( ( "button<seq2seq4repair_space>" + i ) , skin ) ) ; } g . pack ( ) ; final TextButton button = new TextButton ( "Fancy<seq2seq4repair_space>Background" , skin ) ; button . addListener ( new ActorGestureListener ( ) { public boolean longPress ( Actor actor , float x , float y ) { System . out . println ( ( ( ( "long<seq2seq4repair_space>press<seq2seq4repair_space>" + x ) + ",<seq2seq4repair_space>" ) + y ) ) ; return true ; } <START_BUG> public void fling ( InputEvent event , float velocityX , float velocityY , int pointer , int button ) { <END_BUG> System . out . println ( ( ( ( "fling<seq2seq4repair_space>" + velocityX ) + ",<seq2seq4repair_space>" ) + velocityY ) ) ; } public void zoom ( InputEvent event , float initialDistance , float distance ) { System . out . println ( ( ( ( "zoom<seq2seq4repair_space>" + initialDistance ) + ",<seq2seq4repair_space>" ) + distance ) ) ; } public void pan ( InputEvent event , float x , float y , float deltaX , float deltaY ) { event . getListenerActor ( ) . translate ( deltaX , deltaY ) ; if ( deltaX < 0 ) System . out . println ( ( ( ( ( ( "panning<seq2seq4repair_space>" + deltaX ) + ",<seq2seq4repair_space>" ) + deltaY ) + "<seq2seq4repair_space>" ) + ( event . getTarget ( ) ) ) ) ; } } ) ; button . setPosition ( 50 , 50 ) ; stage . addActor ( button ) ; meow . setDuration ( 2 ) ; actor . addAction ( forever ( sequence ( moveBy ( 50 , 0 , 2 ) , moveBy ( ( - 50 ) , 0 , 2 ) , run ( new Runnable ( ) { public void run ( ) { actor . setZIndex ( 0 ) ; } } ) ) ) ) ; patch = new TiledDrawable ( skin . getRegion ( "default-round" ) ) ; Window window = new Window ( "Moo" , skin ) ; Label lbl = new Label ( "ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJ" , skin ) ; lbl . setWrap ( true ) ; window . row ( ) ; window . add ( lbl ) . width ( 400 ) ; window . pack ( ) ; window . pack ( ) ; stage . addActor ( window ) ; } public void render ( ) { } public void resize ( int width , int height ) { } public boolean needsGL20 ( ) { } public void dispose ( ) { } }<BUG2FIX>public void fling ( InputEvent event , float velocityX , float velocityY , int button ) {
public class RobinEngine extends AbstractIndexShardComponent implements Engine { private volatile ByteSizeValue indexingBufferSize ; private volatile int termIndexInterval ; private volatile int termIndexDivisor ; private volatile int indexConcurrency ; private final ReadWriteLock rwl = new ReentrantReadWriteLock ( ) ; private final AtomicBoolean optimizeMutex = new AtomicBoolean ( ) ; private final long gcDeletesInMillis ; private final ThreadPool threadPool ; private final IndexSettingsService indexSettingsService ; private final Store store ; private final SnapshotDeletionPolicy deletionPolicy ; private final Translog translog ; private final MergePolicyProvider mergePolicyProvider ; private final MergeSchedulerProvider mergeScheduler ; private final AnalysisService analysisService ; private final SimilarityService similarityService ; private final BloomCache bloomCache ; private final boolean asyncLoadBloomFilter ; private IndexWriter indexWriter ; private volatile AcquirableResource < ReaderSearcherHolder > nrtResource ; private volatile boolean closed = false ; private volatile boolean dirty = false ; private volatile boolean possibleMergeNeeded = false ; private volatile boolean flushNeeded = false ; private volatile int disableFlushCounter = 0 ; private final AtomicReference < Searcher > indexingSearcher = new AtomicReference < Searcher > ( ) ; private final AtomicBoolean flushing = new AtomicBoolean ( ) ; private final ConcurrentMap < String , RobinEngine . VersionValue > versionMap ; private final Object [ ] dirtyLocks ; private final Object refreshMutex = new Object ( ) ; private final RobinEngine . ApplySettings applySettings = new RobinEngine . ApplySettings ( ) ; private Throwable failedEngine = null ; private final Object failedEngineMutex = new Object ( ) ; private final CopyOnWriteArrayList < FailedEngineListener > failedEngineListeners = new CopyOnWriteArrayList < FailedEngineListener > ( ) ; private final AtomicLong translogIdGenerator = new AtomicLong ( ) ; private SegmentInfos lastCommittedSegmentInfos ; @ Inject public RobinEngine ( ShardId shardId , @ IndexSettings Settings indexSettings , ThreadPool threadPool , IndexSettingsService indexSettingsService , Store store , SnapshotDeletionPolicy deletionPolicy , Translog translog , MergePolicyProvider mergePolicyProvider , MergeSchedulerProvider mergeScheduler , AnalysisService analysisService , SimilarityService similarityService , BloomCache bloomCache ) throws EngineException { } @ Override public void updateIndexingBufferSize ( ByteSizeValue indexingBufferSize ) { } @ Override public void addFailedEngineListener ( FailedEngineListener listener ) { } @ Override public void start ( ) throws EngineException { } @ Override public TimeValue defaultRefreshInterval ( ) { } public GetResult get ( Get get ) throws EngineException { } @ Override public void create ( Create create ) throws EngineException { } private void innerCreate ( Create create , IndexWriter writer ) throws IOException { } @ Override public void index ( Index index ) throws EngineException { } private void innerIndex ( Index index , IndexWriter writer ) throws IOException { } @ Override public void delete ( Delete delete ) throws EngineException { } private void innerDelete ( Delete delete , IndexWriter writer ) throws IOException { } @ Override public void delete ( DeleteByQuery delete ) throws EngineException { } @ Override public Searcher searcher ( ) throws EngineException { } @ Override public boolean refreshNeeded ( ) { } @ Override public boolean possibleMergeNeeded ( ) { } @ Override public void refresh ( Refresh refresh ) throws EngineException { } @ Override public void flush ( Flush flush ) throws EngineException { if ( ( indexWriter ) == null ) { throw new EngineClosedException ( shardId , failedEngine ) ; } if ( ( disableFlushCounter ) > 0 ) { throw new FlushNotAllowedEngineException ( shardId , "Recovery<seq2seq4repair_space>is<seq2seq4repair_space>in<seq2seq4repair_space>progress,<seq2seq4repair_space>flush<seq2seq4repair_space>is<seq2seq4repair_space>not<seq2seq4repair_space>allowed" ) ; } if ( ! ( flushing . compareAndSet ( false , true ) ) ) { throw new FlushNotAllowedEngineException ( shardId , "Already<seq2seq4repair_space>flushing..." ) ; } try { if ( flush . full ( ) ) { rwl . writeLock ( ) . lock ( ) ; try { if ( ( indexWriter ) == null ) { throw new EngineClosedException ( shardId , failedEngine ) ; } if ( ( disableFlushCounter ) > 0 ) { throw new FlushNotAllowedEngineException ( shardId , "Recovery<seq2seq4repair_space>is<seq2seq4repair_space>in<seq2seq4repair_space>progress,<seq2seq4repair_space>flush<seq2seq4repair_space>is<seq2seq4repair_space>not<seq2seq4repair_space>allowed" ) ; } dirty = false ; try { <START_BUG> indexWriter . close ( ) ; <END_BUG> indexWriter = createWriter ( ) ; if ( flushNeeded ) { flushNeeded = false ; long translogId = translogIdGenerator . incrementAndGet ( ) ; indexWriter . commit ( MapBuilder . < String , String > newMapBuilder ( ) . put ( TRANSLOG_ID_KEY , Long . toString ( translogId ) ) . map ( ) ) ; translog . newTranslog ( translogId ) ; } AcquirableResource < ReaderSearcherHolder > current = nrtResource ; nrtResource = buildNrtResource ( indexWriter ) ; current . markForClose ( ) ; } catch ( Exception e ) { throw new FlushFailedEngineException ( shardId , e ) ; } catch ( OutOfMemoryError e ) { failEngine ( e ) ; throw new FlushFailedEngineException ( shardId , e ) ; } } finally { rwl . writeLock ( ) . unlock ( ) ; } } else { rwl . readLock ( ) . lock ( ) ; try { if ( ( indexWriter ) == null ) { throw new EngineClosedException ( shardId , failedEngine ) ; } if ( ( disableFlushCounter ) > 0 ) { throw new FlushNotAllowedEngineException ( shardId , "Recovery<seq2seq4repair_space>is<seq2seq4repair_space>in<seq2seq4repair_space>progress,<seq2seq4repair_space>flush<seq2seq4repair_space>is<seq2seq4repair_space>not<seq2seq4repair_space>allowed" ) ; } if ( flushNeeded ) { flushNeeded = false ; try { long translogId = translogIdGenerator . incrementAndGet ( ) ; translog . newTransientTranslog ( translogId ) ; indexWriter . commit ( MapBuilder . < String , String > newMapBuilder ( ) . put ( TRANSLOG_ID_KEY , Long . toString ( translogId ) ) . map ( ) ) ; translog . makeTransientCurrent ( ) ; } catch ( Exception e ) { translog . revertTransient ( ) ; throw new FlushFailedEngineException ( shardId , e ) ; } catch ( OutOfMemoryError e ) { translog . revertTransient ( ) ; failEngine ( e ) ; throw new FlushFailedEngineException ( shardId , e ) ; } } } finally { rwl . readLock ( ) . unlock ( ) ; } } refreshVersioningTable ( threadPool . estimatedTimeInMillis ( ) ) ; try { SegmentInfos infos = new SegmentInfos ( ) ;<BUG2FIX>indexWriter . close ( false ) ;
@ ThreadLeakFilters ( defaultFilters = true , filters = { ElasticsearchThreadFilter . class } ) @ ThreadLeakScope ( Scope . NONE ) @ TimeoutSuite ( millis = 20 * ( TimeUnits . MINUTE ) ) @ Listeners ( LoggingListener . class ) public abstract class ElasticsearchTestCase extends AbstractRandomizedTest { private static Thread . UncaughtExceptionHandler defaultHandler ; protected final ESLogger logger = Loggers . getLogger ( getClass ( ) ) ; public static final String CHILD_VM_ID = System . getProperty ( "junit4.childvm.id" , ( "" + ( System . currentTimeMillis ( ) ) ) ) ; public static final String TESTS_SECURITY_MANAGER = System . getProperty ( "tests.security.manager" ) ; public static final String JAVA_SECURTY_POLICY = System . getProperty ( "java.security.policy" ) ; public static final boolean ASSERTIONS_ENABLED ; public static boolean awaitBusy ( Predicate < ? > breakPredicate ) throws InterruptedException { } public static boolean awaitBusy ( Predicate < ? > breakPredicate , long maxWaitTime , TimeUnit unit ) throws InterruptedException { } private static final String [ ] numericTypes = new String [ ] { "byte" , "short" , "integer" , "long" } ; public static String randomNumericType ( Random random ) { } public File getResource ( String relativePath ) { } @ Before public void resetPageTracking ( ) { } @ After public void ensureAllPagesReleased ( ) { } @ Before public void resetArrayTracking ( ) { } @ After public void ensureAllArraysReleased ( ) { } public static void ensureAllFilesClosed ( ) throws IOException { try { for ( final MockDirectoryHelper . ElasticsearchMockDirectoryWrapper w : MockDirectoryHelper . wrappers ) { try { ElasticsearchTestCase . awaitBusy ( new Predicate < Object > ( ) { @ Override public boolean apply ( Object input ) { return ! ( w . isOpen ( ) ) ; } } ) ; } catch ( InterruptedException e ) { Thread . interrupted ( ) ; } if ( ! ( w . successfullyClosed ( ) ) ) { if ( ( w . closeException ( ) ) == null ) { w . close ( ) ; <START_BUG> if ( ( w . closeException ( ) ) == null ) { <END_BUG> throw w . closeException ( ) ; } } else { throw w . closeException ( ) ; } } assertThat ( w . isOpen ( ) , is ( false ) ) ; } } finally { ElasticsearchTestCase . forceClearMockWrappers ( ) ; } } public static void ensureAllSearchersClosed ( ) { } public static void forceClearMockWrappers ( ) { } public static boolean hasUnclosedWrapper ( ) { } @ BeforeClass public static void setBeforeClass ( ) throws Exception { } @ AfterClass public static void resetAfterClass ( ) { } public static boolean maybeDocValues ( ) { } private static final List < Version > SORTED_VERSIONS ; public static Version getPreviousVersion ( ) { } public static Version randomVersion ( ) { } public static Version randomVersion ( Random random ) { } static final class ElasticsearchUncaughtExceptionHandler implements Thread . UncaughtExceptionHandler { private final Thread . UncaughtExceptionHandler parent ; private final ESLogger logger = Loggers . getLogger ( getClass ( ) ) ; private ElasticsearchUncaughtExceptionHandler ( Thread . UncaughtExceptionHandler parent ) { } @ Override public void uncaughtException ( Thread t , Throwable e ) { } } protected static final void printStackDump ( ESLogger logger ) { } private static String formatThreadStacks ( Map < Thread , StackTraceElement [ ] > threads ) { } private static String threadName ( Thread t ) { } private static String groupName ( ThreadGroup threadGroup ) { } }<BUG2FIX>if ( ( w . closeException ( ) ) != null ) {
public class GistFragment extends RoboSherlockFragment implements OnItemClickListener { private static final int REQUEST_CODE_COMMENT = 1 ; private String gistId ; private List < Comment > comments ; private Gist gist ; @ InjectView ( id . list ) private ListView list ; @ Inject private GistStore store ; @ Inject private ContextScopedProvider < GistService > service ; private View headerView ; private GistHeaderViewHolder headerHolder ; private View loadingView ; private RefreshAnimation refreshAnimation = new RefreshAnimation ( ) ; private boolean starred ; private boolean loadFinished ; @ Inject private AvatarHelper avatarHelper ; @ Inject private ContextScopedProvider < GistService > gistServiceProvider ; private Executor executor = Executors . newFixedThreadPool ( 1 ) ; private List < View > fileHeaders = Lists . newArrayList ( ) ; @ SuppressWarnings ( "unchecked" ) public void onCreate ( Bundle savedInstanceState ) { } public View onCreateView ( LayoutInflater inflater , ViewGroup container , Bundle savedInstanceState ) { View root = inflater . inflate ( gist_view , null ) ; headerView = inflater . inflate ( gist_header , null ) ; <START_BUG> headerHolder = new GistHeaderViewHolder ( headerView , avatarHelper ) ; <END_BUG> loadingView = inflater . inflate ( comment_load_item , null ) ; return root ; } public void onActivityCreated ( Bundle savedInstanceState ) { } private boolean isOwner ( ) { } @ Override public void onCreateOptionsMenu ( Menu options , MenuInflater inflater ) { } @ Override public void onPrepareOptionsMenu ( Menu menu ) { } @ Override public boolean onOptionsItemSelected ( MenuItem item ) { } private void starGist ( ) { } private void unstarGist ( ) { } @ Override public void onActivityResult ( int requestCode , int resultCode , Intent data ) { } private void createComment ( final String comment ) { } private void updateFiles ( Gist gist ) { } private void updateList ( Gist gist , List < Comment > comments ) { } @ SuppressWarnings ( "unchecked" ) private ViewHoldingListAdapter < Comment > getRootAdapter ( ) { } private void refreshGist ( ) { } public void onItemClick ( AdapterView < ? > parent , View view , int position , long id ) { } }<BUG2FIX>headerHolder = new GistHeaderViewHolder ( headerView ) ;
public class PlainShardsIterator implements ShardsIterator { private final List < ShardRouting > shards ; private final int size ; private final int index ; private final int limit ; private volatile int counter ; public PlainShardsIterator ( List < ShardRouting > shards ) { } public PlainShardsIterator ( List < ShardRouting > shards , int index ) { } @ Override public ShardsIterator reset ( ) { } @ Override public int remaining ( ) { } @ Override public ShardRouting firstOrNull ( ) { if ( ( size ) == 0 ) { return null ; } <START_BUG> return shards . get ( ( ( ( index ) + 1 ) % ( size ) ) ) ; <END_BUG> } @ Override public ShardRouting nextOrNull ( ) { } @ Override public int size ( ) { } @ Override public int sizeActive ( ) { } @ Override public int assignedReplicasIncludingRelocating ( ) { } @ Override public Iterable < ShardRouting > asUnordered ( ) { } }<BUG2FIX>return shards . get ( index ) ;
public final class Intersector { public static float getLowestPositiveRoot ( float a , float b , float c ) { } private static final Vector3 v0 = new Vector3 ( ) ; private static final Vector3 v1 = new Vector3 ( ) ; private static final Vector3 v2 = new Vector3 ( ) ; public static boolean isPointInTriangle ( Vector3 point , Vector3 t1 , Vector3 t2 , Vector3 t3 ) { } public static boolean intersectSegmentPlane ( Vector3 start , Vector3 end , Plane plane , Vector3 intersection ) { } public static int pointLineSide ( Vector2 linePoint1 , Vector2 linePoint2 , Vector2 point ) { } public static int pointLineSide ( float linePoint1X , float linePoint1Y , float linePoint2X , float linePoint2Y , float pointX , float pointY ) { } public static boolean isPointInPolygon ( List < Vector2 > polygon , Vector2 point ) { } public static float distanceLinePoint ( Vector2 start , Vector2 end , Vector2 point ) { } public static float distanceLinePoint ( float startX , float startY , float endX , float endY , float pointX , float pointY ) { } public static boolean intersectSegmentCircle ( Vector2 start , Vector2 end , Vector2 center , float squareRadius ) { } public static float intersectSegmentCircleDisplace ( Vector2 start , Vector2 end , Vector2 point , float radius , Vector2 displacement ) { } public static boolean intersectRayPlane ( Ray ray , Plane plane , Vector3 intersection ) { } public static float intersectLinePlane ( float x , float y , float z , float x2 , float y2 , float z2 , Plane plane , Vector3 intersection ) { } private static final Plane p = new Plane ( new Vector3 ( ) , 0 ) ; private static final Vector3 i = new Vector3 ( ) ; public static boolean intersectRayTriangle ( Ray ray , Vector3 t1 , Vector3 t2 , Vector3 t3 , Vector3 intersection ) { } private static final Vector3 dir = new Vector3 ( ) ; private static final Vector3 start = new Vector3 ( ) ; public static boolean intersectRaySphere ( Ray ray , Vector3 center , float radius , Vector3 intersection ) { } public static boolean intersectRayBounds ( Ray ray , BoundingBox box , Vector3 intersection ) { Vector3 . tmp . set ( ray . origin ) ; Vector3 . tmp2 . set ( ray . origin ) ; Vector3 . tmp . sub ( box . min ) ; <START_BUG> Vector3 . tmp2 . sub ( box . max ) ; <END_BUG> if ( ( ( ( ( ( ( Vector3 . tmp . x ) > 0 ) && ( ( Vector3 . tmp . y ) > 0 ) ) && ( ( Vector3 . tmp . z ) > 0 ) ) && ( ( Vector3 . tmp2 . x ) < 0 ) ) && ( ( Vector3 . tmp2 . y ) < 0 ) ) && ( ( Vector3 . tmp2 . z ) < 0 ) ) { return true ; } float lowest = 0 ; float t ; boolean hit = false ; if ( ( ( ray . origin . x ) <= ( box . min . x ) ) && ( ( ray . direction . x ) > 0 ) ) { t = ( ( box . min . x ) - ( ray . origin . x ) ) / ( ray . direction . x ) ; if ( t >= 0 ) { Vector3 . tmp3 . set ( ray . direction ) . scl ( t ) . add ( ray . origin ) ; if ( ( ( ( ( ( Vector3 . tmp3 . y ) >= ( box . min . y ) ) && ( ( Vector3 . tmp3 . y ) <= ( box . max . y ) ) ) && ( ( Vector3 . tmp3 . z ) >= ( box . min . z ) ) ) && ( ( Vector3 . tmp3 . z ) <= ( box . max . z ) ) ) && ( ( ! hit ) || ( t < lowest ) ) ) { hit = true ; lowest = t ; } } } if ( ( ( ray . origin . x ) >= ( box . max . x ) ) && ( ( ray . direction . x ) < 0 ) ) { t = ( ( box . max . x ) - ( ray . origin . x ) ) / ( ray . direction . x ) ; if ( t >= 0 ) { Vector3 . tmp3 . set ( ray . direction ) . scl ( t ) . add ( ray . origin ) ; if ( ( ( ( ( ( Vector3 . tmp3 . y ) >= ( box . min . y ) ) && ( ( Vector3 . tmp3 . y ) <= ( box . max . y ) ) ) && ( ( Vector3 . tmp3 . z ) >= ( box . min . z ) ) ) && ( ( Vector3 . tmp3 . z ) <= ( box . max . z ) ) ) && ( ( ! hit ) || ( t < lowest ) ) ) { hit = true ; lowest = t ; } } } if ( ( ( ray . origin . y ) <= ( box . min . y ) ) && ( ( ray . direction . y ) > 0 ) ) { t = ( ( box . min . y ) - ( ray . origin . y ) ) / ( ray . direction . y ) ;<BUG2FIX>Vector3 . tmp . sub ( box . max ) ;
public abstract class TransportClusterInfoAction < Request extends ClusterInfoRequest , Response extends ActionResponse > extends TransportMasterNodeReadOperationAction < Request , Response > { public TransportClusterInfoAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool ) { } @ Override protected String executor ( ) { } @ Override protected final void masterOperation ( final Request request , final ClusterState state , final ActionListener < Response > listener ) throws ElasticsearchException { <START_BUG> String [ ] concreteIndices = state . metaData ( ) . concreteIndices ( request . indices ( ) , request . indicesOptions ( ) ) ; <END_BUG> request . indices ( concreteIndices ) ; doMasterOperation ( request , state , listener ) ; } protected abstract void doMasterOperation ( Request request , ClusterState state , final ActionListener < Response > listener ) throws ElasticsearchException { } }<BUG2FIX>String [ ] concreteIndices = state . metaData ( ) . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ;
public class Body { protected final long addr ; private final float [ ] tmp = new float [ 4 ] ; private final World world ; private ArrayList < Fixture > fixtures = new ArrayList < Fixture > ( 2 ) ; protected ArrayList < JointEdge > joints = new ArrayList < JointEdge > ( 2 ) ; private Object userData ; protected Body ( World world , long addr ) { } public Fixture createFixture ( FixtureDef def ) { } private native long jniCreateFixture ( long addr , long shapeAddr , float friction , float restitution , float density , boolean isSensor , short filterCategoryBits , short filterMaskBits , short filterGroupIndex ) { } public Fixture createFixture ( Shape shape , float density ) { } private native long jniCreateFixture ( long addr , long shapeAddr , float density ) { } public void destroyFixture ( Fixture fixture ) { } private native void jniDestroyFixture ( long addr , long fixtureAddr ) { } public void setTransform ( Vector2 position , float angle ) { } private native void jniSetTransform ( long addr , float positionX , float positionY , float angle ) { } private final Transform transform = new Transform ( ) ; public Transform getTransform ( ) { } private native void jniGetTransform ( long addr , float [ ] vals ) { } private final Vector2 position = new Vector2 ( ) ; public Vector2 getPosition ( ) { } private native void jniGetPosition ( long addr , float [ ] position ) { } public float getAngle ( ) { } private native float jniGetAngle ( long addr ) { } private final Vector2 worldCenter = new Vector2 ( ) ; public Vector2 getWorldCenter ( ) { } private native void jniGetWorldCenter ( long addr , float [ ] worldCenter ) { } private final Vector2 localCenter = new Vector2 ( ) ; public Vector2 getLocalCenter ( ) { } private native void jniGetLocalCenter ( long addr , float [ ] localCenter ) { } public void setLinearVelocity ( Vector2 v ) { } private native void jniSetLinearVelocity ( long addr , float x , float y ) { } private final Vector2 linearVelocity = new Vector2 ( ) ; public Vector2 getLinearVelocity ( ) { } private native void jniGetLinearVelocity ( long addr , float [ ] tmpLinearVelocity ) { } public void setAngularVelocity ( float omega ) { } private native void jniSetAngularVelocity ( long addr , float omega ) { } public float getAngularVelocity ( ) { } private native float jniGetAngularVelocity ( long addr ) { } public void applyForce ( Vector2 force , Vector2 point ) { } private native void jniApplyForce ( long addr , float forceX , float forceY , float pointX , float pointY ) { } public void applyTorque ( float torque ) { } private native void jniApplyTorque ( long addr , float torque ) { } public void applyLinearImpulse ( Vector2 impulse , Vector2 point ) { } private native void jniApplyLinearImpulse ( long addr , float impulseX , float impulseY , float pointX , float pointY ) { } public void applyAngularImpulse ( float impulse ) { } private native void jniApplyAngularImpulse ( long addr , float impulse ) { } public float getMass ( ) { } private native float jniGetMass ( long addr ) { } public float getInertia ( ) { } private native float jniGetInertia ( long addr ) { } private final MassData massData = new MassData ( ) ; public MassData getMassData ( ) { jniGetMassData ( addr , tmp ) ; massData . mass = tmp [ 0 ] ; massData . center . x = tmp [ 1 ] ; massData . center . y = tmp [ 2 ] ; massData . I = tmp [ 3 ] ; <START_BUG> return null ; <END_BUG> } private native void jniGetMassData ( long addr , float [ ] massData ) { } public void setMassData ( MassData data ) { } private native void jniSetMassData ( long addr , float mass , float centerX , float centerY , float I ) { } public void resetMassData ( ) { } private native void jniResetMassData ( long addr ) { } private final Vector2 localPoint = new Vector2 ( ) ; public Vector2 getWorldPoint ( Vector2 localPoint ) { } private native void jniGetWorldPoint ( long addr , float localPointX , float localPointY , float [ ] worldPoint ) { } private final Vector2 worldVector = new Vector2 ( ) ; public Vector2 getWorldVector ( Vector2 localVector ) { } private native void jniGetWorldVector ( long addr , float localVectorX , float localVectorY , float [ ] worldVector ) { } public final Vector2 localPoint2 = new Vector2 ( ) ; public Vector2 getLocalPoint ( Vector2 worldPoint ) { } private native void jniGetLocalPoint ( long addr , float worldPointX , float worldPointY , float [ ] localPoint ) { } public final Vector2 localVector = new Vector2 ( ) ; public Vector2 getLocalVector ( Vector2 worldVector ) { } private native void jniGetLocalVector ( long addr , float worldVectorX , float worldVectorY , float [ ] worldVector ) { } public final Vector2 linVelWorld = new Vector2 ( ) ; public Vector2 getLinearVelocityFromWorldPoint ( Vector2 worldPoint ) { } private native void jniGetLinearVelocityFromWorldPoint ( long addr , float worldPointX , float worldPointY , float [ ] linVelWorld ) { } public final Vector2 linVelLoc = new Vector2 ( ) ; public Vector2 getLinearVelocityFromLocalPoint ( Vector2 localPoint ) { } private native void jniGetLinearVelocityFromLocalPoint ( long addr , float localPointX , float localPointY , float [ ] linVelLoc ) { } public float getLinearDamping ( ) { } private native float jniGetLinearDamping ( long add ) { } public void setLinearDamping ( float linearDamping ) { } private native void jniSetLinearDamping ( long addr , float linearDamping ) { }<BUG2FIX>return massData ;
public class RandomScoreFunctionTests extends AbstractSharedClusterTest { @ Override public Settings getSettings ( ) { } @ Override protected int numberOfNodes ( ) { } @ Test public void consistentHitsWithSameSeed ( ) throws Exception { prepareCreate ( "test" ) . execute ( ) . actionGet ( ) ; ensureGreen ( ) ; int docCount = atLeast ( 100 ) ; for ( int i = 0 ; i < docCount ; i ++ ) { <START_BUG> index ( "test" , "type" , ( "" + docCount ) , jsonBuilder ( ) . startObject ( ) . endObject ( ) ) ; <END_BUG> } flush ( ) ; long seed = System . nanoTime ( ) ; String preference = _TestUtil . randomRealisticUnicodeString ( getRandom ( ) ) ; float [ ] scores = null ; for ( int i = 0 ; i < 3 ; i ++ ) { SearchResponse searchResponse = client ( ) . prepareSearch ( ) . setPreference ( preference ) . setQuery ( functionScoreQuery ( matchAllQuery ( ) ) . add ( new RandomScoreFunctionBuilder ( ) . seed ( seed ) ) ) . execute ( ) . actionGet ( ) ; assertThat ( ( "Failures<seq2seq4repair_space>" + ( Arrays . toString ( searchResponse . getShardFailures ( ) ) ) ) , searchResponse . getShardFailures ( ) . length , CoreMatchers . equalTo ( 0 ) ) ; int hitCount = searchResponse . getHits ( ) . getHits ( ) . length ; if ( scores == null ) { scores = new float [ hitCount ] ; for ( int j = 0 ; j < hitCount ; j ++ ) { scores [ j ] = searchResponse . getHits ( ) . getAt ( j ) . score ( ) ; } } else { for ( int j = 0 ; j < hitCount ; j ++ ) { assertThat ( searchResponse . getHits ( ) . getAt ( j ) . score ( ) , CoreMatchers . equalTo ( scores [ j ] ) ) ; } } } } @ Test @ Ignore public void distribution ( ) throws Exception { } }<BUG2FIX>index ( "test" , "type" , ( "" + i ) , jsonBuilder ( ) . startObject ( ) . endObject ( ) ) ;
public class ScriptRangeFacetCollector extends AbstractFacetCollector { private final SearchScript keyScript ; private final SearchScript valueScript ; private final Entry [ ] entries ; public ScriptRangeFacetCollector ( String facetName , String scriptLang , String keyScript , String valueScript , Map < String , Object > params , RangeFacet [ ] entries , SearchContext context ) { } @ Override protected void doSetNextReader ( IndexReader reader , int docBase ) throws IOException { } @ Override protected void doCollect ( int doc ) throws IOException { } @ Override public Facet facet ( ) { <START_BUG> return new InternalRangeFacet ( facetName , "_na" , "_na" , entries ) ; <END_BUG> } }<BUG2FIX>return new InternalRangeFacet ( facetName , entries ) ;
public class WidgetGroup extends Group implements Layout { private boolean needsLayout = true ; private boolean fillParent ; private boolean layoutEnabled = true ; public float getMinWidth ( ) { } public float getMinHeight ( ) { } public float getPrefWidth ( ) { } public float getPrefHeight ( ) { } public float getMaxWidth ( ) { } public float getMaxHeight ( ) { } public void setLayoutEnabled ( boolean enabled ) { } private void setLayoutEnabled ( Group parent , boolean enabled ) { } public void validate ( ) { } public boolean needsLayout ( ) { } public void invalidate ( ) { } public void invalidateHierarchy ( ) { } protected void childrenChanged ( ) { } public void pack ( ) { } public void setFillParent ( boolean fillParent ) { } public void layout ( ) { } public void draw ( SpriteBatch batch , float parentAlpha ) { validate ( ) ; <START_BUG> super . drawChildren ( batch , parentAlpha ) ; <END_BUG> } }<BUG2FIX>super . draw ( batch , parentAlpha ) ;
public class QueryPhase implements SearchPhase { private final FacetsPhase facetsPhase ; @ Inject public QueryPhase ( FacetsPhase facetsPhase ) { } @ Override public Map < String , ? extends SearchParseElement > parseElements ( ) { } public void execute ( SearchContext searchContext ) throws QueryPhaseExecutionException { try { searchContext . queryResult ( ) . from ( searchContext . from ( ) ) ; searchContext . queryResult ( ) . size ( searchContext . size ( ) ) ; Query query = searchContext . query ( ) ; if ( ( searchContext . types ( ) . length ) > 0 ) { if ( ( searchContext . types ( ) . length ) == 1 ) { String type = searchContext . types ( ) [ 0 ] ; DocumentMapper docMapper = searchContext . mapperService ( ) . documentMapper ( type ) ; Filter typeFilter = new org . elasticsearch . util . lucene . search . TermFilter ( docMapper . typeMapper ( ) . term ( docMapper . type ( ) ) ) ; typeFilter = searchContext . filterCache ( ) . cache ( typeFilter ) ; query = new FilteredQuery ( query , typeFilter ) ; } else { BooleanFilter booleanFilter = new BooleanFilter ( ) ; for ( String type : searchContext . types ( ) ) { DocumentMapper docMapper = searchContext . mapperService ( ) . documentMapper ( type ) ; Filter typeFilter = new org . elasticsearch . util . lucene . search . TermFilter ( docMapper . typeMapper ( ) . term ( docMapper . type ( ) ) ) ; typeFilter = searchContext . filterCache ( ) . cache ( typeFilter ) ; booleanFilter . add ( new FilterClause ( typeFilter , Occur . SHOULD ) ) ; } query = new FilteredQuery ( query , booleanFilter ) ; } } TopDocs topDocs ; if ( ( searchContext . sort ( ) ) != null ) { topDocs = searchContext . searcher ( ) . search ( query , null , ( ( searchContext . from ( ) ) + ( searchContext . size ( ) ) ) , searchContext . sort ( ) ) ; } else { topDocs = searchContext . searcher ( ) . search ( query , ( ( searchContext . from ( ) ) + ( searchContext . size ( ) ) ) ) ; } searchContext . queryResult ( ) . topDocs ( topDocs ) ; } catch ( Exception e ) { <START_BUG> throw new QueryPhaseExecutionException ( searchContext ) ; <END_BUG> } facetsPhase . execute ( searchContext ) ; } }<BUG2FIX>throw new QueryPhaseExecutionException ( searchContext , e ) ;
public class JniGenSharedLibraryLoader { private static Set < String > loadedLibraries = new HashSet < String > ( ) ; private String nativesJar ; private SharedLibraryFinder libraryFinder ; private ZipFile nativesZip = null ; public JniGenSharedLibraryLoader ( ) { } public JniGenSharedLibraryLoader ( String nativesJar ) { } public JniGenSharedLibraryLoader ( String nativesJar , SharedLibraryFinder libraryFinder ) { } public void setSharedLibraryFinder ( SharedLibraryFinder libraryFinder ) { } public String crc ( InputStream input ) { } private boolean loadLibrary ( String sharedLibName ) { } private String extractLibrary ( String sharedLibName ) { } private InputStream getFromJar ( String jarFile , String sharedLibrary ) throws IOException { } public synchronized void load ( String sharedLibName ) { if ( JniGenSharedLibraryLoader . loadedLibraries . contains ( sharedLibName ) ) return ; boolean isWindows = System . getProperty ( "os.name" ) . contains ( "Windows" ) ; boolean isLinux = System . getProperty ( "os.name" ) . contains ( "Linux" ) ; boolean isMac = System . getProperty ( "os.name" ) . contains ( "Mac" ) ; boolean isAndroid = false ; <START_BUG> boolean is64Bit = ( System . getProperty ( "os.arch" ) . equals ( "amd64" ) ) || ( System . getProperty ( "os.arch" ) . equals ( "x86_64" ) ) ; <END_BUG> String vm = System . getProperty ( "java.vm.name" ) ; if ( ( vm != null ) && ( vm . contains ( "Dalvik" ) ) ) { isAndroid = true ; isWindows = false ; isLinux = false ; isMac = false ; is64Bit = false ; } boolean loaded = false ; if ( isWindows ) { if ( ( libraryFinder ) != null ) loaded = loadLibrary ( libraryFinder . getSharedLibraryNameWindows ( sharedLibName , is64Bit , nativesZip ) ) ; else if ( ! is64Bit ) loaded = loadLibrary ( ( sharedLibName + ".dll" ) ) ; else loaded = loadLibrary ( ( sharedLibName + "64.dll" ) ) ; } if ( isLinux ) { if ( ( libraryFinder ) != null ) loaded = loadLibrary ( libraryFinder . getSharedLibraryNameLinux ( sharedLibName , is64Bit , nativesZip ) ) ; else if ( ! is64Bit ) loaded = loadLibrary ( ( ( "lib" + sharedLibName ) + ".so" ) ) ; else loaded = loadLibrary ( ( ( "lib" + sharedLibName ) + "64.so" ) ) ; } if ( isMac ) { if ( ( libraryFinder ) != null ) loaded = loadLibrary ( libraryFinder . getSharedLibraryNameMac ( sharedLibName , is64Bit , nativesZip ) ) ; else if ( ! is64Bit ) loaded = loadLibrary ( ( ( "lib" + sharedLibName ) + ".dylib" ) ) ; else loaded = loadLibrary ( ( ( "lib" + sharedLibName ) + "64.dylib" ) ) ; } if ( isAndroid ) { if ( ( libraryFinder ) != null ) System . loadLibrary ( libraryFinder . getSharedLibraryNameAndroid ( sharedLibName , nativesZip ) ) ; else System . loadLibrary ( sharedLibName ) ; loaded = true ; } if ( loaded ) JniGenSharedLibraryLoader . loadedLibraries . add ( sharedLibName ) ; } }<BUG2FIX>boolean is64Bit = System . getProperty ( "os.arch" ) . equals ( "amd64" ) ;
public class AndroidApplication extends Activity implements Application { protected AndroidGraphics graphics ; protected AndroidInput input ; protected AndroidAudio audio ; protected AndroidFiles files ; protected AndroidNet net ; protected ApplicationListener listener ; protected Handler handler ; protected boolean firstResume = true ; protected final Array < Runnable > runnables = new Array < Runnable > ( ) ; protected final Array < Runnable > executedRunnables = new Array < Runnable > ( ) ; protected WakeLock wakeLock = null ; protected int logLevel = LOG_INFO ; public void initialize ( ApplicationListener listener , boolean useGL2IfAvailable ) { } public void initialize ( ApplicationListener listener , AndroidApplicationConfiguration config ) { graphics = new AndroidGraphics ( this , config , ( ( config . resolutionStrategy ) == null ? new FillResolutionStrategy ( ) : config . resolutionStrategy ) ) ; input = new AndroidInput ( this , graphics . view , config ) ; audio = new AndroidAudio ( this , config ) ; files = new AndroidFiles ( this . getAssets ( ) , this . getFilesDir ( ) . getAbsolutePath ( ) ) ; <START_BUG> net = new AndroidNet ( this ) ; <END_BUG> this . listener = listener ; this . handler = new Handler ( ) ; Gdx . app = this ; Gdx . input = this . getInput ( ) ; Gdx . audio = this . getAudio ( ) ; Gdx . files = this . getFiles ( ) ; Gdx . graphics = this . getGraphics ( ) ; Gdx . net = this . getNet ( ) ; try { requestWindowFeature ( FEATURE_NO_TITLE ) ; } catch ( Exception ex ) { log ( "AndroidApplication" , "Content<seq2seq4repair_space>already<seq2seq4repair_space>displayed,<seq2seq4repair_space>cannot<seq2seq4repair_space>request<seq2seq4repair_space>FEATURE_NO_TITLE" , ex ) ; } getWindow ( ) . setFlags ( FLAG_FULLSCREEN , FLAG_FULLSCREEN ) ; getWindow ( ) . clearFlags ( FLAG_FORCE_NOT_FULLSCREEN ) ; setContentView ( graphics . getView ( ) , createLayoutParams ( ) ) ; createWakeLock ( config ) ; } protected LayoutParams createLayoutParams ( ) { } protected void createWakeLock ( AndroidApplicationConfiguration config ) { } public View initializeForView ( ApplicationListener listener , boolean useGL2IfAvailable ) { } public View initializeForView ( ApplicationListener listener , AndroidApplicationConfiguration config ) { } @ Override protected void onPause ( ) { } @ Override protected void onResume ( ) { } @ Override protected void onDestroy ( ) { } @ Override public Audio getAudio ( ) { } @ Override public Files getFiles ( ) { } @ Override public Graphics getGraphics ( ) { } @ Override public Input getInput ( ) { } @ Override public Net getNet ( ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } @ Override public Preferences getPreferences ( String name ) { } AndroidClipboard clipboard ; @ Override public Clipboard getClipboard ( ) { } @ Override public void postRunnable ( Runnable runnable ) { } @ Override public void onConfigurationChanged ( Configuration config ) { } @ Override public void exit ( ) { } @ Override public void debug ( String tag , String message ) { } @ Override public void debug ( String tag , String message , Throwable exception ) { } @ Override public void log ( String tag , String message ) { } @ Override public void log ( String tag , String message , Exception exception ) { } @ Override public void error ( String tag , String message ) { } @ Override public void error ( String tag , String message , Throwable exception ) { } @ Override public void setLogLevel ( int logLevel ) { } }<BUG2FIX>net = new AndroidNet ( ) ;
public class GistsActivity extends RoboFragmentActivity implements OnItemClickListener { private static final int REQUEST_CREATE = 1 ; private static final int REQUEST_VIEW = ( GistsActivity . REQUEST_CREATE ) + 1 ; @ Inject private Context context ; @ Inject private ContextScopedProvider < GistService > serviceProvider ; private GistsFragment gists ; @ Override protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; setContentView ( layout . gists ) ; <START_BUG> setTitle ( getString ( gists_title ) ) ; <END_BUG> gists = ( ( GistsFragment ) ( getSupportFragmentManager ( ) . findFragmentById ( list ) ) ) ; if ( ( gists ) == null ) { gists = new GistsFragment ( ) ; getSupportFragmentManager ( ) . beginTransaction ( ) . add ( list , gists ) . commit ( ) ; } gists . setClickListener ( this ) ; } private void randomGist ( ) { } private void openGist ( ) { } @ Override public boolean onCreateOptionsMenu ( Menu options ) { } @ Override public boolean onOptionsItemSelected ( MenuItem item ) { } public void onActivityResult ( int requestCode , int resultCode , Intent data ) { } public void onItemClick ( AdapterView < ? > list , View view , int position , long id ) { } }<BUG2FIX>setTitle ( gists_title ) ;
public class FiltersFunctionScoreQuery extends Query { public static class FilterFunction { public final Filter filter ; public final ScoreFunction function ; public FilterFunction ( Filter filter , ScoreFunction function ) { } @ Override public boolean equals ( Object o ) { } @ Override public int hashCode ( ) { } } public static enum ScoreMode { First , Avg , Max , Total , Min , Multiply ; } Query subQuery ; final FiltersFunctionScoreQuery . FilterFunction [ ] filterFunctions ; final FiltersFunctionScoreQuery . ScoreMode scoreMode ; final float maxBoost ; public FiltersFunctionScoreQuery ( Query subQuery , FiltersFunctionScoreQuery . ScoreMode scoreMode , FiltersFunctionScoreQuery . FilterFunction [ ] filterFunctions , float maxBoost ) { } public Query getSubQuery ( ) { } public FiltersFunctionScoreQuery . FilterFunction [ ] getFilterFunctions ( ) { } @ Override public Query rewrite ( IndexReader reader ) throws IOException { } @ Override public void extractTerms ( Set < Term > terms ) { } @ Override public Weight createWeight ( IndexSearcher searcher ) throws IOException { } class CustomBoostFactorWeight extends Weight { final Weight subQueryWeight ; final Bits [ ] docSets ; public CustomBoostFactorWeight ( Weight subQueryWeight , int filterFunctionLength ) throws IOException { } public Query getQuery ( ) { } @ Override public float getValueForNormalization ( ) throws IOException { } @ Override public void normalize ( float norm , float topLevelBoost ) { } @ Override public Scorer scorer ( AtomicReaderContext context , boolean scoreDocsInOrder , boolean topScorer , Bits acceptDocs ) throws IOException { } @ Override public Explanation explain ( AtomicReaderContext context , int doc ) throws IOException { } } static class CustomBoostFactorScorer extends Scorer { private final float subQueryBoost ; private final Scorer scorer ; private final FiltersFunctionScoreQuery . FilterFunction [ ] filterFunctions ; private final FiltersFunctionScoreQuery . ScoreMode scoreMode ; private final float maxBoost ; private final Bits [ ] docSets ; private CustomBoostFactorScorer ( FiltersFunctionScoreQuery . CustomBoostFactorWeight w , Scorer scorer , FiltersFunctionScoreQuery . ScoreMode scoreMode , FiltersFunctionScoreQuery . FilterFunction [ ] filterFunctions , float maxBoost , Bits [ ] docSets ) throws IOException { } @ Override public int docID ( ) { } @ Override public int advance ( int target ) throws IOException { } @ Override public int nextDoc ( ) throws IOException { } @ Override public float score ( ) throws IOException { } @ Override <START_BUG> public float freq ( ) throws IOException { <END_BUG> return scorer . freq ( ) ; } } public String toString ( String field ) { } public boolean equals ( Object o ) { } public int hashCode ( ) { } }<BUG2FIX>public int freq ( ) throws IOException {
public class RecyclerBenchmark { private static final long NUM_RECYCLES = 5000000L ; private static final Random RANDOM = new Random ( 0 ) ; private static long bench ( final Recycler < ? > recycler , long numRecycles , int numThreads ) throws InterruptedException { final AtomicLong recycles = new AtomicLong ( numRecycles ) ; final CountDownLatch latch = new CountDownLatch ( 1 ) ; final Thread [ ] threads = new Thread [ numThreads ] ; for ( int i = 0 ; i < numThreads ; ++ i ) { for ( int j = RecyclerBenchmark . RANDOM . nextInt ( 5 ) ; j >= 0 ; -- j ) { new Thread ( ) ; } threads [ i ] = new Thread ( ) { @ Override public void run ( ) { try { latch . await ( ) ; } catch ( InterruptedException e ) { return ; } while ( ( recycles . getAndDecrement ( ) ) > 0 ) { final Recycler . V < ? > v = recycler . obtain ( ) ; <START_BUG> v . release ( ) ; <END_BUG> } } } ; } for ( Thread thread : threads ) { thread . start ( ) ; } final long start = System . nanoTime ( ) ; latch . countDown ( ) ; for ( Thread thread : threads ) { thread . join ( ) ; } return ( System . nanoTime ( ) ) - start ; } public static void main ( String [ ] args ) throws InterruptedException { } }<BUG2FIX>v . close ( ) ;
else if ( "confidence" . equals ( fieldName ) ) { suggestion . setConfidence ( parser . floatValue ( ) ) ; if ( ( suggestion . confidence ( ) ) < 0.0 ) { throw new ElasticsearchIllegalArgumentException ( "confidence<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>>=<seq2seq4repair_space>0.0" ) ; } } else if ( "separator" . equals ( fieldName ) ) { suggestion . setSeparator ( new org . apache . lucene . util . BytesRef ( parser . text ( ) ) ) ; } else if ( ( "max_errors" . equals ( fieldName ) ) || ( "maxErrors" . equals ( fieldName ) ) ) { suggestion . setMaxErrors ( parser . floatValue ( ) ) ; if ( ( suggestion . maxErrors ( ) ) <= 0.0 ) { throw new ElasticsearchIllegalArgumentException ( "max_error<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>><seq2seq4repair_space>0.0" ) ; } } else if ( ( "gram_size" . equals ( fieldName ) ) || ( "gramSize" . equals ( fieldName ) ) ) { suggestion . setGramSize ( parser . intValue ( ) ) ; if ( ( suggestion . gramSize ( ) ) < 1 ) { throw new ElasticsearchIllegalArgumentException ( "gram_size<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>>=<seq2seq4repair_space>1" ) ; } gramSizeSet = true ; } else if ( ( "force_unigrams" . equals ( fieldName ) ) || ( "forceUnigrams" . equals ( fieldName ) ) ) { suggestion . setRequireUnigram ( parser . booleanValue ( ) ) ; } else if ( ( "token_limit" . equals ( fieldName ) ) || ( "tokenLimit" . equals ( fieldName ) ) ) { int tokenLimit = parser . intValue ( ) ; if ( tokenLimit <= 0 ) { throw new ElasticsearchIllegalArgumentException ( "token_limit<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>>=<seq2seq4repair_space>1" ) ; } suggestion . setTokenLimit ( tokenLimit ) ; } else { throw new ElasticsearchIllegalArgumentException ( ( ( "suggester[phrase]<seq2seq4repair_space>doesn't<seq2seq4repair_space>support<seq2seq4repair_space>field<seq2seq4repair_space>[" + fieldName ) + "]" ) ) ; } } } else if ( token == ( Token . START_ARRAY ) ) { if ( ( "direct_generator" . equals ( fieldName ) ) || ( "directGenerator" . equals ( fieldName ) ) ) { while ( ( token = parser . nextToken ( ) ) == ( Token . START_OBJECT ) ) { PhraseSuggestionContext . DirectCandidateGenerator generator = new PhraseSuggestionContext . DirectCandidateGenerator ( ) ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { fieldName = parser . currentName ( ) ; } if ( token . isValue ( ) ) { parseCandidateGenerator ( parser , mapperService , fieldName , generator ) ; } } verifyGenerator ( generator ) ; suggestion . addGenerator ( generator ) ; } } else { throw new ElasticsearchIllegalArgumentException ( ( ( "suggester[phrase]<seq2seq4repair_space>doesn't<seq2seq4repair_space>support<seq2seq4repair_space>array<seq2seq4repair_space>field<seq2seq4repair_space>[" + fieldName ) + "]" ) ) ; } } else if ( token == ( Token . START_OBJECT ) ) { if ( "smoothing" . equals ( fieldName ) ) { parseSmoothingModel ( parser , suggestion , fieldName ) ; } else if ( "highlight" . equals ( fieldName ) ) { while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { fieldName = parser . currentName ( ) ; } else if ( token . isValue ( ) ) { if ( ( "pre_tag" . equals ( fieldName ) ) || ( "preTag" . equals ( fieldName ) ) ) { suggestion . setPreTag ( parser . utf8Bytes ( ) ) ; } else if ( ( "post_tag" . equals ( fieldName ) ) || ( "postTag" . equals ( fieldName ) ) ) { suggestion . setPostTag ( parser . utf8Bytes ( ) ) ; } else { throw new ElasticsearchIllegalArgumentException ( ( ( "suggester[phrase][highlight]<seq2seq4repair_space>doesn't<seq2seq4repair_space>support<seq2seq4repair_space>field<seq2seq4repair_space>[" + fieldName ) + "]" ) ) ; } } } } else if ( "collate" . equals ( fieldName ) ) { while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { fieldName = parser . currentName ( ) ; } else if ( ( "query" . equals ( fieldName ) ) || ( "filter" . equals ( fieldName ) ) ) { String templateNameOrTemplateContent ; <START_BUG> if ( ( token == ( Token . START_OBJECT ) ) && ( ! ( parser . hasTextCharacters ( ) ) ) ) { <END_BUG> XContentBuilder builder = XContentBuilder . builder ( parser . contentType ( ) . xContent ( ) ) ; builder . copyCurrentStructure ( parser ) ; templateNameOrTemplateContent = builder . string ( ) ; } else { templateNameOrTemplateContent = parser . text ( ) ; } if ( templateNameOrTemplateContent == null ) { throw new ElasticsearchIllegalArgumentException ( "suggester[phrase][collate]<seq2seq4repair_space>no<seq2seq4repair_space>query/filter<seq2seq4repair_space>found<seq2seq4repair_space>in<seq2seq4repair_space>collate<seq2seq4repair_space>object" ) ; } if ( ( suggestion . getCollateFilterScript ( ) ) != null ) { throw new ElasticsearchIllegalArgumentException ( ( ( "suggester[phrase][collate]<seq2seq4repair_space>filter<seq2seq4repair_space>already<seq2seq4repair_space>set,<seq2seq4repair_space>doesn't<seq2seq4repair_space>support<seq2seq4repair_space>additional<seq2seq4repair_space>[" + fieldName ) + "]" ) ) ; } if ( ( suggestion . getCollateQueryScript ( ) ) != null ) { throw new ElasticsearchIllegalArgumentException ( ( ( "suggester[phrase][collate]<seq2seq4repair_space>query<seq2seq4repair_space>already<seq2seq4repair_space>set,<seq2seq4repair_space>doesn't<seq2seq4repair_space>support<seq2seq4repair_space>additional<seq2seq4repair_space>[" + fieldName ) + "]" ) ) ; } CompiledScript compiledScript = suggester . scriptService ( ) . compile ( "mustache" , templateNameOrTemplateContent ) ; if ( "query" . equals ( fieldName ) ) { suggestion . setCollateQueryScript ( compiledScript ) ; } else { suggestion . setCollateFilterScript ( compiledScript ) ; } } else if ( "preference" . equals ( fieldName ) ) { suggestion . setPreference ( parser . text ( ) ) ; } else if ( "params" . equals ( fieldName ) ) { suggestion . setCollateScriptParams ( parser . map ( ) ) ; } else if ( "prune" . equals ( fieldName ) ) { if ( parser . isBooleanValue ( ) ) { suggestion . setCollatePrune ( parser . booleanValue ( ) ) ; } else { throw new ElasticsearchIllegalArgumentException ( "suggester[phrase][collate]<seq2seq4repair_space>prune<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>either<seq2seq4repair_space>'true'<seq2seq4repair_space>or<seq2seq4repair_space>'false'" ) ; } }<BUG2FIX>if ( token == ( Token . START_OBJECT ) ) {
public class TransportSearchScrollQueryThenFetchAction extends AbstractComponent { private final ThreadPool threadPool ; private final ClusterService clusterService ; private final SearchServiceTransportAction searchService ; private final SearchPhaseController searchPhaseController ; private final TransportSearchCache searchCache ; @ Inject public TransportSearchScrollQueryThenFetchAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportSearchCache searchCache , SearchServiceTransportAction searchService , SearchPhaseController searchPhaseController ) { } public void execute ( SearchScrollRequest request , ParsedScrollId scrollId , ActionListener < SearchResponse > listener ) { } private class AsyncAction { private final SearchScrollRequest request ; private final ActionListener < SearchResponse > listener ; private final ParsedScrollId scrollId ; private final DiscoveryNodes nodes ; protected volatile Queue < ShardSearchFailure > shardFailures ; private final Map < SearchShardTarget , QuerySearchResultProvider > queryResults = searchCache . obtainQueryResults ( ) ; private final Map < SearchShardTarget , FetchSearchResult > fetchResults = searchCache . obtainFetchResults ( ) ; private volatile ShardDoc [ ] sortedShardList ; private final AtomicInteger successfulOps ; private final long startTime = System . currentTimeMillis ( ) ; private AsyncAction ( SearchScrollRequest request , ParsedScrollId scrollId , ActionListener < SearchResponse > listener ) { } protected final ShardSearchFailure [ ] buildShardFailures ( ) { } protected final void addShardFailure ( ShardSearchFailure failure ) { } public void start ( ) { } private void executeQueryPhase ( final AtomicInteger counter , DiscoveryNode node , final long searchId ) { } private void executeFetchPhase ( ) { } private void finishHim ( ) { try { innerFinishHim ( ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> listener . onFailure ( new ReduceSearchPhaseException ( "fetch" , "" , e , buildShardFailures ( ) ) ) ; } } private void innerFinishHim ( ) { } } }<BUG2FIX>} catch ( Throwable e ) {
public class RestTermsAction extends BaseRestHandler { private static final Pattern fieldsPattern ; @ Inject public RestTermsAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { TermsRequest termsRequest = new TermsRequest ( splitIndices ( request . param ( "index" ) ) ) ; termsRequest . listenerThreaded ( false ) ; try { BroadcastOperationThreading operationThreading = BroadcastOperationThreading . fromString ( request . param ( "operation_threading" ) , SINGLE_THREAD ) ; if ( operationThreading == ( BroadcastOperationThreading . NO_THREADS ) ) { operationThreading = BroadcastOperationThreading . SINGLE_THREAD ; } termsRequest . operationThreading ( operationThreading ) ; List < String > fields = request . params ( "field" ) ; String sField = request . param ( "fields" ) ; if ( sField != null ) { String [ ] sFields = RestTermsAction . fieldsPattern . split ( sField ) ; if ( sFields != null ) { if ( fields == null ) { fields = new ArrayList < String > ( ) ; } for ( String field : sFields ) { fields . add ( field ) ; } } } termsRequest . fields ( fields . toArray ( new String [ fields . size ( ) ] ) ) ; termsRequest . from ( request . param ( "from" ) ) ; termsRequest . to ( request . param ( "to" ) ) ; termsRequest . fromInclusive ( request . paramAsBoolean ( "from_inclusive" , termsRequest . fromInclusive ( ) ) ) ; termsRequest . toInclusive ( request . paramAsBoolean ( "to_inclusive" , termsRequest . toInclusive ( ) ) ) ; Object temp = request . param ( "gt" ) ; if ( temp != null ) { termsRequest . gt ( temp ) ; } else { temp = request . param ( "gte" ) ; if ( temp != null ) { termsRequest . gte ( temp ) ; } } temp = request . param ( "lt" ) ; if ( temp != null ) { termsRequest . lt ( temp ) ; } else { temp = request . param ( "lte" ) ; if ( temp != null ) { termsRequest . lte ( temp ) ; } } termsRequest . exact ( request . paramAsBoolean ( "exact" , termsRequest . exact ( ) ) ) ; termsRequest . minFreq ( request . paramAsInt ( "min_freq" , termsRequest . minFreq ( ) ) ) ; termsRequest . maxFreq ( request . paramAsInt ( "max_freq" , termsRequest . maxFreq ( ) ) ) ; termsRequest . size ( request . paramAsInt ( "size" , termsRequest . size ( ) ) ) ; termsRequest . prefix ( request . param ( "prefix" ) ) ; termsRequest . regexp ( request . param ( "regexp" ) ) ; <START_BUG> termsRequest . sortType ( SortType . fromString ( request . param ( "sort" ) , termsRequest . sortType ( ) ) ) ; <END_BUG> } catch ( Exception e ) { try { JsonBuilder builder = RestJsonBuilder . restJsonBuilder ( request ) ; channel . sendResponse ( new JsonRestResponse ( request , BAD_REQUEST , builder . startObject ( ) . field ( "error" , e . getMessage ( ) ) . endObject ( ) ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } return ; } final boolean termsAsArray = request . paramAsBoolean ( "terms_as_array" , true ) ; client . terms ( termsRequest , new org . elasticsearch . action . ActionListener < TermsResponse > ( ) { @ Override public void onResponse ( TermsResponse response ) { try { JsonBuilder builder = RestJsonBuilder . restJsonBuilder ( request ) ; builder . startObject ( ) ; buildBroadcastShardsHeader ( builder , response ) ; builder . startObject ( "docs" ) ; builder . field ( "num_docs" , response . numDocs ( ) ) ; builder . field ( "max_doc" , response . maxDoc ( ) ) ; builder . field ( "deleted_docs" , response . deletedDocs ( ) ) ; builder . endObject ( ) ; builder . startObject ( "fields" ) ; for ( FieldTermsFreq fieldTermsFreq : response . fields ( ) ) { builder . startObject ( fieldTermsFreq . fieldName ( ) ) ; if ( ! termsAsArray ) { builder . startObject ( "terms" ) ; for ( TermFreq termFreq : fieldTermsFreq . termsFreqs ( ) ) { builder . startObject ( termFreq . termAsString ( ) ) ; builder . field ( "doc_freq" , termFreq . docFreq ( ) ) ; builder . endObject ( ) ; } builder . endObject ( ) ; } else { builder . startArray ( "terms" ) ; for ( TermFreq termFreq : fieldTermsFreq . termsFreqs ( ) ) { builder . startObject ( ) ; builder . field ( "term" , termFreq . term ( ) ) ; builder . field ( "doc_freq" , termFreq . docFreq ( ) ) ; builder . endObject ( ) ; } builder . endArray ( ) ; } builder . endObject ( ) ; } builder . endObject ( ) ; builder . endObject ( ) ; channel . sendResponse ( new JsonRestResponse ( request , OK , builder ) ) ; } catch ( Exception e ) { onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new JsonThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>termsRequest . sortType ( request . param ( "sort" ) ) ;
public class Bits { long [ ] bits = new long [ ] { 0 } ; public boolean get ( int index ) { } public void set ( int index ) { } public void flip ( int index ) { } private void checkCapacity ( int len ) { <START_BUG> if ( len >= ( bits . length ) ) { <END_BUG> long [ ] newBits = new long [ len + 1 ] ; System . arraycopy ( bits , 0 , newBits , 0 , bits . length ) ; bits = newBits ; } } public void clear ( int index ) { } public void clear ( ) { } public int numBits ( ) { } }<BUG2FIX>if ( len > ( bits . length ) ) {
public class Array < T > implements Iterable < T > { public T [ ] items ; public int size ; public boolean ordered ; private Array . ArrayIterator iterator ; public Array ( ) { } public Array ( int capacity ) { } public Array ( boolean ordered , int capacity ) { } public Array ( boolean ordered , int capacity , Class < T > arrayType ) { } public Array ( Class < T > arrayType ) { } public Array ( Array array ) { } public Array ( T [ ] array ) { } public Array ( boolean ordered , T [ ] array ) { } public void add ( T value ) { } public void addAll ( Array array ) { } public void addAll ( Array array , int offset , int length ) { } public void addAll ( T [ ] array ) { } public void addAll ( T [ ] array , int offset , int length ) { } public T get ( int index ) { } public void set ( int index , T value ) { } public void insert ( int index , T value ) { } public boolean contains ( T value , boolean identity ) { } public int indexOf ( T value , boolean identity ) { } public boolean removeValue ( T value , boolean identity ) { } public T removeIndex ( int index ) { } public T pop ( ) { } public T peek ( ) { } public void clear ( ) { } public void shrink ( ) { } public T [ ] ensureCapacity ( int additionalCapacity ) { } protected T [ ] resize ( int newSize ) { } public void sort ( ) { } public void sort ( Comparator < T > comparator ) { } public void reverse ( ) { } public void shuffle ( ) { } public Iterator < T > iterator ( ) { } public void truncate ( int newSize ) { if ( ( size ) <= newSize ) return ; <START_BUG> for ( int i = size ; i < newSize ; i ++ ) <END_BUG> items [ i ] = null ; size = newSize ; } public T [ ] toArray ( ) { } public < V > V [ ] toArray ( Class < V > type ) { } public String toString ( ) { } public static class ArrayIterator < T > implements Iterator < T > { private final Array < T > array ; int index ; public ArrayIterator ( Array < T > array ) { } public boolean hasNext ( ) { } public T next ( ) { } public void remove ( ) { } public void reset ( ) { } } public static class ArrayIterable < T > implements Iterable < T > { private Array . ArrayIterator < T > iterator ; public ArrayIterable ( Array < T > array ) { } @ Override public Iterator < T > iterator ( ) { } } }<BUG2FIX>for ( int i = newSize ; i < ( size ) ; i ++ )
public class ClusterServiceTests extends AbstractZenNodesTests { @ After public void closeNodes ( ) { } @ Test public void testTimeoutUpdateTask ( ) throws Exception { } @ Test public void testPendingUpdateTask ( ) throws Exception { InternalNode node1 = ( ( InternalNode ) ( startNode ( "node1" ) ) ) ; Client client = startNode ( "client-node" , settingsBuilder ( ) . put ( "node.client" , true ) . build ( ) ) . client ( ) ; ClusterService clusterService = node1 . injector ( ) . getInstance ( ClusterService . class ) ; final CountDownLatch block1 = new CountDownLatch ( 1 ) ; final CountDownLatch invoked1 = new CountDownLatch ( 1 ) ; clusterService . submitStateUpdateTask ( "1" , new ClusterStateUpdateTask ( ) { @ Override public ClusterState execute ( ClusterState currentState ) { invoked1 . countDown ( ) ; try { block1 . await ( ) ; } catch ( InterruptedException e ) { assert false ; } return currentState ; } @ Override public void onFailure ( String source , Throwable t ) { invoked1 . countDown ( ) ; assert false ; } } ) ; invoked1 . await ( ) ; <START_BUG> final CountDownLatch invoked2 = new CountDownLatch ( 8 ) ; <END_BUG> for ( int i = 2 ; i <= 10 ; i ++ ) { clusterService . submitStateUpdateTask ( Integer . toString ( i ) , new ClusterStateUpdateTask ( ) { @ Override public ClusterState execute ( ClusterState currentState ) { invoked2 . countDown ( ) ; return currentState ; } @ Override public void onFailure ( String source , Throwable t ) { assert false ; } } ) ; } Set < String > controlSources = new HashSet < String > ( Arrays . asList ( "2" , "3" , "4" , "5" , "6" , "7" , "8" , "9" , "10" ) ) ; List < PendingClusterTask > pendingClusterTasks = clusterService . pendingTasks ( ) ; assertThat ( pendingClusterTasks . size ( ) , equalTo ( 9 ) ) ; for ( PendingClusterTask task : pendingClusterTasks ) { assertTrue ( controlSources . remove ( task . source ( ) . string ( ) ) ) ; } assertTrue ( controlSources . isEmpty ( ) ) ; controlSources = new HashSet < String > ( Arrays . asList ( "2" , "3" , "4" , "5" , "6" , "7" , "8" , "9" , "10" ) ) ; PendingClusterTasksResponse response = client . admin ( ) . cluster ( ) . preparePendingClusterTasks ( ) . execute ( ) . actionGet ( ) ; assertThat ( response . pendingTasks ( ) . size ( ) , equalTo ( 9 ) ) ; for ( PendingClusterTask task : response ) { assertTrue ( controlSources . remove ( task . source ( ) . string ( ) ) ) ; } assertTrue ( controlSources . isEmpty ( ) ) ; block1 . countDown ( ) ; invoked2 . await ( ) ; pendingClusterTasks = clusterService . pendingTasks ( ) ; assertThat ( pendingClusterTasks , empty ( ) ) ; response = client . admin ( ) . cluster ( ) . preparePendingClusterTasks ( ) . execute ( ) . actionGet ( ) ; assertThat ( response . pendingTasks ( ) , empty ( ) ) ; final CountDownLatch block2 = new CountDownLatch ( 1 ) ; final CountDownLatch invoked3 = new CountDownLatch ( 1 ) ; clusterService . submitStateUpdateTask ( "1" , new ClusterStateUpdateTask ( ) { @ Override public ClusterState execute ( ClusterState currentState ) { invoked3 . countDown ( ) ; try { block2 . await ( ) ; } catch ( InterruptedException e ) { assert false ; } return currentState ; } @ Override public void onFailure ( String source , Throwable t ) { invoked3 . countDown ( ) ; assert false ; } } ) ; invoked3 . await ( ) ; for ( int i = 2 ; i <= 5 ; i ++ ) { clusterService . submitStateUpdateTask ( Integer . toString ( i ) , new ClusterStateUpdateTask ( ) { @ Override public ClusterState execute ( ClusterState currentState ) { return currentState ; } @ Override public void onFailure ( String source , Throwable t ) { assert false ; } } ) ; } Thread . sleep ( 100 ) ; pendingClusterTasks = clusterService . pendingTasks ( ) ; assertThat ( pendingClusterTasks . size ( ) , equalTo ( 4 ) ) ; controlSources = new HashSet < String > ( Arrays . asList ( "2" , "3" , "4" , "5" ) ) ; for ( PendingClusterTask task : pendingClusterTasks ) { assertTrue ( controlSources . remove ( task . source ( ) . string ( ) ) ) ; } assertTrue ( controlSources . isEmpty ( ) ) ; response = client . admin ( ) . cluster ( ) . preparePendingClusterTasks ( ) . execute ( ) . actionGet ( ) ; assertThat ( response . pendingTasks ( ) . size ( ) , equalTo ( 4 ) ) ; controlSources = new HashSet < String > ( Arrays . asList ( "2" , "3" , "4" , "5" ) ) ; for ( PendingClusterTask task : response ) { assertTrue ( controlSources . remove ( task . source ( ) . string ( ) ) ) ; assertThat ( task . getTimeInQueueInMillis ( ) , greaterThan ( 0L ) ) ; } assertTrue ( controlSources . isEmpty ( ) ) ; block2 . countDown ( ) ; } @ Test public void testListenerCallbacks ( ) throws Exception { } public static class TestPlugin extends AbstractPlugin { @ Override public String name ( ) { } @ Override public String description ( ) { } @ Override public Collection < Class < ? extends LifecycleComponent > > services ( ) { } }<BUG2FIX>final CountDownLatch invoked2 = new CountDownLatch ( 9 ) ;
public class Table { private ArrayList < Table . Column > cols ; private byte numcols ; private byte height ; public Table ( ) { } public Table addRow ( Row row ) { } public void ensureCapacity ( int size ) { } public Table addRow ( Row row , boolean header ) { } public String render ( ) { } public String render ( boolean withHeaders ) { StringBuilder out = new StringBuilder ( ) ; for ( byte i = 0 ; i < ( height ) ; i ++ ) { StringBuilder row = new StringBuilder ( ) ; for ( Table . Column col : cols ) { Cell cell = col . getCell ( i ) ; boolean headerRowWhenNotWantingHeaders = ( ( i == 0 ) && ( ! withHeaders ) ) && ( col . hasHeader ( ) ) ; if ( ! headerRowWhenNotWantingHeaders ) { row . append ( cell . toString ( col . width ( ) , col . align ( ) ) ) ; row . append ( "<seq2seq4repair_space>" ) ; } } out . append ( row . toString ( ) . trim ( ) ) ; out . append ( "\n" ) ; } <START_BUG> return out . toString ( ) . trim ( ) ; <END_BUG> } private class Column { private boolean hasHeader ; private ArrayList < Cell > cells ; private byte width ; private Align align ; Column ( ) { } public Table . Column addCell ( Cell cell ) { } public Table . Column addCell ( Cell cell , boolean header ) { } public Cell getCell ( int index ) { } public Align align ( ) { } public byte width ( ) { } public boolean hasHeader ( ) { } } }<BUG2FIX>return out . toString ( ) ;
public class RestClusterRerouteAction extends BaseRestHandler { private final SettingsFilter settingsFilter ; @ Inject public RestClusterRerouteAction ( Settings settings , Client client , RestController controller , SettingsFilter settingsFilter ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { final ClusterRerouteRequest clusterRerouteRequest = Requests . clusterRerouteRequest ( ) ; clusterRerouteRequest . listenerThreaded ( false ) ; clusterRerouteRequest . dryRun ( request . paramAsBoolean ( "dry_run" , clusterRerouteRequest . dryRun ( ) ) ) ; if ( request . hasContent ( ) ) { try { clusterRerouteRequest . source ( request . content ( ) ) ; } catch ( Exception e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . warn ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>response" , e1 ) ; } return ; } } client . admin ( ) . cluster ( ) . reroute ( clusterRerouteRequest , new org . elasticsearch . action . ActionListener < ClusterRerouteResponse > ( ) { @ Override public void onResponse ( ClusterRerouteResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( "ok" , true ) ; builder . startObject ( "state" ) ; if ( ( request . param ( "filter_metadata" ) ) == null ) { request . params ( ) . put ( "filter_metadata" , "true" ) ; } response . getState ( ) . settingsFilter ( settingsFilter ) . toXContent ( builder , request ) ; builder . endObject ( ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>handle<seq2seq4repair_space>cluster<seq2seq4repair_space>reroute" , e ) ; } try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class ActionSequenceTest extends GdxTest implements Runnable { Image img ; Image img2 ; Image img3 ; Stage stage ; Texture texture ; @ Override public void create ( ) { <START_BUG> stage = new Stage ( 480 , 320 , true ) ; <END_BUG> texture = new Texture ( files . internal ( "data/badlogic.jpg" ) , false ) ; texture . setFilter ( Linear , Linear ) ; img = new Image ( new com . badlogic . gdx . graphics . g2d . TextureRegion ( texture ) ) ; img . setSize ( 100 , 100 ) ; img . setOrigin ( 50 , 50 ) ; img . setPosition ( 100 , 100 ) ; img2 = new Image ( new com . badlogic . gdx . graphics . g2d . TextureRegion ( texture ) ) ; img2 . setSize ( 100 , 100 ) ; img2 . setOrigin ( 50 , 50 ) ; img2 . setPosition ( 100 , 100 ) ; img3 = new Image ( new com . badlogic . gdx . graphics . g2d . TextureRegion ( texture ) ) ; img3 . setSize ( 100 , 100 ) ; img3 . setOrigin ( 50 , 50 ) ; img3 . setPosition ( 100 , 100 ) ; stage . addActor ( img ) ; stage . addActor ( img2 ) ; stage . addActor ( img3 ) ; img . addAction ( sequence ( ) ) ; img2 . addAction ( parallel ( sequence ( ) , moveBy ( 100 , 0 , 1 ) ) ) ; img3 . addAction ( sequence ( parallel ( moveBy ( 100 , 200 , 2 ) ) , Actions . run ( this ) ) ) ; } @ Override public void render ( ) { } @ Override public void run ( ) { } @ Override public void dispose ( ) { } }<BUG2FIX>stage = new Stage ( ) ;
public class ObjectSet < T > implements Iterable < T > { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; public int size ; T [ ] keyTable ; int capacity ; int stashSize ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private ObjectSet . SetIterator iterator1 ; private ObjectSet . SetIterator iterator2 ; public ObjectSet ( ) { } public ObjectSet ( int initialCapacity ) { } public ObjectSet ( int initialCapacity , float loadFactor ) { } public ObjectSet ( ObjectSet set ) { } public boolean add ( T key ) { } public void addAll ( Array < ? extends T > array ) { } public void addAll ( Array < ? extends T > array , int offset , int length ) { } public void addAll ( T ... array ) { } public void addAll ( T [ ] array , int offset , int length ) { } public void addAll ( ObjectSet < T > set ) { } private void addResize ( T key ) { } private void push ( T insertKey , int index1 , T key1 , int index2 , T key2 , int index3 , T key3 ) { } private void addStash ( T key ) { } public boolean remove ( T key ) { } boolean removeStash ( T key ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean contains ( T key ) { } private boolean containsKeyStash ( T key ) { } public T first ( ) { T [ ] keyTable = this . keyTable ; <START_BUG> for ( int i = 0 , n = ( capacity ) + ( stashSize ) ; i < n ; ) <END_BUG> if ( ( keyTable [ i ] ) != null ) return keyTable [ i ] ; throw new IllegalStateException ( "IntSet<seq2seq4repair_space>is<seq2seq4repair_space>empty." ) ; } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( int h ) { } private int hash3 ( int h ) { } public String toString ( ) { } public String toString ( String separator ) { } public ObjectSet . SetIterator < T > iterator ( ) { } public static < T > ObjectSet < T > with ( T ... array ) { } public static class SetIterator < K > implements Iterable < K > , Iterator < K > { public boolean hasNext ; final ObjectSet < K > set ; int nextIndex ; int currentIndex ; boolean valid = true ; public SetIterator ( ObjectSet < K > set ) { } public void reset ( ) { } void findNextIndex ( ) { } public void remove ( ) { } public boolean hasNext ( ) { } public K next ( ) { } public Iterator < K > iterator ( ) { } public Array < K > toArray ( ) { } } }<BUG2FIX>for ( int i = 0 , n = ( capacity ) + ( stashSize ) ; i < n ; i ++ )
public class OrganizationLoader extends AuthenticatedUserLoader < List < User > > { private static final String TAG = "OrganizationLoader" ; private final Provider < UserComparator > userComparatorProvider ; private final AccountDataManager accountDataManager ; @ Inject public OrganizationLoader ( Activity activity , AccountDataManager accountDataManager , Provider < UserComparator > userComparatorProvider ) { } @ Override protected List < User > getAccountFailureData ( ) { } @ Override public List < User > load ( final Account account ) { List < User > orgs ; try { <START_BUG> orgs = accountDataManager . getOrgs ( ) ; <END_BUG> } catch ( final IOException e ) { Log . e ( OrganizationLoader . TAG , "Exception<seq2seq4repair_space>loading<seq2seq4repair_space>organizations" , e ) ; ToastUtils . show ( activity , e , error_orgs_load ) ; return Collections . emptyList ( ) ; } Collections . sort ( orgs , userComparatorProvider . get ( ) ) ; return orgs ; } }<BUG2FIX>orgs = accountDataManager . getOrgs ( false ) ;
public class FilterIssuesActivity extends RoboFragmentActivity { @ Inject private CollaboratorService collaborators ; @ Inject private MilestoneService milestones ; @ Inject private LabelService labels ; private List < Label > allLabels ; private List < User > allCollaborators ; private List < Milestone > allMilestones ; private IssueFilter filter ; public static Intent createIntent ( Repository repo , IssueFilter filter ) { } @ Override protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; setContentView ( issues_filter ) ; <START_BUG> setTitle ( getString ( filter_issues_title ) ) ; <END_BUG> final Repository repository = ( ( Repository ) ( getIntent ( ) . getSerializableExtra ( EXTRA_REPOSITORY ) ) ) ; if ( savedInstanceState != null ) filter = ( ( IssueFilter ) ( savedInstanceState . getSerializable ( EXTRA_ISSUE_FILTER ) ) ) ; if ( ( filter ) == null ) filter = ( ( IssueFilter ) ( getIntent ( ) . getSerializableExtra ( EXTRA_ISSUE_FILTER ) ) ) . clone ( ) ; OnClickListener assigneeListener = new OnClickListener ( ) { public void onClick ( View v ) { if ( ( allCollaborators ) == null ) { final ProgressDialog loader = new ProgressDialog ( FilterIssuesActivity . this ) ; loader . setMessage ( "Loading<seq2seq4repair_space>Collaborators.." ) ; loader . show ( ) ; new roboguice . util . RoboAsyncTask < List < User > > ( FilterIssuesActivity . this ) { public List < User > call ( ) throws Exception { allCollaborators = collaborators . getCollaborators ( repository ) ; java . util . Collections . sort ( allCollaborators , new java . util . Comparator < User > ( ) { public int compare ( User u1 , User u2 ) { return u1 . getLogin ( ) . compareToIgnoreCase ( u2 . getLogin ( ) ) ; } } ) ; return allCollaborators ; } protected void onSuccess ( List < User > users ) throws Exception { loader . dismiss ( ) ; promptForAssignee ( ) ; } protected void onException ( Exception e ) throws RuntimeException { loader . dismiss ( ) ; } } . execute ( ) ; } else promptForAssignee ( ) ; } } ; ( ( TextView ) ( findViewById ( tv_assignee_label ) ) ) . setOnClickListener ( assigneeListener ) ; ( ( TextView ) ( findViewById ( tv_assignee ) ) ) . setOnClickListener ( assigneeListener ) ; OnClickListener milestoneListener = new OnClickListener ( ) { public void onClick ( View v ) { if ( ( allMilestones ) == null ) { final ProgressDialog loader = new ProgressDialog ( FilterIssuesActivity . this ) ; loader . setMessage ( "Loading<seq2seq4repair_space>Milestones..." ) ; loader . show ( ) ; new roboguice . util . RoboAsyncTask < List < Milestone > > ( FilterIssuesActivity . this ) { public List < Milestone > call ( ) throws Exception { List < Milestone > all = new java . util . ArrayList < Milestone > ( ) ; all . addAll ( milestones . getMilestones ( repository , IssueService . STATE_OPEN ) ) ; all . addAll ( milestones . getMilestones ( repository , IssueService . STATE_CLOSED ) ) ; java . util . Collections . sort ( all , new java . util . Comparator < Milestone > ( ) { public int compare ( Milestone m1 , Milestone m2 ) { return m1 . getTitle ( ) . compareToIgnoreCase ( m2 . getTitle ( ) ) ; } } ) ; allMilestones = all ; return allMilestones ; } protected void onSuccess ( List < Milestone > all ) throws Exception { loader . dismiss ( ) ; promptForMilestone ( ) ; } protected void onException ( Exception e ) throws RuntimeException { loader . dismiss ( ) ; } } . execute ( ) ; } else promptForMilestone ( ) ; } } ; ( ( TextView ) ( findViewById ( tv_milestone_label ) ) ) . setOnClickListener ( milestoneListener ) ; ( ( TextView ) ( findViewById ( tv_milestone ) ) ) . setOnClickListener ( milestoneListener ) ; OnClickListener labelsListener = new OnClickListener ( ) { public void onClick ( View v ) { if ( ( allLabels ) == null ) { final ProgressDialog loader = new ProgressDialog ( FilterIssuesActivity . this ) ; loader . setMessage ( "Loading<seq2seq4repair_space>Labels..." ) ; loader . show ( ) ; new roboguice . util . RoboAsyncTask < List < Label > > ( FilterIssuesActivity . this ) { public List < Label > call ( ) throws Exception { allLabels = labels . getLabels ( repository ) ; java . util . Collections . sort ( allLabels , new java . util . Comparator < Label > ( ) { public int compare ( Label l1 , Label l2 ) { return l1 . getName ( ) . compareToIgnoreCase ( l2 . getName ( ) ) ; } } ) ; return allLabels ; } protected void onSuccess ( List < Label > all ) throws Exception { loader . dismiss ( ) ; promptForLabels ( ) ; } protected void onException ( Exception e ) throws RuntimeException { loader . dismiss ( ) ; } } . execute ( ) ; } else promptForLabels ( ) ; } } ; ( ( TextView ) ( findViewById ( tv_labels_label ) ) ) . setOnClickListener ( labelsListener ) ; ( ( TextView ) ( findViewById ( tv_labels ) ) ) . setOnClickListener ( labelsListener ) ; updateAssignee ( ) ; updateMilestone ( ) ; updateLabels ( ) ; RadioButton openButton = ( ( RadioButton ) ( findViewById ( rb_open ) ) ) ; openButton . setOnCheckedChangeListener ( new OnCheckedChangeListener ( ) { public void onCheckedChanged ( CompoundButton buttonView , boolean isChecked ) { if ( isChecked ) filter . setOpenOnly ( ) ; } } ) ; RadioButton closedButton = ( ( RadioButton ) ( findViewById ( rb_closed ) ) ) ;<BUG2FIX>setTitle ( filter_issues_title ) ;
public class CubocDesktop { public static void main ( String [ ] argv ) { <START_BUG> new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new Cubocy ( ) , "Cubocy" , 480 , 320 , true ) ; <END_BUG> app . setLogLevel ( LOG_DEBUG ) ; } }<BUG2FIX>new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new Cubocy ( ) , "Cubocy" , 480 , 320 ) ;
public class TransportCloseIndexAction extends TransportMasterNodeOperationAction < CloseIndexRequest , CloseIndexResponse > { private final MetaDataIndexStateService indexStateService ; private final DestructiveOperations destructiveOperations ; @ Inject public TransportCloseIndexAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool , MetaDataIndexStateService indexStateService , NodeSettingsService nodeSettingsService ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected CloseIndexRequest newRequest ( ) { } @ Override protected CloseIndexResponse newResponse ( ) { } @ Override protected void doExecute ( CloseIndexRequest request , ActionListener < CloseIndexResponse > listener ) { } @ Override protected ClusterBlockException checkBlock ( CloseIndexRequest request , ClusterState state ) { } @ Override protected void masterOperation ( final CloseIndexRequest request , final ClusterState state , final ActionListener < CloseIndexResponse > listener ) throws ElasticsearchException { <START_BUG> request . indices ( state . metaData ( ) . concreteIndices ( request . indices ( ) , request . indicesOptions ( ) ) ) ; <END_BUG> CloseIndexClusterStateUpdateRequest updateRequest = new CloseIndexClusterStateUpdateRequest ( ) . ackTimeout ( request . timeout ( ) ) . masterNodeTimeout ( request . masterNodeTimeout ( ) ) . indices ( request . indices ( ) ) ; indexStateService . closeIndex ( updateRequest , new ClusterStateUpdateListener ( ) { @ Override public void onResponse ( ClusterStateUpdateResponse response ) { listener . onResponse ( new CloseIndexResponse ( response . isAcknowledged ( ) ) ) ; } @ Override public void onFailure ( Throwable t ) { logger . debug ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>close<seq2seq4repair_space>indices<seq2seq4repair_space>[{}]" , t , request . indices ( ) ) ; listener . onFailure ( t ) ; } } ) ; } }<BUG2FIX>request . indices ( state . metaData ( ) . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ) ;
public class MembersFragment extends ItemListFragment < User > implements OrganizationSelectionListener { private User org ; @ Inject private OrganizationService service ; @ Inject private AvatarLoader avatarHelper ; @ Override public void onAttach ( Activity activity ) { } @ Override public void onActivityCreated ( Bundle savedInstanceState ) { } @ Override public Loader < List < User > > onCreateLoader ( int id , Bundle args ) { } @ Override protected ItemListAdapter < User , ? extends ItemView > createAdapter ( List < User > items ) { } @ Override public void onOrganizationSelected ( User organization ) { int previousOrgId = ( ( org ) != null ) ? org . getId ( ) : - 1 ; org = organization ; <START_BUG> if ( ( ( getView ( ) ) != null ) && ( previousOrgId != ( org . getId ( ) ) ) ) <END_BUG> refreshWithProgress ( ) ; } @ Override public void onListItemClick ( ListView l , View v , int position , long id ) { } }<BUG2FIX>if ( previousOrgId != ( org . getId ( ) ) )
public class BlobStoreIndexShardRepository extends AbstractComponent implements IndexShardRepository { private BlobStore blobStore ; private BlobPath basePath ; private final String repositoryName ; private ByteSizeValue chunkSize ; private final IndicesService indicesService ; private RateLimiter snapshotRateLimiter ; private RateLimiter restoreRateLimiter ; private BlobStoreIndexShardRepository . RateLimiterListener rateLimiterListener ; private Listener snapshotThrottleListener ; private static final String SNAPSHOT_PREFIX = "snapshot-" ; @ Inject BlobStoreIndexShardRepository ( Settings settings , RepositoryName repositoryName , IndicesService indicesService ) { } public void initialize ( BlobStore blobStore , BlobPath basePath , ByteSizeValue chunkSize , RateLimiter snapshotRateLimiter , RateLimiter restoreRateLimiter , final BlobStoreIndexShardRepository . RateLimiterListener rateLimiterListener ) { } @ Override public void snapshot ( SnapshotId snapshotId , ShardId shardId , SnapshotIndexCommit snapshotIndexCommit , IndexShardSnapshotStatus snapshotStatus ) { } @ Override public void restore ( SnapshotId snapshotId , ShardId shardId , ShardId snapshotShardId , RecoveryState recoveryState ) { } @ Override public IndexShardSnapshotStatus snapshotStatus ( SnapshotId snapshotId , ShardId shardId ) { } public void delete ( SnapshotId snapshotId , ShardId shardId ) { } @ Override public String toString ( ) { } private String snapshotBlobName ( SnapshotId snapshotId ) { } public static byte [ ] writeSnapshot ( BlobStoreIndexShardSnapshot snapshot ) throws IOException { } public static BlobStoreIndexShardSnapshot readSnapshot ( byte [ ] data ) throws IOException { } private class Context { protected final SnapshotId snapshotId ; protected final ShardId shardId ; protected final ImmutableBlobContainer blobContainer ; public Context ( SnapshotId snapshotId , ShardId shardId ) { } public Context ( SnapshotId snapshotId , ShardId shardId , ShardId snapshotShardId ) { } public void delete ( ) { } public BlobStoreIndexShardSnapshot loadSnapshot ( ) { } protected void cleanup ( List < BlobStoreIndexShardSnapshot > snapshots , ImmutableMap < String , BlobMetaData > blobs ) { } protected String fileNameFromGeneration ( long generation ) { } protected long findLatestFileNameGeneration ( ImmutableMap < String , BlobMetaData > blobs ) { } protected BlobStoreIndexShardSnapshots buildBlobStoreIndexShardSnapshots ( ImmutableMap < String , BlobMetaData > blobs ) { } } private class SnapshotContext extends BlobStoreIndexShardRepository . Context { private final Store store ; private final IndexShardSnapshotStatus snapshotStatus ; public SnapshotContext ( SnapshotId snapshotId , ShardId shardId , IndexShardSnapshotStatus snapshotStatus ) { } public void snapshot ( SnapshotIndexCommit snapshotIndexCommit ) { logger . debug ( "[{}]<seq2seq4repair_space>[{}]<seq2seq4repair_space>snapshot<seq2seq4repair_space>to<seq2seq4repair_space>[{}]<seq2seq4repair_space>..." , shardId , snapshotId , repositoryName ) ; store . incRef ( ) ; try { final ImmutableMap < String , BlobMetaData > blobs ; try { blobs = blobContainer . listBlobs ( ) ; } catch ( IOException e ) { throw new IndexShardSnapshotFailedException ( shardId , "failed<seq2seq4repair_space>to<seq2seq4repair_space>list<seq2seq4repair_space>blobs" , e ) ; } long generation = findLatestFileNameGeneration ( blobs ) ; BlobStoreIndexShardSnapshots snapshots = buildBlobStoreIndexShardSnapshots ( blobs ) ; final CopyOnWriteArrayList < Throwable > failures = new CopyOnWriteArrayList < > ( ) ; final List < BlobStoreIndexShardSnapshot . FileInfo > indexCommitPointFiles = Lists . newArrayList ( ) ; int indexNumberOfFiles = 0 ; long indexTotalFilesSize = 0 ; ArrayList < FileInfo > filesToSnapshot = Lists . newArrayList ( ) ; final Store . MetadataSnapshot metadata ; try { <START_BUG> metadata = store . getMetadata ( ) ; <END_BUG> } catch ( IOException e ) { throw new IndexShardSnapshotFailedException ( shardId , "Failed<seq2seq4repair_space>to<seq2seq4repair_space>get<seq2seq4repair_space>store<seq2seq4repair_space>file<seq2seq4repair_space>metadata" , e ) ; } for ( String fileName : snapshotIndexCommit . getFiles ( ) ) { if ( snapshotStatus . aborted ( ) ) { logger . debug ( "[{}]<seq2seq4repair_space>[{}]<seq2seq4repair_space>Aborted<seq2seq4repair_space>on<seq2seq4repair_space>the<seq2seq4repair_space>file<seq2seq4repair_space>[{}],<seq2seq4repair_space>exiting" , shardId , snapshotId , fileName ) ; throw new IndexShardSnapshotFailedException ( shardId , "Aborted" ) ; } logger . trace ( "[{}]<seq2seq4repair_space>[{}]<seq2seq4repair_space>Processing<seq2seq4repair_space>[{}]" , shardId , snapshotId , fileName ) ; final StoreFileMetaData md = metadata . get ( fileName ) ; boolean snapshotRequired = false ; BlobStoreIndexShardSnapshot . FileInfo fileInfo = snapshots . findPhysicalIndexFile ( fileName ) ; if ( ( ( fileInfo == null ) || ( ! ( fileInfo . isSame ( md ) ) ) ) || ( ! ( snapshotFileExistsInBlobs ( fileInfo , blobs ) ) ) ) { snapshotRequired = true ; } if ( snapshotRequired ) { indexNumberOfFiles ++ ; indexTotalFilesSize += md . length ( ) ; BlobStoreIndexShardSnapshot . FileInfo snapshotFileInfo = new BlobStoreIndexShardSnapshot . FileInfo ( fileNameFromGeneration ( ( ++ generation ) ) , md , chunkSize ) ; indexCommitPointFiles . add ( snapshotFileInfo ) ; filesToSnapshot . add ( snapshotFileInfo ) ; } else { indexCommitPointFiles . add ( fileInfo ) ; } } snapshotStatus . files ( indexNumberOfFiles , indexTotalFilesSize ) ; snapshotStatus . updateStage ( STARTED ) ; final CountDownLatch indexLatch = new CountDownLatch ( filesToSnapshot . size ( ) ) ; for ( FileInfo snapshotFileInfo : filesToSnapshot ) { try { snapshotFile ( snapshotFileInfo , indexLatch , failures ) ; } catch ( IOException e ) { failures . add ( e ) ; } } snapshotStatus . indexVersion ( snapshotIndexCommit . getGeneration ( ) ) ; try { indexLatch . await ( ) ; } catch ( InterruptedException e ) { failures . add ( e ) ; Thread . currentThread ( ) . interrupt ( ) ; } if ( ! ( failures . isEmpty ( ) ) ) { throw new IndexShardSnapshotFailedException ( shardId , "Failed<seq2seq4repair_space>to<seq2seq4repair_space>perform<seq2seq4repair_space>snapshot<seq2seq4repair_space>(index<seq2seq4repair_space>files)" , failures . get ( 0 ) ) ; } snapshotStatus . updateStage ( FINALIZE ) ; String commitPointName = snapshotBlobName ( snapshotId ) ; BlobStoreIndexShardSnapshot snapshot = new BlobStoreIndexShardSnapshot ( snapshotId . getSnapshot ( ) , snapshotIndexCommit . getGeneration ( ) , indexCommitPointFiles , snapshotStatus . startTime ( ) , ( ( System . currentTimeMillis ( ) ) - ( snapshotStatus . startTime ( ) ) ) , indexNumberOfFiles , indexTotalFilesSize ) ; try { byte [ ] snapshotData = BlobStoreIndexShardRepository . writeSnapshot ( snapshot ) ; logger . trace ( "[{}]<seq2seq4repair_space>[{}]<seq2seq4repair_space>writing<seq2seq4repair_space>shard<seq2seq4repair_space>snapshot<seq2seq4repair_space>file" , shardId , snapshotId ) ; blobContainer . writeBlob ( commitPointName , new BytesStreamInput ( snapshotData , false ) , snapshotData . length ) ; } catch ( IOException e ) { throw new IndexShardSnapshotFailedException ( shardId , "Failed<seq2seq4repair_space>to<seq2seq4repair_space>write<seq2seq4repair_space>commit<seq2seq4repair_space>point" , e ) ; } List < BlobStoreIndexShardSnapshot > newSnapshotsList = Lists . newArrayList ( ) ;<BUG2FIX>metadata = store . getMetadata ( snapshotIndexCommit ) ;
public class PercolatorQueriesRegistry extends AbstractIndexShardComponent { private final IndexQueryParserService queryParserService ; private final MapperService mapperService ; private final IndicesLifecycle indicesLifecycle ; private final IndexCache indexCache ; private final IndexFieldDataService indexFieldDataService ; private final ShardIndexingService indexingService ; private final ConcurrentMap < HashedBytesRef , Query > percolateQueries = ConcurrentCollections . newConcurrentMapWithAggressiveConcurrency ( ) ; private final PercolatorQueriesRegistry . ShardLifecycleListener shardLifecycleListener = new PercolatorQueriesRegistry . ShardLifecycleListener ( ) ; private final PercolatorQueriesRegistry . RealTimePercolatorOperationListener realTimePercolatorOperationListener = new PercolatorQueriesRegistry . RealTimePercolatorOperationListener ( ) ; private final PercolatorQueriesRegistry . PercolateTypeListener percolateTypeListener = new PercolatorQueriesRegistry . PercolateTypeListener ( ) ; private volatile boolean realTimePercolatorEnabled = false ; @ Inject public PercolatorQueriesRegistry ( ShardId shardId , @ IndexSettings Settings indexSettings , IndexQueryParserService queryParserService , ShardIndexingService indexingService , IndicesLifecycle indicesLifecycle , MapperService mapperService , IndexCache indexCache , IndexFieldDataService indexFieldDataService ) { } public ConcurrentMap < HashedBytesRef , Query > percolateQueries ( ) { } public void close ( ) { } public void clear ( ) { } void enableRealTimePercolator ( ) { } void disableRealTimePercolator ( ) { } public void addPercolateQuery ( String idAsString , BytesReference source ) { } public void removePercolateQuery ( String idAsString ) { } Query parsePercolatorDocument ( String id , BytesReference source ) { } private Query parseQuery ( String type , BytesReference querySource , XContentParser parser ) { } private class PercolateTypeListener implements DocumentTypeListener { @ Override public void created ( String type ) { } @ Override public void removed ( String type ) { } } private class ShardLifecycleListener extends IndicesLifecycle . Listener { @ Override public void afterIndexShardCreated ( IndexShard indexShard ) { } @ Override public void afterIndexShardStarted ( IndexShard indexShard ) { } private boolean hasPercolatorType ( IndexShard indexShard ) { } private void loadQueries ( IndexShard shard ) { try { shard . refresh ( new Engine . Refresh ( ) . force ( true ) . source ( "percolator_load_queries" ) ) ; <START_BUG> Engine . Searcher searcher = shard . acquireSearcher ( ) ; <END_BUG> try { Query query = new org . elasticsearch . common . lucene . search . XConstantScoreQuery ( indexCache . filter ( ) . cache ( new TermFilter ( new org . apache . lucene . index . Term ( TypeFieldMapper . NAME , Constants . TYPE_NAME ) ) ) ) ; QueriesLoaderCollector queries = new QueriesLoaderCollector ( PercolatorQueriesRegistry . this , logger , indexFieldDataService ) ; searcher . searcher ( ) . search ( query , queries ) ; percolateQueries . putAll ( queries . queries ( ) ) ; } finally { searcher . release ( ) ; } } catch ( Exception e ) { throw new PercolatorException ( shardId . index ( ) , "failed<seq2seq4repair_space>to<seq2seq4repair_space>load<seq2seq4repair_space>queries<seq2seq4repair_space>from<seq2seq4repair_space>percolator<seq2seq4repair_space>index" , e ) ; } } } private class RealTimePercolatorOperationListener extends IndexingOperationListener { @ Override public Create preCreate ( Engine . Create create ) { } @ Override public void postCreateUnderLock ( Engine . Create create ) { } @ Override public Index preIndex ( Engine . Index index ) { } @ Override public void postIndexUnderLock ( Engine . Index index ) { } @ Override public void postDeleteUnderLock ( Engine . Delete delete ) { } } }<BUG2FIX>Engine . Searcher searcher = shard . acquireSearcher ( "percolator_load_queries" ) ;
public class TransportOpenIndexAction extends TransportMasterNodeOperationAction < OpenIndexRequest , OpenIndexResponse > { private final MetaDataIndexStateService indexStateService ; private final DestructiveOperations destructiveOperations ; @ Inject public TransportOpenIndexAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool , MetaDataIndexStateService indexStateService , NodeSettingsService nodeSettingsService ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected OpenIndexRequest newRequest ( ) { } @ Override protected OpenIndexResponse newResponse ( ) { } @ Override protected void doExecute ( OpenIndexRequest request , ActionListener < OpenIndexResponse > listener ) { } @ Override protected ClusterBlockException checkBlock ( OpenIndexRequest request , ClusterState state ) { } @ Override protected void masterOperation ( final OpenIndexRequest request , final ClusterState state , final ActionListener < OpenIndexResponse > listener ) throws ElasticsearchException { <START_BUG> request . indices ( state . metaData ( ) . concreteIndices ( request . indices ( ) , request . indicesOptions ( ) ) ) ; <END_BUG> OpenIndexClusterStateUpdateRequest updateRequest = new OpenIndexClusterStateUpdateRequest ( ) . ackTimeout ( request . timeout ( ) ) . masterNodeTimeout ( request . masterNodeTimeout ( ) ) . indices ( request . indices ( ) ) ; indexStateService . openIndex ( updateRequest , new ClusterStateUpdateListener ( ) { @ Override public void onResponse ( ClusterStateUpdateResponse response ) { listener . onResponse ( new OpenIndexResponse ( response . isAcknowledged ( ) ) ) ; } @ Override public void onFailure ( Throwable t ) { logger . debug ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>open<seq2seq4repair_space>indices<seq2seq4repair_space>[{}]" , t , request . indices ( ) ) ; listener . onFailure ( t ) ; } } ) ; } }<BUG2FIX>request . indices ( state . metaData ( ) . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ) ;
public class LongMap < V > { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; private static final int EMPTY = 0 ; public int size ; long [ ] keyTable ; V [ ] valueTable ; int capacity ; int stashSize ; V zeroValue ; boolean hasZeroValue ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private LongMap . Entries entries1 ; private LongMap . Entries entries2 ; private LongMap . Values values1 ; private LongMap . Values values2 ; private LongMap . Keys keys1 ; private LongMap . Keys keys2 ; public LongMap ( ) { } public LongMap ( int initialCapacity ) { } public LongMap ( int initialCapacity , float loadFactor ) { } public LongMap ( LongMap < ? extends V > map ) { } public V put ( long key , V value ) { } public void putAll ( LongMap < V > map ) { } private void putResize ( long key , V value ) { } private void push ( long insertKey , V insertValue , int index1 , long key1 , int index2 , long key2 , int index3 , long key3 ) { } private void putStash ( long key , V value ) { } public V get ( long key ) { } public V get ( long key , V defaultValue ) { } private V getStash ( long key , V defaultValue ) { } public V remove ( long key ) { } V removeStash ( long key ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean containsValue ( Object value , boolean identity ) { } public boolean containsKey ( long key ) { } private boolean containsKeyStash ( long key ) { } public long findKey ( Object value , boolean identity , long notFound ) { } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( long h ) { } private int hash3 ( long h ) { } public String toString ( ) { } public LongMap . Entries < V > entries ( ) { } public LongMap . Values < V > values ( ) { } public LongMap . Keys keys ( ) { } public static class Entry < V > { public long key ; public V value ; public String toString ( ) { } } private static class MapIterator < V > { static final int INDEX_ILLEGAL = - 2 ; static final int INDEX_ZERO = - 1 ; public boolean hasNext ; final LongMap < V > map ; int nextIndex ; int currentIndex ; boolean valid = true ; public MapIterator ( LongMap < V > map ) { } public void reset ( ) { } void findNextIndex ( ) { } public void remove ( ) { if ( ( ( currentIndex ) == ( LongMap . MapIterator . INDEX_ZERO ) ) && ( map . hasZeroValue ) ) { map . zeroValue = null ; map . hasZeroValue = false ; } else if ( ( currentIndex ) < 0 ) { throw new IllegalStateException ( "next<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>called<seq2seq4repair_space>before<seq2seq4repair_space>remove." ) ; } else if ( ( currentIndex ) >= ( map . capacity ) ) { map . removeStashIndex ( currentIndex ) ; <START_BUG> nextIndex = currentIndex ; <END_BUG> findNextIndex ( ) ; } else { map . keyTable [ currentIndex ] = LongMap . EMPTY ; map . valueTable [ currentIndex ] = null ; } currentIndex = LongMap . MapIterator . INDEX_ILLEGAL ; ( map . size ) -- ; } } public static class Entries < V > extends LongMap . MapIterator < V > implements Iterable < LongMap . Entry < V > > , Iterator < LongMap . Entry < V > > { private LongMap . Entry < V > entry = new LongMap . Entry ( ) ; public Entries ( LongMap map ) { } public LongMap . Entry < V > next ( ) { } public boolean hasNext ( ) { } public Iterator < LongMap . Entry < V > > iterator ( ) { } } public static class Values < V > extends LongMap . MapIterator < V > implements Iterable < V > , Iterator < V > { public Values ( LongMap < V > map ) { } public boolean hasNext ( ) { } public V next ( ) { } public Iterator < V > iterator ( ) { } public Array < V > toArray ( ) { } } public static class Keys extends LongMap . MapIterator { public Keys ( LongMap map ) { } public long next ( ) { } public LongArray toArray ( ) { } } }<BUG2FIX>nextIndex = ( currentIndex ) - 1 ;
public class TextureAtlasLoader extends SynchronousAssetLoader < TextureAtlas , TextureAtlasLoader . TextureAtlasParameter > { public TextureAtlasLoader ( FileHandleResolver resolver ) { } TextureAtlasData data ; @ Override public TextureAtlas load ( AssetManager assetManager , String fileName , FileHandle file , TextureAtlasLoader . TextureAtlasParameter parameter ) { } @ Override public Array < AssetDescriptor > getDependencies ( String fileName , FileHandle atlasFile , TextureAtlasLoader . TextureAtlasParameter parameter ) { FileHandle imgDir = atlasFile . parent ( ) ; if ( parameter != null ) data = new TextureAtlasData ( atlasFile , imgDir , parameter . flip ) ; else { data = new TextureAtlasData ( atlasFile , imgDir , false ) ; } <START_BUG> Array < AssetDescriptor > dependencies = new Array ( ) ; <END_BUG> for ( Page page : data . getPages ( ) ) { TextureParameter params = new TextureParameter ( ) ; params . format = page . format ; params . genMipMaps = page . useMipMaps ; params . minFilter = page . minFilter ; params . magFilter = page . magFilter ; dependencies . add ( new AssetDescriptor ( page . textureFile , Texture . class , params ) ) ; } return dependencies ; } public static class TextureAtlasParameter extends AssetLoaderParameters < TextureAtlas > { public boolean flip = false ; public TextureAtlasParameter ( ) { } public TextureAtlasParameter ( boolean flip ) { } } }<BUG2FIX>Array < AssetDescriptor > dependencies = new Array < AssetDescriptor > ( ) ;
public class TransportSearchDfsQueryAndFetchAction extends TransportSearchTypeAction { @ Inject public TransportSearchDfsQueryAndFetchAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportSearchCache transportSearchCache , SearchServiceTransportAction searchService , SearchPhaseController searchPhaseController ) { } @ Override protected void doExecute ( SearchRequest searchRequest , ActionListener < SearchResponse > listener ) { } private class AsyncAction extends BaseAsyncAction < DfsSearchResult > { private final Collection < DfsSearchResult > dfsResults = searchCache . obtainDfsResults ( ) ; private final Map < SearchShardTarget , QueryFetchSearchResult > queryFetchResults = searchCache . obtainQueryFetchResults ( ) ; private AsyncAction ( SearchRequest request , ActionListener < SearchResponse > listener ) { } @ Override protected String firstPhaseName ( ) { } @ Override protected void sendExecuteFirstPhase ( DiscoveryNode node , InternalSearchRequest request , SearchServiceListener < DfsSearchResult > listener ) { } @ Override protected void processFirstPhaseResult ( ShardRouting shard , DfsSearchResult result ) { } @ Override protected void moveToSecondPhase ( ) { } private void executeSecondPhase ( final DfsSearchResult dfsResult , final AtomicInteger counter , DiscoveryNode node , final QuerySearchRequest querySearchRequest ) { } private void finishHim ( ) { } private void innerFinishHim ( ) throws Exception { sortedShardList = searchPhaseController . sortDocs ( queryFetchResults . values ( ) ) ; final InternalSearchResponse internalResponse = searchPhaseController . merge ( sortedShardList , queryFetchResults , queryFetchResults ) ; String scrollId = null ; if ( ( request . scroll ( ) ) != null ) { <START_BUG> scrollId = buildScrollId ( request . searchType ( ) , dfsResults ) ; <END_BUG> } listener . onResponse ( new SearchResponse ( internalResponse , scrollId , expectedSuccessfulOps , successulOps . get ( ) , buildTookInMillis ( ) , buildShardFailures ( ) ) ) ; } } }<BUG2FIX>scrollId = buildScrollId ( request . searchType ( ) , dfsResults , null ) ;
public class SingleThreadBulkStress { public static void main ( String [ ] args ) throws Exception { Random random = new Random ( ) ; Settings settings = settingsBuilder ( ) . put ( "cluster.routing.schedule" , 200 , TimeUnit . MILLISECONDS ) . put ( "index.engine.robin.refreshInterval" , "-1" ) . put ( "gateway.type" , "local" ) . put ( SETTING_NUMBER_OF_SHARDS , 2 ) . put ( SETTING_NUMBER_OF_REPLICAS , 1 ) . build ( ) ; Node node1 = nodeBuilder ( ) . settings ( settingsBuilder ( ) . put ( settings ) . put ( "name" , "server1" ) ) . node ( ) ; Node node2 = nodeBuilder ( ) . settings ( settingsBuilder ( ) . put ( settings ) . put ( "name" , "server2" ) ) . node ( ) ; Node client = nodeBuilder ( ) . settings ( settingsBuilder ( ) . put ( settings ) . put ( "name" , "client" ) ) . client ( true ) . node ( ) ; Client client1 = client . client ( ) ; Thread . sleep ( 1000 ) ; client1 . admin ( ) . indices ( ) . create ( createIndexRequest ( "test" ) ) . actionGet ( ) ; Thread . sleep ( 5000 ) ; StopWatch stopWatch = new StopWatch ( ) . start ( ) ; long COUNT = SizeValue . parseSizeValue ( "5m" ) . singles ( ) ; int BATCH = 100 ; System . out . println ( ( ( "Indexing<seq2seq4repair_space>[" + COUNT ) + "]<seq2seq4repair_space>..." ) ) ; long ITERS = COUNT / BATCH ; long i = 1 ; int counter = 0 ; for ( ; i <= ITERS ; i ++ ) { BulkRequestBuilder request = client1 . prepareBulk ( ) ; for ( int j = 0 ; j < BATCH ; j ++ ) { counter ++ ; request . add ( Requests . indexRequest ( "test" ) . type ( "type1" ) . id ( Integer . toString ( counter ) ) . source ( SingleThreadBulkStress . source ( Integer . toString ( counter ) , ( "test" + counter ) ) ) ) ; } BulkResponse response = request . execute ( ) . actionGet ( ) ; if ( response . hasFailures ( ) ) { System . err . println ( "failures..." ) ; } if ( ( ( i * BATCH ) % 10000 ) == 0 ) { <START_BUG> System . out . println ( ( ( ( "Indexed<seq2seq4repair_space>" + ( i * 100 ) ) + "<seq2seq4repair_space>took<seq2seq4repair_space>" ) + ( stopWatch . stop ( ) . lastTaskTime ( ) ) ) ) ; <END_BUG> stopWatch . start ( ) ; } } System . out . println ( ( ( ( "Indexing<seq2seq4repair_space>took<seq2seq4repair_space>" + ( stopWatch . totalTime ( ) ) ) + ",<seq2seq4repair_space>TPS<seq2seq4repair_space>" ) + ( ( ( double ) ( COUNT ) ) / ( stopWatch . totalTime ( ) . secondsFrac ( ) ) ) ) ) ; client . client ( ) . admin ( ) . indices ( ) . prepareRefresh ( ) . execute ( ) . actionGet ( ) ; System . out . println ( ( "Count:<seq2seq4repair_space>" + ( client . client ( ) . prepareCount ( ) . setQuery ( matchAllQuery ( ) ) . execute ( ) . actionGet ( ) . count ( ) ) ) ) ; client . close ( ) ; node1 . close ( ) ; node2 . close ( ) ; } private static XContentBuilder source ( String id , String nameValue ) throws IOException { } }<BUG2FIX>System . out . println ( ( ( ( "Indexed<seq2seq4repair_space>" + ( i * BATCH ) ) + "<seq2seq4repair_space>took<seq2seq4repair_space>" ) + ( stopWatch . stop ( ) . lastTaskTime ( ) ) ) ) ;
public class Cell < T extends Actor > implements Poolable { Value minWidth ; Value minHeight ; Value prefWidth ; Value prefHeight ; Value maxWidth ; Value maxHeight ; Value spaceTop ; Value spaceLeft ; Value spaceBottom ; Value spaceRight ; Value padTop ; Value padLeft ; Value padBottom ; Value padRight ; Float fillX ; Float fillY ; Integer align ; Integer expandX ; Integer expandY ; Integer colspan ; Boolean uniformX ; Boolean uniformY ; Actor actor ; float actorX ; float actorY ; float actorWidth ; float actorHeight ; private Table table ; boolean endRow ; int column ; int row ; int cellAboveIndex = - 1 ; float computedPadTop ; float computedPadLeft ; float computedPadBottom ; float computedPadRight ; public void setLayout ( Table table ) { } void set ( Cell defaults ) { } void merge ( Cell cell ) { } public < A extends Actor > Cell < A > setActor ( A newActor ) { } public T getActor ( ) { } public boolean hasActor ( ) { } public Cell < T > size ( Value size ) { } public Cell < T > size ( Value width , Value height ) { } public Cell < T > size ( float size ) { } public Cell < T > size ( float width , float height ) { } public Cell < T > width ( Value width ) { } public Cell < T > width ( float width ) { } public Cell < T > height ( Value height ) { } public Cell < T > height ( float height ) { } public Cell < T > minSize ( Value size ) { } public Cell < T > minSize ( Value width , Value height ) { } public Cell < T > minWidth ( Value minWidth ) { } public Cell < T > minHeight ( Value minHeight ) { } public Cell < T > minSize ( float size ) { } public Cell < T > minSize ( float width , float height ) { } public Cell < T > minWidth ( float minWidth ) { } public Cell < T > minHeight ( float minHeight ) { } public Cell < T > prefSize ( Value size ) { } public Cell < T > prefSize ( Value width , Value height ) { } public Cell < T > prefWidth ( Value prefWidth ) { } public Cell < T > prefHeight ( Value prefHeight ) { } public Cell < T > prefSize ( float width , float height ) { <START_BUG> prefSize ( new Fixed ( width ) , new Fixed ( height ) ) ; <END_BUG> return this ; } public Cell < T > prefSize ( float size ) { } public Cell < T > prefWidth ( float prefWidth ) { } public Cell < T > prefHeight ( float prefHeight ) { } public Cell < T > maxSize ( Value size ) { } public Cell < T > maxSize ( Value width , Value height ) { } public Cell < T > maxWidth ( Value maxWidth ) { } public Cell < T > maxHeight ( Value maxHeight ) { } public Cell < T > maxSize ( float size ) { } public Cell < T > maxSize ( float width , float height ) { } public Cell < T > maxWidth ( float maxWidth ) { } public Cell < T > maxHeight ( float maxHeight ) { } public Cell < T > space ( Value space ) { } public Cell < T > space ( Value top , Value left , Value bottom , Value right ) { } public Cell < T > spaceTop ( Value spaceTop ) { } public Cell < T > spaceLeft ( Value spaceLeft ) { } public Cell < T > spaceBottom ( Value spaceBottom ) { } public Cell < T > spaceRight ( Value spaceRight ) { } public Cell < T > space ( float space ) { } public Cell < T > space ( float top , float left , float bottom , float right ) { } public Cell < T > spaceTop ( float spaceTop ) { } public Cell < T > spaceLeft ( float spaceLeft ) { } public Cell < T > spaceBottom ( float spaceBottom ) { } public Cell < T > spaceRight ( float spaceRight ) { } public Cell < T > pad ( Value pad ) { } public Cell < T > pad ( Value top , Value left , Value bottom , Value right ) { } public Cell < T > padTop ( Value padTop ) { } public Cell < T > padLeft ( Value padLeft ) { } public Cell < T > padBottom ( Value padBottom ) { } public Cell < T > padRight ( Value padRight ) { } public Cell < T > pad ( float pad ) { } public Cell < T > pad ( float top , float left , float bottom , float right ) { } public Cell < T > padTop ( float padTop ) { } public Cell < T > padLeft ( float padLeft ) { } public Cell < T > padBottom ( float padBottom ) { } public Cell < T > padRight ( float padRight ) { } public Cell < T > fill ( ) { } public Cell < T > fillX ( ) { } public Cell < T > fillY ( ) { } public Cell < T > fill ( Float x , Float y ) { } public Cell < T > fill ( boolean x , boolean y ) { }<BUG2FIX>prefSize ( new Fixed ( width ) ) ;
@ Test public class ToAndFromJsonMetaDataTests { @ Test public void testSimpleJsonFromAndTo ( ) throws IOException { MetaData . MetaData metaData = newMetaDataBuilder ( ) . put ( newIndexMetaDataBuilder ( "test1" ) . numberOfShards ( 1 ) . numberOfReplicas ( 2 ) ) . put ( newIndexMetaDataBuilder ( "test2" ) . settings ( settingsBuilder ( ) . put ( "setting1" , "value1" ) . put ( "setting2" , "value2" ) ) . numberOfShards ( 2 ) . numberOfReplicas ( 3 ) ) . put ( newIndexMetaDataBuilder ( "test3" ) . numberOfShards ( 1 ) . numberOfReplicas ( 2 ) . putMapping ( "mapping1" , ToAndFromJsonMetaDataTests . MAPPING_SOURCE1 ) ) . put ( newIndexMetaDataBuilder ( "test4" ) . settings ( settingsBuilder ( ) . put ( "setting1" , "value1" ) . put ( "setting2" , "value2" ) ) . numberOfShards ( 1 ) . numberOfReplicas ( 2 ) . putMapping ( "mapping1" , ToAndFromJsonMetaDataTests . MAPPING_SOURCE1 ) . putMapping ( "mapping2" , ToAndFromJsonMetaDataTests . MAPPING_SOURCE2 ) ) . build ( ) ; String metaDataSource = Builder . toXContent ( metaData ) ; System . out . println ( ( "ToJson:<seq2seq4repair_space>" + metaDataSource ) ) ; <START_BUG> MetaData . MetaData parsedMetaData = Builder . fromXContent ( XContentFactory . xContent ( JSON ) . createParser ( metaDataSource ) , null ) ; <END_BUG> IndexMetaData . IndexMetaData indexMetaData = parsedMetaData . index ( "test1" ) ; assertThat ( indexMetaData . numberOfShards ( ) , equalTo ( 1 ) ) ; assertThat ( indexMetaData . numberOfReplicas ( ) , equalTo ( 2 ) ) ; assertThat ( indexMetaData . settings ( ) . getAsMap ( ) . size ( ) , equalTo ( 2 ) ) ; assertThat ( indexMetaData . mappings ( ) . size ( ) , equalTo ( 0 ) ) ; indexMetaData = parsedMetaData . index ( "test2" ) ; assertThat ( indexMetaData . numberOfShards ( ) , equalTo ( 2 ) ) ; assertThat ( indexMetaData . numberOfReplicas ( ) , equalTo ( 3 ) ) ; assertThat ( indexMetaData . settings ( ) . getAsMap ( ) . size ( ) , equalTo ( 4 ) ) ; assertThat ( indexMetaData . settings ( ) . get ( "setting1" ) , equalTo ( "value1" ) ) ; assertThat ( indexMetaData . settings ( ) . get ( "setting2" ) , equalTo ( "value2" ) ) ; assertThat ( indexMetaData . mappings ( ) . size ( ) , equalTo ( 0 ) ) ; indexMetaData = parsedMetaData . index ( "test3" ) ; assertThat ( indexMetaData . numberOfShards ( ) , equalTo ( 1 ) ) ; assertThat ( indexMetaData . numberOfReplicas ( ) , equalTo ( 2 ) ) ; assertThat ( indexMetaData . settings ( ) . getAsMap ( ) . size ( ) , equalTo ( 2 ) ) ; assertThat ( indexMetaData . mappings ( ) . size ( ) , equalTo ( 1 ) ) ; assertThat ( indexMetaData . mappings ( ) . get ( "mapping1" ) . source ( ) . string ( ) , equalTo ( ToAndFromJsonMetaDataTests . MAPPING_SOURCE1 ) ) ; indexMetaData = parsedMetaData . index ( "test4" ) ; assertThat ( indexMetaData . numberOfShards ( ) , equalTo ( 1 ) ) ; assertThat ( indexMetaData . numberOfReplicas ( ) , equalTo ( 2 ) ) ; assertThat ( indexMetaData . settings ( ) . getAsMap ( ) . size ( ) , equalTo ( 4 ) ) ; assertThat ( indexMetaData . settings ( ) . get ( "setting1" ) , equalTo ( "value1" ) ) ; assertThat ( indexMetaData . settings ( ) . get ( "setting2" ) , equalTo ( "value2" ) ) ; assertThat ( indexMetaData . mappings ( ) . size ( ) , equalTo ( 2 ) ) ; assertThat ( indexMetaData . mappings ( ) . get ( "mapping1" ) . source ( ) . string ( ) , equalTo ( ToAndFromJsonMetaDataTests . MAPPING_SOURCE1 ) ) ; assertThat ( indexMetaData . mappings ( ) . get ( "mapping2" ) . source ( ) . string ( ) , equalTo ( ToAndFromJsonMetaDataTests . MAPPING_SOURCE2 ) ) ; } private static final String MAPPING_SOURCE1 = "{\"mapping1\":{\"text1\":{\"type\":\"string\"}}}" ; private static final String MAPPING_SOURCE2 = "{\"mapping2\":{\"text2\":{\"type\":\"string\"}}}" ; }<BUG2FIX>MetaData . MetaData parsedMetaData = Builder . fromXContent ( XContentFactory . xContent ( JSON ) . createParser ( metaDataSource ) ) ;
public class TermsShortFacetCollector extends AbstractFacetCollector { private final FieldDataCache fieldDataCache ; private final String indexFieldName ; private final ComparatorType comparatorType ; private final int size ; private final int numberOfShards ; private final FieldDataType fieldDataType ; private ShortFieldData fieldData ; private final TermsShortFacetCollector . StaticAggregatorValueProc aggregator ; private final SearchScript script ; public TermsShortFacetCollector ( String facetName , String fieldName , int size , TermsFacet . ComparatorType comparatorType , boolean allTerms , SearchContext context , ImmutableSet < BytesRef > excluded , String scriptLang , String script , Map < String , Object > params ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override protected void doSetNextReader ( AtomicReaderContext context ) throws IOException { fieldData = ( ( ShortFieldData ) ( fieldDataCache . cache ( fieldDataType , context . reader ( ) , indexFieldName ) ) ) ; if ( ( script ) != null ) { <START_BUG> script . setNextReader ( context . reader ( ) ) ; <END_BUG> } } @ Override protected void doCollect ( int doc ) throws IOException { } @ Override public Facet facet ( ) { } public static class AggregatorValueProc extends TermsShortFacetCollector . StaticAggregatorValueProc { private final SearchScript script ; private final TShortHashSet excluded ; public AggregatorValueProc ( TShortIntHashMap facets , Set < BytesRef > excluded , SearchScript script ) { } @ Override public void onValue ( int docId , short value ) { } } public static class StaticAggregatorValueProc implements ShortFieldData . ValueInDocProc , ShortFieldData . ValueProc { private final TShortIntHashMap facets ; private int missing ; private int total ; public StaticAggregatorValueProc ( TShortIntHashMap facets ) { } @ Override public void onValue ( short value ) { } @ Override public void onValue ( int docId , short value ) { } @ Override public void onMissing ( int docId ) { } public final TShortIntHashMap facets ( ) { } public final int missing ( ) { } public final int total ( ) { } } }<BUG2FIX>script . setNextReader ( context ) ;
public class Touchpad extends Widget { private Touchpad . TouchpadStyle style ; boolean touched ; private float deadzoneRadius ; private final Circle padBounds = new Circle ( 0 , 0 , 0 ) ; private final Circle deadzoneBounds = new Circle ( 0 , 0 , 0 ) ; private final Vector2 knobPosition = new Vector2 ( ) ; private final Vector2 knobPercent = new Vector2 ( ) ; public Touchpad ( float deadzoneRadius , Skin skin ) { } public Touchpad ( float deadzoneRadius , Skin skin , String styleName ) { } public Touchpad ( float deadzoneRadius , Touchpad . TouchpadStyle style ) { } void calculatePositionAndValue ( float x , float y , boolean isTouchUp ) { } public void setStyle ( Touchpad . TouchpadStyle style ) { } public Touchpad . TouchpadStyle getStyle ( ) { } @ Override <START_BUG> public Actor hit ( float x , float y , boolean touchable ) { <END_BUG> return padBounds . contains ( x , y ) ? this : null ; } @ Override public void layout ( ) { } @ Override public void draw ( SpriteBatch batch , float parentAlpha ) { } @ Override public float getPrefWidth ( ) { } @ Override public float getPrefHeight ( ) { } public boolean isTouched ( ) { } public void setDeadzone ( float deadzoneRadius ) { } public float getKnobX ( ) { } public float getKnobY ( ) { } public float getKnobPercentX ( ) { } public float getKnobPercentY ( ) { } public static class TouchpadStyle { public Drawable background ; public Drawable knob ; public TouchpadStyle ( ) { } public TouchpadStyle ( Drawable background , Drawable knob ) { } public TouchpadStyle ( Touchpad . TouchpadStyle style ) { } } }<BUG2FIX>public Actor hit ( float x , float y ) {
public class ClusterState { private final long version ; private final RoutingTable routingTable ; private final DiscoveryNodes nodes ; private final MetaData metaData ; private final ClusterBlocks blocks ; private final AllocationExplanation allocationExplanation ; private volatile RoutingNodes routingNodes ; public ClusterState ( long version , ClusterState state ) { } public ClusterState ( long version , MetaData metaData , RoutingTable routingTable , DiscoveryNodes nodes , ClusterBlocks blocks , AllocationExplanation allocationExplanation ) { } public long version ( ) { } public long getVersion ( ) { } public DiscoveryNodes nodes ( ) { } public DiscoveryNodes getNodes ( ) { } public MetaData metaData ( ) { } public MetaData getMetaData ( ) { } public RoutingTable routingTable ( ) { } public RoutingTable getRoutingTable ( ) { } public RoutingNodes routingNodes ( ) { } public RoutingNodes getRoutingNodes ( ) { } public ClusterBlocks blocks ( ) { } public ClusterBlocks getBlocks ( ) { } public AllocationExplanation allocationExplanation ( ) { } public AllocationExplanation getAllocationExplanation ( ) { } public RoutingNodes readOnlyRoutingNodes ( ) { } public static ClusterState . Builder builder ( ) { } public static ClusterState . Builder newClusterStateBuilder ( ) { } public static class Builder { private long version = 0 ; private MetaData metaData = MetaData . EMPTY_META_DATA ; private RoutingTable routingTable = RoutingTable . EMPTY_ROUTING_TABLE ; private DiscoveryNodes nodes = DiscoveryNodes . EMPTY_NODES ; private ClusterBlocks blocks = ClusterBlocks . EMPTY_CLUSTER_BLOCK ; private AllocationExplanation allocationExplanation = AllocationExplanation . EMPTY ; public ClusterState . Builder nodes ( DiscoveryNodes . Builder nodesBuilder ) { } public ClusterState . Builder nodes ( DiscoveryNodes nodes ) { } public ClusterState . Builder routingTable ( RoutingTable . Builder routingTable ) { } public ClusterState . Builder routingResult ( RoutingAllocation . Result routingResult ) { } public ClusterState . Builder routingTable ( RoutingTable routingTable ) { } public ClusterState . Builder metaData ( MetaData . Builder metaDataBuilder ) { } public ClusterState . Builder metaData ( MetaData metaData ) { } public ClusterState . Builder blocks ( ClusterBlocks . Builder blocksBuilder ) { } public ClusterState . Builder blocks ( ClusterBlocks block ) { } public ClusterState . Builder allocationExplanation ( AllocationExplanation allocationExplanation ) { } public ClusterState . Builder version ( long version ) { } public ClusterState . Builder state ( ClusterState state ) { } public ClusterState build ( ) { } public static byte [ ] toBytes ( ClusterState state ) throws IOException { } public static ClusterState fromBytes ( byte [ ] data , DiscoveryNode localNode ) throws IOException { <START_BUG> return ClusterState . Builder . readFrom ( new BytesStreamInput ( data ) , localNode ) ; <END_BUG> } public static void writeTo ( ClusterState state , StreamOutput out ) throws IOException { } public static ClusterState readFrom ( StreamInput in , @ Nullable DiscoveryNode localNode ) throws IOException { } } }<BUG2FIX>return ClusterState . Builder . readFrom ( new BytesStreamInput ( data , false ) , localNode ) ;
public abstract class TransportIndicesReplicationOperationAction < Request extends IndicesReplicationOperationRequest , Response extends ActionResponse , IndexRequest extends IndexReplicationOperationRequest , IndexResponse extends ActionResponse , ShardRequest extends ShardReplicationOperationRequest , ShardReplicaRequest extends ActionRequest , ShardResponse extends ActionResponse > extends TransportAction < Request , Response > { protected final ClusterService clusterService ; protected final TransportIndexReplicationOperationAction < IndexRequest , IndexResponse , ShardRequest , ShardReplicaRequest , ShardResponse > indexAction ; final String transportAction ; @ Inject public TransportIndicesReplicationOperationAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool , TransportIndexReplicationOperationAction < IndexRequest , IndexResponse , ShardRequest , ShardReplicaRequest , ShardResponse > indexAction ) { } protected abstract Map < String , Set < String > > resolveRouting ( ClusterState clusterState , Request request ) throws ElasticSearchException { } @ Override protected void doExecute ( final Request request , final ActionListener < Response > listener ) { } protected abstract Request newRequestInstance ( ) { } protected abstract Response newResponseInstance ( Request request , AtomicReferenceArray indexResponses ) { } protected abstract String transportAction ( ) { } protected abstract IndexRequest newIndexRequestInstance ( Request request , String index , Set < String > routing ) { } protected abstract boolean accumulateExceptions ( ) { } protected abstract ClusterBlockException checkGlobalBlock ( ClusterState state , Request request ) { } protected abstract ClusterBlockException checkRequestBlock ( ClusterState state , Request request , String [ ] concreteIndices ) { } private class TransportHandler extends BaseTransportRequestHandler < Request > { @ Override public Request newInstance ( ) { } @ Override public String executor ( ) { } @ Override public void messageReceived ( final Request request , final TransportChannel channel ) throws Exception { request . listenerThreaded ( false ) ; TransportIndicesReplicationOperationAction . TransportHandler . execute ( request , new ActionListener < Response > ( ) { @ Override public void onResponse ( Response result ) { try { channel . sendResponse ( result ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( e ) ; } catch ( Exception e1 ) { logger . warn ( ( ( ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>error<seq2seq4repair_space>response<seq2seq4repair_space>for<seq2seq4repair_space>action<seq2seq4repair_space>[" + ( transportAction ) ) + "]<seq2seq4repair_space>and<seq2seq4repair_space>request<seq2seq4repair_space>[" ) + request ) + "]" ) , e1 ) ; } } } ) ; } } }<BUG2FIX>} catch ( Throwable e ) {
public class AudioTools { public static native void convertToFloat ( ShortBuffer source , FloatBuffer target , int numSamples ) { } public static native void convertToShort ( FloatBuffer source , ShortBuffer target , int numSamples ) { } public static native void convertToMonoShort ( ShortBuffer source , ShortBuffer target , int numSamples ) { } public static native void convertToMonoFloat ( FloatBuffer source , FloatBuffer target , int numSamples ) { } public static native float spectralFlux ( FloatBuffer spectrumA , FloatBuffer spectrumB , int numSamples ) { } public static FloatBuffer allocateFloatBuffer ( int numSamples , int numChannels ) { } public static ShortBuffer allocateShortBuffer ( int numSamples , int numChannels ) { } public static void toShort ( byte [ ] src , int offsetSrc , short [ ] dst , int offsetDst , int numBytes ) { } public static void toFloat ( byte [ ] src , int offsetSrc , float [ ] dst , int offsetDst , int numBytes ) { } public static void toFloat ( short [ ] src , int offsetSrc , float [ ] dst , int offsetDst , int numBytes ) { float scale = 1.0F / ( Short . MAX_VALUE ) ; for ( int i = offsetSrc , ii = offsetDst ; i < numBytes ; i ++ , ii ++ ) <START_BUG> dst [ i ] = ( src [ ii ] ) * scale ; <END_BUG> } public static short [ ] generate ( int samplingRate , int frequency , int numSamples ) { } public static short [ ] generate ( int samplingRate , int frequency , float length ) { } public static float [ ] generateFloat ( int samplingRate , int frequency , int numSamples ) { } public static float [ ] generateFloat ( int samplingRate , int frequency , float length ) { } }<BUG2FIX>dst [ ii ] = ( src [ i ] ) * scale ;
public class RestPercolateAction extends BaseRestHandler { @ Inject public RestPercolateAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { PercolateRequest percolateRequest = new PercolateRequest ( request . param ( "index" ) , request . param ( "type" ) ) ; percolateRequest . listenerThreaded ( false ) ; percolateRequest . source ( request . content ( ) , request . contentUnsafe ( ) ) ; percolateRequest . listenerThreaded ( false ) ; percolateRequest . operationThreaded ( true ) ; percolateRequest . preferLocal ( request . paramAsBoolean ( "prefer_local" , percolateRequest . preferLocalShard ( ) ) ) ; client . percolate ( percolateRequest , new org . elasticsearch . action . ActionListener < PercolateResponse > ( ) { @ Override public void onResponse ( PercolateResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( RestPercolateAction . Fields . OK , true ) ; builder . startArray ( RestPercolateAction . Fields . MATCHES ) ; for ( String match : response ) { builder . value ( match ) ; } builder . endArray ( ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } static final class Fields { static final XContentBuilderString OK = new XContentBuilderString ( "ok" ) ; static final XContentBuilderString MATCHES = new XContentBuilderString ( "matches" ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class NestedQueryParser implements QueryParser { public static final String NAME = "nested" ; @ Inject public NestedQueryParser ( ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; Query query = null ; Filter filter = null ; float boost = 1.0F ; String scope = null ; String path = null ; BlockJoinQuery . ScoreMode scoreMode = ScoreMode . Avg ; NestedQueryParser . LateBindingParentFilter currentParentFilterContext = NestedQueryParser . parentFilterContext . get ( ) ; NestedQueryParser . LateBindingParentFilter usAsParentFilter = new NestedQueryParser . LateBindingParentFilter ( ) ; NestedQueryParser . parentFilterContext . set ( usAsParentFilter ) ; String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_OBJECT ) ) { if ( "query" . equals ( currentFieldName ) ) { query = parseContext . parseInnerQuery ( ) ; } else if ( "filter" . equals ( currentFieldName ) ) { filter = parseContext . parseInnerFilter ( ) ; } } else if ( token . isValue ( ) ) { if ( "path" . equals ( currentFieldName ) ) { path = parser . text ( ) ; } else if ( "boost" . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } else if ( "_scope" . equals ( currentFieldName ) ) { scope = parser . text ( ) ; } else <START_BUG> if ( ( "score_mode" . equals ( currentFieldName ) ) || ( "scoreMode" . equals ( scoreMode ) ) ) { <END_BUG> String sScoreMode = parser . text ( ) ; if ( "avg" . equals ( sScoreMode ) ) { scoreMode = ScoreMode . Avg ; } else if ( "max" . equals ( sScoreMode ) ) { scoreMode = ScoreMode . Max ; } else if ( "total" . equals ( sScoreMode ) ) { scoreMode = ScoreMode . Total ; } else if ( "none" . equals ( sScoreMode ) ) { scoreMode = ScoreMode . None ; } else { throw new QueryParsingException ( parseContext . index ( ) , ( ( "illegal<seq2seq4repair_space>score_mode<seq2seq4repair_space>for<seq2seq4repair_space>nested<seq2seq4repair_space>query<seq2seq4repair_space>[" + sScoreMode ) + "]" ) ) ; } } } } if ( ( query == null ) && ( filter == null ) ) { throw new QueryParsingException ( parseContext . index ( ) , "[nested]<seq2seq4repair_space>requires<seq2seq4repair_space>either<seq2seq4repair_space>'query'<seq2seq4repair_space>or<seq2seq4repair_space>'filter'<seq2seq4repair_space>field" ) ; } if ( path == null ) { throw new QueryParsingException ( parseContext . index ( ) , "[nested]<seq2seq4repair_space>requires<seq2seq4repair_space>'path'<seq2seq4repair_space>field" ) ; } if ( filter != null ) { query = new org . apache . lucene . search . DeletionAwareConstantScoreQuery ( filter ) ; } MapperService . SmartNameObjectMapper mapper = parseContext . smartObjectMapper ( path ) ; if ( mapper == null ) { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[nested]<seq2seq4repair_space>failed<seq2seq4repair_space>to<seq2seq4repair_space>find<seq2seq4repair_space>nested<seq2seq4repair_space>object<seq2seq4repair_space>under<seq2seq4repair_space>path<seq2seq4repair_space>[" + path ) + "]" ) ) ; } ObjectMapper objectMapper = mapper . mapper ( ) ; if ( objectMapper == null ) { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[nested]<seq2seq4repair_space>failed<seq2seq4repair_space>to<seq2seq4repair_space>find<seq2seq4repair_space>nested<seq2seq4repair_space>object<seq2seq4repair_space>under<seq2seq4repair_space>path<seq2seq4repair_space>[" + path ) + "]" ) ) ; } if ( ! ( objectMapper . nested ( ) . isNested ( ) ) ) { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[nested]<seq2seq4repair_space>nested<seq2seq4repair_space>object<seq2seq4repair_space>under<seq2seq4repair_space>path<seq2seq4repair_space>[" + path ) + "]<seq2seq4repair_space>is<seq2seq4repair_space>not<seq2seq4repair_space>of<seq2seq4repair_space>nested<seq2seq4repair_space>type" ) ) ; } Filter childFilter = parseContext . cacheFilter ( objectMapper . nestedTypeFilter ( ) , null ) ; usAsParentFilter . filter = childFilter ; query = new org . apache . lucene . search . FilteredQuery ( query , childFilter ) ; Filter parentFilter = currentParentFilterContext ; if ( parentFilter == null ) { parentFilter = NonNestedDocsFilter . INSTANCE ; if ( mapper . hasDocMapper ( ) ) { parentFilter = mapper . docMapper ( ) . typeFilter ( ) ; } parentFilter = parseContext . cacheFilter ( parentFilter , null ) ; } NestedQueryParser . parentFilterContext . set ( currentParentFilterContext ) ; BlockJoinQuery joinQuery = new BlockJoinQuery ( query , parentFilter , scoreMode ) ; joinQuery . setBoost ( boost ) ; if ( scope != null ) { SearchContext . current ( ) . addNestedQuery ( scope , joinQuery ) ; } return joinQuery ; } static ThreadLocal < NestedQueryParser . LateBindingParentFilter > parentFilterContext = new ThreadLocal < NestedQueryParser . LateBindingParentFilter > ( ) ; static class LateBindingParentFilter extends Filter { Filter filter ; @ Override public int hashCode ( ) { } @ Override public boolean equals ( Object obj ) { } @ Override public String toString ( ) { } @ Override public DocIdSet getDocIdSet ( IndexReader reader ) throws IOException { } } }<BUG2FIX>if ( ( "score_mode" . equals ( currentFieldName ) ) || ( "scoreMode" . equals ( currentFieldName ) ) ) {
public T pathType ( ContentPath . Type pathType ) { } public T includeInAll ( boolean includeInAll ) { } public T add ( Mapper . Builder builder ) { } @ Override public Y build ( BuilderContext context ) { } protected ObjectMapper createMapper ( String name , String fullPath , boolean enabled , ObjectMapper . Nested nested , ObjectMapper . Dynamic dynamic , ContentPath . Type pathType , Map < String , Mapper > mappers ) { } } public static class TypeParser implements Mapper . TypeParser { @ Override public Mapper . Builder parse ( String name , Map < String , Object > node , ParserContext parserContext ) throws MapperParsingException { } private void parseProperties ( ObjectMapper . Builder objBuilder , Map < String , Object > propsNode , ParserContext parserContext ) { } protected ObjectMapper . Builder createBuilder ( String name ) { } protected void processField ( ObjectMapper . Builder builder , String fieldName , Object fieldNode ) { } } private final String name ; private final String fullPath ; private final boolean enabled ; private final ObjectMapper . Nested nested ; private final String nestedTypePath ; private final Filter nestedTypeFilter ; private final ObjectMapper . Dynamic dynamic ; private final Type pathType ; private Boolean includeInAll ; private volatile ImmutableMap < String , Mapper > mappers = ImmutableMap . of ( ) ; private final Object mutex = new Object ( ) ; ObjectMapper ( String name , String fullPath , boolean enabled , ObjectMapper . Nested nested , ObjectMapper . Dynamic dynamic , ContentPath . Type pathType , Map < String , Mapper > mappers ) { } @ Override public String name ( ) { } @ Override public void includeInAll ( Boolean includeInAll ) { } @ Override public void includeInAllIfNotSet ( Boolean includeInAll ) { } public ObjectMapper . Nested nested ( ) { } public Filter nestedTypeFilter ( ) { } public ObjectMapper putMapper ( Mapper mapper ) { } @ Override public void traverse ( FieldMapperListener fieldMapperListener ) { } @ Override public void traverse ( ObjectMapperListener objectMapperListener ) { } public String fullPath ( ) { } public String nestedTypePath ( ) { } public final ObjectMapper . Dynamic dynamic ( ) { } public void parse ( ParseContext context ) throws IOException { } private void serializeNullValue ( ParseContext context , String lastFieldName ) throws IOException { } private void serializeObject ( final ParseContext context , String currentFieldName ) throws IOException { } private void serializeArray ( ParseContext context , String lastFieldName ) throws IOException { } private void serializeValue ( final ParseContext context , String currentFieldName , XContentParser . Token token ) throws IOException { if ( currentFieldName == null ) { throw new MapperParsingException ( ( ( ( ( "object<seq2seq4repair_space>mapping<seq2seq4repair_space>[" + ( name ) ) + "]<seq2seq4repair_space>trying<seq2seq4repair_space>to<seq2seq4repair_space>serialize<seq2seq4repair_space>a<seq2seq4repair_space>value<seq2seq4repair_space>with<seq2seq4repair_space>no<seq2seq4repair_space>field<seq2seq4repair_space>associated<seq2seq4repair_space>with<seq2seq4repair_space>it,<seq2seq4repair_space>current<seq2seq4repair_space>value<seq2seq4repair_space>[" ) + ( context . parser ( ) . textOrNull ( ) ) ) + "]" ) ) ; } Mapper mapper = mappers . get ( currentFieldName ) ; if ( mapper != null ) { mapper . parse ( context ) ; return ; } ObjectMapper . Dynamic dynamic = this . dynamic ; if ( dynamic == null ) { dynamic = context . root ( ) . dynamic ( ) ; } if ( dynamic == ( ObjectMapper . Dynamic . STRICT ) ) { throw new StrictDynamicMappingException ( currentFieldName ) ; } if ( dynamic == ( ObjectMapper . Dynamic . FALSE ) ) { return ; } boolean newMapper = false ; synchronized ( mutex ) { mapper = mappers . get ( currentFieldName ) ; if ( mapper == null ) { newMapper = true ; BuilderContext builderContext = new BuilderContext ( context . path ( ) ) ; if ( token == ( Token . VALUE_STRING ) ) { boolean resolved = false ; if ( ! resolved ) { <START_BUG> Mapper . Builder builder = context . root ( ) . findTemplateBuilder ( context , currentFieldName , "string" ) ; <END_BUG> if ( builder != null ) { mapper = builder . build ( builderContext ) ; resolved = true ; } } if ( ( ! resolved ) && ( context . root ( ) . dateDetection ( ) ) ) { String text = context . parser ( ) . text ( ) ; if ( ( ( text . contains ( ":" ) ) || ( text . contains ( "-" ) ) ) || ( text . contains ( "/" ) ) ) { for ( FormatDateTimeFormatter dateTimeFormatter : context . root ( ) . dynamicDateTimeFormatters ( ) ) { try { dateTimeFormatter . parser ( ) . parseMillis ( text ) ; Mapper . Builder builder = context . root ( ) . findTemplateBuilder ( context , currentFieldName , "date" ) ; if ( builder == null ) { builder = dateField ( currentFieldName ) . dateTimeFormatter ( dateTimeFormatter ) ; } mapper = builder . build ( builderContext ) ; resolved = true ; break ; } catch ( Exception e ) { } } } } if ( ( ! resolved ) && ( context . root ( ) . numericDetection ( ) ) ) { String text = context . parser ( ) . text ( ) ; try { Long . parseLong ( text ) ; Mapper . Builder builder = context . root ( ) . findTemplateBuilder ( context , currentFieldName , "long" ) ; if ( builder == null ) { builder = longField ( currentFieldName ) ; } mapper = builder . build ( builderContext ) ; resolved = true ; } catch ( Exception e ) { } if ( ! resolved ) { try { Double . parseDouble ( text ) ; Mapper . Builder builder = context . root ( ) . findTemplateBuilder ( context , currentFieldName , "double" ) ;<BUG2FIX>Mapper . Builder builder = context . root ( ) . findTemplateBuilder ( context , currentFieldName , "string" , null ) ;
public class ClusterRerouteRequestBuilder extends MasterNodeOperationRequestBuilder < ClusterRerouteRequest , ClusterRerouteResponse , ClusterRerouteRequestBuilder > { public ClusterRerouteRequestBuilder ( ClusterAdminClient clusterClient ) { } public ClusterRerouteRequestBuilder add ( AllocationCommand ... commands ) { } public ClusterRerouteRequestBuilder setDryRun ( boolean dryRun ) { } public ClusterRerouteRequestBuilder setSource ( BytesReference source ) throws Exception { <START_BUG> request . source ( source ) ; <END_BUG> return this ; } @ Override protected void doExecute ( ActionListener < ClusterRerouteResponse > listener ) { } }<BUG2FIX>request . setSource ( source ) ;
public class MultiValueDoubleFieldData extends DoubleFieldData { private static final int VALUE_CACHE_SIZE = 10 ; private ThreadLocal < ThreadLocals . CleanableValue < double [ ] [ ] > > valuesCache = new ThreadLocal < ThreadLocals . CleanableValue < double [ ] [ ] > > ( ) { @ Override protected ThreadLocals . CleanableValue < double [ ] [ ] > initialValue ( ) { } } ; private final int [ ] [ ] ordinals ; public MultiValueDoubleFieldData ( String fieldName , int [ ] [ ] ordinals , double [ ] values ) { } @ Override protected long computeSizeInBytes ( ) { } @ Override public boolean multiValued ( ) { } @ Override public boolean hasValue ( int docId ) { } @ Override public void forEachValueInDoc ( int docId , StringValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , DoubleValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , LongValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , MissingDoubleValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , MissingLongValueInDocProc proc ) { } @ Override public void forEachValueInDoc ( int docId , ValueInDocProc proc ) { } @ Override public void forEachOrdinalInDoc ( int docId , OrdinalInDocProc proc ) { boolean found = false ; for ( int [ ] ordinal : ordinals ) { int loc = ordinal [ docId ] ; if ( loc != 0 ) { found = true ; <START_BUG> proc . onOrdinal ( docId , ordinal [ docId ] ) ; <END_BUG> } } if ( ! found ) { proc . onOrdinal ( docId , 0 ) ; } } @ Override public double [ ] doubleValues ( int docId ) { } @ Override public double value ( int docId ) { } @ Override public double [ ] values ( int docId ) { } }<BUG2FIX>proc . onOrdinal ( docId , loc ) ;
public final class BytesRefOrdValComparator extends NestedWrappableComparator < BytesRef > { final IndexFieldData . WithOrdinals < ? > indexFieldData ; final BytesRef missingValue ; final long [ ] ords ; final MultiValueMode sortMode ; final BytesRef [ ] values ; final int [ ] readerGen ; int currentReaderGen = - 1 ; WithOrdinals termsIndex ; long missingOrd ; int bottomSlot = - 1 ; long bottomOrd ; BytesRef top ; long topOrd ; public BytesRefOrdValComparator ( IndexFieldData . WithOrdinals < ? > indexFieldData , int numHits , MultiValueMode sortMode , BytesRef missingValue ) { } @ Override public int compare ( int slot1 , int slot2 ) { } @ Override public int compareBottom ( int doc ) { } @ Override public int compareTop ( int doc ) throws IOException { } @ Override public int compareBottomMissing ( ) { } @ Override public void copy ( int slot , int doc ) { } @ Override public void missing ( int slot ) { } @ Override public int compareTopMissing ( ) { } class PerSegmentComparator extends NestedWrappableComparator < BytesRef > { final Docs readerOrds ; final WithOrdinals termsIndex ; public PerSegmentComparator ( BytesValues . WithOrdinals termsIndex ) { } @ Override public FieldComparator < BytesRef > setNextReader ( AtomicReaderContext context ) throws IOException { return BytesRefOrdValComparator . this . setNextReader ( context ) ; } @ Override public int compare ( int slot1 , int slot2 ) { } @ Override public void setBottom ( final int bottom ) { } @ Override public void setTopValue ( BytesRef value ) { } @ Override public BytesRef value ( int slot ) { } @ Override public int compareValues ( BytesRef val1 , BytesRef val2 ) { } protected long getOrd ( int doc ) { } @ Override public int compareBottom ( int doc ) { } @ Override public int compareTop ( int doc ) throws IOException { } @ Override public int compareBottomMissing ( ) { } @ Override public int compareTopMissing ( ) { } @ Override public void copy ( int slot , int doc ) { } @ Override public void missing ( int slot ) { } } private boolean consistentInsertedOrd ( BytesValues . WithOrdinals termsIndex , long ord , BytesRef value ) { } private long ordInCurrentReader ( BytesValues . WithOrdinals termsIndex , BytesRef value ) { } @ Override public FieldComparator < BytesRef > setNextReader ( AtomicReaderContext context ) throws IOException { <START_BUG> termsIndex = indexFieldData . load ( context ) . getBytesValues ( false ) ; <END_BUG> assert ( termsIndex . ordinals ( ) ) != null ; missingOrd = ordInCurrentReader ( termsIndex , missingValue ) ; assert consistentInsertedOrd ( termsIndex , missingOrd , missingValue ) ; FieldComparator < BytesRef > perSegComp = null ; assert ( termsIndex . ordinals ( ) ) != null ; if ( termsIndex . isMultiValued ( ) ) { perSegComp = new BytesRefOrdValComparator . PerSegmentComparator ( termsIndex ) { @ Override protected long getOrd ( int doc ) { return BytesRefOrdValComparator . getRelevantOrd ( readerOrds , doc , sortMode ) ; } } ; } else { perSegComp = new BytesRefOrdValComparator . PerSegmentComparator ( termsIndex ) ; } ( currentReaderGen ) ++ ; if ( ( bottomSlot ) != ( - 1 ) ) { perSegComp . setBottom ( bottomSlot ) ; } if ( ( top ) != null ) { perSegComp . setTopValue ( top ) ; topOrd = ordInCurrentReader ( termsIndex , top ) ; } else { topOrd = missingOrd ; } return perSegComp ; } @ Override public void setBottom ( final int bottom ) { } @ Override public void setTopValue ( BytesRef value ) { } @ Override public BytesRef value ( int slot ) { } protected static final long binarySearch ( BytesValues . WithOrdinals a , BytesRef key ) { } protected static final long binarySearch ( BytesValues . WithOrdinals a , BytesRef key , long low , long high ) { } static long getRelevantOrd ( Ordinals . Docs readerOrds , int docId , MultiValueMode sortMode ) { } }<BUG2FIX>termsIndex = indexFieldData . load ( context ) . getBytesValues ( ) ;
public abstract class BlobStoreIndexShardGateway extends AbstractIndexShardComponent implements IndexShardGateway { protected final ThreadPool threadPool ; protected final InternalIndexShard indexShard ; protected final Store store ; protected final ByteSizeValue chunkSize ; protected final BlobStore blobStore ; protected final BlobPath shardPath ; protected final ImmutableBlobContainer blobContainer ; private volatile RecoveryStatus recoveryStatus ; private volatile SnapshotStatus lastSnapshotStatus ; private volatile SnapshotStatus currentSnapshotStatus ; protected BlobStoreIndexShardGateway ( ShardId shardId , @ IndexSettings Settings indexSettings , ThreadPool threadPool , IndexGateway indexGateway , IndexShard indexShard , Store store ) { } @ Override public RecoveryStatus recoveryStatus ( ) { } @ Override public String toString ( ) { } @ Override public boolean requiresSnapshot ( ) { } @ Override public boolean requiresSnapshotScheduling ( ) { } @ Override public SnapshotLock obtainSnapshotLock ( ) throws Exception { } @ Override public void close ( ) throws ElasticSearchException { } @ Override public SnapshotStatus lastSnapshotStatus ( ) { } @ Override public SnapshotStatus currentSnapshotStatus ( ) { } @ Override public SnapshotStatus snapshot ( final Snapshot snapshot ) throws IndexShardGatewaySnapshotFailedException { } private void doSnapshot ( final Snapshot snapshot ) throws IndexShardGatewaySnapshotFailedException { } @ Override public void recover ( boolean indexShouldExists , RecoveryStatus recoveryStatus ) throws IndexShardGatewayRecoveryException { } private void recoverTranslog ( CommitPoint commitPoint , ImmutableMap < String , BlobMetaData > blobs ) throws IndexShardGatewayRecoveryException { } private void recoverIndex ( CommitPoint commitPoint , ImmutableMap < String , BlobMetaData > blobs ) throws Exception { recoveryStatus . updateStage ( INDEX ) ; int numberOfFiles = 0 ; long totalSize = 0 ; int numberOfReusedFiles = 0 ; long reusedTotalSize = 0 ; List < CommitPoint . FileInfo > filesToRecover = Lists . newArrayList ( ) ; for ( CommitPoint . FileInfo fileInfo : commitPoint . indexFiles ( ) ) { String fileName = fileInfo . physicalName ( ) ; StoreFileMetaData md = null ; try { md = store . metaData ( fileName ) ; } catch ( Exception e ) { } if ( ( ( ! ( fileName . startsWith ( "segments" ) ) ) && ( md != null ) ) && ( fileInfo . isSame ( md ) ) ) { numberOfFiles ++ ; totalSize += md . length ( ) ; numberOfReusedFiles ++ ; reusedTotalSize += md . length ( ) ; if ( logger . isTraceEnabled ( ) ) { logger . trace ( "not_recovering<seq2seq4repair_space>[{}],<seq2seq4repair_space>exists<seq2seq4repair_space>in<seq2seq4repair_space>local<seq2seq4repair_space>store<seq2seq4repair_space>and<seq2seq4repair_space>is<seq2seq4repair_space>same" , fileInfo . physicalName ( ) ) ; } } else { if ( logger . isTraceEnabled ( ) ) { if ( md == null ) { logger . trace ( "recovering<seq2seq4repair_space>[{}],<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>exists<seq2seq4repair_space>in<seq2seq4repair_space>local<seq2seq4repair_space>store" , fileInfo . physicalName ( ) ) ; } else { logger . trace ( "recovering<seq2seq4repair_space>[{}],<seq2seq4repair_space>exists<seq2seq4repair_space>in<seq2seq4repair_space>local<seq2seq4repair_space>store<seq2seq4repair_space>but<seq2seq4repair_space>is<seq2seq4repair_space>different" , fileInfo . physicalName ( ) ) ; } } numberOfFiles ++ ; totalSize += fileInfo . length ( ) ; filesToRecover . add ( fileInfo ) ; } } recoveryStatus . index ( ) . files ( numberOfFiles , totalSize , numberOfReusedFiles , reusedTotalSize ) ; if ( filesToRecover . isEmpty ( ) ) { logger . trace ( "no<seq2seq4repair_space>files<seq2seq4repair_space>to<seq2seq4repair_space>recover,<seq2seq4repair_space>all<seq2seq4repair_space>exists<seq2seq4repair_space>within<seq2seq4repair_space>the<seq2seq4repair_space>local<seq2seq4repair_space>store" ) ; } if ( logger . isTraceEnabled ( ) ) { logger . trace ( "recovering_files<seq2seq4repair_space>[{}]<seq2seq4repair_space>with<seq2seq4repair_space>total_size<seq2seq4repair_space>[{}],<seq2seq4repair_space>reusing_files<seq2seq4repair_space>[{}]<seq2seq4repair_space>with<seq2seq4repair_space>reused_size<seq2seq4repair_space>[{}]" , numberOfFiles , new ByteSizeValue ( totalSize ) , numberOfReusedFiles , new ByteSizeValue ( reusedTotalSize ) ) ; } final CountDownLatch latch = new CountDownLatch ( filesToRecover . size ( ) ) ; final CopyOnWriteArrayList < Throwable > failures = new CopyOnWriteArrayList < Throwable > ( ) ; for ( final CommitPoint . FileInfo fileToRecover : filesToRecover ) { recoverFile ( fileToRecover , blobs , latch , failures ) ; } try { latch . await ( ) ; } catch ( InterruptedException e ) { throw new IndexShardGatewayRecoveryException ( shardId , "Interrupted<seq2seq4repair_space>while<seq2seq4repair_space>recovering<seq2seq4repair_space>index" , e ) ; } if ( ! ( failures . isEmpty ( ) ) ) { throw new IndexShardGatewayRecoveryException ( shardId , "Failed<seq2seq4repair_space>to<seq2seq4repair_space>recover<seq2seq4repair_space>index" , failures . get ( 0 ) ) ; } long version = - 1 ; try { <START_BUG> if ( DirectoryReader . indexExists ( store . directory ( ) ) ) { <END_BUG> version = Lucene . readSegmentInfos ( store . directory ( ) ) . getVersion ( ) ; } } catch ( IOException e ) { throw new IndexShardGatewayRecoveryException ( shardId ( ) , "Failed<seq2seq4repair_space>to<seq2seq4repair_space>fetch<seq2seq4repair_space>index<seq2seq4repair_space>version<seq2seq4repair_space>after<seq2seq4repair_space>copying<seq2seq4repair_space>it<seq2seq4repair_space>over" , e ) ; } recoveryStatus . index ( ) . updateVersion ( version ) ; try { for ( String storeFile : store . directory ( ) . listAll ( ) ) { if ( ! ( commitPoint . containPhysicalIndexFile ( storeFile ) ) ) { try { store . directory ( ) . deleteFile ( storeFile ) ; } catch ( Exception e ) { } } } } catch ( Exception e ) { } } private void recoverFile ( final CommitPoint . FileInfo fileInfo , final ImmutableMap < String , BlobMetaData > blobs , final CountDownLatch latch , final List < Throwable > failures ) { } private void snapshotTranslog ( Translog . Snapshot snapshot , CommitPoint . FileInfo fileInfo ) throws IOException { } private void snapshotFile ( Directory dir , final CommitPoint . FileInfo fileInfo , final CountDownLatch latch , final List < Throwable > failures ) throws IOException { } private boolean commitPointExistsInBlobs ( CommitPoint commitPoint , ImmutableMap < String , BlobMetaData > blobs ) { } private boolean commitPointFileExistsInBlobs ( CommitPoint . FileInfo fileInfo , ImmutableMap < String , BlobMetaData > blobs ) { } private CommitPoints buildCommitPoints ( ImmutableMap < String , BlobMetaData > blobs ) { } private String fileNameFromGeneration ( long generation ) { } private long findLatestFileNameGeneration ( ImmutableMap < String , BlobMetaData > blobs ) { } }<BUG2FIX>if ( Lucene . indexExists ( store . directory ( ) ) ) {
public class RestExplainAction extends BaseRestHandler { @ Inject public RestExplainAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { final ExplainRequest explainRequest = new ExplainRequest ( request . param ( "index" ) , request . param ( "type" ) , request . param ( "id" ) ) ; explainRequest . parent ( request . param ( "parent" ) ) ; explainRequest . routing ( request . param ( "routing" ) ) ; explainRequest . preference ( request . param ( "preference" ) ) ; String sourceString = request . param ( "source" ) ; String queryString = request . param ( "q" ) ; if ( request . hasContent ( ) ) { explainRequest . source ( request . content ( ) , request . contentUnsafe ( ) ) ; } else if ( sourceString != null ) { explainRequest . source ( new org . elasticsearch . common . bytes . BytesArray ( request . param ( "source" ) ) , false ) ; } else if ( queryString != null ) { QueryStringQueryBuilder queryStringBuilder = QueryBuilders . queryString ( queryString ) ; queryStringBuilder . defaultField ( request . param ( "df" ) ) ; queryStringBuilder . analyzer ( request . param ( "analyzer" ) ) ; queryStringBuilder . analyzeWildcard ( request . paramAsBoolean ( "analyze_wildcard" , false ) ) ; queryStringBuilder . lowercaseExpandedTerms ( request . paramAsBoolean ( "lowercase_expanded_terms" , true ) ) ; <START_BUG> queryStringBuilder . lenient ( request . paramAsBooleanOptional ( "lenient" , null ) ) ; <END_BUG> String defaultOperator = request . param ( "default_operator" ) ; if ( defaultOperator != null ) { if ( "OR" . equals ( defaultOperator ) ) { queryStringBuilder . defaultOperator ( OR ) ; } else if ( "AND" . equals ( defaultOperator ) ) { queryStringBuilder . defaultOperator ( AND ) ; } else { throw new ElasticsearchIllegalArgumentException ( ( ( "Unsupported<seq2seq4repair_space>defaultOperator<seq2seq4repair_space>[" + defaultOperator ) + "],<seq2seq4repair_space>can<seq2seq4repair_space>either<seq2seq4repair_space>be<seq2seq4repair_space>[OR]<seq2seq4repair_space>or<seq2seq4repair_space>[AND]" ) ) ; } } QuerySourceBuilder querySourceBuilder = new QuerySourceBuilder ( ) ; querySourceBuilder . setQuery ( queryStringBuilder ) ; explainRequest . source ( querySourceBuilder ) ; } String sField = request . param ( "fields" ) ; if ( sField != null ) { String [ ] sFields = Strings . splitStringByCommaToArray ( sField ) ; if ( sFields != null ) { explainRequest . fields ( sFields ) ; } } explainRequest . fetchSourceContext ( FetchSourceContext . parseFromRestRequest ( request ) ) ; client . explain ( explainRequest , new org . elasticsearch . action . ActionListener < ExplainResponse > ( ) { @ Override public void onResponse ( ExplainResponse response ) { try { XContentBuilder builder = restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( RestExplainAction . Fields . _INDEX , explainRequest . index ( ) ) . field ( RestExplainAction . Fields . _TYPE , explainRequest . type ( ) ) . field ( RestExplainAction . Fields . _ID , explainRequest . id ( ) ) . field ( RestExplainAction . Fields . MATCHED , response . isMatch ( ) ) ; if ( response . hasExplanation ( ) ) { builder . startObject ( RestExplainAction . Fields . EXPLANATION ) ; buildExplanation ( builder , response . getExplanation ( ) ) ; builder . endObject ( ) ; } GetResult getResult = response . getGetResult ( ) ; if ( getResult != null ) { builder . startObject ( RestExplainAction . Fields . GET ) ; response . getGetResult ( ) . toXContentEmbedded ( builder , request ) ; builder . endObject ( ) ; } builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , ( response . isExists ( ) ? RestStatus . OK : RestStatus . NOT_FOUND ) , builder ) ) ; } catch ( Throwable e ) { onFailure ( e ) ; } } private void buildExplanation ( XContentBuilder builder , Explanation explanation ) throws IOException { builder . field ( RestExplainAction . Fields . VALUE , explanation . getValue ( ) ) ; builder . field ( RestExplainAction . Fields . DESCRIPTION , explanation . getDescription ( ) ) ; Explanation [ ] innerExps = explanation . getDetails ( ) ; if ( innerExps != null ) { builder . startArray ( RestExplainAction . Fields . DETAILS ) ; for ( Explanation exp : innerExps ) { builder . startObject ( ) ; buildExplanation ( builder , exp ) ; builder . endObject ( ) ; } builder . endArray ( ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } static class Fields { static final XContentBuilderString _INDEX = new XContentBuilderString ( "_index" ) ; static final XContentBuilderString _TYPE = new XContentBuilderString ( "_type" ) ; static final XContentBuilderString _ID = new XContentBuilderString ( "_id" ) ; static final XContentBuilderString MATCHED = new XContentBuilderString ( "matched" ) ; static final XContentBuilderString EXPLANATION = new XContentBuilderString ( "explanation" ) ; static final XContentBuilderString VALUE = new XContentBuilderString ( "value" ) ; static final XContentBuilderString DESCRIPTION = new XContentBuilderString ( "description" ) ; static final XContentBuilderString DETAILS = new XContentBuilderString ( "details" ) ; static final XContentBuilderString GET = new XContentBuilderString ( "get" ) ; } }<BUG2FIX>queryStringBuilder . lenient ( request . paramAsBoolean ( "lenient" , null ) ) ;
public class ValueHistogramFacetExecutor extends FacetExecutor { private final IndexNumericFieldData keyIndexFieldData ; private final IndexNumericFieldData valueIndexFieldData ; private final ComparatorType comparatorType ; private final long interval ; final Recycler . V < LongObjectOpenHashMap < InternalFullHistogramFacet . FullEntry > > entries ; public ValueHistogramFacetExecutor ( IndexNumericFieldData keyIndexFieldData , IndexNumericFieldData valueIndexFieldData , long interval , HistogramFacet . ComparatorType comparatorType , SearchContext context ) { } @ Override public ValueHistogramFacetExecutor . Collector collector ( ) { } @ Override public InternalFacet buildFacet ( String facetName ) { List < InternalFullHistogramFacet . FullEntry > entries1 = new java . util . ArrayList ( entries . v ( ) . size ( ) ) ; final boolean [ ] states = entries . v ( ) . allocated ; final Object [ ] values = entries . v ( ) . values ; for ( int i = 0 ; i < ( states . length ) ; i ++ ) { if ( states [ i ] ) { InternalFullHistogramFacet . FullEntry value = ( ( InternalFullHistogramFacet . FullEntry ) ( values [ i ] ) ) ; entries1 . add ( value ) ; } } <START_BUG> entries . release ( ) ; <END_BUG> return new InternalFullHistogramFacet ( facetName , comparatorType , entries1 ) ; } class Collector extends FacetExecutor . Collector { private final ValueHistogramFacetExecutor . HistogramProc histoProc ; private DoubleValues keyValues ; public Collector ( ) { } @ Override public void setNextReader ( AtomicReaderContext context ) throws IOException { } @ Override public void collect ( int doc ) throws IOException { } @ Override public void postCollection ( ) { } } public static final class HistogramProc extends DoubleFacetAggregatorBase { final long interval ; final LongObjectOpenHashMap < InternalFullHistogramFacet . FullEntry > entries ; DoubleValues valueValues ; final ValueHistogramFacetExecutor . HistogramProc . ValueAggregator valueAggregator = new ValueHistogramFacetExecutor . HistogramProc . ValueAggregator ( ) ; public HistogramProc ( long interval , LongObjectOpenHashMap < InternalFullHistogramFacet . FullEntry > entries ) { } @ Override public void onValue ( int docId , double value ) { } public static final class ValueAggregator extends DoubleFacetAggregatorBase { FullEntry entry ; @ Override public void onValue ( int docId , double value ) { } } } }<BUG2FIX>entries . close ( ) ;
public class DashboardIssueFragment extends PagedItemFragment < RepositoryIssue > { public static final String ARG_FILTER = "filter" ; @ Inject private IssueService service ; @ Inject private IssueStore store ; @ Inject private AvatarLoader avatarHelper ; private Map < String , String > filterData ; @ Override public void onCreate ( Bundle savedInstanceState ) { } @ SuppressWarnings ( "unchecked" ) @ Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; filterData = ( ( Map < String , String > ) ( getArguments ( ) . getSerializable ( DashboardIssueFragment . ARG_FILTER ) ) ) ; <START_BUG> ListViewUtils . configure ( getActivity ( ) , getListView ( ) , true ) ; <END_BUG> } @ Override public void onListItemClick ( ListView l , View v , int position , long id ) { } @ Override protected ResourcePager < RepositoryIssue > createPager ( ) { } @ Override protected int getLoadingMessage ( ) { } @ Override protected ItemListAdapter < RepositoryIssue , ? extends ItemView > createAdapter ( List < RepositoryIssue > items ) { } }<BUG2FIX>ListViewUtils . configure ( getActivity ( ) , getListView ( ) ) ;
public class RestHeadAction extends BaseRestHandler { @ Inject public RestHeadAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { final GetRequest getRequest = new GetRequest ( request . param ( "index" ) , request . param ( "type" ) , request . param ( "id" ) ) ; getRequest . listenerThreaded ( false ) ; getRequest . operationThreaded ( true ) ; getRequest . refresh ( request . paramAsBoolean ( "refresh" , getRequest . refresh ( ) ) ) ; getRequest . routing ( request . param ( "routing" ) ) ; getRequest . parent ( request . param ( "parent" ) ) ; getRequest . preference ( request . param ( "preference" ) ) ; <START_BUG> getRequest . realtime ( request . paramAsBooleanOptional ( "realtime" , null ) ) ; <END_BUG> getRequest . fields ( EMPTY_ARRAY ) ; client . get ( getRequest , new org . elasticsearch . action . ActionListener < GetResponse > ( ) { @ Override public void onResponse ( GetResponse response ) { try { if ( ! ( response . isExists ( ) ) ) { channel . sendResponse ( new StringRestResponse ( RestStatus . NOT_FOUND ) ) ; } else { channel . sendResponse ( new StringRestResponse ( RestStatus . OK ) ) ; } } catch ( Throwable e ) { onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new StringRestResponse ( ExceptionsHelper . status ( e ) ) ) ; } catch ( Exception e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>getRequest . realtime ( request . paramAsBoolean ( "realtime" , null ) ) ;
public class Mesh { private static final ArrayList < Mesh > meshes = new ArrayList < Mesh > ( ) ; private final VertexAttributes attributes ; private final int maxVertices ; private final int maxIndices ; private final Buffer vertices ; private final FloatBuffer verticesFloat ; private final IntBuffer verticesFixed ; private final ShortBuffer indices ; private int vertexBufferObjectHandle ; private int indexBufferObjectHandle ; private boolean dirty = false ; private final Graphics graphics ; private final boolean managed ; private final boolean isStatic ; private final boolean useFixedPoint ; private boolean invalidated = false ; private boolean bufferCreatedFirstTime = false ; public Mesh ( Graphics graphics , boolean managed , boolean isStatic , boolean useFixedPoint , int maxVertices , int maxIndices , VertexAttribute ... attributes ) { } private void createBuffers ( ) { } private void constructBufferObjects ( GL11 gl ) { } private void constructBufferObjects ( GL20 gl ) { } private void fillBuffers ( ) { } private void fillBuffers ( GL11 gl ) { } private void fillBuffers ( GL20 gl ) { } public void setVertices ( float [ ] vertices ) { } public void setVertices ( float [ ] vertices , int offset , int count ) { if ( useFixedPoint ) throw new IllegalArgumentException ( "can't<seq2seq4repair_space>set<seq2seq4repair_space>float<seq2seq4repair_space>vertices<seq2seq4repair_space>for<seq2seq4repair_space>fixed<seq2seq4repair_space>point<seq2seq4repair_space>mesh" ) ; <START_BUG> int result = BufferUtils . copy ( vertices , this . vertices , count , offset ) ; <END_BUG> this . verticesFloat . limit ( ( ( this . vertices . limit ( ) ) > > 2 ) ) ; this . verticesFloat . position ( 0 ) ; dirty = true ; } public void setVertices ( int [ ] vertices ) { } public void setVertices ( int [ ] vertices , int offset , int count ) { } public void setIndices ( short [ ] indices ) { } public int getNumIndices ( ) { } public int getNumVertices ( ) { } public int getVertexSize ( ) { } public void render ( int primitiveType ) { } public void render ( int primitiveType , int offset , int count ) { } private void renderVBO ( int primitiveType , int offset , int count ) { } private void renderVA ( int primitiveType , int offset , int count ) { } public void render ( ShaderProgram shader , int primitiveType ) { } public void render ( ShaderProgram shader , int primitiveType , int offset , int count ) { } private void checkManagedAndDirty ( ) { } public void dispose ( ) { } private void dispose ( GL11 gl ) { } private void dispose ( GL20 gl ) { } public boolean usesFixedPoint ( ) { } public int getMaxVertices ( ) { } public int getMaxIndices ( ) { } public VertexAttribute getVertexAttribute ( int usage ) { } public VertexAttributes getVertexAttributes ( ) { } public Buffer getVerticesBuffer ( ) { } public ShortBuffer getIndicesBuffer ( ) { } public void getVertices ( float [ ] vertices ) { } public void getVertices ( int [ ] vertices ) { } public void getIndices ( short [ ] indices ) { } public static void invalidateAllMeshes ( ) { } }<BUG2FIX>BufferUtils . copy ( vertices , this . vertices , count , offset ) ;
public void retryRecovery ( final StartRecoveryRequest request , final RecoveryStatus status , final RecoveryTarget . RecoveryListener listener ) { } private void doRecovery ( final StartRecoveryRequest request , final RecoveryStatus recoveryStatus , final RecoveryTarget . RecoveryListener listener ) { } public static interface RecoveryListener { void onRecoveryDone ( ) { } void onRetryRecovery ( TimeValue retryAfter , RecoveryStatus status ) { } void onIgnoreRecovery ( boolean removeShard , String reason ) { } void onRecoveryFailure ( RecoveryFailedException e , boolean sendShardFailure ) { } } @ Nullable private RecoveryStatus findRecoveryByShardId ( ShardId shardId ) { } @ Nullable private RecoveryStatus findRecoveryByShard ( IndexShard indexShard ) { } private void removeAndCleanOnGoingRecovery ( @ Nullable RecoveryStatus status ) { } class PrepareForTranslogOperationsRequestHandler extends BaseTransportRequestHandler < RecoveryPrepareForTranslogOperationsRequest > { @ Override public RecoveryPrepareForTranslogOperationsRequest newInstance ( ) { } @ Override public String executor ( ) { } @ Override public void messageReceived ( RecoveryPrepareForTranslogOperationsRequest request , TransportChannel channel ) throws Exception { } } class FinalizeRecoveryRequestHandler extends BaseTransportRequestHandler < RecoveryFinalizeRecoveryRequest > { @ Override public RecoveryFinalizeRecoveryRequest newInstance ( ) { } @ Override public String executor ( ) { } @ Override public void messageReceived ( RecoveryFinalizeRecoveryRequest request , TransportChannel channel ) throws Exception { } } class TranslogOperationsRequestHandler extends BaseTransportRequestHandler < RecoveryTranslogOperationsRequest > { @ Override public RecoveryTranslogOperationsRequest newInstance ( ) { } @ Override public String executor ( ) { } @ Override public void messageReceived ( RecoveryTranslogOperationsRequest request , TransportChannel channel ) throws Exception { } } class FilesInfoRequestHandler extends BaseTransportRequestHandler < RecoveryFilesInfoRequest > { @ Override public RecoveryFilesInfoRequest newInstance ( ) { } @ Override public String executor ( ) { } @ Override public void messageReceived ( RecoveryFilesInfoRequest request , TransportChannel channel ) throws Exception { } } class CleanFilesRequestHandler extends BaseTransportRequestHandler < RecoveryCleanFilesRequest > { @ Override public RecoveryCleanFilesRequest newInstance ( ) { } @ Override public String executor ( ) { } @ Override public void messageReceived ( RecoveryCleanFilesRequest request , TransportChannel channel ) throws Exception { } } class FileChunkTransportRequestHandler extends BaseTransportRequestHandler < RecoveryFileChunkRequest > { @ Override public RecoveryFileChunkRequest newInstance ( ) { } @ Override public String executor ( ) { } @ Override public void messageReceived ( final RecoveryFileChunkRequest request , TransportChannel channel ) throws Exception { RecoveryStatus onGoingRecovery = onGoingRecoveries . get ( request . recoveryId ( ) ) ; if ( onGoingRecovery == null ) { throw new IndexShardClosedException ( request . shardId ( ) ) ; } if ( onGoingRecovery . isCanceled ( ) ) { onGoingRecovery . sentCanceledToSource = true ; throw new IndexShardClosedException ( request . shardId ( ) ) ; } Store store = onGoingRecovery . indexShard . store ( ) ; store . incRef ( ) ; try { IndexOutput indexOutput ; if ( ( request . position ( ) ) == 0 ) { onGoingRecovery . checksums . remove ( request . name ( ) ) ; indexOutput = onGoingRecovery . removeOpenIndexOutputs ( request . name ( ) ) ; IOUtils . closeWhileHandlingException ( indexOutput ) ; String fileName = request . name ( ) ; if ( store . directory ( ) . fileExists ( fileName ) ) { fileName = ( ( "recovery." + ( onGoingRecovery . recoveryState ( ) . getTimer ( ) . startTime ( ) ) ) + "." ) + fileName ; } indexOutput = onGoingRecovery . openAndPutIndexOutput ( request . name ( ) , fileName , store ) ; } else { indexOutput = onGoingRecovery . getOpenIndexOutput ( request . name ( ) ) ; } if ( indexOutput == null ) { throw new IndexShardClosedException ( request . shardId ( ) ) ; } boolean success = false ; synchronized ( indexOutput ) { try { if ( ( recoverySettings . rateLimiter ( ) ) != null ) { recoverySettings . rateLimiter ( ) . pause ( request . content ( ) . length ( ) ) ; } BytesReference content = request . content ( ) ; if ( ! ( content . hasArray ( ) ) ) { content = content . toBytesArray ( ) ; } indexOutput . writeBytes ( content . array ( ) , content . arrayOffset ( ) , content . length ( ) ) ; <START_BUG> onGoingRecovery . recoveryState . getIndex ( ) . addRecoveredByteCount ( request . length ( ) ) ; <END_BUG> RecoveryState . File file = onGoingRecovery . recoveryState . getIndex ( ) . file ( request . name ( ) ) ; if ( file != null ) { file . updateRecovered ( request . length ( ) ) ; } if ( ( indexOutput . getFilePointer ( ) ) == ( request . length ( ) ) ) { indexOutput . close ( ) ; if ( ( request . checksum ( ) ) != null ) { onGoingRecovery . checksums . put ( request . name ( ) , request . checksum ( ) ) ; } store . directory ( ) . sync ( Collections . singleton ( request . name ( ) ) ) ; IndexOutput remove = onGoingRecovery . removeOpenIndexOutputs ( request . name ( ) ) ; onGoingRecovery . recoveryState . getIndex ( ) . addRecoveredFileCount ( 1 ) ; assert ( remove == null ) || ( remove == indexOutput ) ; } success = true ; } finally { if ( ( ! success ) || ( onGoingRecovery . isCanceled ( ) ) ) { IndexOutput remove = onGoingRecovery . removeOpenIndexOutputs ( request . name ( ) ) ; assert ( remove == null ) || ( remove == indexOutput ) ; IOUtils . closeWhileHandlingException ( indexOutput ) ; } } } if ( onGoingRecovery . isCanceled ( ) ) { onGoingRecovery . sentCanceledToSource = true ; throw new IndexShardClosedException ( request . shardId ( ) ) ; } channel . sendResponse ( INSTANCE ) ; } finally { store . decRef ( ) ; } } } }<BUG2FIX>onGoingRecovery . recoveryState . getIndex ( ) . addRecoveredByteCount ( content . length ( ) ) ;
public class QueryStringJsonQueryParser extends AbstractIndexComponent implements JsonQueryParser { public static final String NAME = "queryString" ; private final AnalysisService analysisService ; @ Inject public QueryStringJsonQueryParser ( Index index , @ IndexSettings Settings settings , AnalysisService analysisService ) { } @ Override public String name ( ) { } @ Override public Query parse ( JsonQueryParseContext parseContext ) throws IOException , QueryParsingException { JsonParser jp = parseContext . jp ( ) ; String queryString = null ; String defaultField = null ; MapperQueryParser . Operator defaultOperator = Operator . OR ; boolean allowLeadingWildcard = true ; boolean lowercaseExpandedTerms = true ; boolean enablePositionIncrements = true ; float fuzzyMinSim = FuzzyQuery . defaultMinSimilarity ; int fuzzyPrefixLength = FuzzyQuery . defaultPrefixLength ; int phraseSlop = 0 ; float boost = 1.0F ; <START_BUG> boolean escape = true ; <END_BUG> Analyzer analyzer = null ; String currentFieldName = null ; JsonToken token ; while ( ( token = jp . nextToken ( ) ) != ( JsonToken . END_OBJECT ) ) { if ( token == ( JsonToken . FIELD_NAME ) ) { currentFieldName = jp . getCurrentName ( ) ; } else if ( token == ( JsonToken . VALUE_STRING ) ) { if ( "query" . equals ( currentFieldName ) ) { queryString = jp . getText ( ) ; } else if ( "defaultField" . equals ( currentFieldName ) ) { defaultField = parseContext . indexName ( jp . getText ( ) ) ; } else if ( "defaultOperator" . equals ( currentFieldName ) ) { String op = jp . getText ( ) ; if ( "or" . equalsIgnoreCase ( op ) ) { defaultOperator = Operator . OR ; } else if ( "and" . equalsIgnoreCase ( op ) ) { defaultOperator = Operator . AND ; } else { throw new QueryParsingException ( index , ( ( "Query<seq2seq4repair_space>default<seq2seq4repair_space>operator<seq2seq4repair_space>[" + op ) + "]<seq2seq4repair_space>is<seq2seq4repair_space>not<seq2seq4repair_space>allowed" ) ) ; } } else if ( "analyzer" . equals ( currentFieldName ) ) { analyzer = analysisService . analyzer ( jp . getText ( ) ) ; } } else if ( ( token == ( JsonToken . VALUE_FALSE ) ) || ( token == ( JsonToken . VALUE_TRUE ) ) ) { if ( "allowLeadingWildcard" . equals ( currentFieldName ) ) { allowLeadingWildcard = token == ( JsonToken . VALUE_TRUE ) ; } else if ( "lowercaseExpandedTerms" . equals ( currentFieldName ) ) { lowercaseExpandedTerms = token == ( JsonToken . VALUE_TRUE ) ; } else if ( "enablePositionIncrements" . equals ( currentFieldName ) ) { enablePositionIncrements = token == ( JsonToken . VALUE_TRUE ) ; } else if ( "escape" . equals ( currentFieldName ) ) { escape = token == ( JsonToken . VALUE_TRUE ) ; } } else if ( token == ( JsonToken . VALUE_NUMBER_FLOAT ) ) { if ( "fuzzyMinSim" . equals ( currentFieldName ) ) { fuzzyMinSim = jp . getFloatValue ( ) ; } else if ( "boost" . equals ( currentFieldName ) ) { boost = jp . getFloatValue ( ) ; } } else if ( token == ( JsonToken . VALUE_NUMBER_INT ) ) { if ( "fuzzyPrefixLength" . equals ( currentFieldName ) ) { fuzzyPrefixLength = jp . getIntValue ( ) ; } else if ( "phraseSlop" . equals ( currentFieldName ) ) { phraseSlop = jp . getIntValue ( ) ; } else if ( "fuzzyMinSim" . equals ( currentFieldName ) ) { fuzzyMinSim = jp . getFloatValue ( ) ; } else if ( "boost" . equals ( currentFieldName ) ) { boost = jp . getFloatValue ( ) ; } else if ( "allowLeadingWildcard" . equals ( currentFieldName ) ) { allowLeadingWildcard = ( jp . getIntValue ( ) ) != 0 ; } else if ( "lowercaseExpandedTerms" . equals ( currentFieldName ) ) { lowercaseExpandedTerms = ( jp . getIntValue ( ) ) != 0 ; } else if ( "enablePositionIncrements" . equals ( currentFieldName ) ) { enablePositionIncrements = ( jp . getIntValue ( ) ) != 0 ; } else if ( "escape" . equals ( currentFieldName ) ) { escape = ( jp . getIntValue ( ) ) != 0 ; } } } if ( queryString == null ) { throw new QueryParsingException ( index , "QueryString<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>provided<seq2seq4repair_space>with<seq2seq4repair_space>a<seq2seq4repair_space>[query]" ) ; } if ( analyzer == null ) { analyzer = parseContext . mapperService ( ) . searchAnalyzer ( ) ; } MapperQueryParser queryParser = new MapperQueryParser ( defaultField , analyzer , parseContext . mapperService ( ) , parseContext . filterCache ( ) ) ; queryParser . setEnablePositionIncrements ( enablePositionIncrements ) ; queryParser . setLowercaseExpandedTerms ( lowercaseExpandedTerms ) ; queryParser . setAllowLeadingWildcard ( allowLeadingWildcard ) ; queryParser . setDefaultOperator ( defaultOperator ) ; queryParser . setFuzzyMinSim ( fuzzyMinSim ) ; queryParser . setFuzzyPrefixLength ( fuzzyPrefixLength ) ; queryParser . setPhraseSlop ( phraseSlop ) ; if ( escape ) { queryString = QueryParser . escape ( queryString ) ; } try { Query query = queryParser . parse ( queryString ) ; query . setBoost ( boost ) ; return query ; } catch ( ParseException e ) { throw new QueryParsingException ( index , ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>parse<seq2seq4repair_space>query<seq2seq4repair_space>[" + queryString ) + "]" ) , e ) ; } } }<BUG2FIX>boolean escape = false ;
int shardSize = - 1 ; String [ ] fieldsNames = null ; ImmutableSet < BytesRef > excluded = ImmutableSet . of ( ) ; String regex = null ; String regexFlags = null ; TermsFacet . ComparatorType comparatorType = ComparatorType . COUNT ; String scriptLang = null ; String script = null ; Map < String , Object > params = null ; boolean allTerms = false ; String executionHint = null ; String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_OBJECT ) ) { if ( "params" . equals ( currentFieldName ) ) { params = parser . map ( ) ; } } else if ( token == ( Token . START_ARRAY ) ) { if ( "exclude" . equals ( currentFieldName ) ) { ImmutableSet . Builder < BytesRef > builder = ImmutableSet . builder ( ) ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_ARRAY ) ) { builder . add ( parser . bytes ( ) ) ; } excluded = builder . build ( ) ; } else if ( "fields" . equals ( currentFieldName ) ) { List < String > fields = Lists . newArrayListWithCapacity ( 4 ) ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_ARRAY ) ) { fields . add ( parser . text ( ) ) ; } fieldsNames = fields . toArray ( new String [ fields . size ( ) ] ) ; } } else if ( token . isValue ( ) ) { if ( "field" . equals ( currentFieldName ) ) { field = parser . text ( ) ; } else if ( ( "script_field" . equals ( currentFieldName ) ) || ( "scriptField" . equals ( currentFieldName ) ) ) { script = parser . text ( ) ; } else if ( "size" . equals ( currentFieldName ) ) { size = parser . intValue ( ) ; } else if ( "shard_size" . equals ( currentFieldName ) ) { shardSize = parser . intValue ( ) ; } else if ( ( "all_terms" . equals ( currentFieldName ) ) || ( "allTerms" . equals ( currentFieldName ) ) ) { allTerms = parser . booleanValue ( ) ; } else if ( "regex" . equals ( currentFieldName ) ) { regex = parser . text ( ) ; } else if ( ( "regex_flags" . equals ( currentFieldName ) ) || ( "regexFlags" . equals ( currentFieldName ) ) ) { regexFlags = parser . text ( ) ; } else if ( ( "order" . equals ( currentFieldName ) ) || ( "comparator" . equals ( currentFieldName ) ) ) { comparatorType = ComparatorType . fromString ( parser . text ( ) ) ; } else if ( "script" . equals ( currentFieldName ) ) { script = parser . text ( ) ; } else if ( "lang" . equals ( currentFieldName ) ) { scriptLang = parser . text ( ) ; } else if ( ( "execution_hint" . equals ( currentFieldName ) ) || ( "executionHint" . equals ( currentFieldName ) ) ) { executionHint = parser . textOrNull ( ) ; } } } if ( "_index" . equals ( field ) ) { <START_BUG> return new org . elasticsearch . search . facet . terms . index . IndexNameFacetExecutor ( context . shardTarget ( ) . index ( ) , comparatorType , size , shardSize ) ; <END_BUG> } if ( ( fieldsNames != null ) && ( ( fieldsNames . length ) == 1 ) ) { field = fieldsNames [ 0 ] ; fieldsNames = null ; } Pattern pattern = null ; if ( regex != null ) { pattern = Regex . compile ( regex , regexFlags ) ; } SearchScript searchScript = null ; if ( script != null ) { searchScript = context . scriptService ( ) . search ( context . lookup ( ) , scriptLang , script , params ) ; } if ( shardSize < size ) { shardSize = size ; } if ( fieldsNames != null ) { ArrayList < FieldMapper > mappers = new ArrayList < FieldMapper > ( fieldsNames . length ) ; for ( int i = 0 ; i < ( fieldsNames . length ) ; i ++ ) { FieldMapper mapper = context . smartNameFieldMapper ( fieldsNames [ i ] ) ; if ( mapper != null ) { mappers . add ( mapper ) ; } } if ( mappers . isEmpty ( ) ) { return new org . elasticsearch . search . facet . terms . unmapped . UnmappedFieldExecutor ( size , comparatorType ) ; } return new org . elasticsearch . search . facet . terms . strings . FieldsTermsStringFacetExecutor ( mappers . toArray ( new FieldMapper [ mappers . size ( ) ] ) , size , shardSize , comparatorType , allTerms , context , excluded , pattern , searchScript ) ; } if ( ( ( field == null ) && ( fieldsNames == null ) ) && ( script != null ) ) { return new org . elasticsearch . search . facet . terms . strings . ScriptTermsStringFieldFacetExecutor ( size , shardSize , comparatorType , context , excluded , pattern , scriptLang , script , params , context . cacheRecycler ( ) ) ; } FieldMapper fieldMapper = context . smartNameFieldMapper ( field ) ; if ( fieldMapper == null ) { return new org . elasticsearch . search . facet . terms . unmapped . UnmappedFieldExecutor ( size , comparatorType ) ;<BUG2FIX>return new org . elasticsearch . search . facet . terms . index . IndexNameFacetExecutor ( context . shardTarget ( ) . index ( ) , comparatorType , size ) ;
public class QueryParseElement implements SearchParseElement { @ Override public void parse ( JsonParser jp , SearchContext context ) throws Exception { JsonIndexQueryParser indexQueryParser = ( ( JsonIndexQueryParser ) ( context . queryParser ( ) ) ) ; <START_BUG> Query query = indexQueryParser . parse ( jp , context . source ( ) ) ; <END_BUG> query . setBoost ( ( ( query . getBoost ( ) ) * ( context . queryBoost ( ) ) ) ) ; context . query ( query ) ; } }<BUG2FIX>Query query = indexQueryParser . parse ( jp ) ;
public class TransportGetFieldMappingsAction extends TransportAction < GetFieldMappingsRequest , GetFieldMappingsResponse > { private final ClusterService clusterService ; private final TransportGetFieldMappingsIndexAction shardAction ; private final String transportAction ; @ Inject public TransportGetFieldMappingsAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool , TransportGetFieldMappingsIndexAction shardAction ) { } @ Override protected void doExecute ( GetFieldMappingsRequest request , final ActionListener < GetFieldMappingsResponse > listener ) { ClusterState clusterState = clusterService . state ( ) ; <START_BUG> String [ ] concreteIndices = clusterState . metaData ( ) . concreteIndices ( request . indices ( ) , request . indicesOptions ( ) ) ; <END_BUG> final AtomicInteger indexCounter = new AtomicInteger ( ) ; final AtomicInteger completionCounter = new AtomicInteger ( concreteIndices . length ) ; final AtomicReferenceArray < Object > indexResponses = new AtomicReferenceArray < > ( concreteIndices . length ) ; if ( ( concreteIndices == null ) || ( ( concreteIndices . length ) == 0 ) ) { listener . onResponse ( new GetFieldMappingsResponse ( ) ) ; } else { boolean probablySingleFieldRequest = ( ( ( concreteIndices . length ) == 1 ) && ( ( request . types ( ) . length ) == 1 ) ) && ( ( request . fields ( ) . length ) == 1 ) ; for ( final String index : concreteIndices ) { GetFieldMappingsIndexRequest shardRequest = new GetFieldMappingsIndexRequest ( request , index , probablySingleFieldRequest ) ; shardRequest . listenerThreaded ( false ) ; shardAction . execute ( shardRequest , new ActionListener < GetFieldMappingsResponse > ( ) { @ Override public void onResponse ( GetFieldMappingsResponse result ) { indexResponses . set ( indexCounter . getAndIncrement ( ) , result ) ; if ( ( completionCounter . decrementAndGet ( ) ) == 0 ) { listener . onResponse ( merge ( indexResponses ) ) ; } } @ Override public void onFailure ( Throwable e ) { int index = indexCounter . getAndIncrement ( ) ; indexResponses . set ( index , e ) ; if ( ( completionCounter . decrementAndGet ( ) ) == 0 ) { listener . onResponse ( merge ( indexResponses ) ) ; } } } ) ; } } } private GetFieldMappingsResponse merge ( AtomicReferenceArray < Object > indexResponses ) { } private class TransportHandler extends BaseTransportRequestHandler < GetFieldMappingsRequest > { @ Override public GetFieldMappingsRequest newInstance ( ) { } @ Override public String executor ( ) { } @ Override public void messageReceived ( final GetFieldMappingsRequest request , final TransportChannel channel ) throws Exception { } } }<BUG2FIX>String [ ] concreteIndices = clusterState . metaData ( ) . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ;
public class IOSMusic implements Music { private final OALAudioTrack track ; OnCompletionListener onCompletionListener ; public IOSMusic ( OALAudioTrack track ) { } @ Override public void play ( ) { } @ Override public void pause ( ) { } @ Override public void stop ( ) { } @ Override public boolean isPlaying ( ) { <START_BUG> return ( track . isPlaying ( ) ) && ( ! ( track . isPaused ( ) ) ) ; <END_BUG> } @ Override public void setLooping ( boolean isLooping ) { } @ Override public boolean isLooping ( ) { } @ Override public void setVolume ( float volume ) { } public void setPosition ( float position ) { } @ Override public float getPosition ( ) { } @ Override public void dispose ( ) { } @ Override public float getVolume ( ) { } @ Override public void setPan ( float pan , float volume ) { } @ Override public void setOnCompletionListener ( OnCompletionListener listener ) { } }<BUG2FIX>return track . isPlaying ( ) ;
public class QueryParseContext { private static ThreadLocal < String [ ] > typesContext = new ThreadLocal < String [ ] > ( ) ; public static void setTypes ( String [ ] types ) { } public static String [ ] getTypes ( ) { } public static String [ ] setTypesWithPrevious ( String [ ] types ) { } public static void removeTypes ( ) { } private final Index index ; IndexQueryParserService indexQueryParser ; private final Map < String , Filter > namedFilters = Maps . newHashMap ( ) ; private final MapperQueryParser queryParser = new MapperQueryParser ( this ) ; private XContentParser parser ; public QueryParseContext ( Index index , IndexQueryParserService indexQueryParser ) { } public void reset ( XContentParser jp ) { } public Index index ( ) { } public XContentParser parser ( ) { } public AnalysisService analysisService ( ) { } public ScriptService scriptService ( ) { } public MapperService mapperService ( ) { } public IndexEngine indexEngine ( ) { } @ Nullable public SimilarityService similarityService ( ) { } public Similarity searchSimilarity ( ) { } public IndexCache indexCache ( ) { } public String defaultField ( ) { } public boolean queryStringLenient ( ) { } public MapperQueryParser queryParser ( QueryParserSettings settings ) { } public Filter cacheFilter ( Filter filter , @ Nullable CacheKeyFilter . Key cacheKey ) { } public void addNamedFilter ( String name , Filter filter ) { } public ImmutableMap < String , Filter > copyNamedFilters ( ) { } @ Nullable public Query parseInnerQuery ( ) throws IOException , QueryParsingException { } @ Nullable public Filter parseInnerFilter ( ) throws IOException , QueryParsingException { } public Filter parseInnerFilter ( String filterName ) throws IOException , QueryParsingException { } public FieldMapper fieldMapper ( String name ) { } public String indexName ( String name ) { } public SmartNameFieldMappers smartFieldMappers ( String name ) { } public SmartNameObjectMapper smartObjectMapper ( String name ) { } public Collection < String > queryTypes ( ) { } private SearchLookup lookup = null ; public SearchLookup lookup ( ) { SearchContext current = SearchContext . current ( ) ; if ( current != null ) { return current . lookup ( ) ; } if ( ( lookup ) == null ) { <START_BUG> lookup = new SearchLookup ( mapperService ( ) , indexCache ( ) . fieldData ( ) ) ; <END_BUG> } return lookup ; } public long nowInMillis ( ) { } }<BUG2FIX>lookup = new SearchLookup ( mapperService ( ) , indexCache ( ) . fieldData ( ) , null ) ;
public class ClickListener extends InputListener { public static float visualPressedDuration = 0.1F ; private float tapSquareSize = 14 ; private float touchDownX = - 1 ; private float touchDownY = - 1 ; private int pressedPointer = - 1 ; private int pressedButton = - 1 ; private int button ; private boolean pressed ; private boolean over ; private boolean cancelled ; private float visualPressedTime ; private long tapCountInterval = ( ( long ) ( 0.4F * 1000000000L ) ) ; private int tapCount ; private long lastTapTime ; public ClickListener ( ) { } public ClickListener ( int button ) { } public boolean touchDown ( InputEvent event , float x , float y , int pointer , int button ) { } public void touchDragged ( InputEvent event , float x , float y , int pointer ) { } public void touchUp ( InputEvent event , float x , float y , int pointer , int button ) { } public void enter ( InputEvent event , float x , float y , int pointer , Actor fromActor ) { } public void exit ( InputEvent event , float x , float y , int pointer , Actor toActor ) { } public void cancel ( ) { } public void clicked ( InputEvent event , float x , float y ) { } public boolean isOver ( Actor actor , float x , float y ) { } public boolean inTapSquare ( float x , float y ) { } public boolean inTapSquare ( ) { } public void invalidateTapSquare ( ) { } public boolean isPressed ( ) { } public boolean isVisualPressed ( ) { if ( pressed ) return true ; if ( ( visualPressedTime ) <= 0 ) return false ; <START_BUG> if ( ( ( visualPressedTime ) > ( TimeUtils . nanoTime ( ) ) ) && ( graphics . isContinuousRendering ( ) ) ) <END_BUG> return true ; visualPressedTime = 0 ; return false ; } public boolean isOver ( ) { } public void setTapSquareSize ( float halfTapSquareSize ) { } public float getTapSquareSize ( ) { } public void setTapCountInterval ( float tapCountInterval ) { } public int getTapCount ( ) { } public float getTouchDownX ( ) { } public float getTouchDownY ( ) { } public int getPressedButton ( ) { } public int getPressedPointer ( ) { } public int getButton ( ) { } public void setButton ( int button ) { } }<BUG2FIX>if ( ( visualPressedTime ) > ( TimeUtils . nanoTime ( ) ) )
public class SoundTest extends GdxTest { Sound sound ; float volume = 0.5F ; long soundId = 0 ; Stage ui ; Skin skin ; @ Override public void create ( ) { sound = audio . newSound ( files . getFileHandle ( "data/shotgun.ogg" , Internal ) ) ; skin = new Skin ( files . internal ( "data/uiskin.json" ) ) ; <START_BUG> ui = new Stage ( graphics . getWidth ( ) , graphics . getHeight ( ) , true ) ; <END_BUG> TextButton play = new TextButton ( "Play" , skin ) ; TextButton stop = new TextButton ( "Stop" , skin ) ; final Slider pitch = new Slider ( 0.1F , 4 , 0.1F , false , skin ) ; pitch . setValue ( 1 ) ; final Label pitchValue = new Label ( "1.0" , skin ) ; final Slider volume = new Slider ( 0.1F , 1 , 0.1F , false , skin ) ; volume . setValue ( 1 ) ; final Label volumeValue = new Label ( "1.0" , skin ) ; Table table = new Table ( ) ; final Slider pan = new Slider ( ( - 1.0F ) , 1.0F , 0.1F , false , skin ) ; pan . setValue ( 0 ) ; final Label panValue = new Label ( "0.0" , skin ) ; table . setFillParent ( true ) ; table . align ( ( ( Align . center ) | ( Align . top ) ) ) ; table . columnDefaults ( 0 ) . expandX ( ) . right ( ) . uniformX ( ) ; table . columnDefaults ( 2 ) . expandX ( ) . left ( ) . uniformX ( ) ; table . add ( play ) ; table . add ( stop ) . left ( ) ; table . row ( ) ; table . add ( new Label ( "Pitch" , skin ) ) ; table . add ( pitch ) ; table . add ( pitchValue ) ; table . row ( ) ; table . add ( new Label ( "Volume" , skin ) ) ; table . add ( volume ) ; table . add ( volumeValue ) ; table . row ( ) ; table . add ( new Label ( "Pan" , skin ) ) ; table . add ( pan ) ; table . add ( panValue ) ; ui . addActor ( table ) ; play . addListener ( new ClickListener ( ) { public void clicked ( InputEvent event , float x , float y ) { soundId = sound . play ( volume . getValue ( ) ) ; sound . setPitch ( soundId , pitch . getValue ( ) ) ; sound . setPan ( soundId , pan . getValue ( ) , volume . getValue ( ) ) ; } } ) ; stop . addListener ( new ClickListener ( ) { public void clicked ( InputEvent event , float x , float y ) { sound . stop ( soundId ) ; } } ) ; pitch . addListener ( new ChangeListener ( ) { public void changed ( ChangeEvent event , Actor actor ) { sound . setPitch ( soundId , pitch . getValue ( ) ) ; pitchValue . setText ( ( "" + ( pitch . getValue ( ) ) ) ) ; } } ) ; volume . addListener ( new ChangeListener ( ) { public void changed ( ChangeEvent event , Actor actor ) { sound . setVolume ( soundId , volume . getValue ( ) ) ; volumeValue . setText ( ( "" + ( volume . getValue ( ) ) ) ) ; } } ) ; pan . addListener ( new ChangeListener ( ) { public void changed ( ChangeEvent event , Actor actor ) { sound . setPan ( soundId , pan . getValue ( ) , volume . getValue ( ) ) ; panValue . setText ( ( "" + ( pan . getValue ( ) ) ) ) ; } } ) ; input . setInputProcessor ( ui ) ; } @ Override public void render ( ) { } @ Override public void dispose ( ) { } }<BUG2FIX>ui = new Stage ( ) ;
public class ShardsRoutingStrategy extends AbstractComponent { private final PreferUnallocatedShardUnassignedStrategy preferUnallocatedShardUnassignedStrategy ; public ShardsRoutingStrategy ( ) { } @ Inject public ShardsRoutingStrategy ( Settings settings , @ Nullable PreferUnallocatedShardUnassignedStrategy preferUnallocatedShardUnassignedStrategy ) { } public RoutingTable applyStartedShards ( ClusterState clusterState , Iterable < ? extends ShardRouting > startedShardEntries ) { } public RoutingTable applyFailedShards ( ClusterState clusterState , Iterable < ? extends ShardRouting > failedShardEntries ) { } public RoutingTable reroute ( ClusterState clusterState ) { } private boolean reroute ( RoutingNodes routingNodes , DiscoveryNodes nodes ) { Iterable < DiscoveryNode > dataNodes = nodes . dataNodes ( ) . values ( ) ; boolean changed = false ; changed |= deassociateDeadNodes ( routingNodes , dataNodes ) ; applyNewNodes ( routingNodes , dataNodes ) ; changed |= electPrimaries ( routingNodes ) ; if ( routingNodes . hasUnassigned ( ) ) { if ( ( preferUnallocatedShardUnassignedStrategy ) != null ) { <START_BUG> changed |= preferUnallocatedShardUnassignedStrategy . allocateUnassigned ( routingNodes ) ; <END_BUG> } changed |= allocateUnassigned ( routingNodes ) ; changed |= electPrimaries ( routingNodes ) ; } changed |= rebalance ( routingNodes ) ; return changed ; } private boolean rebalance ( RoutingNodes routingNodes ) { } private boolean electPrimaries ( RoutingNodes routingNodes ) { } private boolean allocateUnassigned ( RoutingNodes routingNodes ) { } private void applyNewNodes ( RoutingNodes routingNodes , Iterable < DiscoveryNode > liveNodes ) { } private boolean deassociateDeadNodes ( RoutingNodes routingNodes , Iterable < DiscoveryNode > liveNodes ) { } private boolean applyStartedShards ( RoutingNodes routingNodes , Iterable < ? extends ShardRouting > startedShardEntries ) { } private boolean applyFailedShards ( RoutingNodes routingNodes , Iterable < ? extends ShardRouting > failedShardEntries ) { } }<BUG2FIX>changed |= preferUnallocatedShardUnassignedStrategy . allocateUnassigned ( routingNodes , nodes ) ;
public class TypeFilterParser implements FilterParser { public static final String NAME = "type" ; @ Inject public TypeFilterParser ( ) { } @ Override public String [ ] names ( ) { } @ Override public Filter parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; XContentParser . Token token = parser . nextToken ( ) ; if ( token != ( Token . FIELD_NAME ) ) { throw new QueryParsingException ( parseContext . index ( ) , "[type]<seq2seq4repair_space>filter<seq2seq4repair_space>should<seq2seq4repair_space>have<seq2seq4repair_space>a<seq2seq4repair_space>value<seq2seq4repair_space>field,<seq2seq4repair_space>and<seq2seq4repair_space>the<seq2seq4repair_space>type<seq2seq4repair_space>name" ) ; } String fieldName = parser . currentName ( ) ; if ( ! ( fieldName . equals ( "value" ) ) ) { throw new QueryParsingException ( parseContext . index ( ) , "[type]<seq2seq4repair_space>filter<seq2seq4repair_space>should<seq2seq4repair_space>have<seq2seq4repair_space>a<seq2seq4repair_space>value<seq2seq4repair_space>field,<seq2seq4repair_space>and<seq2seq4repair_space>the<seq2seq4repair_space>type<seq2seq4repair_space>name" ) ; } token = parser . nextToken ( ) ; if ( token != ( Token . VALUE_STRING ) ) { throw new QueryParsingException ( parseContext . index ( ) , "[type]<seq2seq4repair_space>filter<seq2seq4repair_space>should<seq2seq4repair_space>have<seq2seq4repair_space>a<seq2seq4repair_space>value<seq2seq4repair_space>field,<seq2seq4repair_space>and<seq2seq4repair_space>the<seq2seq4repair_space>type<seq2seq4repair_space>name" ) ; } <START_BUG> BytesRef type = parser . bytes ( null ) ; <END_BUG> parser . nextToken ( ) ; Filter filter ; DocumentMapper documentMapper = parseContext . mapperService ( ) . documentMapper ( type . utf8ToString ( ) ) ; if ( documentMapper == null ) { filter = new TermFilter ( new org . apache . lucene . index . Term ( TERM_FACTORY . field ( ) , type ) ) ; } else { filter = documentMapper . typeFilter ( ) ; } return parseContext . cacheFilter ( filter , null ) ; } }<BUG2FIX>BytesRef type = parser . bytes ( ) ;
public class WallElement extends FieldElement { Body wallBody ; Collection bodySet ; float x1 ; float y1 ; float x2 ; float y2 ; float kick ; boolean killBall ; boolean retractWhenHit ; @ Override public void finishCreate ( Map params , World world ) { } public boolean isRetracted ( ) { } public void setRetracted ( boolean retracted ) { } @ Override public Collection getBodies ( ) { } @ Override public boolean shouldCallTick ( ) { } Vector2 impulseForBall ( Body ball ) { } @ Override public void handleCollision ( Body ball , Body bodyHit , Field field ) { if ( retractWhenHit ) { this . setRetracted ( true ) ; } if ( killBall ) { field . removeBall ( ball ) ; } else { Vector2 impulse = this . impulseForBall ( ball ) ; if ( impulse != null ) { <START_BUG> ball . applyLinearImpulse ( impulse , ball . getWorldCenter ( ) , true ) ; <END_BUG> flashForFrames ( 3 ) ; } } } @ Override public void draw ( IFieldRenderer renderer ) { } }<BUG2FIX>ball . applyLinearImpulse ( impulse , ball . getWorldCenter ( ) ) ;
buildNode ( "node3" , settingsBuilder ( ) . put ( "gateway.type" , "local" ) ) ; buildNode ( "node4" , settingsBuilder ( ) . put ( "gateway.type" , "local" ) ) ; cleanAndCloseNodes ( ) ; Settings settings = settingsBuilder ( ) . put ( "discovery.zen.minimum_master_nodes" , 3 ) . put ( "discovery.zen.ping_timeout" , "200ms" ) . put ( "discovery.initial_state_timeout" , "500ms" ) . put ( "gateway.type" , "local" ) . build ( ) ; logger . info ( "--><seq2seq4repair_space>start<seq2seq4repair_space>first<seq2seq4repair_space>2<seq2seq4repair_space>nodes" ) ; startNode ( "node1" , settings ) ; startNode ( "node2" , settings ) ; Thread . sleep ( 500 ) ; ClusterState state = client ( "node1" ) . admin ( ) . cluster ( ) . prepareState ( ) . setLocal ( true ) . execute ( ) . actionGet ( ) . state ( ) ; assertThat ( state . blocks ( ) . hasGlobalBlock ( NO_MASTER_BLOCK ) , equalTo ( true ) ) ; state = client ( "node2" ) . admin ( ) . cluster ( ) . prepareState ( ) . setLocal ( true ) . execute ( ) . actionGet ( ) . state ( ) ; assertThat ( state . blocks ( ) . hasGlobalBlock ( NO_MASTER_BLOCK ) , equalTo ( true ) ) ; logger . info ( "--><seq2seq4repair_space>start<seq2seq4repair_space>two<seq2seq4repair_space>more<seq2seq4repair_space>nodes" ) ; startNode ( "node3" , settings ) ; startNode ( "node4" , settings ) ; ClusterHealthResponse clusterHealthResponse = client ( "node1" ) . admin ( ) . cluster ( ) . prepareHealth ( ) . setWaitForNodes ( "4" ) . execute ( ) . actionGet ( ) ; assertThat ( clusterHealthResponse . timedOut ( ) , equalTo ( false ) ) ; state = client ( "node1" ) . admin ( ) . cluster ( ) . prepareState ( ) . execute ( ) . actionGet ( ) . state ( ) ; assertThat ( state . nodes ( ) . size ( ) , equalTo ( 4 ) ) ; String masterNode = state . nodes ( ) . masterNode ( ) . name ( ) ; LinkedList < String > nonMasterNodes = new LinkedList < String > ( ) ; for ( DiscoveryNode node : state . nodes ( ) ) { if ( ! ( node . name ( ) . equals ( masterNode ) ) ) { nonMasterNodes . add ( node . name ( ) ) ; } } logger . info ( "--><seq2seq4repair_space>indexing<seq2seq4repair_space>some<seq2seq4repair_space>data" ) ; for ( int i = 0 ; i < 100 ; i ++ ) { client ( "node1" ) . prepareIndex ( "test" , "type1" , Integer . toString ( i ) ) . setSource ( "field" , "value" ) . execute ( ) . actionGet ( ) ; } client ( "node1" ) . admin ( ) . indices ( ) . prepareFlush ( ) . execute ( ) . actionGet ( ) ; client ( "node1" ) . admin ( ) . indices ( ) . prepareRefresh ( ) . execute ( ) . actionGet ( ) ; logger . info ( "--><seq2seq4repair_space>verify<seq2seq4repair_space>we<seq2seq4repair_space>the<seq2seq4repair_space>data<seq2seq4repair_space>back" ) ; for ( int i = 0 ; i < 10 ; i ++ ) { assertThat ( client ( "node1" ) . prepareCount ( ) . setQuery ( QueryBuilders . matchAllQuery ( ) ) . execute ( ) . actionGet ( ) . count ( ) , equalTo ( 100L ) ) ; } Set < String > nodesToShutdown = Sets . newHashSet ( ) ; nodesToShutdown . add ( nonMasterNodes . removeLast ( ) ) ; nodesToShutdown . add ( nonMasterNodes . removeLast ( ) ) ; logger . info ( "--><seq2seq4repair_space>shutting<seq2seq4repair_space>down<seq2seq4repair_space>two<seq2seq4repair_space>master<seq2seq4repair_space>nodes<seq2seq4repair_space>{}" , nodesToShutdown ) ; for ( String nodeToShutdown : nodesToShutdown ) { closeNode ( nodeToShutdown ) ; } <START_BUG> Thread . sleep ( 500 ) ; <END_BUG> String lastNonMasterNodeUp = nonMasterNodes . removeLast ( ) ; logger . info ( "--><seq2seq4repair_space>verify<seq2seq4repair_space>that<seq2seq4repair_space>there<seq2seq4repair_space>is<seq2seq4repair_space>no<seq2seq4repair_space>master<seq2seq4repair_space>anymore<seq2seq4repair_space>on<seq2seq4repair_space>remaining<seq2seq4repair_space>nodes" ) ; state = client ( masterNode ) . admin ( ) . cluster ( ) . prepareState ( ) . setLocal ( true ) . execute ( ) . actionGet ( ) . state ( ) ; assertThat ( state . blocks ( ) . hasGlobalBlock ( NO_MASTER_BLOCK ) , equalTo ( true ) ) ; state = client ( lastNonMasterNodeUp ) . admin ( ) . cluster ( ) . prepareState ( ) . setLocal ( true ) . execute ( ) . actionGet ( ) . state ( ) ; assertThat ( state . blocks ( ) . hasGlobalBlock ( NO_MASTER_BLOCK ) , equalTo ( true ) ) ; logger . info ( "--><seq2seq4repair_space>start<seq2seq4repair_space>back<seq2seq4repair_space>the<seq2seq4repair_space>nodes<seq2seq4repair_space>{}" , nodesToShutdown ) ; for ( String nodeToShutdown : nodesToShutdown ) { startNode ( nodeToShutdown , settings ) ; } clusterHealthResponse = client ( "node1" ) . admin ( ) . cluster ( ) . prepareHealth ( ) . setWaitForNodes ( "4" ) . execute ( ) . actionGet ( ) ; assertThat ( clusterHealthResponse . timedOut ( ) , equalTo ( false ) ) ; logger . info ( "Running<seq2seq4repair_space>Cluster<seq2seq4repair_space>Health" ) ; ClusterHealthResponse clusterHealth = client ( "node1" ) . admin ( ) . cluster ( ) . health ( clusterHealthRequest ( ) . waitForGreenStatus ( ) ) . actionGet ( ) ; logger . info ( ( "Done<seq2seq4repair_space>Cluster<seq2seq4repair_space>Health,<seq2seq4repair_space>status<seq2seq4repair_space>" + ( clusterHealth . status ( ) ) ) ) ; assertThat ( clusterHealth . timedOut ( ) , equalTo ( false ) ) ; assertThat ( clusterHealth . status ( ) , equalTo ( GREEN ) ) ; state = client ( "node1" ) . admin ( ) . cluster ( ) . prepareState ( ) . execute ( ) . actionGet ( ) . state ( ) ; assertThat ( state . nodes ( ) . size ( ) , equalTo ( 4 ) ) ; logger . info ( "--><seq2seq4repair_space>verify<seq2seq4repair_space>we<seq2seq4repair_space>the<seq2seq4repair_space>data<seq2seq4repair_space>back" ) ; for ( int i = 0 ; i < 10 ;<BUG2FIX>Thread . sleep ( 1000 ) ;
public class FsIndexShardGateway extends BlobStoreIndexShardGateway { private final boolean snapshotLock ; @ Inject public FsIndexShardGateway ( ShardId shardId , @ IndexSettings Settings indexSettings , ThreadPool threadPool , IndexGateway fsIndexGateway , IndexShard indexShard , Store store ) { } @ Override public String type ( ) { } @ Override public SnapshotLock obtainSnapshotLock ( ) throws Exception { } public class FsSnapshotLock implements SnapshotLock { private final Lock lock ; public FsSnapshotLock ( Lock lock ) { } @ Override public void release ( ) { try { <START_BUG> lock . release ( ) ; <END_BUG> } catch ( IOException e ) { logger . warn ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>release<seq2seq4repair_space>snapshot<seq2seq4repair_space>lock<seq2seq4repair_space>[{}]" , e , lock ) ; } } } }<BUG2FIX>lock . close ( ) ;
public class RestSearchAction extends BaseRestHandler { private static final Pattern fieldsPattern ; private static final Pattern indicesBoostPattern ; @ Inject public RestSearchAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { } private SearchRequest parseSearchRequest ( RestRequest request ) { } private byte [ ] parseSearchSource ( RestRequest request ) { SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder ( ) ; String queryString = request . param ( "q" ) ; if ( queryString != null ) { QueryStringJsonQueryBuilder queryBuilder = JsonQueryBuilders . queryString ( queryString ) ; queryBuilder . defaultField ( request . param ( "df" ) ) ; queryBuilder . analyzer ( request . param ( "analyzer" ) ) ; String defaultOperator = request . param ( "defaultOperator" ) ; if ( defaultOperator != null ) { if ( "OR" . equals ( defaultOperator ) ) { queryBuilder . defaultOperator ( OR ) ; } else if ( "AND" . equals ( defaultOperator ) ) { queryBuilder . defaultOperator ( AND ) ; } else { throw new ElasticSearchIllegalArgumentException ( ( ( "Unsupported<seq2seq4repair_space>defaultOperator<seq2seq4repair_space>[" + defaultOperator ) + "],<seq2seq4repair_space>can<seq2seq4repair_space>either<seq2seq4repair_space>be<seq2seq4repair_space>[OR]<seq2seq4repair_space>or<seq2seq4repair_space>[AND]" ) ) ; } } searchSourceBuilder . query ( queryBuilder ) ; } searchSourceBuilder . queryParserName ( request . param ( "queryParserName" ) ) ; <START_BUG> searchSourceBuilder . explain ( request . paramAsBoolean ( "explain" , false ) ) ; <END_BUG> List < String > fields = request . params ( "field" ) ; if ( ( fields != null ) && ( ! ( fields . isEmpty ( ) ) ) ) { searchSourceBuilder . fields ( fields ) ; } String sField = request . param ( "fields" ) ; if ( sField != null ) { String [ ] sFields = RestSearchAction . fieldsPattern . split ( sField ) ; if ( sFields != null ) { for ( String field : sFields ) { searchSourceBuilder . field ( field ) ; } } } List < String > sorts = request . params ( "sort" ) ; if ( ( sorts != null ) && ( ! ( sorts . isEmpty ( ) ) ) ) { for ( String sort : sorts ) { int delimiter = sort . lastIndexOf ( ":" ) ; if ( delimiter != ( - 1 ) ) { String sortField = sort . substring ( 0 , delimiter ) ; String reverse = sort . substring ( ( delimiter + 1 ) ) ; searchSourceBuilder . sort ( sortField , reverse . equals ( "reverse" ) ) ; } else { searchSourceBuilder . sort ( sort ) ; } } } String sIndicesBoost = request . param ( "indicesBoost" ) ; if ( sIndicesBoost != null ) { String [ ] indicesBoost = RestSearchAction . indicesBoostPattern . split ( sIndicesBoost ) ; for ( String indexBoost : indicesBoost ) { int divisor = indexBoost . indexOf ( ',' ) ; if ( divisor == ( - 1 ) ) { throw new ElasticSearchIllegalArgumentException ( ( ( "Illegal<seq2seq4repair_space>index<seq2seq4repair_space>boost<seq2seq4repair_space>[" + indexBoost ) + "],<seq2seq4repair_space>no<seq2seq4repair_space>','" ) ) ; } String indexName = indexBoost . substring ( 0 , divisor ) ; String sBoost = indexBoost . substring ( ( divisor + 1 ) ) ; try { searchSourceBuilder . indexBoost ( indexName , Float . parseFloat ( sBoost ) ) ; } catch ( NumberFormatException e ) { throw new ElasticSearchIllegalArgumentException ( ( ( "Illegal<seq2seq4repair_space>index<seq2seq4repair_space>boost<seq2seq4repair_space>[" + indexBoost ) + "],<seq2seq4repair_space>boost<seq2seq4repair_space>not<seq2seq4repair_space>a<seq2seq4repair_space>float<seq2seq4repair_space>number" ) ) ; } } } return searchSourceBuilder . build ( ) ; } }<BUG2FIX>searchSourceBuilder . explain ( request . paramAsBoolean ( "explain" , null ) ) ;
public class PercolatorStressBenchmark { public static void main ( String [ ] args ) throws Exception { Settings settings = settingsBuilder ( ) . put ( "cluster.routing.schedule" , 200 , TimeUnit . MILLISECONDS ) . put ( "gateway.type" , "none" ) . put ( SETTING_NUMBER_OF_SHARDS , 4 ) . put ( SETTING_NUMBER_OF_REPLICAS , 0 ) . build ( ) ; <START_BUG> Node [ ] nodes = new Node [ 2 ] ; <END_BUG> for ( int i = 0 ; i < ( nodes . length ) ; i ++ ) { nodes [ i ] = nodeBuilder ( ) . settings ( settingsBuilder ( ) . put ( settings ) . put ( "name" , ( "node" + i ) ) ) . node ( ) ; } Node clientNode = nodeBuilder ( ) . settings ( settingsBuilder ( ) . put ( settings ) . put ( "name" , "client" ) ) . client ( true ) . node ( ) ; Client client = clientNode . client ( ) ; client . admin ( ) . indices ( ) . create ( createIndexRequest ( "test" ) ) . actionGet ( ) ; ClusterHealthResponse healthResponse = client . admin ( ) . cluster ( ) . prepareHealth ( "test" ) . setWaitForGreenStatus ( ) . execute ( ) . actionGet ( ) ; if ( healthResponse . isTimedOut ( ) ) { System . err . println ( "Quiting,<seq2seq4repair_space>because<seq2seq4repair_space>cluster<seq2seq4repair_space>health<seq2seq4repair_space>requested<seq2seq4repair_space>timed<seq2seq4repair_space>out..." ) ; return ; } else if ( ( healthResponse . getStatus ( ) ) != ( ClusterHealthStatus . GREEN ) ) { System . err . println ( "Quiting,<seq2seq4repair_space>because<seq2seq4repair_space>cluster<seq2seq4repair_space>state<seq2seq4repair_space>isn't<seq2seq4repair_space>green..." ) ; return ; } int COUNT = 200000 ; int QUERIES = 100 ; int TERM_QUERIES = QUERIES / 2 ; int RANGE_QUERIES = QUERIES - TERM_QUERIES ; client . prepareIndex ( "test" , "type1" , "1" ) . setSource ( jsonBuilder ( ) . startObject ( ) . field ( "numeric1" , 1 ) . endObject ( ) ) . execute ( ) . actionGet ( ) ; int i = 0 ; for ( ; i < TERM_QUERIES ; i ++ ) { client . prepareIndex ( "test" , "_percolator" , Integer . toString ( i ) ) . setSource ( jsonBuilder ( ) . startObject ( ) . field ( "query" , termQuery ( "name" , "value" ) ) . endObject ( ) ) . execute ( ) . actionGet ( ) ; } int [ ] numbers = new int [ RANGE_QUERIES ] ; for ( ; i < QUERIES ; i ++ ) { client . prepareIndex ( "test" , "_percolator" , Integer . toString ( i ) ) . setSource ( jsonBuilder ( ) . startObject ( ) . field ( "query" , rangeQuery ( "numeric1" ) . from ( i ) . to ( i ) ) . endObject ( ) ) . execute ( ) . actionGet ( ) ; numbers [ ( i - TERM_QUERIES ) ] = i ; } StopWatch stopWatch = new StopWatch ( ) . start ( ) ; System . out . println ( ( ( "Percolating<seq2seq4repair_space>[" + COUNT ) + "]<seq2seq4repair_space>..." ) ) ; for ( i = 1 ; i <= COUNT ; i ++ ) { XContentBuilder source ; int expectedMatches ; if ( ( i % 2 ) == 0 ) { source = PercolatorStressBenchmark . source ( Integer . toString ( i ) , "value" ) ; expectedMatches = TERM_QUERIES ; } else { int number = numbers [ ( i % RANGE_QUERIES ) ] ; source = PercolatorStressBenchmark . source ( Integer . toString ( i ) , number ) ; expectedMatches = 1 ; } PercolateResponse percolate = client . preparePercolate ( ) . setIndices ( "test" ) . setDocumentType ( "type1" ) . setSource ( source ) . execute ( ) . actionGet ( ) ; if ( ( percolate . getMatches ( ) . length ) != expectedMatches ) { System . err . println ( "No<seq2seq4repair_space>matching<seq2seq4repair_space>number<seq2seq4repair_space>of<seq2seq4repair_space>queries" ) ; } if ( ( i % 10000 ) == 0 ) { System . out . println ( ( ( ( "Percolated<seq2seq4repair_space>" + i ) + "<seq2seq4repair_space>took<seq2seq4repair_space>" ) + ( stopWatch . stop ( ) . lastTaskTime ( ) ) ) ) ; stopWatch . start ( ) ; } } System . out . println ( ( ( ( "Percolation<seq2seq4repair_space>took<seq2seq4repair_space>" + ( stopWatch . totalTime ( ) ) ) + ",<seq2seq4repair_space>TPS<seq2seq4repair_space>" ) + ( ( ( double ) ( COUNT ) ) / ( stopWatch . totalTime ( ) . secondsFrac ( ) ) ) ) ) ; clientNode . close ( ) ; for ( Node node : nodes ) { node . close ( ) ; } } private static XContentBuilder source ( String id , String nameValue ) throws IOException { } private static XContentBuilder source ( String id , int number ) throws IOException { } }<BUG2FIX>Node [ ] nodes = new Node [ 1 ] ;
public class FileHandle { protected File file ; protected FileType type ; protected FileHandle ( ) { } public FileHandle ( String fileName ) { } public FileHandle ( File file ) { } protected FileHandle ( String fileName , FileType type ) { } protected FileHandle ( File file , FileType type ) { } public String path ( ) { } public String name ( ) { } public String extension ( ) { } public String nameWithoutExtension ( ) { } public String pathWithoutExtension ( ) { } public FileType type ( ) { } public File file ( ) { } public InputStream read ( ) { } public BufferedInputStream read ( int bufferSize ) { } public Reader reader ( ) { } public Reader reader ( String charset ) { } public BufferedReader reader ( int bufferSize ) { } public BufferedReader reader ( int bufferSize , String charset ) { } public String readString ( ) { } public String readString ( String charset ) { } public byte [ ] readBytes ( ) { } private int estimateLength ( ) { } public int readBytes ( byte [ ] bytes , int offset , int size ) { } public OutputStream write ( boolean append ) { } public void write ( InputStream input , boolean append ) { } public Writer writer ( boolean append ) { } public Writer writer ( boolean append , String charset ) { } public void writeString ( String string , boolean append ) { } public void writeString ( String string , boolean append , String charset ) { } public void writeBytes ( byte [ ] bytes , boolean append ) { } public void writeBytes ( byte [ ] bytes , int offset , int length , boolean append ) { } public FileHandle [ ] list ( ) { } public FileHandle [ ] list ( String suffix ) { } public boolean isDirectory ( ) { } public FileHandle child ( String name ) { } public FileHandle sibling ( String name ) { } public FileHandle parent ( ) { } public void mkdirs ( ) { } public boolean exists ( ) { switch ( type ) { case Internal : <START_BUG> if ( file ( ) . exists ( ) ) <END_BUG> return true ; case Classpath : return ( FileHandle . class . getResource ( ( "/" + ( file . getPath ( ) . replace ( '\\' , '/' ) ) ) ) ) != null ; } return file ( ) . exists ( ) ; } public boolean delete ( ) { } public boolean deleteDirectory ( ) { } public void emptyDirectory ( ) { } public void emptyDirectory ( boolean preserveTree ) { } public void copyTo ( FileHandle dest ) { } public void moveTo ( FileHandle dest ) { } public long length ( ) { } public long lastModified ( ) { } @ Override public boolean equals ( Object obj ) { } @ Override public int hashCode ( ) { } public String toString ( ) { } public static FileHandle tempFile ( String prefix ) { } public static FileHandle tempDirectory ( String prefix ) { } private static void emptyDirectory ( File file , boolean preserveTree ) { } private static boolean deleteDirectory ( File file ) { } private static void copyFile ( FileHandle source , FileHandle dest ) { } private static void copyDirectory ( FileHandle sourceDir , FileHandle destDir ) { } }<BUG2FIX>if ( file . exists ( ) )
public class ValueScriptDateHistogramFacetExecutor extends FacetExecutor { private final IndexNumericFieldData keyIndexFieldData ; private final ComparatorType comparatorType ; final SearchScript valueScript ; final TimeZoneRounding tzRounding ; final Recycler . V < LongObjectOpenHashMap < InternalFullDateHistogramFacet . FullEntry > > entries ; public ValueScriptDateHistogramFacetExecutor ( IndexNumericFieldData keyIndexFieldData , SearchScript valueScript , TimeZoneRounding tzRounding , DateHistogramFacet . ComparatorType comparatorType , CacheRecycler cacheRecycler ) { } @ Override public ValueScriptDateHistogramFacetExecutor . Collector collector ( ) { } @ Override public InternalFacet buildFacet ( String facetName ) { ArrayList < InternalFullDateHistogramFacet . FullEntry > entries1 = new ArrayList ( entries . v ( ) . size ( ) ) ; final boolean [ ] states = entries . v ( ) . allocated ; final Object [ ] values = entries . v ( ) . values ; for ( int i = 0 ; i < ( states . length ) ; i ++ ) { if ( states [ i ] ) { InternalFullDateHistogramFacet . FullEntry value = ( ( InternalFullDateHistogramFacet . FullEntry ) ( values [ i ] ) ) ; entries1 . add ( value ) ; } } <START_BUG> entries . release ( ) ; <END_BUG> return new InternalFullDateHistogramFacet ( facetName , comparatorType , entries1 ) ; } class Collector extends FacetExecutor . Collector { private final ValueScriptDateHistogramFacetExecutor . DateHistogramProc histoProc ; private LongValues keyValues ; public Collector ( ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override public void setNextReader ( AtomicReaderContext context ) throws IOException { } @ Override public void collect ( int doc ) throws IOException { } @ Override public void postCollection ( ) { } } public static class DateHistogramProc extends LongFacetAggregatorBase { private final TimeZoneRounding tzRounding ; protected final SearchScript valueScript ; final LongObjectOpenHashMap < InternalFullDateHistogramFacet . FullEntry > entries ; public DateHistogramProc ( TimeZoneRounding tzRounding , SearchScript valueScript , final LongObjectOpenHashMap < InternalFullDateHistogramFacet . FullEntry > entries ) { } @ Override public void onValue ( int docId , long value ) { } } }<BUG2FIX>entries . close ( ) ;
public class TermsStatsFacetProcessor extends AbstractComponent implements FacetProcessor { @ Inject public TermsStatsFacetProcessor ( Settings settings ) { } @ Override public String [ ] types ( ) { } @ Override public FacetCollector parse ( String facetName , XContentParser parser , SearchContext context ) throws IOException { String keyField = null ; String valueField = null ; int size = 10 ; TermsStatsFacet . ComparatorType comparatorType = ComparatorType . COUNT ; String scriptLang = null ; String script = null ; Map < String , Object > params = null ; String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_OBJECT ) ) { if ( "params" . equals ( currentFieldName ) ) { params = parser . map ( ) ; } } else if ( token . isValue ( ) ) { if ( ( "key_field" . equals ( currentFieldName ) ) || ( "keyField" . equals ( currentFieldName ) ) ) { keyField = parser . text ( ) ; } else if ( ( "value_field" . equals ( currentFieldName ) ) || ( "valueField" . equals ( currentFieldName ) ) ) { valueField = parser . text ( ) ; } else if ( "script_field" . equals ( currentFieldName ) ) { script = parser . text ( ) ; } else if ( "value_script" . equals ( currentFieldName ) ) { script = parser . text ( ) ; } else if ( "size" . equals ( currentFieldName ) ) { size = parser . intValue ( ) ; } else if ( ( "all_terms" . equals ( currentFieldName ) ) || ( "allTerms" . equals ( currentFieldName ) ) ) { if ( parser . booleanValue ( ) ) { size = 0 ; } } else if ( ( "order" . equals ( currentFieldName ) ) || ( "comparator" . equals ( currentFieldName ) ) ) { comparatorType = ComparatorType . fromString ( parser . text ( ) ) ; } else if ( "value_script" . equals ( currentFieldName ) ) { script = parser . text ( ) ; } else if ( "lang" . equals ( currentFieldName ) ) { scriptLang = parser . text ( ) ; } } } if ( keyField == null ) { throw new FacetPhaseExecutionException ( facetName , "[key_field]<seq2seq4repair_space>is<seq2seq4repair_space>required<seq2seq4repair_space>to<seq2seq4repair_space>be<seq2seq4repair_space>set<seq2seq4repair_space>for<seq2seq4repair_space>terms<seq2seq4repair_space>stats<seq2seq4repair_space>facet" ) ; } if ( ( valueField == null ) && ( script == null ) ) { throw new FacetPhaseExecutionException ( facetName , "either<seq2seq4repair_space>[value_field]<seq2seq4repair_space>or<seq2seq4repair_space>[script]<seq2seq4repair_space>are<seq2seq4repair_space>required<seq2seq4repair_space>to<seq2seq4repair_space>be<seq2seq4repair_space>set<seq2seq4repair_space>for<seq2seq4repair_space>terms<seq2seq4repair_space>stats<seq2seq4repair_space>facet" ) ; } <START_BUG> FieldMapper keyFieldMapper = context . mapperService ( ) . smartNameFieldMapper ( keyField ) ; <END_BUG> if ( keyFieldMapper != null ) { if ( ( keyFieldMapper . fieldDataType ( ) ) == ( DefaultTypes . LONG ) ) { return new org . elasticsearch . search . facet . termsstats . longs . TermsStatsLongFacetCollector ( facetName , keyField , valueField , size , comparatorType , context , scriptLang , script , params ) ; } else if ( ( keyFieldMapper . fieldDataType ( ) ) == ( DefaultTypes . INT ) ) { return new org . elasticsearch . search . facet . termsstats . longs . TermsStatsLongFacetCollector ( facetName , keyField , valueField , size , comparatorType , context , scriptLang , script , params ) ; } else if ( ( keyFieldMapper . fieldDataType ( ) ) == ( DefaultTypes . SHORT ) ) { return new org . elasticsearch . search . facet . termsstats . longs . TermsStatsLongFacetCollector ( facetName , keyField , valueField , size , comparatorType , context , scriptLang , script , params ) ; } else if ( ( keyFieldMapper . fieldDataType ( ) ) == ( DefaultTypes . BYTE ) ) { return new org . elasticsearch . search . facet . termsstats . longs . TermsStatsLongFacetCollector ( facetName , keyField , valueField , size , comparatorType , context , scriptLang , script , params ) ; } else if ( ( keyFieldMapper . fieldDataType ( ) ) == ( DefaultTypes . DOUBLE ) ) { return new org . elasticsearch . search . facet . termsstats . doubles . TermsStatsDoubleFacetCollector ( facetName , keyField , valueField , size , comparatorType , context , scriptLang , script , params ) ; } else if ( ( keyFieldMapper . fieldDataType ( ) ) == ( DefaultTypes . FLOAT ) ) { return new org . elasticsearch . search . facet . termsstats . doubles . TermsStatsDoubleFacetCollector ( facetName , keyField , valueField , size , comparatorType , context , scriptLang , script , params ) ; } } return new org . elasticsearch . search . facet . termsstats . strings . TermsStatsStringFacetCollector ( facetName , keyField , valueField , size , comparatorType , context , scriptLang , script , params ) ; } @ Override public Facet reduce ( String name , List < Facet > facets ) { } }<BUG2FIX>FieldMapper keyFieldMapper = context . smartNameFieldMapper ( keyField ) ;
public class NetAPITest extends GdxTest implements HttpResponseListener { SpriteBatch batch ; Skin skin ; Stage stage ; TextButton btnDownloadImage ; TextButton btnDownloadText ; TextButton btnDownloadError ; TextButton btnPost ; TextButton btnCancel ; Label statusLabel ; Texture texture ; String text ; BitmapFont font ; HttpRequest httpRequest ; Object clickedButton ; public boolean needsGL20 ( ) { } @ Override public void dispose ( ) { } @ Override public void create ( ) { } @ Override public void handleHttpResponse ( HttpResponse httpResponse ) { } void setText ( HttpResponse httpResponse ) { } void setButtonDisabled ( boolean disabled ) { } @ Override public void failed ( Throwable t ) { } @ Override public void render ( ) { } @ Override public void resize ( int width , int height ) { <START_BUG> stage . getViewport ( ) . update ( width , height ) ; <END_BUG> } @ Override public void cancelled ( ) { } }<BUG2FIX>stage . getViewport ( ) . update ( width , height , true ) ;
public class OrthographicCamera extends Camera { public float zoom = 1 ; public OrthographicCamera ( ) { } public OrthographicCamera ( float viewportWidth , float viewportHeight ) { } public OrthographicCamera ( float viewportWidth , float viewportHeight , float diamondAngle ) { } public void findDirectionForIsoView ( float targetAngle , float epsilon , int maxIterations ) { } private float calculateAngle ( float a ) { } private Vector3 calculateDirection ( float angle ) { Matrix4 transform = new Matrix4 ( ) ; Vector3 dir = new Vector3 ( ( - 1 ) , 0 , 1 ) . nor ( ) ; float rotAngle = ( ( float ) ( Math . toDegrees ( Math . asin ( Math . tan ( Math . toRadians ( angle ) ) ) ) ) ) ; <START_BUG> transform . setToRotation ( new Vector3 ( 1 , 0 , 1 ) . nor ( ) , angle ) ; <END_BUG> dir . mul ( transform ) . nor ( ) ; return dir ; } private final Vector3 tmp = new Vector3 ( ) ; @ Override public void update ( ) { } @ Override public void update ( boolean updateFrustum ) { } public void setToOrtho ( boolean yDown ) { } public void setToOrtho ( boolean yDown , float viewportWidth , float viewportHeight ) { } public void rotate ( float angle ) { } public void translate ( float x , float y ) { } public void translate ( Vector2 vec ) { } }<BUG2FIX>transform . setToRotation ( new Vector3 ( 1 , 0 , 1 ) . nor ( ) , rotAngle ) ;
public class SimpleChildQuerySearchTests extends ElasticsearchIntegrationTest { @ Test public void multiLevelChild ( ) throws Exception { } @ Test public void test2744 ( ) throws IOException , ElasticSearchException { } @ Test public void simpleChildQuery ( ) throws Exception { } @ Test public void testClearIdCacheBug ( ) throws Exception { } @ Test public void testCachingBug_withFqueryFilter ( ) throws Exception { } @ Test public void testHasParentFilter ( ) throws Exception { } @ Test public void simpleChildQueryWithFlush ( ) throws Exception { } @ Test public void simpleChildQueryWithFlushAnd3Shards ( ) throws Exception { } @ Test public void testScopedFacet ( ) throws Exception { } @ Test public void testDeletedParent ( ) throws Exception { } @ Test public void testDfsSearchType ( ) throws Exception { } @ Test public void testFixAOBEIfTopChildrenIsWrappedInMusNotClause ( ) throws Exception { } @ Test public void testTopChildrenReSearchBug ( ) throws Exception { } @ Test public void testHasChildAndHasParentFailWhenSomeSegmentsDontContainAnyParentOrChildDocs ( ) throws Exception { } @ Test public void testCountApiUsage ( ) throws Exception { } @ Test public void testExplainUsage ( ) throws Exception { } @ Test public void testScoreForParentChildQueries ( ) throws Exception { } List < IndexRequestBuilder > createDocBuilders ( ) { } @ Test public void testScoreForParentChildQueries_withFunctionScore ( ) throws Exception { } @ Test public void testParentChildQueriesCanHandleNoRelevantTypesInIndex ( ) throws Exception { } @ Test public void testHasChildAndHasParentFilter_withFilter ( ) throws Exception { } @ Test public void testSimpleQueryRewrite ( ) throws Exception { } @ Test public void testReIndexingParentAndChildDocuments ( ) throws Exception { } @ Test public void testHasChildQueryWithMinimumScore ( ) throws Exception { client ( ) . admin ( ) . indices ( ) . prepareCreate ( "test" ) . setSettings ( ImmutableSettings . settingsBuilder ( ) . put ( "index.number_of_shards" , 1 ) . put ( "index.number_of_replicas" , 0 ) ) . execute ( ) . actionGet ( ) ; client ( ) . admin ( ) . cluster ( ) . prepareHealth ( ) . setWaitForEvents ( LANGUID ) . setWaitForGreenStatus ( ) . execute ( ) . actionGet ( ) ; client ( ) . admin ( ) . indices ( ) . preparePutMapping ( "test" ) . setType ( "child" ) . setSource ( jsonBuilder ( ) . startObject ( ) . startObject ( "child" ) . startObject ( "_parent" ) . field ( "type" , "parent" ) . endObject ( ) . endObject ( ) . endObject ( ) ) . execute ( ) . actionGet ( ) ; client ( ) . prepareIndex ( "test" , "parent" , "p1" ) . setSource ( "p_field" , "p_value1" ) . execute ( ) . actionGet ( ) ; client ( ) . prepareIndex ( "test" , "child" , "c1" ) . setSource ( "c_field" , "x" ) . setParent ( "p1" ) . execute ( ) . actionGet ( ) ; client ( ) . prepareIndex ( "test" , "parent" , "p2" ) . setSource ( "p_field" , "p_value2" ) . execute ( ) . actionGet ( ) ; client ( ) . prepareIndex ( "test" , "child" , "c3" ) . setSource ( "c_field" , "x" ) . setParent ( "p2" ) . execute ( ) . actionGet ( ) ; client ( ) . prepareIndex ( "test" , "child" , "c4" ) . setSource ( "c_field" , "x" ) . setParent ( "p2" ) . execute ( ) . actionGet ( ) ; client ( ) . prepareIndex ( "test" , "child" , "c5" ) . setSource ( "c_field" , "x" ) . setParent ( "p2" ) . execute ( ) . actionGet ( ) ; refresh ( ) ; <START_BUG> SearchResponse searchResponse = client ( ) . prepareSearch ( "test" ) . setQuery ( SimpleChildQuerySearchTests . hasChildQuery ( "child" , matchAllQuery ( ) ) . scoreType ( "sum" ) ) . setMinScore ( 3 ) . execute ( ) . actionGet ( ) ; <END_BUG> assertNoFailures ( searchResponse ) ; assertThat ( searchResponse . getFailedShards ( ) , equalTo ( 0 ) ) ; assertThat ( searchResponse . getHits ( ) . totalHits ( ) , equalTo ( 1L ) ) ; assertThat ( searchResponse . getHits ( ) . getAt ( 0 ) . id ( ) , equalTo ( "p2" ) ) ; assertThat ( searchResponse . getHits ( ) . getAt ( 0 ) . score ( ) , equalTo ( 3.0F ) ) ; } @ Test public void testParentFieldFilter ( ) throws Exception { } @ Test public void testHasChildNotBeingCached ( ) throws IOException , ElasticSearchException { } @ Test public void testDeleteByQuery_has_child ( ) throws Exception { } @ Test public void testDeleteByQuery_has_child_SingleRefresh ( ) throws Exception { } private QueryBuilder randomHasChild ( String type , String field , String value ) { } @ Test public void testDeleteByQuery_has_parent ( ) throws Exception { } private QueryBuilder randomHasParent ( String type , String field , String value ) { } @ Test public void testHasChildQueryOnlyReturnsSingleChildType ( ) { } @ Test public void indexChildDocWithNoParentMapping ( ) throws IOException , ElasticSearchException { } @ Test public void testAddingParentToExistingMapping ( ) throws IOException , ElasticSearchException { } @ Test public void testTopChildrenBug_concurrencyIssue ( ) throws Exception { } private static HasChildFilterBuilder hasChildFilter ( String type , QueryBuilder queryBuilder ) { } private static HasChildFilterBuilder hasChildFilter ( String type , FilterBuilder filterBuilder ) { } private static HasChildQueryBuilder hasChildQuery ( String type , QueryBuilder queryBuilder ) { } }<BUG2FIX>SearchResponse searchResponse = client ( ) . prepareSearch ( "test" ) . setQuery ( SimpleChildQuerySearchTests . hasChildQuery ( "child" , matchAllQuery ( ) ) . scoreType ( "sum" ) ) . setMinScore ( 2 ) . execute ( ) . actionGet ( ) ;
public class ScriptFilterParser implements FilterParser { public static final String NAME = "script" ; @ Inject public ScriptFilterParser ( ) { } @ Override public String [ ] names ( ) { } @ Override public Filter parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { } public static class ScriptFilter extends Filter { private final String script ; private final Map < String , Object > params ; private final SearchScript searchScript ; private ScriptFilter ( String scriptLang , String script , Map < String , Object > params , ScriptService scriptService ) { } @ Override public String toString ( ) { } @ Override public boolean equals ( Object o ) { } @ Override public int hashCode ( ) { } @ Override public DocIdSet getDocIdSet ( AtomicReaderContext context , Bits acceptDocs ) throws IOException { <START_BUG> searchScript . setNextReader ( context . reader ( ) ) ; <END_BUG> return BitsFilteredDocIdSet . wrap ( new ScriptFilterParser . ScriptFilter . ScriptDocSet ( context . reader ( ) , searchScript ) , acceptDocs ) ; } static class ScriptDocSet extends GetDocSet { private final SearchScript searchScript ; public ScriptDocSet ( IndexReader reader , SearchScript searchScript ) { } @ Override public long sizeInBytes ( ) { } @ Override public boolean isCacheable ( ) { } @ Override public boolean get ( int doc ) { } } } }<BUG2FIX>searchScript . setNextReader ( context ) ;
public class TermsFacetProcessor extends AbstractComponent implements FacetProcessor { @ Inject public TermsFacetProcessor ( Settings settings ) { } @ Override public String [ ] types ( ) { } @ Override public FacetCollector parse ( String facetName , XContentParser parser , SearchContext context ) throws IOException { String field = null ; int size = 10 ; String [ ] fieldsNames = null ; ImmutableSet < String > excluded = ImmutableSet . of ( ) ; String regex = null ; String regexFlags = null ; TermsFacet . ComparatorType comparatorType = ComparatorType . COUNT ; String scriptLang = null ; String script = null ; Map < String , Object > params = null ; boolean allTerms = false ; String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_OBJECT ) ) { if ( "params" . equals ( currentFieldName ) ) { params = parser . map ( ) ; } } else if ( token == ( Token . START_ARRAY ) ) { if ( "exclude" . equals ( currentFieldName ) ) { ImmutableSet . Builder < String > builder = ImmutableSet . builder ( ) ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_ARRAY ) ) { builder . add ( parser . text ( ) ) ; } excluded = builder . build ( ) ; } else if ( "fields" . equals ( currentFieldName ) ) { List < String > fields = Lists . newArrayListWithCapacity ( 4 ) ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_ARRAY ) ) { fields . add ( parser . text ( ) ) ; } fieldsNames = fields . toArray ( new String [ fields . size ( ) ] ) ; } } else if ( token . isValue ( ) ) { if ( "field" . equals ( currentFieldName ) ) { field = parser . text ( ) ; } else if ( "script_field" . equals ( currentFieldName ) ) { script = parser . text ( ) ; } else if ( "size" . equals ( currentFieldName ) ) { size = parser . intValue ( ) ; } else if ( ( "all_terms" . equals ( currentFieldName ) ) || ( "allTerms" . equals ( currentFieldName ) ) ) { allTerms = parser . booleanValue ( ) ; } else if ( "regex" . equals ( currentFieldName ) ) { regex = parser . text ( ) ; } else if ( ( "regex_flags" . equals ( currentFieldName ) ) || ( "regexFlags" . equals ( currentFieldName ) ) ) { regexFlags = parser . text ( ) ; } else <START_BUG> if ( ( "order" . equals ( currentFieldName ) ) || ( "comparator" . equals ( field ) ) ) { <END_BUG> comparatorType = ComparatorType . fromString ( parser . text ( ) ) ; } else if ( "script" . equals ( currentFieldName ) ) { script = parser . text ( ) ; } else if ( "lang" . equals ( currentFieldName ) ) { scriptLang = parser . text ( ) ; } } } if ( "_index" . equals ( field ) ) { return new org . elasticsearch . search . facet . terms . index . IndexNameFacetCollector ( facetName , context . shardTarget ( ) . index ( ) , comparatorType , size ) ; } Pattern pattern = null ; if ( regex != null ) { pattern = Regex . compile ( regex , regexFlags ) ; } if ( fieldsNames != null ) { return new org . elasticsearch . search . facet . terms . strings . FieldsTermsStringFacetCollector ( facetName , fieldsNames , size , comparatorType , allTerms , context , excluded , pattern , scriptLang , script , params ) ; } if ( ( ( field == null ) && ( fieldsNames == null ) ) && ( script != null ) ) { return new org . elasticsearch . search . facet . terms . strings . ScriptTermsStringFieldFacetCollector ( facetName , size , comparatorType , context , excluded , pattern , scriptLang , script , params ) ; } FieldMapper fieldMapper = context . mapperService ( ) . smartNameFieldMapper ( field ) ; if ( fieldMapper != null ) { if ( fieldMapper instanceof IpFieldMapper ) { return new org . elasticsearch . search . facet . terms . ip . TermsIpFacetCollector ( facetName , field , size , comparatorType , allTerms , context , scriptLang , script , params ) ; } else if ( ( fieldMapper . fieldDataType ( ) ) == ( DefaultTypes . LONG ) ) { return new org . elasticsearch . search . facet . terms . longs . TermsLongFacetCollector ( facetName , field , size , comparatorType , allTerms , context , scriptLang , script , params ) ; } else if ( ( fieldMapper . fieldDataType ( ) ) == ( DefaultTypes . DOUBLE ) ) { return new org . elasticsearch . search . facet . terms . doubles . TermsDoubleFacetCollector ( facetName , field , size , comparatorType , allTerms , context , scriptLang , script , params ) ; } else if ( ( fieldMapper . fieldDataType ( ) ) == ( DefaultTypes . INT ) ) { return new org . elasticsearch . search . facet . terms . ints . TermsIntFacetCollector ( facetName , field , size , comparatorType , allTerms , context , scriptLang , script , params ) ; }<BUG2FIX>if ( ( "order" . equals ( currentFieldName ) ) || ( "comparator" . equals ( currentFieldName ) ) ) {
public class JdkESLoggerFactory extends ESLoggerFactory { @ Override public ESLogger newInstance ( String prefix , String name ) { final Logger logger = Logger . getLogger ( name ) ; <START_BUG> return new JdkESLogger ( prefix , logger ) ; <END_BUG> } }<BUG2FIX>return new JdkESLogger ( prefix , name , logger ) ;
public final class HppcMaps { private HppcMaps ( ) { } public static < K , V > ObjectObjectOpenHashMap < K , V > newMap ( int capacity ) { <START_BUG> return new ObjectObjectOpenHashMap < K , V > ( capacity ) ; <END_BUG> } public static < K , V > ObjectObjectOpenHashMap < K , V > newMap ( ) { } public static < K , V > ObjectObjectOpenHashMap < K , V > newNoNullKeysMap ( ) { } public static < K , V > ObjectObjectOpenHashMap < K , V > newNoNullKeysMap ( int capacity ) { } public static < K , V > ObjectObjectOpenHashMap < K , V > ensureNoNullKeys ( int capacity ) { } public static < T > Iterable < T > intersection ( ObjectLookupContainer < T > container1 , final ObjectLookupContainer < T > container2 ) { } public static final class Object { public static final class Integer { public static < V > ObjectIntOpenHashMap < V > ensureNoNullKeys ( int capacity , float loadFactor ) { } } } }<BUG2FIX>return new ObjectObjectOpenHashMap ( capacity ) ;
public class ImageTest extends GdxTest { Skin skin ; Stage ui ; Table root ; TextureRegion image2 ; @ Override public void create ( ) { <START_BUG> skin = new Skin ( files . internal ( "data/uiskin.json" ) , files . internal ( "data/uiskin.png" ) ) ; <END_BUG> image2 = new TextureRegion ( new com . badlogic . gdx . graphics . Texture ( files . internal ( "data/badlogic.jpg" ) ) ) ; ui = new Stage ( graphics . getWidth ( ) , graphics . getHeight ( ) , false ) ; input . setInputProcessor ( ui ) ; root = new Table ( ) ; ui . addActor ( root ) ; root . debug ( ) ; Image image = new Image ( image2 ) ; image . setScaling ( fill ) ; root . add ( image ) . width ( 160 ) . height ( 100 ) ; } @ Override public void dispose ( ) { } @ Override public void render ( ) { } @ Override public void resize ( int width , int height ) { } @ Override public boolean needsGL20 ( ) { } }<BUG2FIX>skin = new Skin ( files . internal ( "data/uiskin.json" ) ) ;
public class CompetitionIteration implements Streamable { private long numQueries ; private CompetitionIteration . SlowRequest [ ] slowRequests ; private long totalTime ; private long sum ; private long sumTotalHits ; private double stddev ; private long min ; private long max ; private double mean ; private double qps ; private double millisPerHit ; private double [ ] percentiles = new double [ 0 ] ; private Map < Double , Double > percentileValues = new TreeMap < > ( ) ; private CompetitionIterationData iterationData ; public CompetitionIteration ( ) { } public CompetitionIteration ( CompetitionIteration . SlowRequest [ ] slowestRequests , long totalTime , long numQueries , long sumTotalHits , CompetitionIterationData iterationData ) { } public void computeStatistics ( ) { <START_BUG> SinglePassStatistics single = new SinglePassStatistics ( ) ; <END_BUG> for ( long datum : iterationData . data ( ) ) { if ( datum > ( - 1 ) ) { single . push ( datum ) ; } } sum = single . sum ( ) ; stddev = single . stddev ( ) ; min = single . min ( ) ; max = single . max ( ) ; mean = single . mean ( ) ; qps = ( numQueries ) * ( 1000.0 / ( ( double ) ( sum ) ) ) ; for ( double percentile : percentiles ) { percentileValues . put ( percentile , single . percentile ( ( percentile / 100 ) ) ) ; } } public CompetitionIterationData competitionIterationData ( ) { } public long numQueries ( ) { } public long totalTime ( ) { } public long sumTotalHits ( ) { } public double millisPerHit ( ) { } public double queriesPerSecond ( ) { } public CompetitionIteration . SlowRequest [ ] slowRequests ( ) { } public long min ( ) { } public long max ( ) { } public double mean ( ) { } public Map < Double , Double > percentileValues ( ) { } public void percentiles ( double [ ] percentiles ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } public static class SlowRequest implements Streamable , ToXContent { private long maxTimeTaken ; private long avgTimeTaken ; private SearchRequest searchRequest ; public SlowRequest ( ) { } public SlowRequest ( long avgTimeTaken , long maxTimeTaken , SearchRequest searchRequest ) { } public long avgTimeTaken ( ) { } public long maxTimeTaken ( ) { } public SearchRequest searchRequest ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } } static final class Fields { static final XContentBuilderString MAX_TIME = new XContentBuilderString ( "max_time" ) ; static final XContentBuilderString AVG_TIME = new XContentBuilderString ( "avg_time" ) ; } }<BUG2FIX>final SinglePassStatistics single = new SinglePassStatistics ( ) ;
public class TransportIndicesStatusAction extends TransportBroadcastOperationAction < IndicesStatusRequest , IndicesStatusResponse , TransportIndicesStatusAction . IndexShardStatusRequest , ShardStatus > { private final IndicesService indicesService ; private final RecoveryTarget peerRecoveryTarget ; @ Inject public TransportIndicesStatusAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportService transportService , IndicesService indicesService , RecoveryTarget peerRecoveryTarget ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected IndicesStatusRequest newRequest ( ) { } @ Override protected GroupShardsIterator shards ( ClusterState state , IndicesStatusRequest request , String [ ] concreteIndices ) { } @ Override protected ClusterBlockException checkGlobalBlock ( ClusterState state , IndicesStatusRequest request ) { } @ Override protected ClusterBlockException checkRequestBlock ( ClusterState state , IndicesStatusRequest countRequest , String [ ] concreteIndices ) { } @ Override protected IndicesStatusResponse newResponse ( IndicesStatusRequest request , AtomicReferenceArray shardsResponses , ClusterState clusterState ) { } @ Override protected TransportIndicesStatusAction . IndexShardStatusRequest newShardRequest ( ) { } @ Override protected TransportIndicesStatusAction . IndexShardStatusRequest newShardRequest ( ShardRouting shard , IndicesStatusRequest request ) { } @ Override protected ShardStatus newShardResponse ( ) { } @ Override protected ShardStatus shardOperation ( TransportIndicesStatusAction . IndexShardStatusRequest request ) throws ElasticsearchException { InternalIndexService indexService = ( ( InternalIndexService ) ( indicesService . indexServiceSafe ( request . index ( ) ) ) ) ; InternalIndexShard indexShard = ( ( InternalIndexShard ) ( indexService . shardSafe ( request . shardId ( ) ) ) ) ; ShardStatus shardStatus = new ShardStatus ( indexShard . routingEntry ( ) ) ; shardStatus . state = indexShard . state ( ) ; try { shardStatus . storeSize = indexShard . store ( ) . estimateSize ( ) ; } catch ( IOException e ) { } if ( ( indexShard . state ( ) ) == ( IndexShardState . STARTED ) ) { shardStatus . translogId = indexShard . translog ( ) . currentId ( ) ; shardStatus . translogOperations = indexShard . translog ( ) . estimatedNumberOfOperations ( ) ; Engine . Searcher searcher = indexShard . acquireSearcher ( "indices_status" ) ; try { shardStatus . docs = new DocsStatus ( ) ; shardStatus . docs . numDocs = searcher . reader ( ) . numDocs ( ) ; shardStatus . docs . maxDoc = searcher . reader ( ) . maxDoc ( ) ; shardStatus . docs . deletedDocs = searcher . reader ( ) . numDeletedDocs ( ) ; } finally { <START_BUG> searcher . release ( ) ; <END_BUG> } shardStatus . mergeStats = indexShard . mergeScheduler ( ) . stats ( ) ; shardStatus . refreshStats = indexShard . refreshStats ( ) ; shardStatus . flushStats = indexShard . flushStats ( ) ; } if ( request . recovery ) { RecoveryStatus peerRecoveryStatus = indexShard . recoveryStatus ( ) ; if ( peerRecoveryStatus == null ) { peerRecoveryStatus = peerRecoveryTarget . recoveryStatus ( indexShard . shardId ( ) ) ; } if ( peerRecoveryStatus != null ) { PeerRecoveryStatus . Stage stage ; switch ( peerRecoveryStatus . stage ( ) ) { case INIT : stage = Stage . INIT ; break ; case INDEX : stage = Stage . INDEX ; break ; case TRANSLOG : stage = Stage . TRANSLOG ; break ; case FINALIZE : stage = Stage . FINALIZE ; break ; case DONE : stage = Stage . DONE ; break ; default : stage = Stage . INIT ; } shardStatus . peerRecoveryStatus = new PeerRecoveryStatus ( stage , peerRecoveryStatus . recoveryState ( ) . getTimer ( ) . startTime ( ) , peerRecoveryStatus . recoveryState ( ) . getTimer ( ) . time ( ) , peerRecoveryStatus . recoveryState ( ) . getIndex ( ) . totalByteCount ( ) , peerRecoveryStatus . recoveryState ( ) . getIndex ( ) . reusedByteCount ( ) , peerRecoveryStatus . recoveryState ( ) . getIndex ( ) . recoveredByteCount ( ) , peerRecoveryStatus . recoveryState ( ) . getTranslog ( ) . currentTranslogOperations ( ) ) ; } IndexShardGatewayService gatewayService = indexService . shardInjector ( request . shardId ( ) ) . getInstance ( IndexShardGatewayService . class ) ; RecoveryState gatewayRecoveryState = gatewayService . recoveryState ( ) ; if ( gatewayRecoveryState != null ) { GatewayRecoveryStatus . Stage stage ; switch ( gatewayRecoveryState . getStage ( ) ) { case INIT : stage = GatewayRecoveryStatus . Stage . INIT ; break ; case INDEX : stage = GatewayRecoveryStatus . Stage . INDEX ; break ; case TRANSLOG : stage = GatewayRecoveryStatus . Stage . TRANSLOG ; break ; case DONE : stage = GatewayRecoveryStatus . Stage . DONE ; break ; default : stage = GatewayRecoveryStatus . Stage . INIT ; } shardStatus . gatewayRecoveryStatus = new GatewayRecoveryStatus ( stage , gatewayRecoveryState . getTimer ( ) . startTime ( ) , gatewayRecoveryState . getTimer ( ) . time ( ) , gatewayRecoveryState . getIndex ( ) . totalByteCount ( ) , gatewayRecoveryState . getIndex ( ) . reusedByteCount ( ) , gatewayRecoveryState . getIndex ( ) . recoveredByteCount ( ) , gatewayRecoveryState . getTranslog ( ) . currentTranslogOperations ( ) ) ; } } return shardStatus ; } public static class IndexShardStatusRequest extends BroadcastShardOperationRequest { boolean recovery ; boolean snapshot ; IndexShardStatusRequest ( ) { } IndexShardStatusRequest ( String index , int shardId , IndicesStatusRequest request ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } }<BUG2FIX>searcher . close ( ) ;
@ Test public class HandlesStreamsTests { @ Test public void testSharedUTFHandles ( ) throws Exception { BytesStreamOutput bytesOut = new BytesStreamOutput ( ) ; HandlesStreamOutput out = new HandlesStreamOutput ( bytesOut , 5 ) ; String lowerThresholdValue = "test" ; String higherThresholdValue = "something<seq2seq4repair_space>that<seq2seq4repair_space>is<seq2seq4repair_space>higher<seq2seq4repair_space>than<seq2seq4repair_space>5" ; out . writeUTF ( lowerThresholdValue ) ; out . writeUTF ( higherThresholdValue ) ; out . writeInt ( 1 ) ; out . writeUTF ( "else" ) ; out . writeUTF ( higherThresholdValue ) ; out . writeUTF ( lowerThresholdValue ) ; <START_BUG> HandlesStreamInput in = new HandlesStreamInput ( new org . elasticsearch . common . io . stream . BytesStreamInput ( bytesOut . copiedByteArray ( ) ) ) ; <END_BUG> assertThat ( in . readUTF ( ) , equalTo ( lowerThresholdValue ) ) ; assertThat ( in . readUTF ( ) , equalTo ( higherThresholdValue ) ) ; assertThat ( in . readInt ( ) , equalTo ( 1 ) ) ; assertThat ( in . readUTF ( ) , equalTo ( "else" ) ) ; assertThat ( in . readUTF ( ) , equalTo ( higherThresholdValue ) ) ; assertThat ( in . readUTF ( ) , equalTo ( lowerThresholdValue ) ) ; } }<BUG2FIX>HandlesStreamInput in = new HandlesStreamInput ( new org . elasticsearch . common . io . stream . BytesStreamInput ( bytesOut . copiedByteArray ( ) , false ) ) ;
public class TransportClusterSearchShardsAction extends TransportMasterNodeReadOperationAction < ClusterSearchShardsRequest , ClusterSearchShardsResponse > { @ Inject public TransportClusterSearchShardsAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool ) { } @ Override protected String transportAction ( ) { } @ Override protected String executor ( ) { } @ Override protected ClusterSearchShardsRequest newRequest ( ) { } @ Override protected ClusterSearchShardsResponse newResponse ( ) { } @ Override protected void masterOperation ( final ClusterSearchShardsRequest request , final ClusterState state , final ActionListener < ClusterSearchShardsResponse > listener ) throws ElasticsearchException { ClusterState clusterState = clusterService . state ( ) ; <START_BUG> String [ ] concreteIndices = clusterState . metaData ( ) . concreteIndices ( request . indices ( ) , request . indicesOptions ( ) ) ; <END_BUG> Map < String , Set < String > > routingMap = clusterState . metaData ( ) . resolveSearchRouting ( request . routing ( ) , request . indices ( ) ) ; Set < String > nodeIds = Sets . newHashSet ( ) ; GroupShardsIterator groupShardsIterator = clusterService . operationRouting ( ) . searchShards ( clusterState , request . indices ( ) , concreteIndices , routingMap , request . preference ( ) ) ; ShardRouting shard ; ClusterSearchShardsGroup [ ] groupResponses = new ClusterSearchShardsGroup [ groupShardsIterator . size ( ) ] ; int currentGroup = 0 ; for ( ShardIterator shardIt : groupShardsIterator ) { String index = shardIt . shardId ( ) . getIndex ( ) ; int shardId = shardIt . shardId ( ) . getId ( ) ; ShardRouting [ ] shardRoutings = new ShardRouting [ shardIt . size ( ) ] ; int currentShard = 0 ; shardIt . reset ( ) ; while ( ( shard = shardIt . nextOrNull ( ) ) != null ) { shardRoutings [ ( currentShard ++ ) ] = shard ; nodeIds . add ( shard . currentNodeId ( ) ) ; } groupResponses [ ( currentGroup ++ ) ] = new ClusterSearchShardsGroup ( index , shardId , shardRoutings ) ; } DiscoveryNode [ ] nodes = new DiscoveryNode [ nodeIds . size ( ) ] ; int currentNode = 0 ; for ( String nodeId : nodeIds ) { nodes [ ( currentNode ++ ) ] = clusterState . getNodes ( ) . get ( nodeId ) ; } listener . onResponse ( new ClusterSearchShardsResponse ( groupResponses , nodes ) ) ; } }<BUG2FIX>String [ ] concreteIndices = clusterState . metaData ( ) . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ;
public class FacetsParseElement implements SearchParseElement { @ Override public void parse ( JsonParser jp , SearchContext context ) throws Exception { JsonToken token ; SearchContextFacets . QueryExecutionType queryExecutionType = QueryExecutionType . COLLECT ; List < SearchContextFacets . QueryFacet > queryFacets = null ; while ( ( token = jp . nextToken ( ) ) != ( JsonToken . END_OBJECT ) ) { if ( token == ( JsonToken . FIELD_NAME ) ) { String topLevelFieldName = jp . getCurrentName ( ) ; if ( "queryExecution" . equals ( topLevelFieldName ) ) { jp . nextToken ( ) ; String text = jp . getText ( ) ; if ( "collect" . equals ( text ) ) { queryExecutionType = QueryExecutionType . COLLECT ; } else if ( "idset" . equals ( text ) ) { queryExecutionType = QueryExecutionType . IDSET ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( "Unsupported<seq2seq4repair_space>query<seq2seq4repair_space>type<seq2seq4repair_space>[" + text ) + "]" ) ) ; } } else { jp . nextToken ( ) ; jp . nextToken ( ) ; String facetType = jp . getCurrentName ( ) ; if ( "query" . equals ( facetType ) ) { JsonIndexQueryParser indexQueryParser = ( ( JsonIndexQueryParser ) ( context . queryParser ( ) ) ) ; <START_BUG> Query facetQuery = indexQueryParser . parse ( jp , context . source ( ) ) ; <END_BUG> if ( queryFacets == null ) { queryFacets = Lists . newArrayListWithCapacity ( 2 ) ; } queryFacets . add ( new SearchContextFacets . QueryFacet ( topLevelFieldName , facetQuery ) ) ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( "Unsupported<seq2seq4repair_space>facet<seq2seq4repair_space>type<seq2seq4repair_space>[" + facetType ) + "]<seq2seq4repair_space>for<seq2seq4repair_space>facet<seq2seq4repair_space>name<seq2seq4repair_space>[" ) + topLevelFieldName ) + "]" ) ) ; } jp . nextToken ( ) ; } } } if ( queryExecutionType == ( QueryExecutionType . IDSET ) ) { context . searcher ( ) . enabledDocIdSet ( ) ; } context . facets ( new SearchContextFacets ( queryExecutionType , queryFacets ) ) ; } }<BUG2FIX>Query facetQuery = indexQueryParser . parse ( jp ) ;
public class InternalIndexService extends AbstractIndexComponent implements IndexService { private final Injector injector ; private final Settings indexSettings ; private final NodeEnvironment nodeEnv ; private final ThreadPool threadPool ; private final PluginsService pluginsService ; private final InternalIndicesLifecycle indicesLifecycle ; private final AnalysisService analysisService ; private final MapperService mapperService ; private final IndexQueryParserService queryParserService ; private final SimilarityService similarityService ; private final IndexAliasesService aliasesService ; private final IndexCache indexCache ; private final IndexFieldDataService indexFieldData ; private final IndexEngine indexEngine ; private final IndexGateway indexGateway ; private final IndexStore indexStore ; private final IndexSettingsService settingsService ; private volatile ImmutableMap < Integer , Injector > shardsInjectors = ImmutableMap . of ( ) ; private volatile ImmutableMap < Integer , IndexShard > shards = ImmutableMap . of ( ) ; private volatile boolean closed = false ; @ Inject public InternalIndexService ( Injector injector , Index index , @ IndexSettings Settings indexSettings , NodeEnvironment nodeEnv , ThreadPool threadPool , AnalysisService analysisService , MapperService mapperService , IndexQueryParserService queryParserService , SimilarityService similarityService , IndexAliasesService aliasesService , IndexCache indexCache , IndexEngine indexEngine , IndexGateway indexGateway , IndexStore indexStore , IndexSettingsService settingsService , IndexFieldDataService indexFieldData ) { } @ Override public int numberOfShards ( ) { } @ Override public UnmodifiableIterator < IndexShard > iterator ( ) { } @ Override public boolean hasShard ( int shardId ) { } @ Override public IndexShard shard ( int shardId ) { } @ Override public IndexShard shardSafe ( int shardId ) throws IndexShardMissingException { } @ Override public ImmutableSet < Integer > shardIds ( ) { } @ Override public Injector injector ( ) { } @ Override public IndexGateway gateway ( ) { } @ Override public IndexSettingsService settingsService ( ) { } @ Override public IndexStore store ( ) { } @ Override public IndexCache cache ( ) { } @ Override public IndexFieldDataService fieldData ( ) { } @ Override public AnalysisService analysisService ( ) { } @ Override public MapperService mapperService ( ) { } @ Override public IndexQueryParserService queryParserService ( ) { } @ Override public SimilarityService similarityService ( ) { } @ Override public IndexAliasesService aliasesService ( ) { } @ Override public IndexEngine engine ( ) { } public void close ( final String reason , @ Nullable Executor executor ) { synchronized ( this ) { closed = true ; } Set < Integer > shardIds = shardIds ( ) ; final CountDownLatch latch = new CountDownLatch ( shardIds . size ( ) ) ; for ( final int shardId : shardIds ) { executor = ( executor == null ) ? threadPool . generic ( ) : executor ; executor . execute ( new Runnable ( ) { @ Override public void run ( ) { try { removeShard ( shardId , reason ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> logger . warn ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>close<seq2seq4repair_space>shard" , e ) ; } finally { latch . countDown ( ) ; } } } ) ; } try { latch . await ( ) ; } catch ( InterruptedException e ) { throw new org . elasticsearch . ElasticSearchInterruptedException ( ( ( "interrupted<seq2seq4repair_space>closing<seq2seq4repair_space>index<seq2seq4repair_space>[<seq2seq4repair_space>" + ( index ( ) . name ( ) ) ) + "]" ) , e ) ; } } @ Override public Injector shardInjector ( int shardId ) throws ElasticSearchException { } @ Override public Injector shardInjectorSafe ( int shardId ) throws IndexShardMissingException { } @ Override public synchronized IndexShard createShard ( int sShardId ) throws ElasticSearchException { } @ Override public synchronized void removeShard ( int shardId , String reason ) throws ElasticSearchException { } }<BUG2FIX>} catch ( Throwable e ) {
public abstract class HasChildFilter extends Filter implements ScopePhase . CollectorPhase { final Query childQuery ; final String scope ; final String parentType ; final String childType ; final SearchContext searchContext ; protected HasChildFilter ( Query childQuery , String scope , String parentType , String childType , SearchContext searchContext ) { } public Query query ( ) { } public String scope ( ) { } @ Override public String toString ( ) { } public static HasChildFilter create ( Query childQuery , String scope , String parentType , String childType , SearchContext searchContext , String executionType ) { } static class Bitset extends HasChildFilter { private Map < Object , FixedBitSet > parentDocs ; public Bitset ( Query childQuery , String scope , String parentType , String childType , SearchContext searchContext ) { } public boolean requiresProcessing ( ) { } public Collector collector ( ) { } public void processCollector ( Collector collector ) { } public void clear ( ) { } public DocIdSet getDocIdSet ( AtomicReaderContext context , Bits acceptDocs ) throws IOException { } } static class Uid extends HasChildFilter { THashSet < HashedBytesArray > collectedUids ; Uid ( Query childQuery , String scope , String parentType , String childType , SearchContext searchContext ) { } public boolean requiresProcessing ( ) { } public Collector collector ( ) { } public void processCollector ( Collector collector ) { } public DocIdSet getDocIdSet ( AtomicReaderContext context , Bits acceptDocs ) throws IOException { } public void clear ( ) { } static class ParentDocSet extends GetDocSet { final IndexReader reader ; final THashSet < HashedBytesArray > parents ; final IdReaderTypeCache typeCache ; final Bits acceptDocs ; ParentDocSet ( IndexReader reader , THashSet < HashedBytesArray > parents , IdReaderTypeCache typeCache , Bits acceptDocs ) { } public boolean get ( int doc ) { <START_BUG> return ( ! ( acceptDocs . get ( doc ) ) ) && ( parents . contains ( typeCache . idByDoc ( doc ) ) ) ; <END_BUG> } } static class UidCollector extends NoopCollector { final String parentType ; final SearchContext context ; final THashSet < HashedBytesArray > collectedUids ; private IdReaderTypeCache typeCache ; UidCollector ( String parentType , SearchContext context , THashSet < HashedBytesArray > collectedUids ) { } @ Override public void collect ( int doc ) throws IOException { } @ Override public void setNextReader ( AtomicReaderContext readerContext ) throws IOException { } } } }<BUG2FIX>return ( acceptDocs . get ( doc ) ) && ( parents . contains ( typeCache . idByDoc ( doc ) ) ) ;
return currentState ; } if ( request . index . contains ( "<seq2seq4repair_space>" ) ) { listener . onFailure ( new org . elasticsearch . indices . InvalidIndexNameException ( new Index ( request . index ) , request . index , "must<seq2seq4repair_space>not<seq2seq4repair_space>contain<seq2seq4repair_space>whitespace" ) ) ; return currentState ; } if ( request . index . contains ( "," ) ) { listener . onFailure ( new org . elasticsearch . indices . InvalidIndexNameException ( new Index ( request . index ) , request . index , "must<seq2seq4repair_space>not<seq2seq4repair_space>contain<seq2seq4repair_space>'," ) ) ; return currentState ; } if ( request . index . contains ( "#" ) ) { listener . onFailure ( new org . elasticsearch . indices . InvalidIndexNameException ( new Index ( request . index ) , request . index , "must<seq2seq4repair_space>not<seq2seq4repair_space>contain<seq2seq4repair_space>'#" ) ) ; return currentState ; } if ( ( ! ( request . index . equals ( riverIndexName ) ) ) && ( ( request . index . charAt ( 0 ) ) == '_' ) ) { listener . onFailure ( new org . elasticsearch . indices . InvalidIndexNameException ( new Index ( request . index ) , request . index , "must<seq2seq4repair_space>not<seq2seq4repair_space>start<seq2seq4repair_space>with<seq2seq4repair_space>'_'" ) ) ; return currentState ; } if ( ! ( request . index . toLowerCase ( ) . equals ( request . index ) ) ) { listener . onFailure ( new org . elasticsearch . indices . InvalidIndexNameException ( new Index ( request . index ) , request . index , "must<seq2seq4repair_space>be<seq2seq4repair_space>lowercase" ) ) ; return currentState ; } if ( ! ( Strings . validFileName ( request . index ) ) ) { listener . onFailure ( new org . elasticsearch . indices . InvalidIndexNameException ( new Index ( request . index ) , request . index , ( "must<seq2seq4repair_space>not<seq2seq4repair_space>contain<seq2seq4repair_space>the<seq2seq4repair_space>following<seq2seq4repair_space>characters<seq2seq4repair_space>" + ( Strings . INVALID_FILENAME_CHARS ) ) ) ) ; return currentState ; } if ( currentState . metaData ( ) . aliases ( ) . contains ( request . index ) ) { listener . onFailure ( new org . elasticsearch . indices . InvalidIndexNameException ( new Index ( request . index ) , request . index , "an<seq2seq4repair_space>alias<seq2seq4repair_space>with<seq2seq4repair_space>the<seq2seq4repair_space>same<seq2seq4repair_space>name<seq2seq4repair_space>already<seq2seq4repair_space>exists" ) ) ; return currentState ; } Map < String , CompressedString > mappings = Maps . newHashMap ( ) ; File mappingsDir = new File ( environment . configFile ( ) , "mappings" ) ; if ( ( mappingsDir . exists ( ) ) && ( mappingsDir . isDirectory ( ) ) ) { File defaultMappingsDir = new File ( mappingsDir , "_default" ) ; if ( ( defaultMappingsDir . exists ( ) ) && ( defaultMappingsDir . isDirectory ( ) ) ) { addMappings ( mappings , defaultMappingsDir ) ; } File indexMappingsDir = new File ( mappingsDir , request . index ) ; if ( ( indexMappingsDir . exists ( ) ) && ( indexMappingsDir . isDirectory ( ) ) ) { addMappings ( mappings , indexMappingsDir ) ; } } for ( Map . Entry < String , String > entry : request . mappings . entrySet ( ) ) { mappings . put ( entry . getKey ( ) , new CompressedString ( entry . getValue ( ) ) ) ; } ImmutableSettings . Builder indexSettingsBuilder = settingsBuilder ( ) . put ( request . settings ) ; if ( ( request . settings . get ( SETTING_NUMBER_OF_SHARDS ) ) == null ) { if ( request . index . equals ( riverIndexName ) ) { indexSettingsBuilder . put ( SETTING_NUMBER_OF_SHARDS , settings . getAsInt ( SETTING_NUMBER_OF_SHARDS , 1 ) ) ; } else { indexSettingsBuilder . put ( SETTING_NUMBER_OF_SHARDS , settings . getAsInt ( SETTING_NUMBER_OF_SHARDS , 5 ) ) ; } } if ( ( request . settings . get ( SETTING_NUMBER_OF_REPLICAS ) ) == null ) { if ( request . index . equals ( riverIndexName ) ) { <START_BUG> indexSettingsBuilder . put ( SETTING_NUMBER_OF_REPLICAS , settings . getAsInt ( SETTING_NUMBER_OF_REPLICAS , 2 ) ) ; <END_BUG> } else { indexSettingsBuilder . put ( SETTING_NUMBER_OF_REPLICAS , settings . getAsInt ( SETTING_NUMBER_OF_REPLICAS , 1 ) ) ; } } Settings actualIndexSettings = indexSettingsBuilder . build ( ) ; indicesService . createIndex ( request . index , actualIndexSettings , clusterService . state ( ) . nodes ( ) . localNode ( ) . id ( ) ) ; IndexService indexService = indicesService . indexServiceSafe ( request . index ) ; MapperService mapperService = indexService . mapperService ( ) ; for ( Map . Entry < String , CompressedString > entry : mappings . entrySet ( ) ) { try { mapperService . add ( entry . getKey ( ) , entry . getValue ( ) . string ( ) ) ; } catch ( Exception e ) { indicesService . deleteIndex ( request . index ) ; throw new org . elasticsearch . index . mapper . MapperParsingException ( ( ( "mapping<seq2seq4repair_space>[" + ( entry . getKey ( ) ) ) + "]" ) , e ) ; } } mappings . clear ( ) ; for ( DocumentMapper mapper : mapperService ) { mappings . put ( mapper . type ( ) , mapper . mappingSource ( ) ) ; } final IndexMetaData . IndexMetaData . Builder indexMetaDataBuilder = newIndexMetaDataBuilder ( request . index ) . settings ( actualIndexSettings ) ; for ( Map . Entry < String , CompressedString > entry : mappings . entrySet ( ) ) { indexMetaDataBuilder . putMapping ( entry . getKey ( ) , entry . getValue ( ) ) ; } final IndexMetaData . IndexMetaData indexMetaData = indexMetaDataBuilder . build ( ) ; MetaData . MetaData newMetaData = newMetaDataBuilder ( ) . metaData ( currentState . metaData ( ) ) . put ( indexMetaData ) . build ( ) ; logger . info ( "[{}]<seq2seq4repair_space>creating<seq2seq4repair_space>index,<seq2seq4repair_space>cause<seq2seq4repair_space>[{}],<seq2seq4repair_space>shards<seq2seq4repair_space>[{}]/[{}],<seq2seq4repair_space>mappings<seq2seq4repair_space>{}"<BUG2FIX>indexSettingsBuilder . put ( SETTING_NUMBER_OF_REPLICAS , settings . getAsInt ( SETTING_NUMBER_OF_REPLICAS , 1 ) ) ;
public class HistogramParser implements Aggregator . Parser { static final ParseField EXTENDED_BOUNDS = new ParseField ( "extended_bounds" ) ; @ Override public String type ( ) { } @ Override public AggregatorFactory parse ( String aggregationName , XContentParser parser , SearchContext context ) throws IOException { <START_BUG> ValuesSourceConfig < NumericValuesSource > config = new ValuesSourceConfig < NumericValuesSource > ( NumericValuesSource . class ) ; <END_BUG> String field = null ; String script = null ; String scriptLang = null ; Map < String , Object > scriptParams = null ; boolean keyed = false ; long minDocCount = 1 ; InternalOrder order = ( ( InternalOrder ) ( InternalOrder . KEY_ASC ) ) ; long interval = - 1 ; boolean assumeSorted = false ; String format = null ; ExtendedBounds extendedBounds = null ; XContentParser . Token token ; String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . VALUE_STRING ) ) { if ( "field" . equals ( currentFieldName ) ) { field = parser . text ( ) ; } else if ( "script" . equals ( currentFieldName ) ) { script = parser . text ( ) ; } else if ( "lang" . equals ( currentFieldName ) ) { scriptLang = parser . text ( ) ; } else if ( "format" . equals ( currentFieldName ) ) { format = parser . text ( ) ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( ( ( "Unknown<seq2seq4repair_space>key<seq2seq4repair_space>for<seq2seq4repair_space>a<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>aggregation<seq2seq4repair_space>[" ) + aggregationName ) + "]:<seq2seq4repair_space>[" ) + currentFieldName ) + "]." ) ) ; } } else if ( token == ( Token . VALUE_NUMBER ) ) { if ( "interval" . equals ( currentFieldName ) ) { interval = parser . longValue ( ) ; } else if ( ( "min_doc_count" . equals ( currentFieldName ) ) || ( "minDocCount" . equals ( currentFieldName ) ) ) { minDocCount = parser . longValue ( ) ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( ( ( "Unknown<seq2seq4repair_space>key<seq2seq4repair_space>for<seq2seq4repair_space>a<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>aggregation<seq2seq4repair_space>[" ) + aggregationName ) + "]:<seq2seq4repair_space>[" ) + currentFieldName ) + "]." ) ) ; } } else if ( token == ( Token . VALUE_BOOLEAN ) ) { if ( "keyed" . equals ( currentFieldName ) ) { keyed = parser . booleanValue ( ) ; } else if ( ( "script_values_sorted" . equals ( currentFieldName ) ) || ( "scriptValuesSorted" . equals ( currentFieldName ) ) ) { assumeSorted = parser . booleanValue ( ) ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( ( ( "Unknown<seq2seq4repair_space>key<seq2seq4repair_space>for<seq2seq4repair_space>a<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>aggregation<seq2seq4repair_space>[" ) + aggregationName ) + "]:<seq2seq4repair_space>[" ) + currentFieldName ) + "]." ) ) ; } } else if ( token == ( Token . START_OBJECT ) ) { if ( "params" . equals ( currentFieldName ) ) { scriptParams = parser . map ( ) ; } else if ( "order" . equals ( currentFieldName ) ) { while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . VALUE_STRING ) ) { String dir = parser . text ( ) ; boolean asc = "asc" . equals ( dir ) ; if ( ( ! asc ) && ( ! ( "desc" . equals ( dir ) ) ) ) { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( "Unknown<seq2seq4repair_space>order<seq2seq4repair_space>direction<seq2seq4repair_space>[" + dir ) + "]<seq2seq4repair_space>in<seq2seq4repair_space>aggregation<seq2seq4repair_space>[" ) + aggregationName ) + "].<seq2seq4repair_space>Should<seq2seq4repair_space>be<seq2seq4repair_space>either<seq2seq4repair_space>[asc]<seq2seq4repair_space>or<seq2seq4repair_space>[desc]" ) ) ; } order = HistogramParser . resolveOrder ( currentFieldName , asc ) ; } } } else if ( HistogramParser . EXTENDED_BOUNDS . match ( currentFieldName ) ) { extendedBounds = new ExtendedBounds ( ) ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token . isValue ( ) ) { if ( "min" . equals ( currentFieldName ) ) { extendedBounds . min = parser . longValue ( true ) ; } else if ( "max" . equals ( currentFieldName ) ) { extendedBounds . max = parser . longValue ( true ) ; } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( ( ( "Unknown<seq2seq4repair_space>extended_bounds<seq2seq4repair_space>key<seq2seq4repair_space>for<seq2seq4repair_space>a<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>aggregation<seq2seq4repair_space>[" ) + aggregationName ) + "]:<seq2seq4repair_space>[" ) + currentFieldName ) + "]." ) ) ; } } } } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( ( ( "Unknown<seq2seq4repair_space>key<seq2seq4repair_space>for<seq2seq4repair_space>a<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>aggregation<seq2seq4repair_space>[" ) + aggregationName ) + "]:<seq2seq4repair_space>[" ) + currentFieldName ) + "]." ) ) ; } } else { throw new org . elasticsearch . search . SearchParseException ( context , ( ( ( ( "Unexpected<seq2seq4repair_space>token<seq2seq4repair_space>" + token ) + "<seq2seq4repair_space>in<seq2seq4repair_space>aggregation<seq2seq4repair_space>[" ) + aggregationName ) + "]." ) ) ; } } if ( interval < 0 ) { throw new org . elasticsearch . search . SearchParseException ( context , ( ( "Missing<seq2seq4repair_space>required<seq2seq4repair_space>field<seq2seq4repair_space>[interval]<seq2seq4repair_space>for<seq2seq4repair_space>histogram<seq2seq4repair_space>aggregation<seq2seq4repair_space>[" + aggregationName ) + "]" ) ) ; } Rounding rounding = new Rounding . Interval ( interval ) ;<BUG2FIX>ValuesSourceConfig < NumericValuesSource > config = new ValuesSourceConfig ( NumericValuesSource . class ) ;
public class BulletTestCollection extends GdxTest implements InputProcessor , GestureListener { protected final BulletTest [ ] tests = new BulletTest [ ] { new ShootTest ( ) , new BasicShapesTest ( ) , new KinematicTest ( ) , new ConstraintsTest ( ) , new MeshShapeTest ( ) , new ConvexHullTest ( ) , new RayCastTest ( ) , new RayPickRagdollTest ( ) , new InternalTickTest ( ) , new CollisionWorldTest ( ) , new CollisionTest ( ) , new FrustumCullingTest ( ) , new ContactCallbackTest ( ) , new SoftBodyTest ( ) } ; protected int testIndex = 0 ; private Application app = null ; private BitmapFont font ; private Stage hud ; private Label fpsLabel ; private Label titleLabel ; private Label instructLabel ; private int loading = 0 ; @ Override public void render ( ) { } @ Override public void create ( ) { } @ Override public void dispose ( ) { } public void next ( ) { } public void loadnext ( ) { } @ Override public boolean keyDown ( int keycode ) { } @ Override public boolean keyTyped ( char character ) { } @ Override public boolean keyUp ( int keycode ) { } @ Override public boolean touchDown ( int x , int y , int pointer , int button ) { } @ Override public boolean touchDragged ( int x , int y , int pointer ) { } @ Override public boolean touchUp ( int x , int y , int pointer , int button ) { } @ Override public boolean needsGL20 ( ) { <START_BUG> return true ; <END_BUG> } @ Override public boolean mouseMoved ( int x , int y ) { } @ Override public boolean scrolled ( int amount ) { } @ Override public boolean touchDown ( float x , float y , int pointer , int button ) { } @ Override public boolean tap ( float x , float y , int count , int button ) { } @ Override public boolean longPress ( float x , float y ) { } @ Override public boolean fling ( float velocityX , float velocityY , int button ) { } @ Override public boolean pan ( float x , float y , float deltaX , float deltaY ) { } @ Override public boolean zoom ( float originalDistance , float currentDistance ) { } @ Override public boolean pinch ( Vector2 initialFirstPointer , Vector2 initialSecondPointer , Vector2 firstPointer , Vector2 secondPointer ) { } }<BUG2FIX>return false ;
public class IndexWarmersMetaData implements IndexMetaData . Custom { public static final String TYPE = "warmers" ; public static final IndexWarmersMetaData . Factory FACTORY = new IndexWarmersMetaData . Factory ( ) ; public static class Entry { private final String name ; private final String [ ] types ; private final BytesReference source ; public Entry ( String name , String [ ] types , BytesReference source ) { } public String name ( ) { } public String [ ] types ( ) { } @ Nullable public BytesReference source ( ) { } } private final ImmutableList < IndexWarmersMetaData . Entry > entries ; public IndexWarmersMetaData ( IndexWarmersMetaData . Entry ... entries ) { } public ImmutableList < IndexWarmersMetaData . Entry > entries ( ) { } @ Override public String type ( ) { } public static class Factory implements IndexMetaData . Custom . Factory < IndexWarmersMetaData > { @ Override public String type ( ) { } @ Override public IndexWarmersMetaData readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( IndexWarmersMetaData warmers , StreamOutput out ) throws IOException { out . writeVInt ( warmers . entries ( ) . size ( ) ) ; for ( IndexWarmersMetaData . Entry entry : warmers . entries ( ) ) { out . writeUTF ( entry . name ( ) ) ; out . writeStringArray ( entry . types ( ) ) ; if ( ( entry . source ( ) ) == null ) { out . writeBoolean ( false ) ; } else { out . writeBoolean ( true ) ; <START_BUG> out . writeBytesReference ( entry . source ( ) , true ) ; <END_BUG> } } } @ Override public IndexWarmersMetaData fromMap ( Map < String , Object > map ) throws IOException { } @ Override public IndexWarmersMetaData fromXContent ( XContentParser parser ) throws IOException { } @ Override public void toXContent ( IndexWarmersMetaData warmers , XContentBuilder builder , ToXContent . Params params ) throws IOException { } public void toXContent ( IndexWarmersMetaData . Entry entry , XContentBuilder builder , ToXContent . Params params ) throws IOException { } @ Override public IndexWarmersMetaData merge ( IndexWarmersMetaData first , IndexWarmersMetaData second ) { } } }<BUG2FIX>out . writeBytesReference ( entry . source ( ) ) ;
public class PixmapPackerTest extends GdxTest { OrthographicCamera camera ; SpriteBatch batch ; Texture texture ; TextureAtlas atlas ; @ Override public void create ( ) { batch = new SpriteBatch ( ) ; camera = new OrthographicCamera ( graphics . getWidth ( ) , graphics . getHeight ( ) ) ; camera . position . set ( ( ( graphics . getWidth ( ) ) / 2 ) , ( ( graphics . getHeight ( ) ) / 2 ) , 0 ) ; camera . update ( ) ; Pixmap pixmap1 = new Pixmap ( files . internal ( "data/badlogic.jpg" ) ) ; Pixmap pixmap2 = new Pixmap ( files . internal ( "data/wheel.png" ) ) ; Pixmap pixmap3 = new Pixmap ( files . internal ( "data/egg.png" ) ) ; PixmapPacker packer = new PixmapPacker ( 1024 , 1024 , Format . RGBA8888 , 2 , true ) ; packer . pack ( "badlogic" , pixmap1 ) ; packer . pack ( "wheel" , pixmap1 ) ; packer . pack ( "egg" , pixmap1 ) ; pixmap1 . dispose ( ) ; pixmap2 . dispose ( ) ; pixmap3 . dispose ( ) ; atlas = packer . generateTextureAtlas ( Nearest , Nearest , false ) ; <START_BUG> app . log ( "PixmaPackerTest" , ( "Number<seq2seq4repair_space>of<seq2seq4repair_space>textures:<seq2seq4repair_space>" + ( atlas . getTextures ( ) . size ) ) ) ; <END_BUG> } @ Override public void render ( ) { } @ Override public void dispose ( ) { } }<BUG2FIX>app . log ( "PixmaPackerTest" , ( "Number<seq2seq4repair_space>of<seq2seq4repair_space>textures:<seq2seq4repair_space>" + ( atlas . getTextures ( ) . size ( ) ) ) ) ;
public class ComplexActionTest extends GdxTest { Stage stage ; Texture texture ; @ Override public void create ( ) { <START_BUG> stage = new Stage ( 480 , 320 , true ) ; <END_BUG> Action complexAction = forever ( sequence ( parallel ( rotateBy ( 180 , 2 ) , scaleTo ( 1.4F , 1.4F , 2 ) , alpha ( 0.7F , 2 ) ) , parallel ( rotateBy ( 180 , 2 ) , scaleTo ( 1.0F , 1.0F , 2 ) , alpha ( 1.0F , 2 ) ) ) ) ; texture = new Texture ( files . internal ( "data/badlogic.jpg" ) , false ) ; texture . setFilter ( Linear , Linear ) ; final Image img1 = new Image ( new com . badlogic . gdx . graphics . g2d . TextureRegion ( texture ) ) ; img1 . setSize ( 100 , 100 ) ; img1 . setOrigin ( 50 , 50 ) ; img1 . setPosition ( 50 , 50 ) ; final Image img2 = new Image ( new com . badlogic . gdx . graphics . g2d . TextureRegion ( texture ) ) ; img2 . setSize ( 50 , 50 ) ; img2 . setOrigin ( 50 , 50 ) ; img2 . setPosition ( 150 , 150 ) ; stage . addActor ( img1 ) ; stage . addActor ( img2 ) ; img1 . addAction ( complexAction ) ; } @ Override public void render ( ) { } @ Override public void dispose ( ) { } }<BUG2FIX>stage = new Stage ( ) ;
public class TransportTypesExistsAction extends TransportMasterNodeReadOperationAction < TypesExistsRequest , TypesExistsResponse > { @ Inject public TransportTypesExistsAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected TypesExistsRequest newRequest ( ) { } @ Override protected TypesExistsResponse newResponse ( ) { } @ Override protected ClusterBlockException checkBlock ( TypesExistsRequest request , ClusterState state ) { } @ Override protected void masterOperation ( final TypesExistsRequest request , final ClusterState state , final ActionListener < TypesExistsResponse > listener ) throws ElasticsearchException { <START_BUG> String [ ] concreteIndices = state . metaData ( ) . concreteIndices ( request . indices ( ) , request . indicesOptions ( ) ) ; <END_BUG> if ( ( concreteIndices . length ) == 0 ) { listener . onResponse ( new TypesExistsResponse ( false ) ) ; return ; } for ( String concreteIndex : concreteIndices ) { if ( ! ( state . metaData ( ) . hasConcreteIndex ( concreteIndex ) ) ) { listener . onResponse ( new TypesExistsResponse ( false ) ) ; return ; } ImmutableOpenMap < String , MappingMetaData > mappings = state . metaData ( ) . getIndices ( ) . get ( concreteIndex ) . mappings ( ) ; if ( mappings . isEmpty ( ) ) { listener . onResponse ( new TypesExistsResponse ( false ) ) ; return ; } for ( String type : request . types ( ) ) { if ( ! ( mappings . containsKey ( type ) ) ) { listener . onResponse ( new TypesExistsResponse ( false ) ) ; return ; } } } listener . onResponse ( new TypesExistsResponse ( true ) ) ; } }<BUG2FIX>String [ ] concreteIndices = state . metaData ( ) . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ;
public abstract class AbstractSimpleTranslogTests { protected final ShardId shardId = new ShardId ( new Index ( "index" ) , 1 ) ; protected Translog translog ; @ BeforeMethod public void setUp ( ) { } @ AfterMethod public void tearDown ( ) { } protected abstract Translog create ( ) { } @ Test public void testTransientTranslog ( ) { } @ Test public void testSimpleOperations ( ) { Translog . Snapshot snapshot = translog . snapshot ( ) ; assertThat ( snapshot , translogSize ( 0 ) ) ; snapshot . release ( ) ; translog . add ( new Translog . Create ( "test" , "1" , new byte [ ] { 1 } ) ) ; snapshot = translog . snapshot ( ) ; assertThat ( snapshot , translogSize ( 1 ) ) ; assertThat ( snapshot . estimatedTotalOperations ( ) , equalTo ( 1 ) ) ; snapshot . release ( ) ; translog . add ( new Translog . Index ( "test" , "2" , new byte [ ] { 2 } ) ) ; snapshot = translog . snapshot ( ) ; assertThat ( snapshot , translogSize ( 2 ) ) ; assertThat ( snapshot . estimatedTotalOperations ( ) , equalTo ( 2 ) ) ; snapshot . release ( ) ; translog . add ( new Translog . Delete ( newUid ( "3" ) ) ) ; snapshot = translog . snapshot ( ) ; assertThat ( snapshot , translogSize ( 3 ) ) ; assertThat ( snapshot . estimatedTotalOperations ( ) , equalTo ( 3 ) ) ; snapshot . release ( ) ; <START_BUG> translog . add ( new Translog . DeleteByQuery ( new byte [ ] { 4 } , null ) ) ; <END_BUG> snapshot = translog . snapshot ( ) ; assertThat ( snapshot , translogSize ( 4 ) ) ; assertThat ( snapshot . estimatedTotalOperations ( ) , equalTo ( 4 ) ) ; snapshot . release ( ) ; snapshot = translog . snapshot ( ) ; assertThat ( snapshot . hasNext ( ) , equalTo ( true ) ) ; Translog . Create create = ( ( Translog . Create ) ( snapshot . next ( ) ) ) ; assertThat ( create . source ( ) , equalTo ( new byte [ ] { 1 } ) ) ; assertThat ( snapshot . hasNext ( ) , equalTo ( true ) ) ; Translog . Index index = ( ( Translog . Index ) ( snapshot . next ( ) ) ) ; assertThat ( index . source ( ) , equalTo ( new byte [ ] { 2 } ) ) ; assertThat ( snapshot . hasNext ( ) , equalTo ( true ) ) ; Translog . Delete delete = ( ( Translog . Delete ) ( snapshot . next ( ) ) ) ; assertThat ( delete . uid ( ) , equalTo ( newUid ( "3" ) ) ) ; assertThat ( snapshot . hasNext ( ) , equalTo ( true ) ) ; Translog . DeleteByQuery deleteByQuery = ( ( Translog . DeleteByQuery ) ( snapshot . next ( ) ) ) ; assertThat ( deleteByQuery . source ( ) , equalTo ( new byte [ ] { 4 } ) ) ; assertThat ( snapshot . hasNext ( ) , equalTo ( false ) ) ; snapshot . release ( ) ; long firstId = translog . currentId ( ) ; translog . newTranslog ( 2 ) ; assertThat ( translog . currentId ( ) , Matchers . not ( equalTo ( firstId ) ) ) ; snapshot = translog . snapshot ( ) ; assertThat ( snapshot , translogSize ( 0 ) ) ; assertThat ( snapshot . estimatedTotalOperations ( ) , equalTo ( 0 ) ) ; snapshot . release ( ) ; } @ Test public void testSnapshot ( ) { } @ Test public void testSnapshotWithNewTranslog ( ) { } @ Test public void testSnapshotWithSeekForward ( ) { } private Term newUid ( String id ) { } }<BUG2FIX>translog . add ( new Translog . DeleteByQuery ( new byte [ ] { 4 } , null , null ) ) ;
public class MainMenu implements Screen { private final SpriteBatch spriteBatch ; private final Texture background ; private final Texture logo ; private final BitmapFont font ; private boolean isDone = false ; private final Matrix4 viewMatrix = new Matrix4 ( ) ; private final Matrix4 transformMatrix = new Matrix4 ( ) ; public MainMenu ( Application app ) { } @ Override public void render ( Application app ) { app . getGraphics ( ) . getGL10 ( ) . glClear ( GL_COLOR_BUFFER_BIT ) ; viewMatrix . setToOrtho2D ( 0 , 0 , 480 , 320 ) ; spriteBatch . setProjectionMatrix ( viewMatrix ) ; spriteBatch . setTransformMatrix ( transformMatrix ) ; spriteBatch . begin ( ) ; spriteBatch . disableBlending ( ) ; spriteBatch . setColor ( WHITE ) ; spriteBatch . draw ( background , 0 , 0 , 480 , 320 , 0 , 0 , 512 , 512 , false , false ) ; spriteBatch . enableBlending ( ) ; spriteBatch . draw ( logo , 0 , ( 320 - 128 ) , 480 , 128 , 0 , 0 , 512 , 256 , false , false ) ; spriteBatch . setBlendFunction ( GL_ONE , GL_ONE_MINUS_SRC_ALPHA ) ; String text = "Touch<seq2seq4repair_space>screen<seq2seq4repair_space>to<seq2seq4repair_space>start!" ; <START_BUG> int width = font . getBounds ( text ) . width ; <END_BUG> font . draw ( spriteBatch , text , ( 240 - ( width / 2 ) ) , 128 ) ; spriteBatch . end ( ) ; } @ Override public void update ( Application app ) { } @ Override public boolean isDone ( ) { } @ Override public void dispose ( ) { } }<BUG2FIX>float width = font . getBounds ( text ) . width ;
public class SpriteCacheTest extends GdxTest implements InputProcessor { int SPRITES = 400 / 2 ; long startTime = System . nanoTime ( ) ; int frames = 0 ; Texture texture ; Texture texture2 ; SpriteCache spriteCache ; int normalCacheID ; int spriteCacheID ; int renderMethod = 0 ; private float [ ] sprites ; private float [ ] sprites2 ; @ Override public void render ( ) { } private void renderNormal ( ) { } private void renderSprites ( ) { } @ Override public void create ( ) { <START_BUG> spriteCache = new SpriteCache ( 1000 ) ; <END_BUG> Pixmap pixmap = graphics . newPixmap ( files . getFileHandle ( "data/badlogicsmall.jpg" , Internal ) ) ; texture = graphics . newUnmanagedTexture ( 32 , 32 , RGB565 , Linear , Linear , ClampToEdge , ClampToEdge ) ; texture . draw ( pixmap , 0 , 0 ) ; pixmap . dispose ( ) ; pixmap = graphics . newPixmap ( 32 , 32 , RGBA8888 ) ; pixmap . setColor ( 1 , 1 , 0 , 0.5F ) ; pixmap . fill ( ) ; texture2 = graphics . newUnmanagedTexture ( pixmap , Nearest , Nearest , ClampToEdge , ClampToEdge ) ; pixmap . dispose ( ) ; sprites = new float [ ( SPRITES ) * 6 ] ; sprites2 = new float [ ( SPRITES ) * 6 ] ; Sprite [ ] sprites3 = new Sprite [ ( SPRITES ) * 2 ] ; for ( int i = 0 ; i < ( sprites . length ) ; i += 6 ) { sprites [ i ] = ( ( int ) ( ( Math . random ( ) ) * ( ( graphics . getWidth ( ) ) - 32 ) ) ) ; sprites [ ( i + 1 ) ] = ( ( int ) ( ( Math . random ( ) ) * ( ( graphics . getHeight ( ) ) - 32 ) ) ) ; sprites [ ( i + 2 ) ] = 0 ; sprites [ ( i + 3 ) ] = 0 ; sprites [ ( i + 4 ) ] = 32 ; sprites [ ( i + 5 ) ] = 32 ; sprites2 [ i ] = ( ( int ) ( ( Math . random ( ) ) * ( ( graphics . getWidth ( ) ) - 32 ) ) ) ; sprites2 [ ( i + 1 ) ] = ( ( int ) ( ( Math . random ( ) ) * ( ( graphics . getHeight ( ) ) - 32 ) ) ) ; sprites2 [ ( i + 2 ) ] = 0 ; sprites2 [ ( i + 3 ) ] = 0 ; sprites2 [ ( i + 4 ) ] = 32 ; sprites2 [ ( i + 5 ) ] = 32 ; } for ( int i = 0 ; i < ( ( SPRITES ) * 2 ) ; i ++ ) { int x = ( ( int ) ( ( Math . random ( ) ) * ( ( graphics . getWidth ( ) ) - 32 ) ) ) ; int y = ( ( int ) ( ( Math . random ( ) ) * ( ( graphics . getHeight ( ) ) - 32 ) ) ) ; if ( i >= ( SPRITES ) ) sprites3 [ i ] = new Sprite ( texture2 , 32 , 32 ) ; else sprites3 [ i ] = new Sprite ( texture , 32 , 32 ) ; sprites3 [ i ] . setPosition ( x , y ) ; sprites3 [ i ] . setOrigin ( 16 , 16 ) ; } float scale = 1 ; float angle = 15 ; spriteCache . beginCache ( ) ; for ( int i = 0 ; i < ( sprites2 . length ) ; i += 6 ) spriteCache . add ( texture2 , sprites2 [ i ] , sprites2 [ ( i + 1 ) ] , 16 , 16 , 32 , 32 , scale , scale , angle , 0 , 0 , 32 , 32 , WHITE , false , false ) ; for ( int i = 0 ; i < ( sprites . length ) ; i += 6 ) spriteCache . add ( texture , sprites [ i ] , sprites [ ( i + 1 ) ] , 16 , 16 , 32 , 32 , scale , scale , angle , 0 , 0 , 32 , 32 , WHITE , false , false ) ; normalCacheID = spriteCache . endCache ( ) ; angle = - 15 ; spriteCache . beginCache ( ) ; for ( int i = SPRITES ; i < ( ( SPRITES ) << 1 ) ; i ++ ) { sprites3 [ i ] . setRotation ( angle ) ; sprites3 [ i ] . setScale ( scale ) ; spriteCache . add ( sprites3 [ i ] ) ; } for ( int i = 0 ; i < ( SPRITES ) ; i ++ ) { sprites3 [ i ] . setRotation ( angle ) ; sprites3 [ i ] . setScale ( scale ) ; spriteCache . add ( sprites3 [ i ] ) ; } spriteCacheID = spriteCache . endCache ( ) ; input . setInputProcessor ( this ) ; } @ Override public boolean keyDown ( int keycode ) { } @ Override public boolean keyTyped ( char character ) { } @ Override public boolean keyUp ( int keycode ) { } @ Override public boolean touchDown ( int x , int y , int pointer ) { } @ Override public boolean touchDragged ( int x , int y , int pointer ) { }<BUG2FIX>spriteCache = new SpriteCache ( 1000 , true ) ;
public class GwtTestWrapper extends GdxTest { Stage ui ; Table container ; Skin skin ; BitmapFont font ; GdxTest test ; boolean dispose = false ; @ Override public void create ( ) { } public void render ( ) { } public void resize ( int width , int height ) { <START_BUG> ui . getViewport ( ) . update ( width , height ) ; <END_BUG> container . setSize ( width , height ) ; if ( ( test ) != null ) { test . resize ( width , height ) ; } } class InputWrapper extends InputAdapter implements Input { Input input ; InputProcessor lastProcessor ; InputMultiplexer multiplexer ; public InputWrapper ( Input input ) { } @ Override public float getAccelerometerX ( ) { } @ Override public float getAccelerometerY ( ) { } @ Override public float getAccelerometerZ ( ) { } @ Override public int getX ( ) { } @ Override public int getX ( int pointer ) { } @ Override public int getDeltaX ( ) { } @ Override public int getDeltaX ( int pointer ) { } @ Override public int getY ( ) { } @ Override public int getY ( int pointer ) { } @ Override public int getDeltaY ( ) { } @ Override public int getDeltaY ( int pointer ) { } @ Override public boolean isTouched ( ) { } @ Override public boolean justTouched ( ) { } @ Override public boolean isTouched ( int pointer ) { } @ Override public boolean isButtonPressed ( int button ) { } @ Override public boolean isKeyPressed ( int key ) { } @ Override public void getTextInput ( TextInputListener listener , String title , String text ) { } @ Override public void getPlaceholderTextInput ( TextInputListener listener , String title , String placeholder ) { } @ Override public void setOnscreenKeyboardVisible ( boolean visible ) { } @ Override public void vibrate ( int milliseconds ) { } @ Override public void vibrate ( long [ ] pattern , int repeat ) { } @ Override public void cancelVibrate ( ) { } @ Override public float getAzimuth ( ) { } @ Override public float getPitch ( ) { } @ Override public float getRoll ( ) { } @ Override public void getRotationMatrix ( float [ ] matrix ) { } @ Override public long getCurrentEventTime ( ) { } @ Override public void setCatchBackKey ( boolean catchBack ) { } @ Override public void setCatchMenuKey ( boolean catchMenu ) { } @ Override public void setInputProcessor ( InputProcessor processor ) { } @ Override public InputProcessor getInputProcessor ( ) { } @ Override public boolean isPeripheralAvailable ( Peripheral peripheral ) { } @ Override public int getRotation ( ) { } @ Override public Orientation getNativeOrientation ( ) { } @ Override public void setCursorCatched ( boolean catched ) { } @ Override public boolean isCursorCatched ( ) { } @ Override public void setCursorPosition ( int x , int y ) { } @ Override public void setCursorImage ( Pixmap pixmap , int xHotspot , int yHotspot ) { } } interface Instancer { public GdxTest instance ( ) { } } GwtTestWrapper . Instancer [ ] tests = new GwtTestWrapper . Instancer [ ] { new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } } , new GwtTestWrapper . Instancer ( ) { public GdxTest instance ( ) { } }<BUG2FIX>ui . getViewport ( ) . update ( width , height , true ) ;
public class RepoBrowseActivity extends RoboFragmentActivity { private static final int VERSION_RECENT_REPOS = 2 ; private static final String FILE_RECENT_REPOS = "recent_repos.ser" ; private static final int MAX_RECENT_REPOS = 5 ; public static Intent createIntent ( User user ) { } private LinkedHashSet < String > recentRepos ; @ InjectExtra ( EXTRA_USER ) private User user ; @ Inject private AvatarHelper avatarHelper ; private RepoListFragment repoFragment ; @ Override protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; setContentView ( repo_list ) ; <START_BUG> setTitle ( getString ( repositories_title ) ) ; <END_BUG> ( ( TextView ) ( findViewById ( tv_org_name ) ) ) . setText ( user . getLogin ( ) ) ; avatarHelper . bind ( ( ( ImageView ) ( findViewById ( iv_gravatar ) ) ) , user ) ; recentRepos = new RequestReader ( getRecentReposFile ( ) , RepoBrowseActivity . VERSION_RECENT_REPOS ) . read ( ) ; if ( ( recentRepos ) == null ) recentRepos = new LinkedHashSet < String > ( ) ; OnItemClickListener repoClickListener = new OnItemClickListener ( ) { public void onItemClick ( AdapterView < ? > view , View arg1 , int position , long id ) { Repository repo = ( ( Repository ) ( view . getItemAtPosition ( position ) ) ) ; Iterator < String > iter = recentRepos . iterator ( ) ; String repoId = repo . generateId ( ) ; while ( iter . hasNext ( ) ) if ( repoId . equals ( iter . next ( ) ) ) iter . remove ( ) ; if ( ( recentRepos . size ( ) ) == ( RepoBrowseActivity . MAX_RECENT_REPOS ) ) while ( iter . hasNext ( ) ) { iter . next ( ) ; if ( ! ( iter . hasNext ( ) ) ) iter . remove ( ) ; } recentRepos . add ( repoId ) ; startActivity ( IssueBrowseActivity . createIntent ( repo ) ) ; } } ; repoFragment = ( ( RepoListFragment ) ( getSupportFragmentManager ( ) . findFragmentById ( list ) ) ) ; if ( ( repoFragment ) == null ) { repoFragment = new RepoListFragment ( ) ; getSupportFragmentManager ( ) . beginTransaction ( ) . add ( list , repoFragment ) . commit ( ) ; } repoFragment . setRecent ( recentRepos ) . setClickListener ( repoClickListener ) ; } @ Override protected void onResume ( ) { } private File getRecentReposFile ( ) { } @ Override protected void onStop ( ) { } }<BUG2FIX>setTitle ( repositories_title ) ;
public final class BytesRefValComparator extends NestedWrappableComparator < BytesRef > { private final IndexFieldData < ? > indexFieldData ; private final SortMode sortMode ; private final BytesRef missingValue ; private final BytesRef [ ] values ; private BytesRef bottom ; private BytesValues docTerms ; BytesRefValComparator ( IndexFieldData < ? > indexFieldData , int numHits , SortMode sortMode , BytesRef missingValue ) { } @ Override public int compare ( int slot1 , int slot2 ) { } @ Override public int compareBottom ( int doc ) throws IOException { } @ Override public void copy ( int slot , int doc ) throws IOException { } @ Override public FieldComparator < BytesRef > setNextReader ( AtomicReaderContext context ) throws IOException { <START_BUG> docTerms = indexFieldData . load ( context ) . getBytesValues ( ) ; <END_BUG> if ( docTerms . isMultiValued ( ) ) { docTerms = new BytesRefValComparator . MultiValuedBytesWrapper ( docTerms , sortMode ) ; } return this ; } @ Override public void setBottom ( final int bottom ) { } @ Override public BytesRef value ( int slot ) { } @ Override public int compareValues ( BytesRef val1 , BytesRef val2 ) { } @ Override public int compareDocToValue ( int doc , BytesRef value ) { } private static final class MultiValuedBytesWrapper extends FilterBytesValues { private final SortMode sortMode ; private int numValues ; public MultiValuedBytesWrapper ( BytesValues delegate , SortMode sortMode ) { } @ Override public BytesRef getValue ( int docId ) { } public int setDocument ( int docId ) { } public BytesRef nextValue ( ) { } } @ Override public void missing ( int slot ) { } @ Override public int compareBottomMissing ( ) { } }<BUG2FIX>docTerms = indexFieldData . load ( context ) . getBytesValues ( false ) ;
public class RestIndexAction extends BaseRestHandler { @ Inject public RestIndexAction ( Settings settings , Client client , RestController controller ) { } final class CreateHandler implements RestHandler { @ Override public void handleRequest ( RestRequest request , RestChannel channel ) { request . params ( ) . put ( "op_type" , "create" ) ; RestIndexAction . this . handleRequest ( request , channel ) ; } } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { IndexRequest indexRequest = new IndexRequest ( request . param ( "index" ) , request . param ( "type" ) , request . param ( "id" ) ) ; indexRequest . listenerThreaded ( false ) ; indexRequest . operationThreaded ( true ) ; indexRequest . routing ( request . param ( "routing" ) ) ; indexRequest . parent ( request . param ( "parent" ) ) ; indexRequest . timestamp ( request . param ( "timestamp" ) ) ; if ( request . hasParam ( "ttl" ) ) { indexRequest . ttl ( request . paramAsTime ( "ttl" , null ) . millis ( ) ) ; } indexRequest . source ( request . content ( ) , request . contentUnsafe ( ) ) ; indexRequest . timeout ( request . paramAsTime ( "timeout" , DEFAULT_TIMEOUT ) ) ; indexRequest . refresh ( request . paramAsBoolean ( "refresh" , indexRequest . refresh ( ) ) ) ; indexRequest . version ( RestActions . parseVersion ( request ) ) ; indexRequest . versionType ( VersionType . fromString ( request . param ( "version_type" ) , indexRequest . versionType ( ) ) ) ; indexRequest . percolate ( request . param ( "percolate" , null ) ) ; String sOpType = request . param ( "op_type" ) ; if ( sOpType != null ) { if ( "index" . equals ( sOpType ) ) { indexRequest . opType ( INDEX ) ; } else if ( "create" . equals ( sOpType ) ) { indexRequest . opType ( CREATE ) ; } else { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; channel . sendResponse ( new XContentRestResponse ( request , BAD_REQUEST , builder . startObject ( ) . field ( "error" , ( ( "opType<seq2seq4repair_space>[" + sOpType ) + "]<seq2seq4repair_space>not<seq2seq4repair_space>allowed,<seq2seq4repair_space>either<seq2seq4repair_space>[index]<seq2seq4repair_space>or<seq2seq4repair_space>[create]<seq2seq4repair_space>are<seq2seq4repair_space>allowed" ) ) . endObject ( ) ) ) ; } catch ( IOException e1 ) { logger . warn ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>response" , e1 ) ; return ; } } } String replicationType = request . param ( "replication" ) ; if ( replicationType != null ) { indexRequest . replicationType ( ReplicationType . fromString ( replicationType ) ) ; } String consistencyLevel = request . param ( "consistency" ) ; if ( consistencyLevel != null ) { indexRequest . consistencyLevel ( WriteConsistencyLevel . fromString ( consistencyLevel ) ) ; } client . index ( indexRequest , new org . elasticsearch . action . ActionListener < IndexResponse > ( ) { @ Override public void onResponse ( IndexResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) . field ( RestIndexAction . Fields . OK , true ) . field ( RestIndexAction . Fields . _INDEX , response . getIndex ( ) ) . field ( RestIndexAction . Fields . _TYPE , response . getType ( ) ) . field ( RestIndexAction . Fields . _ID , response . getId ( ) ) . field ( RestIndexAction . Fields . _VERSION , response . getVersion ( ) ) ; if ( ( response . getMatches ( ) ) != null ) { builder . startArray ( RestIndexAction . Fields . MATCHES ) ; for ( String match : response . getMatches ( ) ) { builder . value ( match ) ; } builder . endArray ( ) ; } builder . endObject ( ) ; RestStatus . RestStatus status = OK ; if ( ( response . getVersion ( ) ) == 1 ) { status = CREATED ; } channel . sendResponse ( new XContentRestResponse ( request , status , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } static final class Fields { static final XContentBuilderString OK = new XContentBuilderString ( "ok" ) ; static final XContentBuilderString _INDEX = new XContentBuilderString ( "_index" ) ; static final XContentBuilderString _TYPE = new XContentBuilderString ( "_type" ) ; static final XContentBuilderString _ID = new XContentBuilderString ( "_id" ) ; static final XContentBuilderString _VERSION = new XContentBuilderString ( "_version" ) ; static final XContentBuilderString MATCHES = new XContentBuilderString ( "matches" ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class ObjectFloatMap < K > { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; public int size ; K [ ] keyTable ; float [ ] valueTable ; int capacity ; int stashSize ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private ObjectFloatMap . Entries entries1 ; private ObjectFloatMap . Entries entries2 ; private ObjectFloatMap . Values values1 ; private ObjectFloatMap . Values values2 ; private ObjectFloatMap . Keys keys1 ; private ObjectFloatMap . Keys keys2 ; public ObjectFloatMap ( ) { } public ObjectFloatMap ( int initialCapacity ) { } public ObjectFloatMap ( int initialCapacity , float loadFactor ) { } public ObjectFloatMap ( ObjectFloatMap < ? extends K > map ) { } public void put ( K key , float value ) { } public void putAll ( ObjectFloatMap < K > map ) { } private void putResize ( K key , float value ) { } private void push ( K insertKey , float insertValue , int index1 , K key1 , int index2 , K key2 , int index3 , K key3 ) { } private void putStash ( K key , float value ) { } public float get ( K key , float defaultValue ) { } private float getStash ( K key , float defaultValue ) { } public float getAndIncrement ( K key , float defaultValue , float increment ) { } private float getAndIncrementStash ( K key , float defaultValue , float increment ) { } public float remove ( K key , float defaultValue ) { } float removeStash ( K key , float defaultValue ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean containsValue ( float value ) { } public boolean containsKey ( K key ) { } private boolean containsKeyStash ( K key ) { } public K findKey ( float value ) { } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( int h ) { } private int hash3 ( int h ) { } public String toString ( ) { } public ObjectFloatMap . Entries < K > entries ( ) { } public ObjectFloatMap . Values values ( ) { } public ObjectFloatMap . Keys < K > keys ( ) { } public static class Entry < K > { public K key ; public float value ; public String toString ( ) { } } private static class MapIterator < K > { public boolean hasNext ; final ObjectFloatMap < K > map ; int nextIndex ; int currentIndex ; boolean valid = true ; public MapIterator ( ObjectFloatMap < K > map ) { } public void reset ( ) { } void findNextIndex ( ) { } public void remove ( ) { if ( ( currentIndex ) < 0 ) throw new IllegalStateException ( "next<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>called<seq2seq4repair_space>before<seq2seq4repair_space>remove." ) ; if ( ( currentIndex ) >= ( map . capacity ) ) { map . removeStashIndex ( currentIndex ) ; <START_BUG> nextIndex = ( currentIndex ) - 1 ; <END_BUG> findNextIndex ( ) ; } else { map . keyTable [ currentIndex ] = null ; } currentIndex = - 1 ; ( map . size ) -- ; } } public static class Entries < K > extends ObjectFloatMap . MapIterator < K > implements Iterable < ObjectFloatMap . Entry < K > > , Iterator < ObjectFloatMap . Entry < K > > { private ObjectFloatMap . Entry < K > entry = new ObjectFloatMap . Entry ( ) ; public Entries ( ObjectFloatMap < K > map ) { } public ObjectFloatMap . Entry < K > next ( ) { } public boolean hasNext ( ) { } public Iterator < ObjectFloatMap . Entry < K > > iterator ( ) { } } public static class Values extends ObjectFloatMap . MapIterator < Object > { public Values ( ObjectFloatMap < ? > map ) { } public boolean hasNext ( ) { } public float next ( ) { } public FloatArray toArray ( ) { } } public static class Keys < K > extends ObjectFloatMap . MapIterator < K > implements Iterable < K > , Iterator < K > { public Keys ( ObjectFloatMap < K > map ) { } public boolean hasNext ( ) { } public K next ( ) { } public Iterator < K > iterator ( ) { } public Array < K > toArray ( ) { } } }<BUG2FIX>nextIndex = currentIndex ;
public class FilesTest extends GdxTest { String message = "" ; boolean success ; BitmapFont font ; SpriteBatch batch ; @ Override public void create ( ) { } private void testClasspath ( ) throws IOException { } private void testInternal ( ) throws IOException { } private void testExternal ( ) throws IOException { } private void testAbsolute ( ) throws IOException { } private void testLocal ( ) throws IOException { String path = "meow" ; FileHandle handle = files . local ( path ) ; handle . delete ( ) ; if ( handle . exists ( ) ) fail ( ) ; if ( handle . isDirectory ( ) ) fail ( ) ; if ( handle . delete ( ) ) fail ( ) ; if ( ( handle . list ( ) . length ) != 0 ) fail ( ) ; if ( handle . child ( "meow" ) . exists ( ) ) fail ( ) ; <START_BUG> if ( ! ( handle . parent ( ) . exists ( ) ) ) <END_BUG> fail ( ) ; try { handle . read ( ) . close ( ) ; fail ( ) ; } catch ( Exception ignored ) { } handle . mkdirs ( ) ; if ( ! ( handle . exists ( ) ) ) fail ( ) ; if ( ! ( handle . isDirectory ( ) ) ) fail ( ) ; if ( ( handle . list ( ) . length ) != 0 ) fail ( ) ; handle . child ( "meow" ) . mkdirs ( ) ; if ( ( handle . list ( ) . length ) != 1 ) fail ( ) ; FileHandle child = handle . list ( ) [ 0 ] ; if ( ! ( child . name ( ) . equals ( "meow" ) ) ) fail ( ) ; if ( ! ( child . parent ( ) . exists ( ) ) ) fail ( ) ; if ( ! ( handle . deleteDirectory ( ) ) ) fail ( ) ; if ( handle . exists ( ) ) fail ( ) ; OutputStream output = handle . write ( false ) ; output . write ( "moo" . getBytes ( ) ) ; output . close ( ) ; if ( ! ( handle . exists ( ) ) ) fail ( ) ; if ( ( handle . length ( ) ) != 3 ) fail ( ) ; FileHandle copy = files . local ( ( path + "-copy" ) ) ; copy . delete ( ) ; if ( copy . exists ( ) ) fail ( ) ; handle . copyTo ( copy ) ; if ( ! ( copy . exists ( ) ) ) fail ( ) ; if ( ( copy . length ( ) ) != 3 ) fail ( ) ; FileHandle move = files . local ( ( path + "-move" ) ) ; move . delete ( ) ; if ( move . exists ( ) ) fail ( ) ; copy . moveTo ( move ) ; if ( ! ( move . exists ( ) ) ) fail ( ) ; if ( ( move . length ( ) ) != 3 ) fail ( ) ; move . deleteDirectory ( ) ; if ( move . exists ( ) ) fail ( ) ; InputStream input = handle . read ( ) ; byte [ ] bytes = new byte [ 6 ] ; if ( ( input . read ( bytes ) ) != 3 ) fail ( ) ; input . close ( ) ; if ( ! ( new String ( bytes , 0 , 3 ) . equals ( "moo" ) ) ) fail ( ) ; output = handle . write ( true ) ; output . write ( "cow" . getBytes ( ) ) ; output . close ( ) ; if ( ( handle . length ( ) ) != 6 ) fail ( ) ; input = handle . read ( ) ; if ( ( input . read ( bytes ) ) != 6 ) fail ( ) ; input . close ( ) ; if ( ! ( new String ( bytes , 0 , 6 ) . equals ( "moocow" ) ) ) fail ( ) ; if ( handle . isDirectory ( ) ) fail ( ) ; if ( ( handle . list ( ) . length ) != 0 ) fail ( ) ; if ( ! ( handle . name ( ) . equals ( "meow" ) ) ) fail ( ) ; if ( ! ( handle . nameWithoutExtension ( ) . equals ( "meow" ) ) ) fail ( ) ; if ( ! ( handle . extension ( ) . equals ( "" ) ) ) fail ( ) ; handle . deleteDirectory ( ) ; if ( handle . exists ( ) ) fail ( ) ; if ( handle . isDirectory ( ) ) fail ( ) ; handle . delete ( ) ; handle . deleteDirectory ( ) ; } private void fail ( ) { } private void fail ( String msg ) { } @ Override public void render ( ) { } @ Override public void dispose ( ) { } @ Override public boolean needsGL20 ( ) { } }<BUG2FIX>if ( handle . parent ( ) . exists ( ) )
final class LwjglAudio implements Audio , Runnable { private SourceDataLine line ; private final List < LwjglAudio . LwjglSoundBuffer > buffers = new ArrayList < LwjglAudio . LwjglSoundBuffer > ( ) ; private Thread thread ; private volatile boolean run = false ; class LwjglSoundBuffer { private final float [ ] samples ; private final AudioFormat format ; private final float volume ; private int writtenSamples = 0 ; public LwjglSoundBuffer ( LwjglSound sound , float volume ) throws Exception { } public boolean writeSamples ( int numSamples , float [ ] buffer ) { } } LwjglAudio ( ) { } public AudioDevice newAudioDevice ( boolean isMono ) { } public Music newMusic ( FileHandle file ) { try { LwjglMusic music = new LwjglMusic ( ( ( LwjglFileHandle ) ( file ) ) ) ; return music ; <START_BUG> } catch ( Exception e ) { <END_BUG> throw new com . badlogic . gdx . utils . GdxRuntimeException ( ( ( "Couldn't<seq2seq4repair_space>create<seq2seq4repair_space>Music<seq2seq4repair_space>instance<seq2seq4repair_space>from<seq2seq4repair_space>file<seq2seq4repair_space>'" + file ) + "'" ) , e ) ; } } public Sound newSound ( FileHandle file ) { } protected void enqueueSound ( LwjglSound sound , float volume ) { } public void run ( ) { } private void fillBuffer ( float [ ] buffer , byte [ ] bytes , int samplesToWrite ) { } public AudioRecorder newAudioRecoder ( int samplingRate , boolean isMono ) { } void dispose ( ) { } }<BUG2FIX>} catch ( Throwable e ) {
public class TextureBindTest extends GdxTest { Texture tex1 ; Texture tex2 ; Mesh mesh ; ShaderProgram shader ; Array < Vector2 > positions = new Array < Vector2 > ( ) ; Camera cam ; public void create ( ) { } public void render ( ) { } @ Override public boolean needsGL20 ( ) { <START_BUG> return false ; <END_BUG> } }<BUG2FIX>return true ;
public class IndicesFilterCache extends AbstractComponent implements RemovalListener < WeightedFilterCache . FilterCacheKey , DocIdSet > { private final ThreadPool threadPool ; private final CacheRecycler cacheRecycler ; private Cache < WeightedFilterCache . FilterCacheKey , DocIdSet > cache ; private volatile String size ; private volatile long sizeInBytes ; private volatile TimeValue expire ; private final TimeValue cleanInterval ; private final Set < Object > readersKeysToClean = ConcurrentCollections . newConcurrentSet ( ) ; private volatile boolean closed ; public static final String INDICES_CACHE_FILTER_SIZE = "indices.cache.filter.size" ; public static final String INDICES_CACHE_FILTER_EXPIRE = "indices.cache.filter.expire" ; class ApplySettings implements NodeSettingsService . Listener { @ Override public void onRefreshSettings ( Settings settings ) { } } @ Inject public IndicesFilterCache ( Settings settings , ThreadPool threadPool , CacheRecycler cacheRecycler , NodeSettingsService nodeSettingsService ) { } private void buildCache ( ) { } private void computeSizeInBytes ( ) { } public void addReaderKeyToClean ( Object readerKey ) { } public void close ( ) { } public Cache < WeightedFilterCache . FilterCacheKey , DocIdSet > cache ( ) { } @ Override public void onRemoval ( RemovalNotification < WeightedFilterCache . FilterCacheKey , DocIdSet > removalNotification ) { } class ReaderCleaner implements Runnable { @ Override public void run ( ) { if ( closed ) { return ; } if ( readersKeysToClean . isEmpty ( ) ) { schedule ( ) ; return ; } try { threadPool . executor ( GENERIC ) . execute ( new Runnable ( ) { @ Override public void run ( ) { Recycler . V < ObjectOpenHashSet < Object > > keys = cacheRecycler . hashSet ( ( - 1 ) ) ; try { for ( Iterator < Object > it = readersKeysToClean . iterator ( ) ; it . hasNext ( ) ; ) { keys . v ( ) . add ( it . next ( ) ) ; it . remove ( ) ; } cache . cleanUp ( ) ; if ( ! ( keys . v ( ) . isEmpty ( ) ) ) { for ( Iterator < WeightedFilterCache . FilterCacheKey > it = cache . asMap ( ) . keySet ( ) . iterator ( ) ; it . hasNext ( ) ; ) { WeightedFilterCache . FilterCacheKey filterCacheKey = it . next ( ) ; if ( keys . v ( ) . contains ( filterCacheKey . readerKey ( ) ) ) { it . remove ( ) ; } } } schedule ( ) ; } finally { <START_BUG> keys . release ( ) ; <END_BUG> } } } ) ; } catch ( EsRejectedExecutionException ex ) { logger . debug ( "Can<seq2seq4repair_space>not<seq2seq4repair_space>run<seq2seq4repair_space>ReaderCleaner<seq2seq4repair_space>-<seq2seq4repair_space>execution<seq2seq4repair_space>rejected" , ex ) ; } } private void schedule ( ) { } } }<BUG2FIX>keys . close ( ) ;
public abstract class GwtApplication implements Application , EntryPoint { private ApplicationListener listener ; private GwtApplicationConfiguration config ; private GwtGraphics graphics ; private Panel root = null ; private TextArea log = null ; private int logLevel = LOG_ERROR ; private Array < Runnable > runnables = new Array < Runnable > ( ) ; private int lastWidth ; private int lastHeight ; private Preloader preloader ; private static GwtApplication . AgentInfo agentInfo ; private ObjectMap < String , Preferences > prefs = new ObjectMap < String , Preferences > ( ) ; @ Override public void onModuleLoad ( ) { } private void setupLoop ( ) { } public abstract GwtApplicationConfiguration getConfig ( ) { } public abstract ApplicationListener getApplicationListener ( ) { } public Panel getRootPanel ( ) { } public PreloaderCallback getPreloaderCallback ( ) { } @ Override public Graphics getGraphics ( ) { } @ Override public Audio getAudio ( ) { } @ Override public Input getInput ( ) { } @ Override public Files getFiles ( ) { } private void checkLogLabel ( ) { } @ Override public void log ( String tag , String message ) { } @ Override public void log ( String tag , String message , Exception exception ) { } @ Override public void error ( String tag , String message ) { } @ Override public void error ( String tag , String message , Throwable exception ) { } @ Override public void debug ( String tag , String message ) { } @ Override public void debug ( String tag , String message , Throwable exception ) { } private String getStackTrace ( Throwable e ) { } @ Override public void setLogLevel ( int logLevel ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } @ Override public Preferences getPreferences ( String name ) { Preferences pref = prefs . get ( name ) ; if ( pref == null ) { <START_BUG> pref = new GwtPreferences ( ) ; <END_BUG> prefs . put ( name , pref ) ; } return pref ; } @ Override public void postRunnable ( Runnable runnable ) { } @ Override public void exit ( ) { } public static GwtApplication . AgentInfo agentInfo ( ) { } private static native GwtApplication . AgentInfo computeAgentInfo ( ) { } public static class AgentInfo extends JavaScriptObject { public final native boolean isFirefox ( ) { } public final native boolean isChrome ( ) { } public final native boolean isSafari ( ) { } public final native boolean isOpera ( ) { } public final native boolean isIE ( ) { } public final native boolean isMacOS ( ) { } public final native boolean isLinux ( ) { } public final native boolean isWindows ( ) { } protected AgentInfo ( ) { } } }<BUG2FIX>pref = new GwtPreferences ( name ) ;
public void setElementType ( Class type , String fieldName , Class elementType ) { } private ObjectMap < String , Json . FieldMetadata > cacheFields ( Class type ) { } public String toJson ( Object object ) { } public String toJson ( Object object , Class knownType ) { } public String toJson ( Object object , Class knownType , Class elementType ) { } public void toJson ( Object object , FileHandle file ) { } public void toJson ( Object object , Class knownType , FileHandle file ) { } public void toJson ( Object object , Class knownType , Class elementType , FileHandle file ) { } public void toJson ( Object object , Writer writer ) { } public void toJson ( Object object , Class knownType , Writer writer ) { } public void toJson ( Object object , Class knownType , Class elementType , Writer writer ) { } public void setWriter ( Writer writer ) { } public JsonWriter getWriter ( ) { } public void writeFields ( Object object ) { } private Object [ ] getDefaultValues ( Class type ) { } public void writeField ( Object object , String name ) { } public void writeField ( Object object , String name , Class elementType ) { } public void writeField ( Object object , String fieldName , String jsonName ) { } public void writeField ( Object object , String fieldName , String jsonName , Class elementType ) { } public void writeValue ( String name , Object value ) { } public void writeValue ( String name , Object value , Class knownType ) { } public void writeValue ( String name , Object value , Class knownType , Class elementType ) { } public void writeValue ( Object value ) { } public void writeValue ( Object value , Class knownType ) { } public void writeValue ( Object value , Class knownType , Class elementType ) { try { if ( value == null ) { writer . value ( null ) ; return ; } if ( ( ( ( ( ( ( ( ( ( ( knownType != null ) && ( knownType . isPrimitive ( ) ) ) || ( knownType == ( String . class ) ) ) || ( knownType == ( Integer . class ) ) ) || ( knownType == ( Boolean . class ) ) ) || ( knownType == ( Float . class ) ) ) || ( knownType == ( Long . class ) ) ) || ( knownType == ( Double . class ) ) ) || ( knownType == ( Short . class ) ) ) || ( knownType == ( Byte . class ) ) ) || ( knownType == ( Character . class ) ) ) { writer . value ( value ) ; return ; } Class actualType = value . getClass ( ) ; if ( ( ( ( ( ( ( ( ( ( actualType . isPrimitive ( ) ) || ( actualType == ( String . class ) ) ) || ( actualType == ( Integer . class ) ) ) || ( actualType == ( Boolean . class ) ) ) || ( actualType == ( Float . class ) ) ) || ( actualType == ( Long . class ) ) ) || ( actualType == ( Double . class ) ) ) || ( actualType == ( Short . class ) ) ) || ( actualType == ( Byte . class ) ) ) || ( actualType == ( Character . class ) ) ) { writeObjectStart ( actualType , null ) ; writeValue ( "value" , value ) ; writeObjectEnd ( ) ; return ; } if ( value instanceof Json . Serializable ) { writeObjectStart ( actualType , knownType ) ; ( ( Json . Serializable ) ( value ) ) . write ( this ) ; writeObjectEnd ( ) ; return ; } Json . Serializer serializer = classToSerializer . get ( actualType ) ; if ( serializer != null ) { serializer . write ( this , value , knownType ) ; return ; } if ( value instanceof Array ) { <START_BUG> if ( ( ( knownType != null ) && ( actualType != knownType ) ) && ( actualType != ( Array . class ) ) ) <END_BUG> throw new SerializationException ( ( ( ( ( "Serialization<seq2seq4repair_space>of<seq2seq4repair_space>an<seq2seq4repair_space>Array<seq2seq4repair_space>other<seq2seq4repair_space>than<seq2seq4repair_space>the<seq2seq4repair_space>known<seq2seq4repair_space>type<seq2seq4repair_space>is<seq2seq4repair_space>not<seq2seq4repair_space>supported.\n" + "Known<seq2seq4repair_space>type:<seq2seq4repair_space>" ) + knownType ) + "\nActual<seq2seq4repair_space>type:<seq2seq4repair_space>" ) + actualType ) ) ; writeArrayStart ( ) ; Array array = ( ( Array ) ( value ) ) ; for ( int i = 0 , n = array . size ; i < n ; i ++ ) writeValue ( array . get ( i ) , elementType , null ) ; writeArrayEnd ( ) ; return ; } if ( value instanceof Collection ) { if ( ( ( knownType != null ) && ( actualType != knownType ) ) && ( actualType != ( ArrayList . class ) ) ) throw new SerializationException ( ( ( ( ( "Serialization<seq2seq4repair_space>of<seq2seq4repair_space>a<seq2seq4repair_space>Collection<seq2seq4repair_space>other<seq2seq4repair_space>than<seq2seq4repair_space>the<seq2seq4repair_space>known<seq2seq4repair_space>type<seq2seq4repair_space>is<seq2seq4repair_space>not<seq2seq4repair_space>supported.\n" + "Known<seq2seq4repair_space>type:<seq2seq4repair_space>" ) + knownType ) + "\nActual<seq2seq4repair_space>type:<seq2seq4repair_space>" ) + actualType ) ) ; writeArrayStart ( ) ; for ( Object item : ( ( Collection ) ( value ) ) ) writeValue ( item , elementType , null ) ; writeArrayEnd ( ) ; return ; } if ( actualType . isArray ( ) ) { if ( elementType == null ) elementType = actualType . getComponentType ( ) ; int length = java . lang . reflect . Array . getLength ( value ) ; writeArrayStart ( ) ; for ( int i = 0 ; i < length ; i ++ ) writeValue ( java . lang . reflect . Array . get ( value , i ) , elementType , null ) ; writeArrayEnd ( ) ; return ;<BUG2FIX>if ( ( knownType != null ) && ( actualType != knownType ) )
public interface Indexer extends IndexerComponent { <START_BUG> void close ( boolean delete ) ; <END_BUG> }<BUG2FIX>void close ( ) ;
public class RepoListFragment extends ItemListFragment < Repository > implements OrganizationSelectionListener { @ Inject private AccountDataManager cache ; private final AtomicReference < User > org = new AtomicReference < User > ( ) ; private final AtomicReference < RecentRepositories > recentRepos = new AtomicReference < RecentRepositories > ( ) ; @ Override public void onAttach ( Activity activity ) { } @ Override public void onOrganizationSelected ( final User organization ) { } @ Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; setEmptyText ( getString ( no_repositories ) ) ; <START_BUG> ListViewUtils . configure ( getActivity ( ) , getListView ( ) , true ) ; <END_BUG> } @ Override public void onListItemClick ( ListView list , View v , int position , long id ) { } @ Override public void onStop ( ) { } @ Override public Loader < List < Repository > > onCreateLoader ( int id , final Bundle args ) { } @ Override protected ItemListAdapter < Repository , ? extends ItemView > createAdapter ( List < Repository > items ) { } @ Override public void onLoadFinished ( Loader < List < Repository > > loader , List < Repository > items ) { } }<BUG2FIX>ListViewUtils . configure ( getActivity ( ) , getListView ( ) ) ;
public class GistViewHolder implements ViewHolder < Gist > { private final TextView gistId ; private final TextView title ; private final TextView created ; private final TextView comments ; private final TextView files ; public GistViewHolder ( View v ) { } @ Override public void updateViewFor ( final Gist gist ) { String id = gist . getId ( ) ; String description = gist . getDescription ( ) ; if ( ( ( ( ! ( gist . isPublic ( ) ) ) && ( description != null ) ) && ( ( description . length ( ) ) > 0 ) ) && ( ( id . length ( ) ) > 8 ) ) id = ( id . substring ( 0 , 8 ) ) + "..." ; gistId . setText ( id ) ; <START_BUG> title . setText ( gist . getDescription ( ) ) ; <END_BUG> created . setText ( Time . relativeTimeFor ( gist . getCreatedAt ( ) ) ) ; comments . setText ( MessageFormat . format ( "{0}" , gist . getComments ( ) ) ) ; if ( ( gist . getFiles ( ) . size ( ) ) != 1 ) files . setText ( files . getContext ( ) . getString ( multiple_files , gist . getFiles ( ) . size ( ) ) ) ; else files . setText ( single_file ) ; } }<BUG2FIX>title . setText ( description ) ;
public final class SortedSetDVBytesAtomicFieldData extends SortedSetDVAtomicFieldData implements AtomicFieldData . WithOrdinals < ScriptDocValues . Strings > { SortedSetDVBytesAtomicFieldData ( AtomicReader reader , String field ) { } @ Override public Strings getScriptValues ( ) { <START_BUG> return new ScriptDocValues . Strings ( getBytesValues ( false ) ) ; <END_BUG> } }<BUG2FIX>return new ScriptDocValues . Strings ( getBytesValues ( ) ) ;
public class LabelTest extends GdxTest { Skin skin ; Stage stage ; SpriteBatch batch ; Actor root ; ShapeRenderer renderer ; @ Override public void create ( ) { } @ Override public void dispose ( ) { } @ Override public void render ( ) { } public void drawLine ( float x1 , float y1 , float x2 , float y2 ) { } @ Override public void resize ( int width , int height ) { <START_BUG> stage . getViewport ( ) . update ( width , height ) ; <END_BUG> } }<BUG2FIX>stage . getViewport ( ) . update ( width , height , true ) ;
public class Viewer implements ApplicationListener { public static void main ( String [ ] argv ) { } static final int NUM_INSTANCES = 1 ; SkeletonModel model ; PerspectiveCamera cam ; ImmediateModeRenderer renderer ; float angle = 0 ; SpriteBatch batch ; BitmapFont font ; List < String > animNames = new ArrayList < String > ( ) ; String animation ; float time = 0 ; int currAnimIdx = 0 ; @ Override public void create ( ) { } @ Override public void resume ( ) { } float [ ] lightColor = new float [ ] { 1 , 1 , 1 , 0 } ; float [ ] lightPosition = new float [ ] { 2 , 5 , 10 , 0 } ; @ Override public void render ( ) { gl . glClearColor ( 0.2F , 0.2F , 0.2F , 1 ) ; gl . glClear ( ( ( GL10 . GL_COLOR_BUFFER_BIT ) | ( GL10 . GL_DEPTH_BUFFER_BIT ) ) ) ; gl . glEnable ( GL_DEPTH_TEST ) ; gl . glEnable ( GL_TEXTURE_2D ) ; gl . glEnable ( GL_LIGHTING ) ; gl . glEnable ( GL_COLOR_MATERIAL ) ; cam . update ( ) ; cam . apply ( gl10 ) ; gl . glEnable ( GL_LIGHT0 ) ; gl10 . glLightfv ( GL_LIGHT0 , GL_DIFFUSE , lightColor , 0 ) ; gl10 . glLightfv ( GL_LIGHT0 , GL_POSITION , lightPosition , 0 ) ; angle += 45 * ( graphics . getDeltaTime ( ) ) ; long processingTime = 0 ; for ( int i = 0 ; i < ( Viewer . NUM_INSTANCES ) ; i ++ ) { <START_BUG> model . setAnimation ( animation , time ) ; <END_BUG> model . render ( ) ; } gl . glDisable ( GL_LIGHTING ) ; gl . glDisable ( GL_DEPTH_TEST ) ; gl . glDisable ( GL_TEXTURE_2D ) ; renderSkeleton ( ) ; app . log ( "Skinning" , ( ( "took:<seq2seq4repair_space>" + ( processingTime / 1.0E9F ) ) + "<seq2seq4repair_space>secs" ) ) ; batch . begin ( ) ; font . draw ( batch , ( ( ( "Touch<seq2seq4repair_space>to<seq2seq4repair_space>switch<seq2seq4repair_space>Animation,<seq2seq4repair_space>Animation:<seq2seq4repair_space>" + ( animation ) ) + ",<seq2seq4repair_space>FPS:<seq2seq4repair_space>" ) + ( graphics . getFramesPerSecond ( ) ) ) , 10 , 30 ) ; batch . end ( ) ; if ( input . justTouched ( ) ) { ( currAnimIdx ) ++ ; if ( ( currAnimIdx ) == ( animNames . size ( ) ) ) currAnimIdx = 0 ; animation = animNames . get ( currAnimIdx ) ; time = 0 ; } time += ( graphics . getDeltaTime ( ) ) / 10 ; if ( ( time ) > ( model . skeleton . animations . get ( animation ) . totalDuration ) ) { time = 0 ; } } Vector3 point1 = new Vector3 ( ) ; Vector3 point2 = new Vector3 ( ) ; private void renderSkeleton ( ) { } @ Override public void resize ( int width , int height ) { } @ Override public void pause ( ) { } @ Override public void dispose ( ) { } }<BUG2FIX>model . setAnimation ( animation , time , true ) ;
public class FilteredQueryParser extends AbstractIndexComponent implements XContentQueryParser { public static final String NAME = "filtered" ; @ Inject public FilteredQueryParser ( Index index , @ IndexSettings Settings settings ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; Query query = null ; Filter filter = null ; float boost = 1.0F ; <START_BUG> boolean cache = true ; <END_BUG> String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_OBJECT ) ) { if ( "query" . equals ( currentFieldName ) ) { query = parseContext . parseInnerQuery ( ) ; } else if ( "filter" . equals ( currentFieldName ) ) { filter = parseContext . parseInnerFilter ( ) ; } } else if ( token . isValue ( ) ) { if ( "boost" . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } else if ( "cache" . equals ( currentFieldName ) ) { cache = parser . booleanValue ( ) ; } } } if ( query == null ) { throw new QueryParsingException ( index , "[filtered]<seq2seq4repair_space>requires<seq2seq4repair_space>'query'<seq2seq4repair_space>element" ) ; } if ( filter == null ) { throw new QueryParsingException ( index , "[filtered]<seq2seq4repair_space>requires<seq2seq4repair_space>'filter'<seq2seq4repair_space>element" ) ; } if ( cache ) { filter = parseContext . cacheFilter ( filter ) ; } FilteredQuery filteredQuery = new FilteredQuery ( query , filter ) ; filteredQuery . setBoost ( boost ) ; return filteredQuery ; } }<BUG2FIX>boolean cache = false ;
public class LocalGatewayAllocator extends AbstractComponent implements GatewayAllocator { public static final String INDEX_RECOVERY_INITIAL_SHARDS = "index.recovery.initial_shards" ; private final TransportNodesListGatewayStartedShards listGatewayStartedShards ; private final TransportNodesListShardStoreMetaData listShardStoreMetaData ; private final ConcurrentMap < ShardId , Map < DiscoveryNode , TransportNodesListShardStoreMetaData . StoreFilesMetaData > > cachedStores = ConcurrentCollections . newConcurrentMap ( ) ; private final ConcurrentMap < ShardId , ObjectLongOpenHashMap < DiscoveryNode > > cachedShardsState = ConcurrentCollections . newConcurrentMap ( ) ; private final TimeValue listTimeout ; private final String initialShards ; @ Inject public LocalGatewayAllocator ( Settings settings , TransportNodesListGatewayStartedShards listGatewayStartedShards , TransportNodesListShardStoreMetaData listShardStoreMetaData ) { } @ Override public void applyStartedShards ( StartedRerouteAllocation allocation ) { } @ Override public void applyFailedShards ( FailedRerouteAllocation allocation ) { } @ Override public boolean allocateUnassigned ( RoutingAllocation allocation ) { } private ObjectLongOpenHashMap < DiscoveryNode > buildShardStates ( final DiscoveryNodes nodes , MutableShardRouting shard ) { ObjectLongOpenHashMap < DiscoveryNode > shardStates = cachedShardsState . get ( shard . shardId ( ) ) ; ObjectOpenHashSet < String > nodeIds ; if ( shardStates == null ) { <START_BUG> shardStates = new ObjectLongOpenHashMap < DiscoveryNode > ( ) ; <END_BUG> cachedShardsState . put ( shard . shardId ( ) , shardStates ) ; nodeIds = ObjectOpenHashSet . from ( nodes . dataNodes ( ) . keys ( ) ) ; } else { shardStates . keys ( ) . removeAll ( new com . carrotsearch . hppc . predicates . ObjectPredicate < DiscoveryNode > ( ) { @ Override public boolean apply ( DiscoveryNode node ) { return ! ( nodes . nodeExists ( node . id ( ) ) ) ; } } ) ; nodeIds = ObjectOpenHashSet . newInstance ( ) ; for ( ObjectCursor < DiscoveryNode > cursor : nodes . dataNodes ( ) . values ( ) ) { DiscoveryNode node = cursor . value ; if ( ! ( shardStates . containsKey ( node ) ) ) { nodeIds . add ( node . id ( ) ) ; } } } if ( nodeIds . isEmpty ( ) ) { return shardStates ; } String [ ] nodesIdsArray = nodeIds . toArray ( String . class ) ; TransportNodesListGatewayStartedShards . NodesLocalGatewayStartedShards response = listGatewayStartedShards . list ( shard . shardId ( ) , nodesIdsArray , listTimeout ) . actionGet ( ) ; if ( logger . isDebugEnabled ( ) ) { if ( ( response . failures ( ) . length ) > 0 ) { StringBuilder sb = new StringBuilder ( ( shard + ":<seq2seq4repair_space>failures<seq2seq4repair_space>when<seq2seq4repair_space>trying<seq2seq4repair_space>to<seq2seq4repair_space>list<seq2seq4repair_space>shards<seq2seq4repair_space>on<seq2seq4repair_space>nodes:" ) ) ; for ( int i = 0 ; i < ( response . failures ( ) . length ) ; i ++ ) { Throwable cause = ExceptionsHelper . unwrapCause ( response . failures ( ) [ i ] ) ; if ( cause instanceof ConnectTransportException ) { continue ; } sb . append ( "\n<seq2seq4repair_space>-><seq2seq4repair_space>" ) . append ( response . failures ( ) [ i ] . getDetailedMessage ( ) ) ; } logger . debug ( sb . toString ( ) ) ; } } for ( TransportNodesListGatewayStartedShards . NodeLocalGatewayStartedShards nodeShardState : response ) { shardStates . put ( nodeShardState . getNode ( ) , nodeShardState . version ( ) ) ; } return shardStates ; } private Map < DiscoveryNode , TransportNodesListShardStoreMetaData . StoreFilesMetaData > buildShardStores ( DiscoveryNodes nodes , MutableShardRouting shard ) { } }<BUG2FIX>shardStates = new ObjectLongOpenHashMap ( ) ;
public class TransportCountAction extends TransportBroadcastOperationAction < CountRequest , CountResponse , ShardCountRequest , ShardCountResponse > { private final IndicesService indicesService ; @ Inject public TransportCountAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportService transportService , IndicesService indicesService ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected String transportShardAction ( ) { } @ Override protected CountRequest newRequest ( ) { } @ Override protected ShardCountRequest newShardRequest ( ) { } @ Override protected ShardCountRequest newShardRequest ( ShardRouting shard , CountRequest request ) { } @ Override protected ShardCountResponse newShardResponse ( ) { } @ Override protected GroupShardsIterator shards ( CountRequest request , String [ ] concreteIndices , ClusterState clusterState ) { } @ Override protected void checkBlock ( CountRequest request , String [ ] concreteIndices , ClusterState state ) { } @ Override protected CountResponse newResponse ( CountRequest request , AtomicReferenceArray shardsResponses , ClusterState clusterState ) { } @ Override protected ShardCountResponse shardOperation ( ShardCountRequest request ) throws ElasticSearchException { IndexShard indexShard = indicesService . indexServiceSafe ( request . index ( ) ) . shardSafe ( request . shardId ( ) ) ; <START_BUG> long count = indexShard . count ( request . minScore ( ) , request . querySource ( ) , request . querySourceOffset ( ) , request . querySourceLength ( ) , request . queryParserName ( ) , request . filteringAliases ( ) , request . types ( ) ) ; <END_BUG> return new ShardCountResponse ( request . index ( ) , request . shardId ( ) , count ) ; } }<BUG2FIX>long count = indexShard . count ( request . minScore ( ) , request . querySource ( ) , request . querySourceOffset ( ) , request . querySourceLength ( ) , request . filteringAliases ( ) , request . types ( ) ) ;
public class TransportMoreLikeThisAction extends BaseAction < MoreLikeThisRequest , SearchResponse > { private final TransportSearchAction searchAction ; private final TransportGetAction getAction ; private final IndicesService indicesService ; @ Inject public TransportMoreLikeThisAction ( Settings settings , TransportSearchAction searchAction , TransportGetAction getAction , IndicesService indicesService , TransportService transportService ) { } @ Override protected void doExecute ( final MoreLikeThisRequest request , final ActionListener < SearchResponse > listener ) { GetRequest getRequest = getRequest ( request . index ( ) ) . type ( request . type ( ) ) . id ( request . id ( ) ) . listenerThreaded ( false ) ; getAction . execute ( getRequest , new ActionListener < GetResponse > ( ) { @ Override public void onResponse ( GetResponse getResponse ) { <START_BUG> if ( getResponse . exists ( ) ) { <END_BUG> listener . onFailure ( new ElasticSearchException ( "document<seq2seq4repair_space>missing" ) ) ; return ; } final BoolJsonQueryBuilder boolBuilder = boolQuery ( ) ; try { DocumentMapper docMapper = indicesService . indexServiceSafe ( request . index ( ) ) . mapperService ( ) . documentMapper ( request . type ( ) ) ; final Set < String > fields = Sets . newHashSet ( ) ; if ( ( request . fields ( ) ) != null ) { for ( String field : request . fields ( ) ) { FieldMappers fieldMappers = docMapper . mappers ( ) . smartName ( field ) ; if ( fieldMappers != null ) { fields . add ( fieldMappers . mapper ( ) . names ( ) . indexName ( ) ) ; } else { fields . add ( field ) ; } } } docMapper . parse ( request . type ( ) , request . id ( ) , getResponse . source ( ) , new DocumentMapper . ParseListenerAdapter ( ) { @ Override public boolean beforeFieldAdded ( FieldMapper fieldMapper , Fieldable field , Object parseContext ) { if ( fieldMapper instanceof InternalMapper ) { return true ; } String value = fieldMapper . valueAsString ( field ) ; if ( value == null ) { return false ; } if ( ( fields . isEmpty ( ) ) || ( fields . contains ( field . name ( ) ) ) ) { addMoreLikeThis ( request , boolBuilder , fieldMapper , field ) ; } return false ; } } ) ; Term uidTerm = docMapper . uidMapper ( ) . term ( request . type ( ) , request . id ( ) ) ; boolBuilder . mustNot ( termQuery ( uidTerm . field ( ) , uidTerm . text ( ) ) ) ; } catch ( Exception e ) { listener . onFailure ( e ) ; } String [ ] searchIndices = request . searchIndices ( ) ; if ( searchIndices == null ) { searchIndices = new String [ ] { request . index ( ) } ; } String [ ] searchTypes = request . searchTypes ( ) ; if ( searchTypes == null ) { searchTypes = new String [ ] { request . type ( ) } ; } SearchRequest searchRequest = searchRequest ( searchIndices ) . types ( searchTypes ) . searchType ( request . searchType ( ) ) . source ( request . searchSource ( ) ) . scroll ( request . searchScroll ( ) ) . extraSource ( searchSource ( ) . query ( boolBuilder ) ) . listenerThreaded ( request . listenerThreaded ( ) ) ; searchAction . execute ( searchRequest , new ActionListener < SearchResponse > ( ) { @ Override public void onResponse ( SearchResponse response ) { listener . onResponse ( response ) ; } @ Override public void onFailure ( Throwable e ) { listener . onFailure ( e ) ; } } ) ; } @ Override public void onFailure ( Throwable e ) { listener . onFailure ( e ) ; } } ) ; } private void addMoreLikeThis ( MoreLikeThisRequest request , BoolJsonQueryBuilder boolBuilder , FieldMapper fieldMapper , Fieldable field ) { } private class TransportHandler extends BaseTransportRequestHandler < MoreLikeThisRequest > { @ Override public MoreLikeThisRequest newInstance ( ) { } @ Override public void messageReceived ( MoreLikeThisRequest request , final TransportChannel channel ) throws Exception { } @ Override public boolean spawn ( ) { } } }<BUG2FIX>if ( ! ( getResponse . exists ( ) ) ) {
public class RestClusterSearchShardsAction extends BaseRestHandler { @ Inject public RestClusterSearchShardsAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { String [ ] indices = RestActions . splitIndices ( request . param ( "index" ) ) ; final ClusterSearchShardsRequest clusterSearchShardsRequest = Requests . clusterSearchShardsRequest ( indices ) ; clusterSearchShardsRequest . local ( request . paramAsBoolean ( "local" , clusterSearchShardsRequest . local ( ) ) ) ; clusterSearchShardsRequest . listenerThreaded ( false ) ; clusterSearchShardsRequest . types ( RestActions . splitTypes ( request . param ( "type" ) ) ) ; clusterSearchShardsRequest . routing ( request . param ( "routing" ) ) ; clusterSearchShardsRequest . preference ( request . param ( "preference" ) ) ; if ( request . hasParam ( "ignore_indices" ) ) { clusterSearchShardsRequest . ignoreIndices ( IgnoreIndices . fromString ( request . param ( "ignore_indices" ) ) ) ; } client . admin ( ) . cluster ( ) . searchShards ( clusterSearchShardsRequest , new org . elasticsearch . action . ActionListener < ClusterSearchShardsResponse > ( ) { @ Override public void onResponse ( ClusterSearchShardsResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( "ok" , true ) ; response . toXContent ( builder , request ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class ShortArrayRef extends AbstractList < Short > implements RandomAccess { public static final ShortArrayRef EMPTY = new ShortArrayRef ( new short [ 0 ] ) ; public short [ ] values ; public int start ; public int end ; public ShortArrayRef ( short [ ] values ) { } public ShortArrayRef ( short [ ] values , int length ) { } public ShortArrayRef ( short [ ] values , int start , int end ) { } public void reset ( int newLength ) { } @ Override public int size ( ) { } @ Override public boolean isEmpty ( ) { <START_BUG> return ( size ( ) ) != 0 ; <END_BUG> } @ Override public Short get ( int index ) { } @ Override public boolean contains ( Object target ) { } @ Override public int indexOf ( Object target ) { } @ Override public int lastIndexOf ( Object target ) { } @ Override public Short set ( int index , Short element ) { } @ Override public boolean equals ( Object object ) { } @ Override public int hashCode ( ) { } @ Override public String toString ( ) { } private static int indexOf ( short [ ] array , short target , int start , int end ) { } private static int lastIndexOf ( short [ ] array , short target , int start , int end ) { } }<BUG2FIX>return ( size ( ) ) == 0 ;
public class PostingsHighlighter implements Highlighter { private static final String CACHE_KEY = "highlight-postings" ; @ Override public String [ ] names ( ) { } @ Override public HighlightField highlight ( HighlighterContext highlighterContext ) { FieldMapper < ? > fieldMapper = highlighterContext . mapper ; SearchContextHighlight . Field field = highlighterContext . field ; if ( ( fieldMapper . fieldType ( ) . indexOptions ( ) ) != ( IndexOptions . DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS ) ) { throw new org . elasticsearch . ElasticSearchIllegalArgumentException ( ( ( "the<seq2seq4repair_space>field<seq2seq4repair_space>[" + ( field . field ( ) ) ) + "]<seq2seq4repair_space>should<seq2seq4repair_space>be<seq2seq4repair_space>indexed<seq2seq4repair_space>with<seq2seq4repair_space>positions<seq2seq4repair_space>and<seq2seq4repair_space>offsets<seq2seq4repair_space>in<seq2seq4repair_space>the<seq2seq4repair_space>postings<seq2seq4repair_space>list<seq2seq4repair_space>to<seq2seq4repair_space>be<seq2seq4repair_space>used<seq2seq4repair_space>with<seq2seq4repair_space>postings<seq2seq4repair_space>highlighter" ) ) ; } SearchContext context = highlighterContext . context ; FetchSubPhase . HitContext hitContext = highlighterContext . hitContext ; if ( ! ( hitContext . cache ( ) . containsKey ( PostingsHighlighter . CACHE_KEY ) ) ) { Query query ; try { query = PostingsHighlighter . rewrite ( highlighterContext , hitContext . topLevelReader ( ) ) ; } catch ( IOException e ) { throw new org . elasticsearch . search . fetch . FetchPhaseExecutionException ( context , ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>highlight<seq2seq4repair_space>field<seq2seq4repair_space>[" + ( highlighterContext . fieldName ) ) + "]" ) , e ) ; } SortedSet < Term > queryTerms = PostingsHighlighter . extractTerms ( query ) ; hitContext . cache ( ) . put ( PostingsHighlighter . CACHE_KEY , new PostingsHighlighter . HighlighterEntry ( queryTerms ) ) ; } PostingsHighlighter . HighlighterEntry highlighterEntry = ( ( PostingsHighlighter . HighlighterEntry ) ( hitContext . cache ( ) . get ( PostingsHighlighter . CACHE_KEY ) ) ) ; PostingsHighlighter . MapperHighlighterEntry mapperHighlighterEntry = highlighterEntry . mappers . get ( fieldMapper ) ; if ( mapperHighlighterEntry == null ) { Encoder encoder = ( field . encoder ( ) . equals ( "html" ) ) ? Encoders . HTML : Encoders . DEFAULT ; CustomPassageFormatter passageFormatter = new CustomPassageFormatter ( field . preTags ( ) [ 0 ] , field . postTags ( ) [ 0 ] , encoder ) ; BytesRef [ ] filteredQueryTerms = PostingsHighlighter . filterTerms ( highlighterEntry . queryTerms , fieldMapper . names ( ) . indexName ( ) , field . requireFieldMatch ( ) ) ; mapperHighlighterEntry = new PostingsHighlighter . MapperHighlighterEntry ( passageFormatter , filteredQueryTerms ) ; } boolean mergeValues = ( field . numberOfFragments ( ) ) != 0 ; List < Snippet > snippets = new ArrayList < Snippet > ( ) ; int numberOfFragments ; try { <START_BUG> List < Object > textsToHighlight = HighlightUtils . loadFieldValues ( fieldMapper , context , hitContext , field . forceSource ( ) ) ; <END_BUG> CustomPostingsHighlighter highlighter = new CustomPostingsHighlighter ( mapperHighlighterEntry . passageFormatter , textsToHighlight , mergeValues , ( ( Integer . MAX_VALUE ) - 1 ) , field . noMatchSize ( ) ) ; if ( ( field . numberOfFragments ( ) ) == 0 ) { highlighter . setBreakIterator ( new WholeBreakIterator ( ) ) ; numberOfFragments = 1 ; } else { numberOfFragments = field . numberOfFragments ( ) ; } int values = ( mergeValues ) ? 1 : textsToHighlight . size ( ) ; for ( int i = 0 ; i < values ; i ++ ) { Snippet [ ] fieldSnippets = highlighter . highlightDoc ( fieldMapper . names ( ) . indexName ( ) , mapperHighlighterEntry . filteredQueryTerms , hitContext . searcher ( ) , hitContext . docId ( ) , numberOfFragments ) ; if ( fieldSnippets != null ) { for ( Snippet fieldSnippet : fieldSnippets ) { if ( Strings . hasText ( fieldSnippet . getText ( ) ) ) { snippets . add ( fieldSnippet ) ; } } } } } catch ( IOException e ) { throw new org . elasticsearch . search . fetch . FetchPhaseExecutionException ( context , ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>highlight<seq2seq4repair_space>field<seq2seq4repair_space>[" + ( highlighterContext . fieldName ) ) + "]" ) , e ) ; } snippets = PostingsHighlighter . filterSnippets ( snippets , field . numberOfFragments ( ) ) ; if ( field . scoreOrdered ( ) ) { CollectionUtil . introSort ( snippets , new Comparator < Snippet > ( ) { public int compare ( Snippet o1 , Snippet o2 ) { return ( ( int ) ( Math . signum ( ( ( o2 . getScore ( ) ) - ( o1 . getScore ( ) ) ) ) ) ) ; } } ) ; } String [ ] fragments = new String [ snippets . size ( ) ] ; for ( int i = 0 ; i < ( fragments . length ) ; i ++ ) { fragments [ i ] = snippets . get ( i ) . getText ( ) ; } if ( ( fragments . length ) > 0 ) { return new HighlightField ( highlighterContext . fieldName , StringText . convertFromStringArray ( fragments ) ) ; } return null ; } private static Query rewrite ( HighlighterContext highlighterContext , IndexReader reader ) throws IOException { } private static boolean allowsForTermExtraction ( MultiTermQuery . RewriteMethod rewriteMethod ) { } private static SortedSet < Term > extractTerms ( Query query ) { } private static BytesRef [ ] filterTerms ( SortedSet < Term > queryTerms , String field , boolean requireFieldMatch ) { } private static List < Snippet > filterSnippets ( List < Snippet > snippets , int numberOfFragments ) { } private static class HighlighterEntry { final SortedSet < Term > queryTerms ; Map < FieldMapper < ? > , PostingsHighlighter . MapperHighlighterEntry > mappers = Maps . newHashMap ( ) ; private HighlighterEntry ( SortedSet < Term > queryTerms ) { } } private static class MapperHighlighterEntry { final CustomPassageFormatter passageFormatter ; final BytesRef [ ] filteredQueryTerms ; private MapperHighlighterEntry ( CustomPassageFormatter passageFormatter , BytesRef [ ] filteredQueryTerms ) { } } }<BUG2FIX>List < Object > textsToHighlight = HighlightUtils . loadFieldValues ( fieldMapper , context , hitContext ) ;
public class TransportSearchDfsQueryAndFetchAction extends TransportSearchTypeAction { @ Inject public TransportSearchDfsQueryAndFetchAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , SearchServiceTransportAction searchService , SearchPhaseController searchPhaseController ) { } @ Override protected void doExecute ( SearchRequest searchRequest , ActionListener < SearchResponse > listener ) { } private class AsyncAction extends BaseAsyncAction < DfsSearchResult > { private final AtomicArray < QueryFetchSearchResult > queryFetchResults ; private AsyncAction ( SearchRequest request , ActionListener < SearchResponse > listener ) { } @ Override protected String firstPhaseName ( ) { } @ Override protected void sendExecuteFirstPhase ( DiscoveryNode node , ShardSearchRequest request , SearchServiceListener < DfsSearchResult > listener ) { } @ Override protected void moveToSecondPhase ( ) { } void executeSecondPhase ( final int shardIndex , final DfsSearchResult dfsResult , final AtomicInteger counter , DiscoveryNode node , final QuerySearchRequest querySearchRequest ) { } void finishHim ( ) { try { innerFinishHim ( ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> ReduceSearchPhaseException failure = new ReduceSearchPhaseException ( "query_fetch" , "" , e , buildShardFailures ( ) ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>reduce<seq2seq4repair_space>search" , failure ) ; } listener . onFailure ( failure ) ; } finally { } } void innerFinishHim ( ) throws Exception { } } }<BUG2FIX>} catch ( Throwable e ) {
public class ScriptStatisticalFacetCollector extends AbstractFacetCollector { private final SearchScript script ; private double min = Double . POSITIVE_INFINITY ; private double max = Double . NEGATIVE_INFINITY ; private double total = 0 ; private double sumOfSquares = 0.0 ; private long count ; public ScriptStatisticalFacetCollector ( String facetName , String scriptLang , String script , Map < String , Object > params , SearchContext context ) { } @ Override protected void doCollect ( int doc ) throws IOException { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override protected void doSetNextReader ( AtomicReaderContext context ) throws IOException { <START_BUG> script . setNextReader ( context . reader ( ) ) ; <END_BUG> } @ Override public Facet facet ( ) { } }<BUG2FIX>script . setNextReader ( context ) ;
public class MapperQueryParser extends QueryParser { public static final ImmutableMap < String , FieldQueryExtension > fieldQueryExtensions ; private final QueryParseContext parseContext ; private boolean forcedAnalyzer ; private FieldMapper currentMapper ; private boolean analyzeWildcard ; public MapperQueryParser ( QueryParseContext parseContext ) { } public MapperQueryParser ( QueryParserSettings settings , QueryParseContext parseContext ) { } public void reset ( QueryParserSettings settings ) { } @ Override protected Query newTermQuery ( Term term ) { } @ Override protected Query newMatchAllDocsQuery ( ) { } @ Override public Query getFieldQuery ( String field , String queryText , boolean quoted ) throws ParseException { } @ Override protected Query getRangeQuery ( String field , String part1 , String part2 , boolean inclusive ) throws ParseException { if ( "*" . equals ( part1 ) ) { part1 = null ; } if ( "*" . equals ( part2 ) ) { part2 = null ; } currentMapper = null ; MapperService . SmartNameFieldMappers fieldMappers = parseContext . smartFieldMappers ( field ) ; if ( fieldMappers != null ) { currentMapper = fieldMappers . fieldMappers ( ) . mapper ( ) ; if ( ( currentMapper ) != null ) { <START_BUG> Query rangeQuery = currentMapper . rangeQuery ( part1 , part2 , inclusive , inclusive ) ; <END_BUG> return wrapSmartNameQuery ( rangeQuery , fieldMappers , parseContext ) ; } } return newRangeQuery ( field , part1 , part2 , inclusive ) ; } @ Override protected Query getFuzzyQuery ( String field , String termStr , float minSimilarity ) throws ParseException { } @ Override protected Query getPrefixQuery ( String field , String termStr ) throws ParseException { } private Query getPossiblyAnalyzedPrefixQuery ( String field , String termStr ) throws ParseException { } @ Override protected Query getWildcardQuery ( String field , String termStr ) throws ParseException { } private Query getPossiblyAnalyzedWildcardQuery ( String field , String termStr ) throws ParseException { } @ Override protected Query getBooleanQuery ( List < BooleanClause > clauses , boolean disableCoord ) throws ParseException { } }<BUG2FIX>Query rangeQuery = currentMapper . rangeQuery ( part1 , part2 , inclusive , inclusive , parseContext ) ;
public class PrefixQueryParser extends AbstractIndexComponent implements XContentQueryParser { public static final String NAME = "prefix" ; @ Inject public PrefixQueryParser ( Index index , @ IndexSettings Settings settings ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; XContentParser . Token token = parser . nextToken ( ) ; assert token == ( Token . FIELD_NAME ) ; String fieldName = parser . currentName ( ) ; String value = null ; float boost = 1.0F ; token = parser . nextToken ( ) ; if ( token == ( Token . START_OBJECT ) ) { String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token . isValue ( ) ) { if ( PrefixQueryParser . NAME . equals ( currentFieldName ) ) { value = parser . text ( ) ; } else if ( "boost" . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } } } } else { value = parser . text ( ) ; parser . nextToken ( ) ; } if ( value == null ) { throw new QueryParsingException ( index , "No<seq2seq4repair_space>value<seq2seq4repair_space>specified<seq2seq4repair_space>for<seq2seq4repair_space>prefix<seq2seq4repair_space>query" ) ; } MapperService . SmartNameFieldMappers smartNameFieldMappers = parseContext . smartFieldMappers ( fieldName ) ; if ( smartNameFieldMappers != null ) { if ( smartNameFieldMappers . hasMapper ( ) ) { fieldName = smartNameFieldMappers . mapper ( ) . names ( ) . indexName ( ) ; value = smartNameFieldMappers . mapper ( ) . indexedValue ( value ) ; } } PrefixQuery query = new PrefixQuery ( new Term ( fieldName , value ) ) ; query . setRewriteMethod ( CONSTANT_SCORE_AUTO_REWRITE_DEFAULT ) ; query . setBoost ( boost ) ; <START_BUG> return wrapSmartNameQuery ( query , smartNameFieldMappers , parseContext . indexCache ( ) ) ; <END_BUG> } }<BUG2FIX>return wrapSmartNameQuery ( query , smartNameFieldMappers , parseContext ) ;
@ Immutable public class IndexRoutingTable implements Iterable < IndexShardRoutingTable > { private final String index ; private final ImmutableMap < Integer , IndexShardRoutingTable > shards ; private final ImmutableList < ShardRouting > allShards ; private final AtomicInteger counter = new AtomicInteger ( ) ; IndexRoutingTable ( String index , Map < Integer , IndexShardRoutingTable > shards ) { } public String index ( ) { } public String getIndex ( ) { } public IndexRoutingTable normalizeVersions ( ) { } public void validate ( RoutingTableValidation validation , MetaData metaData ) { } @ Override public UnmodifiableIterator < IndexShardRoutingTable > iterator ( ) { } public int numberOfNodesShardsAreAllocatedOn ( String ... excludedNodes ) { } public ImmutableMap < Integer , IndexShardRoutingTable > shards ( ) { } public ImmutableMap < Integer , IndexShardRoutingTable > getShards ( ) { } public IndexShardRoutingTable shard ( int shardId ) { } public boolean allPrimaryShardsActive ( ) { } public int primaryShardsActive ( ) { } public boolean allPrimaryShardsUnassigned ( ) { } public int primaryShardsUnassigned ( ) { } public List < ShardRouting > shardsWithState ( ShardRoutingState ... states ) { } public ShardsIterator randomAllShardsIt ( ) { <START_BUG> return new PlainShardsIterator ( allShards , Math . abs ( counter . incrementAndGet ( ) ) ) ; <END_BUG> } public GroupShardsIterator groupByShardsIt ( ) { } public GroupShardsIterator groupByAllIt ( ) { } public void validate ( ) throws RoutingValidationException { } public static class Builder { private final String index ; private final Map < Integer , IndexShardRoutingTable > shards = new HashMap < Integer , IndexShardRoutingTable > ( ) ; public Builder ( String index ) { } public static IndexRoutingTable readFrom ( StreamInput in ) throws IOException { } public static void writeTo ( IndexRoutingTable index , StreamOutput out ) throws IOException { } public IndexRoutingTable . Builder initializeEmpty ( IndexMetaData indexMetaData ) { } public IndexRoutingTable . Builder initializeEmpty ( IndexMetaData indexMetaData , boolean fromApi ) { } public IndexRoutingTable . Builder addReplica ( ) { } public IndexRoutingTable . Builder removeReplica ( ) { } public IndexRoutingTable . Builder addIndexShard ( IndexShardRoutingTable indexShard ) { } public IndexRoutingTable . Builder addShard ( ShardRouting shard , boolean fromApi ) { } private IndexRoutingTable . Builder addShard ( int shardId , String nodeId , boolean primary , ShardRoutingState state , long version , boolean fromApi ) { } private IndexRoutingTable . Builder internalAddShard ( ImmutableShardRouting shard , boolean fromApi ) { } public IndexRoutingTable build ( ) throws RoutingValidationException { } } public String prettyPrint ( ) { } }<BUG2FIX>return new PlainShardsIterator ( allShards , counter . incrementAndGet ( ) ) ;
public class CachedDfSource extends Searcher { private final AggregatedDfs dfs ; private final int maxDoc ; public CachedDfSource ( AggregatedDfs dfs , Similarity similarity ) throws IOException { } public int docFreq ( Term term ) { int df = dfs . dfMap ( ) . get ( term ) ; if ( df == ( - 1 ) ) { <START_BUG> throw new IllegalArgumentException ( ( ( "df<seq2seq4repair_space>for<seq2seq4repair_space>term<seq2seq4repair_space>" + ( term . text ( ) ) ) + "<seq2seq4repair_space>not<seq2seq4repair_space>available" ) ) ; <END_BUG> } return df ; } public int [ ] docFreqs ( Term [ ] terms ) { } public int maxDoc ( ) { } public Query rewrite ( Query query ) { } public void close ( ) { } public Document doc ( int i ) { } public Document doc ( int i , FieldSelector fieldSelector ) { } public Explanation explain ( Weight weight , int doc ) { } public void search ( Weight weight , Filter filter , Collector results ) { } public TopDocs search ( Weight weight , Filter filter , int n ) { } public TopFieldDocs search ( Weight weight , Filter filter , int n , Sort sort ) { } }<BUG2FIX>throw new IllegalArgumentException ( ( ( "df<seq2seq4repair_space>for<seq2seq4repair_space>term<seq2seq4repair_space>" + term ) + "<seq2seq4repair_space>not<seq2seq4repair_space>available" ) ) ;
public class FreqTermsEnumTests extends ElasticsearchLuceneTestCase { private String [ ] terms ; private IndexWriter iw ; private IndexReader reader ; private Map < String , FreqTermsEnumTests . FreqHolder > referenceAll ; private Map < String , FreqTermsEnumTests . FreqHolder > referenceNotDeleted ; private Map < String , FreqTermsEnumTests . FreqHolder > referenceFilter ; private Filter filter ; static class FreqHolder { int docFreq ; long totalTermFreq ; } @ Before @ Override public void setUp ( ) throws Exception { super . setUp ( ) ; referenceAll = Maps . newHashMap ( ) ; referenceNotDeleted = Maps . newHashMap ( ) ; referenceFilter = Maps . newHashMap ( ) ; Directory dir = newDirectory ( ) ; <START_BUG> IndexWriterConfig conf = newIndexWriterConfig ( TEST_VERSION_CURRENT , new KeywordAnalyzer ( ) ) ; <END_BUG> if ( frequently ( ) ) { conf . setMergePolicy ( INSTANCE ) ; } iw = new IndexWriter ( dir , conf ) ; terms = new String [ scaledRandomIntBetween ( 10 , 300 ) ] ; for ( int i = 0 ; i < ( terms . length ) ; i ++ ) { terms [ i ] = randomAsciiOfLength ( 5 ) ; } int numberOfDocs = scaledRandomIntBetween ( 30 , 300 ) ; Document [ ] docs = new Document [ numberOfDocs ] ; for ( int i = 0 ; i < numberOfDocs ; i ++ ) { Document doc = new Document ( ) ; doc . add ( new org . apache . lucene . document . StringField ( "id" , Integer . toString ( i ) , Store . YES ) ) ; docs [ i ] = doc ; for ( String term : terms ) { if ( randomBoolean ( ) ) { continue ; } int freq = randomIntBetween ( 1 , 3 ) ; for ( int j = 0 ; j < freq ; j ++ ) { doc . add ( new org . apache . lucene . document . TextField ( "field" , term , Store . YES ) ) ; } } } for ( int i = 0 ; i < ( docs . length ) ; i ++ ) { Document doc = docs [ i ] ; iw . addDocument ( doc ) ; if ( rarely ( ) ) { iw . commit ( ) ; } } Set < String > deletedIds = Sets . newHashSet ( ) ; for ( int i = 0 ; i < ( docs . length ) ; i ++ ) { Document doc = docs [ i ] ; if ( ( randomInt ( 5 ) ) == 2 ) { Term idTerm = new Term ( "id" , doc . getField ( "id" ) . stringValue ( ) ) ; deletedIds . add ( idTerm . text ( ) ) ; iw . deleteDocuments ( idTerm ) ; } } for ( String term : terms ) { referenceAll . put ( term , new FreqTermsEnumTests . FreqHolder ( ) ) ; referenceFilter . put ( term , new FreqTermsEnumTests . FreqHolder ( ) ) ; referenceNotDeleted . put ( term , new FreqTermsEnumTests . FreqHolder ( ) ) ; } reader = DirectoryReader . open ( iw , true ) ; List < Term > filterTerms = Lists . newArrayList ( ) ; for ( int docId = 0 ; docId < ( reader . maxDoc ( ) ) ; docId ++ ) { Document doc = reader . document ( docId ) ; addFreqs ( doc , referenceAll ) ; if ( ! ( deletedIds . contains ( doc . getField ( "id" ) . stringValue ( ) ) ) ) { addFreqs ( doc , referenceNotDeleted ) ; if ( randomBoolean ( ) ) { filterTerms . add ( new Term ( "id" , doc . getField ( "id" ) . stringValue ( ) ) ) ; addFreqs ( doc , referenceFilter ) ; } } } filter = new org . apache . lucene . queries . TermsFilter ( filterTerms ) ; } private void addFreqs ( Document doc , Map < String , FreqTermsEnumTests . FreqHolder > reference ) { } @ After @ Override public void tearDown ( ) throws Exception { } @ Test public void testAllFreqs ( ) throws Exception { } @ Test public void testNonDeletedFreqs ( ) throws Exception { } @ Test public void testFilterFreqs ( ) throws Exception { } private void assertAgainstReference ( boolean docFreq , boolean totalTermFreq , Filter filter , Map < String , FreqTermsEnumTests . FreqHolder > reference ) throws Exception { } private void assertAgainstReference ( FreqTermsEnum termsEnum , Map < String , FreqTermsEnumTests . FreqHolder > reference , boolean docFreq , boolean totalTermFreq ) throws Exception { } }<BUG2FIX>IndexWriterConfig conf = newIndexWriterConfig ( new KeywordAnalyzer ( ) ) ;
class AndroidLiveWallpaper implements Application { protected WallpaperService service ; private Engine engine ; protected AndroidGraphicsLiveWallpaper graphics ; protected AndroidInput input ; protected AndroidAudio audio ; protected AndroidFiles files ; protected AndroidNet net ; protected ApplicationListener listener ; protected boolean firstResume = true ; protected final Array < Runnable > runnables = new Array < Runnable > ( ) ; protected final Array < Runnable > executedRunnables = new Array < Runnable > ( ) ; protected int logLevel = LOG_INFO ; public AndroidLiveWallpaper ( WallpaperService service , Engine engine ) { } public void initialize ( ApplicationListener listener , AndroidApplicationConfiguration config ) { graphics = new AndroidGraphicsLiveWallpaper ( this , config . useGL20 , ( ( config . resolutionStrategy ) == null ? new FillResolutionStrategy ( ) : config . resolutionStrategy ) ) ; input = AndroidInputFactory . newAndroidInput ( this , this . getService ( ) , null , config ) ; audio = new AndroidAudio ( this . getService ( ) , config ) ; <START_BUG> files = new AndroidFiles ( this . getService ( ) . getAssets ( ) , this . getService ( ) . getFilesDir ( ) . getAbsolutePath ( ) ) ; <END_BUG> this . listener = listener ; Gdx . app = this ; Gdx . input = this . getInput ( ) ; Gdx . audio = this . getAudio ( ) ; Gdx . files = this . getFiles ( ) ; Gdx . graphics = this . getGraphics ( ) ; } public void onPause ( ) { } public void onResume ( ) { } public void onDestroy ( ) { } public WallpaperService getService ( ) { } public Engine getEngine ( ) { } public ApplicationListener getListener ( ) { } @ Override public void postRunnable ( Runnable runnable ) { } @ Override public Audio getAudio ( ) { } @ Override public Files getFiles ( ) { } @ Override public Graphics getGraphics ( ) { } @ Override public Input getInput ( ) { } @ Override public Net getNet ( ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } @ Override public Preferences getPreferences ( String name ) { } AndroidClipboard clipboard ; @ Override public Clipboard getClipboard ( ) { } @ Override public void debug ( String tag , String message ) { } @ Override public void debug ( String tag , String message , Throwable exception ) { } @ Override public void log ( String tag , String message ) { } @ Override public void log ( String tag , String message , Exception exception ) { } @ Override public void error ( String tag , String message ) { } @ Override public void error ( String tag , String message , Throwable exception ) { } @ Override public void setLogLevel ( int logLevel ) { } @ Override public void exit ( ) { } }<BUG2FIX>files = new AndroidFiles ( this . getService ( ) . getAssets ( ) ) ;
public class ShapeRendererTest extends GdxTest { @ Override public boolean needsGL20 ( ) { <START_BUG> return false ; <END_BUG> } ShapeRenderer renderer ; PerspectiveCamera cam ; PerspectiveCamController controller ; SpriteBatch batch ; BitmapFont font ; public void create ( ) { } public void render ( ) { } }<BUG2FIX>return true ;
public final class BytesRefOrdValComparator extends NestedWrappableComparator < BytesRef > { final IndexFieldData . WithOrdinals < ? > indexFieldData ; final BytesRef missingValue ; final long [ ] ords ; final SortMode sortMode ; final BytesRef [ ] values ; final int [ ] readerGen ; int currentReaderGen = - 1 ; WithOrdinals termsIndex ; long missingOrd ; int bottomSlot = - 1 ; long bottomOrd ; final BytesRef tempBR = new BytesRef ( ) ; public BytesRefOrdValComparator ( IndexFieldData . WithOrdinals < ? > indexFieldData , int numHits , SortMode sortMode , BytesRef missingValue ) { } @ Override public int compare ( int slot1 , int slot2 ) { } @ Override public int compareBottom ( int doc ) { } @ Override public int compareBottomMissing ( ) { } @ Override public void copy ( int slot , int doc ) { } @ Override public void missing ( int slot ) { } @ Override public int compareDocToValue ( int doc , BytesRef value ) { } class PerSegmentComparator extends NestedWrappableComparator < BytesRef > { final Docs readerOrds ; final WithOrdinals termsIndex ; public PerSegmentComparator ( BytesValues . WithOrdinals termsIndex ) { } @ Override public FieldComparator < BytesRef > setNextReader ( AtomicReaderContext context ) throws IOException { return BytesRefOrdValComparator . this . setNextReader ( context ) ; } @ Override public int compare ( int slot1 , int slot2 ) { } @ Override public void setBottom ( final int bottom ) { } @ Override public BytesRef value ( int slot ) { } @ Override public int compareValues ( BytesRef val1 , BytesRef val2 ) { } @ Override public int compareDocToValue ( int doc , BytesRef value ) { } protected long getOrd ( int doc ) { } @ Override public int compareBottom ( int doc ) { } @ Override public int compareBottomMissing ( ) { } @ Override public void copy ( int slot , int doc ) { } @ Override public void missing ( int slot ) { } } private boolean consistentInsertedOrd ( BytesValues . WithOrdinals termsIndex , long ord , BytesRef value ) { } private long ordInCurrentReader ( BytesValues . WithOrdinals termsIndex , BytesRef value ) { } @ Override public FieldComparator < BytesRef > setNextReader ( AtomicReaderContext context ) throws IOException { <START_BUG> termsIndex = indexFieldData . load ( context ) . getBytesValues ( ) ; <END_BUG> assert ( ( termsIndex . ordinals ( ) ) != null ) && ( ( termsIndex . ordinals ( ) . ordinals ( ) ) != null ) ; if ( ( missingValue ) == null ) { missingOrd = Ordinals . MISSING_ORDINAL ; } else { missingOrd = ordInCurrentReader ( termsIndex , missingValue ) ; assert consistentInsertedOrd ( termsIndex , missingOrd , missingValue ) ; } FieldComparator < BytesRef > perSegComp = null ; assert ( ( termsIndex . ordinals ( ) ) != null ) && ( ( termsIndex . ordinals ( ) . ordinals ( ) ) != null ) ; if ( termsIndex . isMultiValued ( ) ) { perSegComp = new BytesRefOrdValComparator . PerSegmentComparator ( termsIndex ) { @ Override protected long getOrd ( int doc ) { return BytesRefOrdValComparator . getRelevantOrd ( readerOrds , doc , sortMode ) ; } } ; } else { perSegComp = new BytesRefOrdValComparator . PerSegmentComparator ( termsIndex ) ; } ( currentReaderGen ) ++ ; if ( ( bottomSlot ) != ( - 1 ) ) { perSegComp . setBottom ( bottomSlot ) ; } return perSegComp ; } @ Override public void setBottom ( final int bottom ) { } @ Override public BytesRef value ( int slot ) { } protected static final long binarySearch ( BytesValues . WithOrdinals a , BytesRef key ) { } protected static final long binarySearch ( BytesValues . WithOrdinals a , BytesRef key , long low , long high ) { } static long getRelevantOrd ( Ordinals . Docs readerOrds , int docId , SortMode sortMode ) { } }<BUG2FIX>termsIndex = indexFieldData . load ( context ) . getBytesValues ( false ) ;
public class RestNodesRestartAction extends BaseRestHandler { @ Inject public RestNodesRestartAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { String [ ] nodesIds = RestActions . splitNodes ( request . param ( "nodeId" ) ) ; NodesRestartRequest nodesRestartRequest = new NodesRestartRequest ( nodesIds ) ; nodesRestartRequest . listenerThreaded ( false ) ; nodesRestartRequest . delay ( request . paramAsTime ( "delay" , nodesRestartRequest . delay ( ) ) ) ; client . admin ( ) . cluster ( ) . nodesRestart ( nodesRestartRequest , new org . elasticsearch . action . ActionListener < NodesRestartResponse > ( ) { @ Override public void onResponse ( NodesRestartResponse result ) { try { XContentBuilder builder = restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( "cluster_name" , result . getClusterName ( ) . value ( ) ) ; builder . startObject ( "nodes" ) ; for ( NodesRestartResponse . NodeRestartResponse nodeInfo : result ) { builder . startObject ( nodeInfo . getNode ( ) . id ( ) ) ; builder . field ( "name" , nodeInfo . getNode ( ) . name ( ) ) ; builder . endObject ( ) ; } builder . endObject ( ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class AndroidFileHandle extends FileHandle { final AssetManager assets ; AndroidFileHandle ( AssetManager assets , String fileName , FileType type ) { } AndroidFileHandle ( AssetManager assets , File file , FileType type ) { } public FileHandle child ( String name ) { } public FileHandle sibling ( String name ) { } public FileHandle parent ( ) { } public InputStream read ( ) { } public FileHandle [ ] list ( ) { } public FileHandle [ ] list ( String suffix ) { if ( ( type ) == ( FileType . Internal ) ) { try { String [ ] relativePaths = assets . list ( file . getPath ( ) ) ; FileHandle [ ] handles = new FileHandle [ relativePaths . length ] ; int count = 0 ; for ( int i = 0 , n = handles . length ; i < n ; i ++ ) { String path = relativePaths [ i ] ; if ( ! ( path . endsWith ( suffix ) ) ) continue ; handles [ count ] = new AndroidFileHandle ( assets , new File ( file , path ) , type ) ; count ++ ; } if ( count < ( relativePaths . length ) ) { FileHandle [ ] newHandles = new FileHandle [ count ] ; System . arraycopy ( handles , 0 , newHandles , 0 , count ) ; handles = newHandles ; } return handles ; } catch ( Exception ex ) { throw new com . badlogic . gdx . utils . GdxRuntimeException ( ( ( ( ( "Error<seq2seq4repair_space>listing<seq2seq4repair_space>children:<seq2seq4repair_space>" + ( file ) ) + "<seq2seq4repair_space>(" ) + ( type ) ) + ")" ) , ex ) ; } } <START_BUG> return super . list ( ) ; <END_BUG> } public boolean isDirectory ( ) { } public boolean exists ( ) { } public long length ( ) { } public long lastModified ( ) { } }<BUG2FIX>return super . list ( suffix ) ;
public class BoolJsonQueryBuilder extends BaseJsonQueryBuilder { private ArrayList < BoolJsonQueryBuilder . Clause > clauses = new ArrayList < BoolJsonQueryBuilder . Clause > ( ) ; private float boost = - 1 ; private Boolean disableCoord ; private int minimumNumberShouldMatch = - 1 ; public BoolJsonQueryBuilder must ( JsonQueryBuilder queryBuilder ) { } public BoolJsonQueryBuilder mustNot ( JsonQueryBuilder queryBuilder ) { } public BoolJsonQueryBuilder should ( JsonQueryBuilder queryBuilder ) { } public BoolJsonQueryBuilder boost ( float boost ) { } public BoolJsonQueryBuilder disableCoord ( boolean disableCoord ) { } public BoolJsonQueryBuilder minimumNumberShouldMatch ( int minimumNumberShouldMatch ) { } @ Override protected void doJson ( JsonBuilder builder , Params params ) throws IOException { builder . startObject ( "bool" ) ; for ( BoolJsonQueryBuilder . Clause clause : clauses ) { if ( ( clause . occur ) == ( Occur . MUST ) ) { builder . field ( "must" ) ; clause . queryBuilder . toJson ( builder , params ) ; } else if ( ( clause . occur ) == ( Occur . MUST_NOT ) ) { builder . field ( "mustNot" ) ; clause . queryBuilder . toJson ( builder , params ) ; } else if ( ( clause . occur ) == ( Occur . SHOULD ) ) { builder . field ( "should" ) ; clause . queryBuilder . toJson ( builder , params ) ; } } if ( ( boost ) != ( - 1 ) ) { builder . field ( "boost" , boost ) ; } if ( ( disableCoord ) != null ) { builder . field ( "disableCoord" , disableCoord ) ; } <START_BUG> if ( ( minimumNumberShouldMatch ) == ( - 1 ) ) { <END_BUG> builder . field ( "minimumNumberShouldMatch" , minimumNumberShouldMatch ) ; } builder . endObject ( ) ; } private static class Clause { final JsonQueryBuilder queryBuilder ; final Occur occur ; private Clause ( JsonQueryBuilder queryBuilder , BooleanClause . Occur occur ) { } } }<BUG2FIX>if ( ( minimumNumberShouldMatch ) != ( - 1 ) ) {
public class TransportDeleteWarmerAction extends TransportMasterNodeOperationAction < DeleteWarmerRequest , DeleteWarmerResponse > { @ Inject public TransportDeleteWarmerAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected DeleteWarmerRequest newRequest ( ) { } @ Override protected DeleteWarmerResponse newResponse ( ) { } @ Override protected void doExecute ( DeleteWarmerRequest request , ActionListener < DeleteWarmerResponse > listener ) { } @ Override protected ClusterBlockException checkBlock ( DeleteWarmerRequest request , ClusterState state ) { } @ Override protected void masterOperation ( final DeleteWarmerRequest request , final ClusterState state , final ActionListener < DeleteWarmerResponse > listener ) throws ElasticSearchException { clusterService . submitStateUpdateTask ( ( ( "delete_warmer<seq2seq4repair_space>[" + ( request . name ( ) ) ) + "]" ) , new AckedClusterStateUpdateTask ( ) { @ Override public boolean mustAck ( DiscoveryNode discoveryNode ) { return true ; } @ Override public void onAllNodesAcked ( @ Nullable Throwable t ) { listener . onResponse ( new DeleteWarmerResponse ( true ) ) ; } @ Override public void onAckTimeout ( ) { listener . onResponse ( new DeleteWarmerResponse ( false ) ) ; } @ Override public TimeValue ackTimeout ( ) { return request . timeout ( ) ; } @ Override public TimeValue timeout ( ) { return request . masterNodeTimeout ( ) ; } @ Override public void onFailure ( String source , Throwable t ) { logger . debug ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>delete<seq2seq4repair_space>warmer<seq2seq4repair_space>[{}]<seq2seq4repair_space>on<seq2seq4repair_space>indices<seq2seq4repair_space>[{}]" , t , request . name ( ) , request . indices ( ) ) ; listener . onFailure ( t ) ; } @ Override public ClusterState execute ( ClusterState currentState ) { MetaData . Builder mdBuilder = MetaData . builder ( currentState . metaData ( ) ) ; boolean globalFoundAtLeastOne = false ; for ( String index : request . indices ( ) ) { IndexMetaData indexMetaData = currentState . metaData ( ) . index ( index ) ; if ( indexMetaData == null ) { throw new org . elasticsearch . indices . IndexMissingException ( new Index ( index ) ) ; } IndexWarmersMetaData warmers = indexMetaData . custom ( TYPE ) ; if ( warmers != null ) { List < IndexWarmersMetaData . Entry > entries = Lists . newArrayList ( ) ; for ( IndexWarmersMetaData . Entry entry : warmers . entries ( ) ) { if ( ( ( request . name ( ) ) == null ) || ( Regex . simpleMatch ( request . name ( ) , entry . name ( ) ) ) ) { globalFoundAtLeastOne = true ; } else { entries . add ( entry ) ; } } if ( ( entries . size ( ) ) != ( warmers . entries ( ) . size ( ) ) ) { warmers = new IndexWarmersMetaData ( entries . toArray ( new IndexWarmersMetaData . Entry [ entries . size ( ) ] ) ) ; <START_BUG> IndexMetaData . Builder indexBuilder = IndexMetaData . newIndexMetaDataBuilder ( indexMetaData ) . putCustom ( TYPE , warmers ) ; <END_BUG> mdBuilder . put ( indexBuilder ) ; } } } if ( ! globalFoundAtLeastOne ) { if ( ( request . name ( ) ) == null ) { return currentState ; } throw new org . elasticsearch . search . warmer . IndexWarmerMissingException ( request . name ( ) ) ; } if ( logger . isInfoEnabled ( ) ) { for ( String index : request . indices ( ) ) { IndexMetaData indexMetaData = currentState . metaData ( ) . index ( index ) ; if ( indexMetaData == null ) { throw new org . elasticsearch . indices . IndexMissingException ( new Index ( index ) ) ; } IndexWarmersMetaData warmers = indexMetaData . custom ( TYPE ) ; if ( warmers != null ) { for ( IndexWarmersMetaData . Entry entry : warmers . entries ( ) ) { if ( Regex . simpleMatch ( request . name ( ) , entry . name ( ) ) ) { logger . info ( "[{}]<seq2seq4repair_space>delete<seq2seq4repair_space>warmer<seq2seq4repair_space>[{}]" , index , entry . name ( ) ) ; } } } } } return ClusterState . builder ( ) . state ( currentState ) . metaData ( mdBuilder ) . build ( ) ; } @ Override public void clusterStateProcessed ( String source , ClusterState oldState , ClusterState newState ) { } } ) ; } }<BUG2FIX>IndexMetaData . Builder indexBuilder = IndexMetaData . builder ( indexMetaData ) . putCustom ( TYPE , warmers ) ;
public class RecoverySource extends AbstractComponent { public static class Actions { public static final String START_RECOVERY = "index/shard/recovery/startRecovery" ; } private final ThreadPool threadPool ; private final TransportService transportService ; private final IndicesService indicesService ; private final RecoveryThrottler recoveryThrottler ; private final ByteSizeValue fileChunkSize ; @ Inject public RecoverySource ( Settings settings , ThreadPool threadPool , TransportService transportService , IndicesService indicesService , RecoveryThrottler recoveryThrottler ) { } private RecoveryResponse recover ( final StartRecoveryRequest request ) { } class StartRecoveryTransportRequestHandler extends BaseTransportRequestHandler < StartRecoveryRequest > { @ Override public StartRecoveryRequest newInstance ( ) { } @ Override public void messageReceived ( final StartRecoveryRequest request , final TransportChannel channel ) throws Exception { threadPool . cached ( ) . execute ( new Runnable ( ) { @ Override public void run ( ) { try { RecoveryResponse response = recover ( request ) ; channel . sendResponse ( response ) ; } catch ( Exception e ) { try { channel . sendResponse ( e ) ; <START_BUG> } catch ( IOException e1 ) { <END_BUG> } } } } ) ; } @ Override public boolean spawn ( ) { } } }<BUG2FIX>} catch ( Exception e1 ) {
updateRequest . parent ( request . param ( "parent" ) ) ; updateRequest . timeout ( request . paramAsTime ( "timeout" , updateRequest . timeout ( ) ) ) ; updateRequest . refresh ( request . paramAsBoolean ( "refresh" , updateRequest . refresh ( ) ) ) ; String replicationType = request . param ( "replication" ) ; if ( replicationType != null ) { updateRequest . replicationType ( ReplicationType . fromString ( replicationType ) ) ; } String consistencyLevel = request . param ( "consistency" ) ; if ( consistencyLevel != null ) { updateRequest . consistencyLevel ( WriteConsistencyLevel . fromString ( consistencyLevel ) ) ; } updateRequest . percolate ( request . param ( "percolate" , null ) ) ; updateRequest . script ( request . param ( "script" ) ) ; updateRequest . scriptLang ( request . param ( "lang" ) ) ; for ( Map . Entry < String , String > entry : request . params ( ) . entrySet ( ) ) { if ( entry . getKey ( ) . startsWith ( "sp_" ) ) { updateRequest . addScriptParam ( entry . getKey ( ) . substring ( 3 ) , entry . getValue ( ) ) ; } } String sField = request . param ( "fields" ) ; if ( sField != null ) { String [ ] sFields = Strings . splitStringByCommaToArray ( sField ) ; if ( sFields != null ) { updateRequest . fields ( sFields ) ; } } updateRequest . retryOnConflict ( request . paramAsInt ( "retry_on_conflict" , updateRequest . retryOnConflict ( ) ) ) ; if ( request . hasContent ( ) ) { try { updateRequest . source ( request . content ( ) ) ; IndexRequest upsertRequest = updateRequest . upsertRequest ( ) ; if ( upsertRequest != null ) { upsertRequest . routing ( request . param ( "routing" ) ) ; upsertRequest . parent ( request . param ( "parent" ) ) ; upsertRequest . timestamp ( request . param ( "timestamp" ) ) ; if ( request . hasParam ( "ttl" ) ) { upsertRequest . ttl ( request . paramAsTime ( "ttl" , null ) . millis ( ) ) ; } upsertRequest . version ( RestActions . parseVersion ( request ) ) ; upsertRequest . versionType ( VersionType . fromString ( request . param ( "version_type" ) , upsertRequest . versionType ( ) ) ) ; } IndexRequest doc = updateRequest . doc ( ) ; if ( doc != null ) { doc . routing ( request . param ( "routing" ) ) ; doc . parent ( request . param ( "parent" ) ) ; doc . timestamp ( request . param ( "timestamp" ) ) ; if ( request . hasParam ( "ttl" ) ) { doc . ttl ( request . paramAsTime ( "ttl" , null ) . millis ( ) ) ; } doc . version ( RestActions . parseVersion ( request ) ) ; doc . versionType ( VersionType . fromString ( request . param ( "version_type" ) , doc . versionType ( ) ) ) ; } } catch ( Exception e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . warn ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>response" , e1 ) ; } return ; } } client . update ( updateRequest , new org . elasticsearch . action . ActionListener < UpdateResponse > ( ) { @ Override public void onResponse ( UpdateResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) . field ( RestUpdateAction . Fields . OK , true ) . field ( RestUpdateAction . Fields . _INDEX , response . getIndex ( ) ) . field ( RestUpdateAction . Fields . _TYPE , response . getType ( ) ) . field ( RestUpdateAction . Fields . _ID , response . getId ( ) ) . field ( RestUpdateAction . Fields . _VERSION , response . getVersion ( ) ) ; if ( ( response . getGetResult ( ) ) != null ) { builder . startObject ( RestUpdateAction . Fields . GET ) ; response . getGetResult ( ) . toXContentEmbedded ( builder , request ) ; builder . endObject ( ) ; } if ( ( response . getMatches ( ) ) != null ) { builder . startArray ( RestUpdateAction . Fields . MATCHES ) ; for ( String match : response . getMatches ( ) ) { builder . value ( match ) ; } builder . endArray ( ) ; } builder . endObject ( ) ; RestStatus status = org . elasticsearch . rest . RestStatus . OK ; if ( ( response . getVersion ( ) ) == 1 ) { status = org . elasticsearch . rest . RestStatus . CREATED ; } channel . sendResponse ( new XContentRestResponse ( request , status , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } static final class Fields { static final XContentBuilderString OK = new XContentBuilderString ( "ok" ) ; static final XContentBuilderString _INDEX = new XContentBuilderString ( "_index" ) ; static final XContentBuilderString _TYPE = new XContentBuilderString ( "_type" ) ; static final XContentBuilderString _ID = new XContentBuilderString ( "_id" ) ; static final XContentBuilderString _VERSION = new XContentBuilderString ( "_version" ) ; static final XContentBuilderString MATCHES = new XContentBuilderString ( "matches" ) ; static final XContentBuilderString GET = new XContentBuilderString ( "get" ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class HomeActivity extends RoboActivity { private static final String TAG = "HA" ; private static final int CODE_LOGIN = 1 ; private class LinksListAdapter extends ArrayAdapter < String > { public LinksListAdapter ( List < String > objects ) { } @ Override public View getView ( int position , View convertView , ViewGroup parent ) { } } private class OrgListAdapter extends ArrayAdapter < User > { public OrgListAdapter ( List < User > objects ) { } @ Override public View getView ( int position , View convertView , ViewGroup parent ) { } } private Map < String , Integer > linkViews = new LinkedHashMap < String , Integer > ( ) ; @ Inject private ContextScopedProvider < Account > accountProvider ; @ Inject private ContextScopedProvider < AccountDataManager > cache ; @ InjectView ( id . lv_orgs ) private ListView orgsList ; @ InjectView ( id . lv_links ) private ListView linksList ; protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; setContentView ( home ) ; linkViews . put ( "Dashboard" , dashboard_icon ) ; linkViews . put ( "Gists" , gist_icon ) ; linksList . setAdapter ( new HomeActivity . LinksListAdapter ( new ArrayList < String > ( linkViews . keySet ( ) ) ) ) ; linksList . setOnItemClickListener ( new OnItemClickListener ( ) { public void onItemClick ( AdapterView < ? > arg0 , View arg1 , int position , long id ) { switch ( position ) { case 1 : startActivity ( new Intent ( HomeActivity . this , GistsActivity . class ) ) ; break ; default : break ; } } } ) ; orgsList . setOnItemClickListener ( new OnItemClickListener ( ) { public void onItemClick ( AdapterView < ? > view , View arg1 , int position , long id ) { User user = ( ( User ) ( view . getItemAtPosition ( position ) ) ) ; <START_BUG> startActivity ( RepoBrowseActivity . createIntent ( HomeActivity . this , user ) ) ; <END_BUG> } } ) ; } private void loadOrgs ( ) { } protected void onActivityResult ( int requestCode , int resultCode , Intent data ) { } @ Override protected void onResume ( ) { } }<BUG2FIX>startActivity ( RepoBrowseActivity . createIntent ( user ) ) ;
public class LongArray { public long [ ] items ; public int size ; public boolean ordered ; public LongArray ( ) { } public LongArray ( int capacity ) { } public LongArray ( boolean ordered , int capacity ) { } public LongArray ( LongArray array ) { } public LongArray ( long [ ] array ) { } public LongArray ( boolean ordered , long [ ] array ) { } public void add ( long value ) { } public void addAll ( LongArray array ) { } public void addAll ( LongArray array , int offset , int length ) { } public void addAll ( long [ ] array ) { } public void addAll ( long [ ] array , int offset , int length ) { } public long get ( int index ) { } public void set ( int index , long value ) { } public void insert ( int index , long value ) { } public void swap ( int first , int second ) { } public boolean contains ( long value ) { } public int indexOf ( long value ) { } public int lastIndexOf ( char value ) { } public boolean removeValue ( long value ) { } public long removeIndex ( int index ) { } public boolean removeAll ( LongArray array ) { int size = this . size ; int startSize = size ; long [ ] items = this . items ; for ( int i = 0 , n = array . size ; i < n ; i ++ ) { long item = array . get ( i ) ; <START_BUG> for ( int ii = 0 , nn = size ; ii < nn ; ii ++ ) { <END_BUG> if ( item == ( items [ ii ] ) ) { removeIndex ( ii ) ; size -- ; break ; } } } return size != startSize ; } public long pop ( ) { } public long peek ( ) { } public long first ( ) { } public void clear ( ) { } public void shrink ( ) { } public long [ ] ensureCapacity ( int additionalCapacity ) { } protected long [ ] resize ( int newSize ) { } public void sort ( ) { } public void reverse ( ) { } public void shuffle ( ) { } public void truncate ( int newSize ) { } public long random ( ) { } public long [ ] toArray ( ) { } public boolean equals ( Object object ) { } public String toString ( ) { } public String toString ( String separator ) { } }<BUG2FIX>for ( int ii = 0 ; ii < size ; ii ++ ) {
public class IndexDeleteByQueryRequest extends IndexReplicationOperationRequest { private BytesReference querySource ; private String [ ] types = Strings . EMPTY_ARRAY ; @ Nullable private Set < String > routing ; @ Nullable private String [ ] filteringAliases ; IndexDeleteByQueryRequest ( DeleteByQueryRequest request , String index , @ Nullable Set < String > routing , @ Nullable String [ ] filteringAliases ) { } IndexDeleteByQueryRequest ( ) { } BytesReference querySource ( ) { } @ Override public ActionRequestValidationException validate ( ) { } Set < String > routing ( ) { } String [ ] types ( ) { } String [ ] filteringAliases ( ) { } public IndexDeleteByQueryRequest timeout ( TimeValue timeout ) { } public void readFrom ( StreamInput in ) throws IOException { } public void writeTo ( StreamOutput out ) throws IOException { super . writeTo ( out ) ; <START_BUG> out . writeBytesReference ( querySource , true ) ; <END_BUG> out . writeVInt ( types . length ) ; for ( String type : types ) { out . writeUTF ( type ) ; } if ( ( routing ) != null ) { out . writeVInt ( routing . size ( ) ) ; for ( String r : routing ) { out . writeUTF ( r ) ; } } else { out . writeVInt ( 0 ) ; } if ( ( filteringAliases ) != null ) { out . writeVInt ( filteringAliases . length ) ; for ( String alias : filteringAliases ) { out . writeUTF ( alias ) ; } } else { out . writeVInt ( 0 ) ; } } }<BUG2FIX>out . writeBytesReference ( querySource ) ;
public abstract class HasParentFilter extends Filter implements ScopePhase . CollectorPhase { final Query parentQuery ; final String scope ; final String parentType ; final SearchContext context ; HasParentFilter ( Query parentQuery , String scope , String parentType , SearchContext context ) { } public String scope ( ) { } public Query query ( ) { } @ Override public String toString ( ) { } public static HasParentFilter create ( String executionType , Query query , String scope , String parentType , SearchContext context ) { } static class Uid extends HasParentFilter { THashSet < HashedBytesArray > parents ; Uid ( Query query , String scope , String parentType , SearchContext context ) { } public boolean requiresProcessing ( ) { } public Collector collector ( ) { } public void processCollector ( Collector collector ) { } public DocIdSet getDocIdSet ( IndexReader reader ) throws IOException { if ( ( parents ) == null ) { throw new ElasticSearchIllegalStateException ( "has_parent<seq2seq4repair_space>filter/query<seq2seq4repair_space>hasn't<seq2seq4repair_space>executed<seq2seq4repair_space>properly" ) ; } IdReaderTypeCache idReaderTypeCache = context . idCache ( ) . reader ( reader ) . type ( parentType ) ; if ( idReaderTypeCache != null ) { return new HasParentFilter . Uid . ChildrenDocSet ( reader , parents , idReaderTypeCache ) ; } else { <START_BUG> return DocIdSet . EMPTY_DOCIDSET ; <END_BUG> } } public void clear ( ) { } static class ChildrenDocSet extends GetDocSet { final IndexReader reader ; final THashSet < HashedBytesArray > parents ; final IdReaderTypeCache idReaderTypeCache ; ChildrenDocSet ( IndexReader reader , THashSet < HashedBytesArray > parents , IdReaderTypeCache idReaderTypeCache ) { } public boolean get ( int doc ) { } } static class ParentUidsCollector extends NoopCollector { final THashSet < HashedBytesArray > collectedUids ; final SearchContext context ; final String parentType ; IdReaderTypeCache typeCache ; ParentUidsCollector ( THashSet < HashedBytesArray > collectedUids , SearchContext context , String parentType ) { } public void collect ( int doc ) throws IOException { } public void setNextReader ( IndexReader reader , int docBase ) throws IOException { } } } static class Bitset extends HasParentFilter { Map < Object , FixedBitSet > parentDocs ; Bitset ( Query query , String scope , String parentType , SearchContext context ) { } public boolean requiresProcessing ( ) { } public Collector collector ( ) { } public void processCollector ( Collector collector ) { } public DocIdSet getDocIdSet ( IndexReader reader ) throws IOException { if ( ( parentDocs ) == null ) { throw new ElasticSearchIllegalStateException ( "has_parent<seq2seq4repair_space>filter/query<seq2seq4repair_space>hasn't<seq2seq4repair_space>executed<seq2seq4repair_space>properly" ) ; } return new HasParentFilter . Bitset . ChildrenDocSet ( reader , parentDocs , context , parentType ) ; } public void clear ( ) { } static class ChildrenDocSet extends GetDocSet { final IdReaderTypeCache currentTypeCache ; final IndexReader currentReader ; final Tuple < IndexReader , IdReaderTypeCache > [ ] readersToTypeCache ; final Map < Object , FixedBitSet > parentDocs ; ChildrenDocSet ( IndexReader currentReader , Map < Object , FixedBitSet > parentDocs , SearchContext context , String parentType ) { } public boolean get ( int doc ) { } } static class ParentDocsCollector extends NoopCollector { final Map < Object , FixedBitSet > segmentResults = Maps . newHashMap ( ) ; FixedBitSet current ; public void collect ( int doc ) throws IOException { } public void setNextReader ( IndexReader reader , int docBase ) throws IOException { } } } }<BUG2FIX>return null ;
final Rectangle vKnobBounds = new Rectangle ( ) ; private final Rectangle widgetAreaBounds = new Rectangle ( ) ; private final Rectangle widgetCullingArea = new Rectangle ( ) ; private final Rectangle scissorBounds = new Rectangle ( ) ; private ActorGestureListener gestureListener ; boolean scrollX ; boolean scrollY ; float amountX ; float amountY ; float visualAmountX ; float visualAmountY ; float maxX ; float maxY ; boolean touchScrollH ; boolean touchScrollV ; final Vector2 lastPoint = new Vector2 ( ) ; float areaWidth ; float areaHeight ; private boolean fadeScrollBars = true ; private boolean smoothScrolling = true ; float fadeAlpha ; float fadeAlphaSeconds = 1 ; float fadeDelay ; float fadeDelaySeconds = 1 ; boolean flickScroll = true ; float velocityX ; float velocityY ; float flingTimer ; private boolean overscrollX = true ; private boolean overscrollY = true ; float flingTime = 1.0F ; private float overscrollDistance = 50 ; private float overscrollSpeedMin = 30 ; private float overscrollSpeedMax = 200 ; private boolean forceOverscrollX ; private boolean forceOverscrollY ; private boolean disableX ; private boolean disableY ; private boolean clamp = true ; private boolean scrollbarsOnTop ; int draggingPointer = - 1 ; public ScrollPane ( Actor widget ) { } public ScrollPane ( Actor widget , Skin skin ) { } public ScrollPane ( Actor widget , Skin skin , String styleName ) { } public ScrollPane ( Actor widget , ScrollPane . ScrollPaneStyle style ) { } void resetFade ( ) { } void cancelTouchFocusedChild ( InputEvent event ) { } void clamp ( ) { } public void setStyle ( ScrollPane . ScrollPaneStyle style ) { } public ScrollPane . ScrollPaneStyle getStyle ( ) { } public void act ( float delta ) { } public void layout ( ) { } @ Override public void draw ( SpriteBatch batch , float parentAlpha ) { if ( ( widget ) == null ) return ; validate ( ) ; applyTransform ( batch , computeTransform ( ) ) ; if ( scrollX ) hKnobBounds . x = ( hScrollBounds . x ) + ( ( int ) ( ( ( hScrollBounds . width ) - ( hKnobBounds . width ) ) * ( getScrollPercentX ( ) ) ) ) ; if ( scrollY ) vKnobBounds . y = ( vScrollBounds . y ) + ( ( int ) ( ( ( vScrollBounds . height ) - ( vKnobBounds . height ) ) * ( 1 - ( getScrollPercentY ( ) ) ) ) ) ; float y = widgetAreaBounds . y ; if ( ! ( scrollY ) ) y -= ( ( int ) ( maxY ) ) ; else y -= ( ( int ) ( ( maxY ) - ( visualAmountY ) ) ) ; <START_BUG> if ( ( ( ! ( fadeScrollBars ) ) && ( scrollbarsOnTop ) ) && ( scrollX ) ) { <END_BUG> float scrollbarHeight = 0 ; if ( ( style . hScrollKnob ) != null ) scrollbarHeight = style . hScrollKnob . getMinHeight ( ) ; if ( ( style . hScroll ) != null ) scrollbarHeight = Math . max ( scrollbarHeight , style . hScroll . getMinHeight ( ) ) ; y += scrollbarHeight ; } float x = widgetAreaBounds . x ; if ( scrollX ) x -= ( ( int ) ( visualAmountX ) ) ; widget . setPosition ( x , y ) ; if ( ( widget ) instanceof Cullable ) { widgetCullingArea . x = ( - ( widget . getX ( ) ) ) + ( widgetAreaBounds . x ) ; widgetCullingArea . y = ( - ( widget . getY ( ) ) ) + ( widgetAreaBounds . y ) ; widgetCullingArea . width = widgetAreaBounds . width ; widgetCullingArea . height = widgetAreaBounds . height ; ( ( Cullable ) ( widget ) ) . setCullingArea ( widgetCullingArea ) ; } ScissorStack . calculateScissors ( getStage ( ) . getCamera ( ) , batch . getTransformMatrix ( ) , widgetAreaBounds , scissorBounds ) ; Color color = getColor ( ) ; batch . setColor ( color . r , color . g , color . b , ( ( color . a ) * parentAlpha ) ) ; if ( ( style . background ) != null ) style . background . draw ( batch , 0 , 0 , getWidth ( ) , getHeight ( ) ) ; batch . flush ( ) ; if ( ScissorStack . pushScissors ( scissorBounds ) ) { drawChildren ( batch , parentAlpha ) ; ScissorStack . popScissors ( ) ; } batch . setColor ( color . r , color . g , color . b , ( ( ( color . a ) * parentAlpha ) * ( fade . apply ( ( ( fadeAlpha ) / ( fadeAlphaSeconds ) ) ) ) ) ) ; if ( ( scrollX ) && ( scrollY ) ) { if ( ( style . corner ) != null ) { style . corner . draw ( batch , ( ( hScrollBounds . x ) + ( hScrollBounds . width ) ) , hScrollBounds . y , vScrollBounds . width , vScrollBounds . y ) ; } } if ( scrollX ) { if ( ( style . hScroll ) != null ) style . hScroll . draw ( batch , hScrollBounds . x , hScrollBounds . y , hScrollBounds . width , hScrollBounds . height ) ; if ( ( style . hScrollKnob ) != null ) style . hScrollKnob . draw ( batch , hKnobBounds . x , hKnobBounds . y , hKnobBounds . width , hKnobBounds . height ) ; } if ( scrollY ) { if ( ( style . vScroll ) != null ) style . vScroll . draw ( batch , vScrollBounds . x , vScrollBounds . y , vScrollBounds . width , vScrollBounds . height ) ;<BUG2FIX>if ( ( scrollbarsOnTop ) && ( scrollX ) ) {
public class ScanContext { private final Map < IndexReader , ScanContext . ReaderState > readerStates = Maps . newHashMap ( ) ; public void clear ( ) { } public TopDocs execute ( SearchContext context ) throws IOException { } static class ScanCollector extends Collector { private final Map < IndexReader , ScanContext . ReaderState > readerStates ; private final int from ; private final int to ; private final ArrayList < ScoreDoc > docs ; private final boolean trackScores ; private Scorer scorer ; private int docBase ; private int counter ; private IndexReader currentReader ; private ScanContext . ReaderState readerState ; ScanCollector ( Map < IndexReader , ScanContext . ReaderState > readerStates , int from , int size , boolean trackScores ) { } void incCounter ( int count ) { } public TopDocs topDocs ( ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override public void collect ( int doc ) throws IOException { } @ Override public void setNextReader ( AtomicReaderContext context ) throws IOException { } @ Override public boolean acceptsDocsOutOfOrder ( ) { <START_BUG> return true ; <END_BUG> } public static final RuntimeException StopCollectingException = new ScanContext . ScanCollector . StopCollectingException ( ) ; static class StopCollectingException extends RuntimeException { @ Override public Throwable fillInStackTrace ( ) { } } } public static class ScanFilter extends Filter { private final Map < IndexReader , ScanContext . ReaderState > readerStates ; private final ScanContext . ScanCollector scanCollector ; public ScanFilter ( Map < IndexReader , ScanContext . ReaderState > readerStates , ScanContext . ScanCollector scanCollector ) { } @ Override public DocIdSet getDocIdSet ( AtomicReaderContext context , Bits acceptedDocs ) throws IOException { } } static class ReaderState { public int count ; public boolean done ; } }<BUG2FIX>return false ;
public class RestExplainAction extends BaseRestHandler { @ Inject public RestExplainAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { final ExplainRequest explainRequest = new ExplainRequest ( request . param ( "index" ) , request . param ( "type" ) , request . param ( "id" ) ) ; explainRequest . parent ( request . param ( "parent" ) ) ; explainRequest . routing ( request . param ( "routing" ) ) ; explainRequest . preference ( request . param ( "preference" ) ) ; String sourceString = request . param ( "source" ) ; String queryString = request . param ( "q" ) ; if ( request . hasContent ( ) ) { explainRequest . source ( request . content ( ) , request . contentUnsafe ( ) ) ; } else if ( sourceString != null ) { explainRequest . source ( new org . elasticsearch . common . bytes . BytesArray ( request . param ( "source" ) ) , false ) ; } else if ( queryString != null ) { QueryStringQueryBuilder queryStringBuilder = QueryBuilders . queryString ( queryString ) ; queryStringBuilder . defaultField ( request . param ( "df" ) ) ; queryStringBuilder . analyzer ( request . param ( "analyzer" ) ) ; queryStringBuilder . analyzeWildcard ( request . paramAsBoolean ( "analyze_wildcard" , false ) ) ; queryStringBuilder . lowercaseExpandedTerms ( request . paramAsBoolean ( "lowercase_expanded_terms" , true ) ) ; queryStringBuilder . lenient ( request . paramAsBooleanOptional ( "lenient" , null ) ) ; String defaultOperator = request . param ( "default_operator" ) ; if ( defaultOperator != null ) { if ( "OR" . equals ( defaultOperator ) ) { queryStringBuilder . defaultOperator ( OR ) ; } else if ( "AND" . equals ( defaultOperator ) ) { queryStringBuilder . defaultOperator ( AND ) ; } else { throw new ElasticSearchIllegalArgumentException ( ( ( "Unsupported<seq2seq4repair_space>defaultOperator<seq2seq4repair_space>[" + defaultOperator ) + "],<seq2seq4repair_space>can<seq2seq4repair_space>either<seq2seq4repair_space>be<seq2seq4repair_space>[OR]<seq2seq4repair_space>or<seq2seq4repair_space>[AND]" ) ) ; } } ExplainSourceBuilder explainSourceBuilder = new ExplainSourceBuilder ( ) ; explainSourceBuilder . setQuery ( queryStringBuilder ) ; explainRequest . source ( explainSourceBuilder ) ; } String sField = request . param ( "fields" ) ; if ( sField != null ) { String [ ] sFields = Strings . splitStringByCommaToArray ( sField ) ; if ( sFields != null ) { explainRequest . fields ( sFields ) ; } } client . explain ( explainRequest , new org . elasticsearch . action . ActionListener < ExplainResponse > ( ) { @ Override public void onResponse ( ExplainResponse response ) { try { XContentBuilder builder = restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( RestExplainAction . Fields . OK , response . isExists ( ) ) . field ( RestExplainAction . Fields . _INDEX , explainRequest . index ( ) ) . field ( RestExplainAction . Fields . _TYPE , explainRequest . type ( ) ) . field ( RestExplainAction . Fields . _ID , explainRequest . id ( ) ) . field ( RestExplainAction . Fields . MATCHED , response . isMatch ( ) ) ; if ( response . hasExplanation ( ) ) { builder . startObject ( RestExplainAction . Fields . EXPLANATION ) ; buildExplanation ( builder , response . getExplanation ( ) ) ; builder . endObject ( ) ; } GetResult getResult = response . getGetResult ( ) ; if ( getResult != null ) { builder . startObject ( RestExplainAction . Fields . GET ) ; response . getGetResult ( ) . toXContentEmbedded ( builder , request ) ; builder . endObject ( ) ; } builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , ( response . isExists ( ) ? RestStatus . OK : RestStatus . NOT_FOUND ) , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } private void buildExplanation ( XContentBuilder builder , Explanation explanation ) throws IOException { builder . field ( RestExplainAction . Fields . VALUE , explanation . getValue ( ) ) ; builder . field ( RestExplainAction . Fields . DESCRIPTION , explanation . getDescription ( ) ) ; Explanation [ ] innerExps = explanation . getDetails ( ) ; if ( innerExps != null ) { builder . startArray ( RestExplainAction . Fields . DETAILS ) ; for ( Explanation exp : innerExps ) { builder . startObject ( ) ; buildExplanation ( builder , exp ) ; builder . endObject ( ) ; } builder . endArray ( ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } static class Fields { static final XContentBuilderString OK = new XContentBuilderString ( "ok" ) ; static final XContentBuilderString _INDEX = new XContentBuilderString ( "_index" ) ; static final XContentBuilderString _TYPE = new XContentBuilderString ( "_type" ) ; static final XContentBuilderString _ID = new XContentBuilderString ( "_id" ) ; static final XContentBuilderString MATCHED = new XContentBuilderString ( "matched" ) ; static final XContentBuilderString EXPLANATION = new XContentBuilderString ( "explanation" ) ; static final XContentBuilderString VALUE = new XContentBuilderString ( "value" ) ; static final XContentBuilderString DESCRIPTION = new XContentBuilderString ( "description" ) ; static final XContentBuilderString DETAILS = new XContentBuilderString ( "details" ) ; static final XContentBuilderString GET = new XContentBuilderString ( "get" ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class LZFCompressedIndexInput extends CompressedIndexInput < LZFCompressorContext > { private final ChunkDecoder decoder ; private byte [ ] inputBuffer ; public LZFCompressedIndexInput ( IndexInput in , ChunkDecoder decoder ) throws IOException { } @ Override protected void readHeader ( IndexInput in ) throws IOException { } @ Override protected int uncompress ( IndexInput in , byte [ ] out ) throws IOException { } @ Override protected void doClose ( ) throws IOException { } @ Override <START_BUG> public Object clone ( ) { <END_BUG> LZFCompressedIndexInput cloned = ( ( LZFCompressedIndexInput ) ( super . clone ( ) ) ) ; cloned . inputBuffer = new byte [ LZFChunk . MAX_CHUNK_LEN ] ; return cloned ; } }<BUG2FIX>public IndexInput clone ( ) {
public class ParticleEmitterBox2D extends ParticleEmitter { final World world ; final Vector2 startPoint = new Vector2 ( ) ; final Vector2 endPoint = new Vector2 ( ) ; boolean particleCollided ; float normalAngle ; private static final float EPSILON = 0.001F ; final RayCastCallback rayCallBack = new RayCastCallback ( ) { public float reportRayFixture ( Fixture fixture , Vector2 point , Vector2 normal , float fraction ) { } } ; public ParticleEmitterBox2D ( World world ) { } public ParticleEmitterBox2D ( World world , BufferedReader reader ) throws IOException { } public ParticleEmitterBox2D ( World world , ParticleEmitter emitter ) { } @ Override protected Particle newParticle ( Sprite sprite ) { } private class ParticleBox2D extends Particle { public ParticleBox2D ( Sprite sprite ) { } @ Override public void translate ( float velocityX , float velocityY ) { if ( ( ( velocityX * velocityX ) + ( velocityY * velocityY ) ) < ( ParticleEmitterBox2D . EPSILON ) ) return ; final float x = ( getX ( ) ) + ( ( getWidth ( ) ) / 2.0F ) ; final float y = ( getY ( ) ) + ( ( getHeight ( ) ) / 2.0F ) ; particleCollided = false ; startPoint . set ( x , y ) ; endPoint . set ( ( x + velocityX ) , ( y + velocityY ) ) ; if ( ( world ) != null ) world . rayCast ( rayCallBack , startPoint , endPoint ) ; <START_BUG> if ( particleCollided ) { <END_BUG> angle = ( ( 2.0F * ( normalAngle ) ) - ( angle ) ) - 180.0F ; angleCos = MathUtils . cosDeg ( angle ) ; angleSin = MathUtils . sinDeg ( angle ) ; velocityX = ( velocity ) * ( angleCos ) ; velocityY = ( velocity ) * ( angleSin ) ; } super . translate ( velocityX , velocityY ) ; } } }<BUG2FIX>if ( ! ( particleCollided ) ) {
public class ObjectIntMap < K > { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; public int size ; K [ ] keyTable ; int [ ] valueTable ; int capacity ; int stashSize ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private ObjectIntMap . Entries entries1 ; private ObjectIntMap . Entries entries2 ; private ObjectIntMap . Values values1 ; private ObjectIntMap . Values values2 ; private ObjectIntMap . Keys keys1 ; private ObjectIntMap . Keys keys2 ; public ObjectIntMap ( ) { } public ObjectIntMap ( int initialCapacity ) { } public ObjectIntMap ( int initialCapacity , float loadFactor ) { } public ObjectIntMap ( ObjectIntMap < ? extends K > map ) { } public void put ( K key , int value ) { } public void putAll ( ObjectIntMap < K > map ) { } private void putResize ( K key , int value ) { } private void push ( K insertKey , int insertValue , int index1 , K key1 , int index2 , K key2 , int index3 , K key3 ) { } private void putStash ( K key , int value ) { } public int get ( K key , int defaultValue ) { } private int getStash ( K key , int defaultValue ) { } public int getAndIncrement ( K key , int defaultValue , int increment ) { } private int getAndIncrementStash ( K key , int defaultValue , int increment ) { } public int remove ( K key , int defaultValue ) { } int removeStash ( K key , int defaultValue ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean containsValue ( int value ) { } public boolean containsKey ( K key ) { } private boolean containsKeyStash ( K key ) { } public K findKey ( int value ) { } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( int h ) { } private int hash3 ( int h ) { } public String toString ( ) { } public ObjectIntMap . Entries < K > entries ( ) { } public ObjectIntMap . Values values ( ) { } public ObjectIntMap . Keys < K > keys ( ) { } public static class Entry < K > { public K key ; public int value ; public String toString ( ) { } } private static class MapIterator < K > { public boolean hasNext ; final ObjectIntMap < K > map ; int nextIndex ; int currentIndex ; boolean valid = true ; public MapIterator ( ObjectIntMap < K > map ) { } public void reset ( ) { } void findNextIndex ( ) { } public void remove ( ) { if ( ( currentIndex ) < 0 ) throw new IllegalStateException ( "next<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>called<seq2seq4repair_space>before<seq2seq4repair_space>remove." ) ; if ( ( currentIndex ) >= ( map . capacity ) ) { map . removeStashIndex ( currentIndex ) ; <START_BUG> nextIndex = ( currentIndex ) - 1 ; <END_BUG> findNextIndex ( ) ; } else { map . keyTable [ currentIndex ] = null ; } currentIndex = - 1 ; ( map . size ) -- ; } } public static class Entries < K > extends ObjectIntMap . MapIterator < K > implements Iterable < ObjectIntMap . Entry < K > > , Iterator < ObjectIntMap . Entry < K > > { private ObjectIntMap . Entry < K > entry = new ObjectIntMap . Entry ( ) ; public Entries ( ObjectIntMap < K > map ) { } public ObjectIntMap . Entry < K > next ( ) { } public boolean hasNext ( ) { } public Iterator < ObjectIntMap . Entry < K > > iterator ( ) { } } public static class Values extends ObjectIntMap . MapIterator < Object > { public Values ( ObjectIntMap < ? > map ) { } public boolean hasNext ( ) { } public int next ( ) { } public IntArray toArray ( ) { } } public static class Keys < K > extends ObjectIntMap . MapIterator < K > implements Iterable < K > , Iterator < K > { public Keys ( ObjectIntMap < K > map ) { } public boolean hasNext ( ) { } public K next ( ) { } public Iterator < K > iterator ( ) { } public Array < K > toArray ( ) { } } }<BUG2FIX>nextIndex = currentIndex ;
public class ImageTest extends GdxTest { Skin skin ; Stage ui ; Table root ; TextureRegion image2 ; @ Override public void create ( ) { } @ Override public void dispose ( ) { } @ Override public void render ( ) { } @ Override public void resize ( int width , int height ) { <START_BUG> ui . getViewport ( ) . update ( width , height ) ; <END_BUG> root . setSize ( width , height ) ; } }<BUG2FIX>ui . getViewport ( ) . update ( width , height , true ) ;
public abstract class AbstractAtomicNumericFieldData implements AtomicNumericFieldData { private boolean isFloat ; public AbstractAtomicNumericFieldData ( boolean isFloat ) { } @ Override public ScriptDocValues getScriptValues ( ) { } @ Override <START_BUG> public BytesValues getBytesValues ( boolean needsHashes ) { <END_BUG> if ( isFloat ) { final DoubleValues values = getDoubleValues ( ) ; return new BytesValues ( values . isMultiValued ( ) ) { @ Override public int setDocument ( int docId ) { this . docId = docId ; return values . setDocument ( docId ) ; } @ Override public BytesRef nextValue ( ) { scratch . copyChars ( Double . toString ( values . nextValue ( ) ) ) ; return scratch ; } @ Override public Order getOrder ( ) { return values . getOrder ( ) ; } } ; } else { final LongValues values = getLongValues ( ) ; return new BytesValues ( values . isMultiValued ( ) ) { @ Override public int setDocument ( int docId ) { this . docId = docId ; return values . setDocument ( docId ) ; } @ Override public BytesRef nextValue ( ) { scratch . copyChars ( Long . toString ( values . nextValue ( ) ) ) ; return scratch ; } @ Override public Order getOrder ( ) { return values . getOrder ( ) ; } } ; } } }<BUG2FIX>public BytesValues getBytesValues ( ) {
public class ValueScriptHistogramFacetCollector extends AbstractFacetCollector { private final String indexFieldName ; private final ComparatorType comparatorType ; private final FieldDataCache fieldDataCache ; private final FieldDataType fieldDataType ; private NumericFieldData fieldData ; private final SearchScript valueScript ; private final ValueScriptHistogramFacetCollector . HistogramProc histoProc ; public ValueScriptHistogramFacetCollector ( String facetName , String fieldName , String scriptLang , String valueScript , Map < String , Object > params , long interval , HistogramFacet . ComparatorType comparatorType , SearchContext context ) { } @ Override protected void doCollect ( int doc ) throws IOException { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override protected void doSetNextReader ( AtomicReaderContext context ) throws IOException { fieldData = ( ( NumericFieldData ) ( fieldDataCache . cache ( fieldDataType , context . reader ( ) , indexFieldName ) ) ) ; <START_BUG> valueScript . setNextReader ( context . reader ( ) ) ; <END_BUG> } @ Override public Facet facet ( ) { } public static long bucket ( double value , long interval ) { } public static class HistogramProc implements NumericFieldData . DoubleValueInDocProc { private final long interval ; private final SearchScript valueScript ; final ExtTLongObjectHashMap < InternalFullHistogramFacet . FullEntry > entries = CacheRecycler . popLongObjectMap ( ) ; public HistogramProc ( long interval , SearchScript valueScript ) { } @ Override public void onValue ( int docId , double value ) { } } }<BUG2FIX>valueScript . setNextReader ( context ) ;
public class ThreadLocals { private static final ESLogger logger = Loggers . getLogger ( ThreadLocals . class ) ; public static class CleanableValue < T > { private T value ; public CleanableValue ( T value ) { } public T get ( ) { } public void set ( T value ) { } } public static void clearReferencesThreadLocals ( ) { } private static void clearThreadLocalMap ( Object map , Field internalTableField ) throws IllegalAccessException , NoSuchFieldException , NoSuchMethodException , InvocationTargetException { if ( map != null ) { Method mapRemove = map . getClass ( ) . getDeclaredMethod ( "remove" , ThreadLocal . class ) ; mapRemove . setAccessible ( true ) ; Object [ ] table = ( ( Object [ ] ) ( internalTableField . get ( map ) ) ) ; int staleEntriesCount = 0 ; if ( table != null ) { for ( int j = 0 ; j < ( table . length ) ; j ++ ) { if ( ( table [ j ] ) != null ) { boolean remove = false ; Object key = ( ( Reference < ? > ) ( table [ j ] ) ) . get ( ) ; Field valueField = table [ j ] . getClass ( ) . getDeclaredField ( "value" ) ; valueField . setAccessible ( true ) ; Object value = valueField . get ( table [ j ] ) ; if ( ( value != null ) && ( ThreadLocals . CleanableValue . class . isAssignableFrom ( value . getClass ( ) ) ) ) { remove = true ; } if ( remove ) { Object [ ] args = new Object [ 4 ] ; if ( key != null ) { args [ 0 ] = key . getClass ( ) . getCanonicalName ( ) ; args [ 1 ] = key . toString ( ) ; } args [ 2 ] = value . getClass ( ) . getCanonicalName ( ) ; args [ 3 ] = value . toString ( ) ; if ( ThreadLocals . logger . isDebugEnabled ( ) ) { <START_BUG> ThreadLocals . logger . debug ( "ThreadLocal<seq2seq4repair_space>with<seq2seq4repair_space>key<seq2seq4repair_space>of<seq2seq4repair_space>type<seq2seq4repair_space>[{0}]<seq2seq4repair_space>(value<seq2seq4repair_space>[{1}])<seq2seq4repair_space>and<seq2seq4repair_space>a<seq2seq4repair_space>value<seq2seq4repair_space>of<seq2seq4repair_space>type<seq2seq4repair_space>[{2}]<seq2seq4repair_space>(value<seq2seq4repair_space>[{3}]):<seq2seq4repair_space>The<seq2seq4repair_space>ThreadLocal<seq2seq4repair_space>has<seq2seq4repair_space>been<seq2seq4repair_space>forcibly<seq2seq4repair_space>removed." , args ) ; <END_BUG> } if ( key == null ) { staleEntriesCount ++ ; } else { mapRemove . invoke ( map , key ) ; } } } } } if ( staleEntriesCount > 0 ) { Method mapRemoveStale = map . getClass ( ) . getDeclaredMethod ( "expungeStaleEntries" ) ; mapRemoveStale . setAccessible ( true ) ; mapRemoveStale . invoke ( map ) ; } } } private static Thread [ ] getThreads ( ) { } }<BUG2FIX>ThreadLocals . logger . trace ( "ThreadLocal<seq2seq4repair_space>with<seq2seq4repair_space>key<seq2seq4repair_space>of<seq2seq4repair_space>type<seq2seq4repair_space>[{0}]<seq2seq4repair_space>(value<seq2seq4repair_space>[{1}])<seq2seq4repair_space>and<seq2seq4repair_space>a<seq2seq4repair_space>value<seq2seq4repair_space>of<seq2seq4repair_space>type<seq2seq4repair_space>[{2}]<seq2seq4repair_space>(value<seq2seq4repair_space>[{3}]):<seq2seq4repair_space>The<seq2seq4repair_space>ThreadLocal<seq2seq4repair_space>has<seq2seq4repair_space>been<seq2seq4repair_space>forcibly<seq2seq4repair_space>removed." , args ) ;
public class BitmapFont implements Disposable { private static final int LOG2_PAGE_SIZE = 9 ; private static final int PAGE_SIZE = 1 << ( BitmapFont . LOG2_PAGE_SIZE ) ; private static final int PAGES = 65536 / ( BitmapFont . PAGE_SIZE ) ; public static final char [ ] xChars = new char [ ] { 'x' , 'e' , 'a' , 'o' , 'n' , 's' , 'r' , 'c' , 'u' , 'm' , 'v' , 'w' , 'z' } ; public static final char [ ] capChars = new char [ ] { 'M' , 'N' , 'B' , 'D' , 'C' , 'E' , 'F' , 'K' , 'A' , 'G' , 'H' , 'I' , 'J' , 'L' , 'O' , 'P' , 'Q' , 'R' , 'S' , 'T' , 'U' , 'V' , 'W' , 'X' , 'Y' , 'Z' } ; final BitmapFont . BitmapFontData data ; TextureRegion [ ] regions ; private final BitmapFontCache cache ; private boolean flipped ; private boolean integer ; private boolean ownsTexture ; public BitmapFont ( ) { } public BitmapFont ( boolean flip ) { } public BitmapFont ( FileHandle fontFile , TextureRegion region ) { } public BitmapFont ( FileHandle fontFile , TextureRegion region , boolean flip ) { } public BitmapFont ( FileHandle fontFile ) { } public BitmapFont ( FileHandle fontFile , boolean flip ) { } public BitmapFont ( FileHandle fontFile , FileHandle imageFile , boolean flip ) { } public BitmapFont ( FileHandle fontFile , FileHandle imageFile , boolean flip , boolean integer ) { } public BitmapFont ( BitmapFont . BitmapFontData data , TextureRegion region , boolean integer ) { } public BitmapFont ( BitmapFont . BitmapFontData data , TextureRegion [ ] regions , boolean integer ) { } private void load ( BitmapFont . BitmapFontData data ) { } public BitmapFont . TextBounds draw ( Batch batch , CharSequence str , float x , float y ) { } public BitmapFont . TextBounds draw ( Batch batch , CharSequence str , float x , float y , int start , int end ) { } public BitmapFont . TextBounds drawMultiLine ( Batch batch , CharSequence str , float x , float y ) { } public BitmapFont . TextBounds drawMultiLine ( Batch batch , CharSequence str , float x , float y , float alignmentWidth , BitmapFont . HAlignment alignment ) { } public BitmapFont . TextBounds drawWrapped ( Batch batch , CharSequence str , float x , float y , float wrapWidth ) { } public BitmapFont . TextBounds drawWrapped ( Batch batch , CharSequence str , float x , float y , float wrapWidth , BitmapFont . HAlignment alignment ) { } public BitmapFont . TextBounds getBounds ( CharSequence str ) { <START_BUG> return getBounds ( str , 0 , str . length ( ) , cache . getBounds ( ) ) ; <END_BUG> } public BitmapFont . TextBounds getBounds ( CharSequence str , BitmapFont . TextBounds textBounds ) { } public BitmapFont . TextBounds getBounds ( CharSequence str , int start , int end ) { } public BitmapFont . TextBounds getBounds ( CharSequence str , int start , int end , BitmapFont . TextBounds textBounds ) { } public BitmapFont . TextBounds getMultiLineBounds ( CharSequence str ) { } public BitmapFont . TextBounds getMultiLineBounds ( CharSequence str , BitmapFont . TextBounds textBounds ) { } public BitmapFont . TextBounds getWrappedBounds ( CharSequence str , float wrapWidth ) { } public BitmapFont . TextBounds getWrappedBounds ( CharSequence str , float wrapWidth , BitmapFont . TextBounds textBounds ) { } public void computeGlyphAdvancesAndPositions ( CharSequence str , FloatArray glyphAdvances , FloatArray glyphPositions ) { } public int computeVisibleGlyphs ( CharSequence str , int start , int end , float availableWidth ) { } public void setColor ( float color ) { } public void setColor ( Color color ) { } public void setColor ( float r , float g , float b , float a ) { } public Color getColor ( ) { } public void setScale ( float scaleX , float scaleY ) { } public void setScale ( float scaleXY ) { } public void scale ( float amount ) { } public float getScaleX ( ) { } public float getScaleY ( ) { } public TextureRegion getRegion ( ) { } public TextureRegion [ ] getRegions ( ) { } public TextureRegion getRegion ( int index ) { } public float getLineHeight ( ) { } public float getSpaceWidth ( ) { } public float getXHeight ( ) { } public float getCapHeight ( ) { } public float getAscent ( ) { } public float getDescent ( ) { } public boolean isFlipped ( ) { } public void dispose ( ) { } public void setFixedWidthGlyphs ( CharSequence glyphs ) { } public boolean containsCharacter ( char character ) { } public void setUseIntegerPositions ( boolean integer ) { } public boolean usesIntegerPositions ( ) { } public BitmapFontCache getCache ( ) { } public BitmapFont . BitmapFontData getData ( ) { } public boolean ownsTexture ( ) { } public void setOwnsTexture ( boolean ownsTexture ) { } public static class Glyph { public int id ; public int srcX ; public int srcY ; public int width ; public int height ; public float u ; public float v ; public float u2 ; public float v2 ; public int xoffset ; public int yoffset ; public int xadvance ; public byte [ ] [ ] kerning ; public int page = 0 ; public int getKerning ( char ch ) { } public void setKerning ( int ch , int value ) { } } static int indexOf ( CharSequence text , char ch , int start ) { } static boolean isWhitespace ( char c ) { } public static class TextBounds { public float width ; public float height ;<BUG2FIX>return getBounds ( str , 0 , str . length ( ) ) ;
public abstract class AbstractSimpleTranslogTests { protected final ShardId shardId = new ShardId ( new Index ( "index" ) , 1 ) ; protected Translog translog ; @ BeforeMethod public void setUp ( ) { } @ AfterMethod public void tearDown ( ) { } protected abstract Translog create ( ) { } @ Test public void testTransientTranslog ( ) { } @ Test public void testSimpleOperations ( ) { Translog . Snapshot snapshot = translog . snapshot ( ) ; assertThat ( snapshot , translogSize ( 0 ) ) ; snapshot . release ( ) ; translog . add ( new Translog . Create ( "test" , "1" , new byte [ ] { 1 } ) ) ; snapshot = translog . snapshot ( ) ; assertThat ( snapshot , translogSize ( 1 ) ) ; assertThat ( snapshot . estimatedTotalOperations ( ) , equalTo ( 1 ) ) ; snapshot . release ( ) ; translog . add ( new Translog . Index ( "test" , "2" , new byte [ ] { 2 } ) ) ; snapshot = translog . snapshot ( ) ; assertThat ( snapshot , translogSize ( 2 ) ) ; assertThat ( snapshot . estimatedTotalOperations ( ) , equalTo ( 2 ) ) ; snapshot . release ( ) ; translog . add ( new Translog . Delete ( newUid ( "3" ) ) ) ; snapshot = translog . snapshot ( ) ; assertThat ( snapshot , translogSize ( 3 ) ) ; assertThat ( snapshot . estimatedTotalOperations ( ) , equalTo ( 3 ) ) ; snapshot . release ( ) ; <START_BUG> translog . add ( new Translog . DeleteByQuery ( new byte [ ] { 4 } , null , null ) ) ; <END_BUG> snapshot = translog . snapshot ( ) ; assertThat ( snapshot , translogSize ( 4 ) ) ; assertThat ( snapshot . estimatedTotalOperations ( ) , equalTo ( 4 ) ) ; snapshot . release ( ) ; snapshot = translog . snapshot ( ) ; assertThat ( snapshot . hasNext ( ) , equalTo ( true ) ) ; Translog . Create create = ( ( Translog . Create ) ( snapshot . next ( ) ) ) ; assertThat ( create . source ( ) , equalTo ( new byte [ ] { 1 } ) ) ; assertThat ( snapshot . hasNext ( ) , equalTo ( true ) ) ; Translog . Index index = ( ( Translog . Index ) ( snapshot . next ( ) ) ) ; assertThat ( index . source ( ) , equalTo ( new byte [ ] { 2 } ) ) ; assertThat ( snapshot . hasNext ( ) , equalTo ( true ) ) ; Translog . Delete delete = ( ( Translog . Delete ) ( snapshot . next ( ) ) ) ; assertThat ( delete . uid ( ) , equalTo ( newUid ( "3" ) ) ) ; assertThat ( snapshot . hasNext ( ) , equalTo ( true ) ) ; Translog . DeleteByQuery deleteByQuery = ( ( Translog . DeleteByQuery ) ( snapshot . next ( ) ) ) ; assertThat ( deleteByQuery . source ( ) , equalTo ( new byte [ ] { 4 } ) ) ; assertThat ( snapshot . hasNext ( ) , equalTo ( false ) ) ; snapshot . release ( ) ; long firstId = translog . currentId ( ) ; translog . newTranslog ( 2 ) ; assertThat ( translog . currentId ( ) , Matchers . not ( equalTo ( firstId ) ) ) ; snapshot = translog . snapshot ( ) ; assertThat ( snapshot , translogSize ( 0 ) ) ; assertThat ( snapshot . estimatedTotalOperations ( ) , equalTo ( 0 ) ) ; snapshot . release ( ) ; } @ Test public void testSnapshot ( ) { } @ Test public void testSnapshotWithNewTranslog ( ) { } @ Test public void testSnapshotWithSeekForward ( ) { } private Term newUid ( String id ) { } }<BUG2FIX>translog . add ( new Translog . DeleteByQuery ( new byte [ ] { 4 } , null ) ) ;
public class BinaryDVFieldDataTests extends AbstractFieldDataTests { @ Test public void testDocValue ( ) throws Exception { String mapping = XContentFactory . jsonBuilder ( ) . startObject ( ) . startObject ( "test" ) . startObject ( "properties" ) . startObject ( "field" ) . field ( "type" , "binary" ) . startObject ( "fielddata" ) . field ( "format" , "doc_values" ) . endObject ( ) . endObject ( ) . endObject ( ) . endObject ( ) . endObject ( ) . string ( ) ; final DocumentMapper mapper = MapperTestUtils . newParser ( ) . parse ( mapping ) ; ObjectArrayList < byte [ ] > bytesList1 = new ObjectArrayList ( 2 ) ; bytesList1 . add ( randomBytes ( ) ) ; bytesList1 . add ( randomBytes ( ) ) ; XContentBuilder doc = XContentFactory . jsonBuilder ( ) . startObject ( ) . startArray ( "field" ) . value ( bytesList1 . get ( 0 ) ) . value ( bytesList1 . get ( 1 ) ) . endArray ( ) . endObject ( ) ; ParsedDocument d = mapper . parse ( "test" , "1" , doc . bytes ( ) ) ; writer . addDocument ( d . rootDoc ( ) ) ; byte [ ] bytes1 = randomBytes ( ) ; doc = XContentFactory . jsonBuilder ( ) . startObject ( ) . field ( "field" , bytes1 ) . endObject ( ) ; d = mapper . parse ( "test" , "2" , doc . bytes ( ) ) ; writer . addDocument ( d . rootDoc ( ) ) ; doc = XContentFactory . jsonBuilder ( ) . startObject ( ) . endObject ( ) ; d = mapper . parse ( "test" , "3" , doc . bytes ( ) ) ; writer . addDocument ( d . rootDoc ( ) ) ; ObjectArrayList < byte [ ] > bytesList2 = new ObjectArrayList ( 2 ) ; bytesList2 . add ( randomBytes ( ) ) ; bytesList2 . add ( randomBytes ( ) ) ; doc = XContentFactory . jsonBuilder ( ) . startObject ( ) . startArray ( "field" ) . value ( bytesList2 . get ( 0 ) ) . value ( bytesList2 . get ( 1 ) ) . value ( bytesList2 . get ( 0 ) ) . endArray ( ) . endObject ( ) ; d = mapper . parse ( "test" , "4" , doc . bytes ( ) ) ; writer . addDocument ( d . rootDoc ( ) ) ; AtomicReaderContext reader = refreshReader ( ) ; IndexFieldData indexFieldData = getForField ( "field" ) ; AtomicFieldData fieldData = indexFieldData . load ( reader ) ; <START_BUG> BytesValues bytesValues = fieldData . getBytesValues ( randomBoolean ( ) ) ; <END_BUG> CollectionUtils . sortAndDedup ( bytesList1 ) ; assertThat ( bytesValues . setDocument ( 0 ) , equalTo ( 2 ) ) ; assertThat ( bytesValues . nextValue ( ) , equalTo ( new BytesRef ( bytesList1 . get ( 0 ) ) ) ) ; assertThat ( bytesValues . nextValue ( ) , equalTo ( new BytesRef ( bytesList1 . get ( 1 ) ) ) ) ; assertThat ( bytesValues . setDocument ( 1 ) , equalTo ( 1 ) ) ; assertThat ( bytesValues . nextValue ( ) , equalTo ( new BytesRef ( bytes1 ) ) ) ; assertThat ( bytesValues . setDocument ( 2 ) , equalTo ( 0 ) ) ; CollectionUtils . sortAndDedup ( bytesList2 ) ; assertThat ( bytesValues . setDocument ( 3 ) , equalTo ( 2 ) ) ; assertThat ( bytesValues . nextValue ( ) , equalTo ( new BytesRef ( bytesList2 . get ( 0 ) ) ) ) ; assertThat ( bytesValues . nextValue ( ) , equalTo ( new BytesRef ( bytesList2 . get ( 1 ) ) ) ) ; } private byte [ ] randomBytes ( ) { } @ Override protected FieldDataType getFieldDataType ( ) { } }<BUG2FIX>BytesValues bytesValues = fieldData . getBytesValues ( ) ;
public class Sprite extends TextureRegion { static final int VERTEX_SIZE = ( 2 + 1 ) + 2 ; static final int SPRITE_SIZE = 4 * ( Sprite . VERTEX_SIZE ) ; final float [ ] vertices = new float [ Sprite . SPRITE_SIZE ] ; private final Color color = new Color ( 1 , 1 , 1 , 1 ) ; private float x ; private float y ; float width ; float height ; private float originX ; private float originY ; private float rotation ; private float scaleX = 1 ; private float scaleY = 1 ; private boolean dirty = true ; private Rectangle bounds ; public Sprite ( ) { } public Sprite ( Texture texture ) { } public Sprite ( Texture texture , int srcWidth , int srcHeight ) { } public Sprite ( Texture texture , int srcX , int srcY , int srcWidth , int srcHeight ) { } public Sprite ( TextureRegion region ) { } public Sprite ( TextureRegion region , int srcX , int srcY , int srcWidth , int srcHeight ) { } public Sprite ( Sprite sprite ) { } public void set ( Sprite sprite ) { } public void setBounds ( float x , float y , float width , float height ) { } public void setSize ( float width , float height ) { } public void setPosition ( float x , float y ) { } public void setX ( float x ) { } public void setY ( float y ) { } public void translateX ( float xAmount ) { } public void translateY ( float yAmount ) { } public void translate ( float xAmount , float yAmount ) { } public void setColor ( Color tint ) { } public void setColor ( float r , float g , float b , float a ) { } public void setOrigin ( float originX , float originY ) { } public void setRotation ( float degrees ) { } public void rotate ( float degrees ) { } public void rotate90 ( boolean clockwise ) { } public void setScale ( float scaleXY ) { } public void setScale ( float scaleX , float scaleY ) { } public void scale ( float amount ) { } public float [ ] getVertices ( ) { } public Rectangle getBoundingRectangle ( ) { } public void draw ( SpriteBatch . SpriteBatch spriteBatch ) { } public void draw ( SpriteBatch . SpriteBatch spriteBatch , float alphaModulation ) { } public float getX ( ) { } public float getY ( ) { } public float getWidth ( ) { } public float getHeight ( ) { } public float getOriginX ( ) { } public float getOriginY ( ) { } public float getRotation ( ) { } public float getScaleX ( ) { } public float getScaleY ( ) { } public Color getColor ( ) { } public void setRegion ( float u , float v , float u2 , float v2 ) { } public void setU ( float u ) { } public void setV ( float v ) { <START_BUG> super . setV ( u ) ; <END_BUG> vertices [ V2 ] = v ; vertices [ V3 ] = v ; } public void setU2 ( float u2 ) { } public void setV2 ( float v2 ) { } public void flip ( boolean x , boolean y ) { } public void scroll ( float xAmount , float yAmount ) { } }<BUG2FIX>super . setV ( v ) ;
public class ScrollPaneTest extends GdxTest { private Stage stage ; private Table container ; public void create ( ) { stage = new Stage ( 0 , 0 , false ) ; Skin skin = new Skin ( files . internal ( "data/uiskin.json" ) ) ; input . setInputProcessor ( stage ) ; container = new Table ( ) ; stage . addActor ( container ) ; container . setFillParent ( true ) ; Table table = new Table ( ) ; final ScrollPane scroll = new ScrollPane ( table , skin ) ; InputListener stopTouchDown = new InputListener ( ) { public boolean touchDown ( InputEvent event , float x , float y , int pointer , int button ) { event . stop ( ) ; return false ; } } ; table . pad ( 10 ) . defaults ( ) . expandX ( ) . space ( 4 ) ; for ( int i = 0 ; i < 100 ; i ++ ) { table . row ( ) ; table . add ( new com . badlogic . gdx . scenes . scene2d . ui . Label ( ( i + "uno" ) , skin ) ) . expandX ( ) . fillX ( ) ; TextButton button = new TextButton ( ( i + "dos" ) , skin ) ; table . add ( button ) ; button . addListener ( new ClickListener ( ) { public void clicked ( InputEvent event , float x , float y ) { System . out . println ( ( ( ( "click<seq2seq4repair_space>" + x ) + ",<seq2seq4repair_space>" ) + y ) ) ; } } ) ; <START_BUG> Slider slider = new Slider ( 0 , 100 , 100 , false , skin ) ; <END_BUG> slider . addListener ( stopTouchDown ) ; table . add ( slider ) ; table . add ( new com . badlogic . gdx . scenes . scene2d . ui . Label ( ( i + "tres<seq2seq4repair_space>long0<seq2seq4repair_space>long1<seq2seq4repair_space>long2<seq2seq4repair_space>long3<seq2seq4repair_space>long4<seq2seq4repair_space>long5<seq2seq4repair_space>long6<seq2seq4repair_space>long7<seq2seq4repair_space>long8<seq2seq4repair_space>long9<seq2seq4repair_space>long10<seq2seq4repair_space>long11<seq2seq4repair_space>long12" ) , skin ) ) ; } final TextButton flickButton = new TextButton ( "Flick<seq2seq4repair_space>Scroll" , skin . get ( "toggle" , TextButtonStyle . class ) ) ; flickButton . setChecked ( true ) ; flickButton . addListener ( new ChangeListener ( ) { public void changed ( ChangeEvent event , Actor actor ) { scroll . setFlickScroll ( flickButton . isChecked ( ) ) ; } } ) ; final TextButton fadeButton = new TextButton ( "Fade<seq2seq4repair_space>Scrollbars" , skin . get ( "toggle" , TextButtonStyle . class ) ) ; fadeButton . setChecked ( true ) ; fadeButton . addListener ( new ChangeListener ( ) { public void changed ( ChangeEvent event , Actor actor ) { scroll . setFadeScrollBars ( fadeButton . isChecked ( ) ) ; } } ) ; final TextButton smoothButton = new TextButton ( "Smooth<seq2seq4repair_space>Scrolling" , skin . get ( "toggle" , TextButtonStyle . class ) ) ; smoothButton . setChecked ( true ) ; smoothButton . addListener ( new ChangeListener ( ) { public void changed ( ChangeEvent event , Actor actor ) { scroll . setSmoothScrolling ( smoothButton . isChecked ( ) ) ; } } ) ; final TextButton onTopButton = new TextButton ( "Scrollbars<seq2seq4repair_space>On<seq2seq4repair_space>Top" , skin . get ( "toggle" , TextButtonStyle . class ) ) ; onTopButton . addListener ( new ChangeListener ( ) { public void changed ( ChangeEvent event , Actor actor ) { scroll . setScrollbarsOnTop ( onTopButton . isChecked ( ) ) ; } } ) ; container . add ( scroll ) . expand ( ) . fill ( ) . colspan ( 4 ) ; container . row ( ) . space ( 10 ) . padBottom ( 10 ) ; container . add ( flickButton ) . right ( ) . expandX ( ) ; container . add ( onTopButton ) ; container . add ( smoothButton ) ; container . add ( fadeButton ) . left ( ) . expandX ( ) ; } public void render ( ) { } public void resize ( int width , int height ) { } public void dispose ( ) { } public boolean needsGL20 ( ) { } }<BUG2FIX>Slider slider = new Slider ( 0 , 100 , 1 , false , skin ) ;
public class TextureAtlasLoader extends SynchronousAssetLoader < TextureAtlas , TextureAtlasLoader . TextureAtlasParameter > { public TextureAtlasLoader ( FileHandleResolver resolver ) { } TextureAtlasData data ; @ Override public TextureAtlas load ( AssetManager assetManager , String fileName , FileHandle file , TextureAtlasLoader . TextureAtlasParameter parameter ) { } @ Override public Array < AssetDescriptor > getDependencies ( String fileName , FileHandle atlasFile , TextureAtlasLoader . TextureAtlasParameter parameter ) { FileHandle imgDir = atlasFile . parent ( ) ; if ( parameter != null ) data = new TextureAtlasData ( atlasFile , imgDir , parameter . flip ) ; else { data = new TextureAtlasData ( atlasFile , imgDir , false ) ; } <START_BUG> Array < AssetDescriptor > dependencies = new Array < AssetDescriptor > ( ) ; <END_BUG> for ( Page page : data . getPages ( ) ) { TextureParameter params = new TextureParameter ( ) ; params . format = page . format ; params . genMipMaps = page . useMipMaps ; params . minFilter = page . minFilter ; params . magFilter = page . magFilter ; dependencies . add ( new AssetDescriptor ( page . textureFile , Texture . class , params ) ) ; } return dependencies ; } public static class TextureAtlasParameter extends AssetLoaderParameters < TextureAtlas > { public boolean flip = false ; public TextureAtlasParameter ( ) { } public TextureAtlasParameter ( boolean flip ) { } } }<BUG2FIX>Array < AssetDescriptor > dependencies = new Array ( ) ;
public class IndicesQueryCache extends AbstractComponent implements RemovalListener < IndicesQueryCache . Key , BytesReference > { public static final String INDEX_CACHE_QUERY_ENABLED = "index.cache.query.enable" ; public static final String INDICES_CACHE_QUERY_CLEAN_INTERVAL = "indices.cache.query.clean_interval" ; public static final String INDICES_CACHE_QUERY_SIZE = "indices.cache.query.size" ; public static final String INDICES_CACHE_QUERY_EXPIRE = "indices.cache.query.expire" ; private final ThreadPool threadPool ; private final ClusterService clusterService ; private final TimeValue cleanInterval ; private final IndicesQueryCache . Reaper reaper ; final ConcurrentMap < IndicesQueryCache . CleanupKey , Boolean > registeredClosedListeners = ConcurrentCollections . newConcurrentMap ( ) ; final Set < IndicesQueryCache . CleanupKey > keysToClean = ConcurrentCollections . newConcurrentSet ( ) ; private volatile String size ; private volatile TimeValue expire ; private volatile Cache < IndicesQueryCache . Key , BytesReference > cache ; @ Inject public IndicesQueryCache ( Settings settings , ClusterService clusterService , ThreadPool threadPool ) { } private void buildCache ( ) { } private static class QueryCacheWeigher implements Weigher < IndicesQueryCache . Key , BytesReference > { @ Override public int weigh ( IndicesQueryCache . Key key , BytesReference value ) { } } public void close ( ) { } public void clear ( IndexShard shard ) { } @ Override public void onRemoval ( RemovalNotification < IndicesQueryCache . Key , BytesReference > notification ) { } public boolean canCache ( ShardSearchRequest request , SearchContext context ) { if ( hasLength ( request . templateSource ( ) ) ) { return false ; } <START_BUG> if ( ( request . searchType ( ) ) != ( SearchType . COUNT ) ) { <END_BUG> return false ; } IndexMetaData index = clusterService . state ( ) . getMetaData ( ) . index ( request . index ( ) ) ; if ( index == null ) { return false ; } if ( ( request . queryCache ( ) ) == null ) { if ( ! ( index . settings ( ) . getAsBoolean ( IndicesQueryCache . INDEX_CACHE_QUERY_ENABLED , Boolean . FALSE ) ) ) { return false ; } } else if ( ! ( request . queryCache ( ) ) ) { return false ; } if ( ! ( ( context . searcher ( ) . getIndexReader ( ) ) instanceof DirectoryReader ) ) { return false ; } if ( context . nowInMillisUsed ( ) ) { return false ; } return true ; } public QuerySearchResultProvider load ( final ShardSearchRequest request , final SearchContext context , final QueryPhase queryPhase ) throws Exception { } private static class Loader implements Callable < BytesReference > { private final QueryPhase queryPhase ; private final SearchContext context ; private final IndicesQueryCache . Key key ; private boolean loaded ; Loader ( QueryPhase queryPhase , SearchContext context , IndicesQueryCache . Key key ) { } public boolean isLoaded ( ) { } @ Override public BytesReference call ( ) throws Exception { } } public static class Key implements Accountable { public final IndexShard shard ; public final long readerVersion ; public final BytesReference value ; Key ( IndexShard shard , long readerVersion , BytesReference value ) { } @ Override public long ramBytesUsed ( ) { } @ Override public boolean equals ( Object o ) { } @ Override public int hashCode ( ) { } } private class CleanupKey implements IndexReader . ReaderClosedListener { IndexShard indexShard ; long readerVersion ; private CleanupKey ( IndexShard indexShard , long readerVersion ) { } @ Override public void onClose ( IndexReader reader ) { } @ Override public boolean equals ( Object o ) { } @ Override public int hashCode ( ) { } } private class Reaper implements Runnable { private final ObjectSet < IndicesQueryCache . CleanupKey > currentKeysToClean = ObjectOpenHashSet . newInstance ( ) ; private final ObjectSet < IndexShard > currentFullClean = ObjectOpenHashSet . newInstance ( ) ; private volatile boolean closed ; void close ( ) { } @ Override public void run ( ) { } private void schedule ( ) { } synchronized void reap ( ) { } } private static boolean verifyCacheSerializationSameAsQueryResult ( BytesReference cacheData , SearchContext context , QuerySearchResult result ) throws Exception { } private static IndicesQueryCache . Key buildKey ( ShardSearchRequest request , SearchContext context ) throws Exception { } private static class BytesQuerySearchResult extends QuerySearchResultProvider { private long id ; private SearchShardTarget shardTarget ; private BytesReference data ; private transient QuerySearchResult result ; private BytesQuerySearchResult ( long id , SearchShardTarget shardTarget , BytesReference data ) { } private BytesQuerySearchResult ( long id , SearchShardTarget shardTarget , BytesReference data , QuerySearchResult result ) { } @ Override public boolean includeFetch ( ) { } @ Override public QuerySearchResult queryResult ( ) { } @ Override public long id ( ) { } @ Override public SearchShardTarget shardTarget ( ) { } @ Override public void shardTarget ( SearchShardTarget shardTarget ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } }<BUG2FIX>if ( ( context . searchType ( ) ) != ( SearchType . COUNT ) ) {
public class RestMultiGetAction extends BaseRestHandler { private final boolean allowExplicitIndex ; @ Inject public RestMultiGetAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { MultiGetRequest multiGetRequest = new MultiGetRequest ( ) ; multiGetRequest . listenerThreaded ( false ) ; multiGetRequest . refresh ( request . paramAsBoolean ( "refresh" , multiGetRequest . refresh ( ) ) ) ; multiGetRequest . preference ( request . param ( "preference" ) ) ; <START_BUG> multiGetRequest . realtime ( request . paramAsBooleanOptional ( "realtime" , null ) ) ; <END_BUG> String [ ] sFields = null ; String sField = request . param ( "fields" ) ; if ( sField != null ) { sFields = Strings . splitStringByCommaToArray ( sField ) ; } FetchSourceContext defaultFetchSource = FetchSourceContext . parseFromRestRequest ( request ) ; try { multiGetRequest . add ( request . param ( "index" ) , request . param ( "type" ) , sFields , defaultFetchSource , request . param ( "routing" ) , request . content ( ) , allowExplicitIndex ) ; } catch ( Exception e ) { try { XContentBuilder builder = restContentBuilder ( request ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . BAD_REQUEST , builder . startObject ( ) . field ( "error" , e . getMessage ( ) ) . endObject ( ) ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } return ; } client . multiGet ( multiGetRequest , new org . elasticsearch . action . ActionListener < MultiGetResponse > ( ) { @ Override public void onResponse ( MultiGetResponse response ) { try { XContentBuilder builder = restContentBuilder ( request ) ; response . toXContent ( builder , request ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; } catch ( Throwable e ) { onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>multiGetRequest . realtime ( request . paramAsBoolean ( "realtime" , null ) ) ;
public class TransportSearchQueryThenFetchAction extends TransportSearchTypeAction { @ Inject public TransportSearchQueryThenFetchAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportSearchCache transportSearchCache , SearchServiceTransportAction searchService , SearchPhaseController searchPhaseController ) { } @ Override protected void doExecute ( SearchRequest searchRequest , ActionListener < SearchResponse > listener ) { } private class AsyncAction extends BaseAsyncAction < QuerySearchResult > { private final Map < SearchShardTarget , QuerySearchResultProvider > queryResults = searchCache . obtainQueryResults ( ) ; private final Map < SearchShardTarget , FetchSearchResult > fetchResults = searchCache . obtainFetchResults ( ) ; private volatile Map < SearchShardTarget , ExtTIntArrayList > docIdsToLoad ; private AsyncAction ( SearchRequest request , ActionListener < SearchResponse > listener ) { } @ Override protected String firstPhaseName ( ) { } @ Override protected void sendExecuteFirstPhase ( DiscoveryNode node , InternalSearchRequest request , SearchServiceListener < QuerySearchResult > listener ) { } @ Override protected void processFirstPhaseResult ( ShardRouting shard , QuerySearchResult result ) { } @ Override protected void moveToSecondPhase ( ) { } private void executeFetch ( final SearchShardTarget shardTarget , final AtomicInteger counter , final FetchSearchRequest fetchSearchRequest , DiscoveryNode node ) { } private void finishHim ( ) { } private void innerFinishHim ( ) throws Exception { InternalSearchResponse internalResponse = searchPhaseController . merge ( sortedShardList , queryResults , fetchResults ) ; String scrollId = null ; if ( ( request . scroll ( ) ) != null ) { <START_BUG> scrollId = TransportSearchHelper . buildScrollId ( request . searchType ( ) , queryResults . values ( ) ) ; <END_BUG> } listener . onResponse ( new SearchResponse ( internalResponse , scrollId , expectedSuccessfulOps , successulOps . get ( ) , buildTookInMillis ( ) , buildShardFailures ( ) ) ) ; } } }<BUG2FIX>scrollId = TransportSearchHelper . buildScrollId ( request . searchType ( ) , queryResults . values ( ) , null ) ;
public class RecoveryAction extends AbstractIndexShardComponent implements CloseableComponent { private final ByteSizeValue fileChunkSize ; private final ThreadPool threadPool ; private final TransportService transportService ; private final InternalIndexShard indexShard ; private final Store store ; private final RecoveryThrottler recoveryThrottler ; private final ConcurrentMap < String , IndexOutput > openIndexOutputs = newConcurrentMap ( ) ; private final String startTransportAction ; private final String fileChunkTransportAction ; private final String cleanFilesTransportAction ; private final String prepareForTranslogOperationsTransportAction ; private final String translogOperationsTransportAction ; private final String finalizeRecoveryTransportAction ; private volatile boolean closed = false ; private volatile Thread sendStartRecoveryThread ; private volatile Thread receiveSnapshotRecoveryThread ; private volatile Thread sendSnapshotRecoveryThread ; private final CopyOnWriteArrayList < Future > sendFileChunksRecoveryFutures = new CopyOnWriteArrayList < Future > ( ) ; @ Inject public RecoveryAction ( ShardId shardId , @ IndexSettings Settings indexSettings , ThreadPool threadPool , TransportService transportService , IndexShard indexShard , Store store , RecoveryThrottler recoveryThrottler ) { } public void close ( ) { } public synchronized void startRecovery ( DiscoveryNode node , DiscoveryNode targetNode , boolean markAsRelocated ) throws ElasticSearchException { } private void cleanOpenIndex ( ) { } static class StartRecoveryRequest implements Streamable { DiscoveryNode node ; boolean markAsRelocated ; Map < String , StoreFileMetaData > existingFiles ; private StartRecoveryRequest ( ) { } private StartRecoveryRequest ( DiscoveryNode node , boolean markAsRelocated , Map < String , StoreFileMetaData > existingFiles ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } private class StartRecoveryTransportRequestHandler extends BaseTransportRequestHandler < RecoveryAction . StartRecoveryRequest > { @ Override public RecoveryAction . StartRecoveryRequest newInstance ( ) { } @ Override public void messageReceived ( final RecoveryAction . StartRecoveryRequest startRecoveryRequest , final TransportChannel channel ) throws Exception { } } private static class RecoveryStatus implements Streamable { boolean retry = false ; List < String > phase1FileNames = Lists . newArrayList ( ) ; List < Long > phase1FileSizes = Lists . newArrayList ( ) ; List < String > phase1ExistingFileNames = Lists . newArrayList ( ) ; List < Long > phase1ExistingFileSizes = Lists . newArrayList ( ) ; long phase1TotalSize ; long phase1ExistingTotalSize ; long phase1Time ; long phase1ThrottlingWaitTime ; int phase2Operations ; long phase2Time ; int phase3Operations ; long phase3Time ; private RecoveryStatus ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } static class CleanFilesRequest implements Streamable { Set < String > snapshotFiles = Sets . newHashSet ( ) ; @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } class CleanFilesRequestHandler extends BaseTransportRequestHandler < RecoveryAction . CleanFilesRequest > { @ Override public RecoveryAction . CleanFilesRequest newInstance ( ) { } @ Override public void messageReceived ( RecoveryAction . CleanFilesRequest request , TransportChannel channel ) throws Exception { } } class PrepareForTranslogOperationsRequestHandler extends BaseTransportRequestHandler < VoidStreamable > { @ Override public VoidStreamable newInstance ( ) { } @ Override public void messageReceived ( VoidStreamable stream , TransportChannel channel ) throws Exception { receiveSnapshotRecoveryThread = Thread . currentThread ( ) ; try { indexShard . performRecoveryPrepareForTranslog ( ) ; channel . sendResponse ( INSTANCE ) ; } finally { receiveSnapshotRecoveryThread = null ; } } } class FinalizeRecoveryRequestHandler extends BaseTransportRequestHandler < VoidStreamable > { @ Override public VoidStreamable newInstance ( ) { } @ Override public void messageReceived ( VoidStreamable stream , TransportChannel channel ) throws Exception { receiveSnapshotRecoveryThread = Thread . currentThread ( ) ; try { <START_BUG> indexShard . performRecoveryFinalization ( ) ; <END_BUG> channel . sendResponse ( INSTANCE ) ; } finally { receiveSnapshotRecoveryThread = null ; } } } class TranslogOperationsRequestHandler extends BaseTransportRequestHandler < RecoveryAction . TranslogOperationsRequest > { @ Override public RecoveryAction . TranslogOperationsRequest newInstance ( ) { } @ Override public void messageReceived ( RecoveryAction . TranslogOperationsRequest snapshot , TransportChannel channel ) throws Exception { } } static class TranslogOperationsRequest implements Streamable { List < Translog . Operation > operations = Lists . newArrayList ( ) ; TranslogOperationsRequest ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } private class FileChunkTransportRequestHandler extends BaseTransportRequestHandler < RecoveryAction . FileChunk > { @ Override public RecoveryAction . FileChunk newInstance ( ) { } @ Override public void messageReceived ( RecoveryAction . FileChunk request , TransportChannel channel ) throws Exception { } } private static class FileChunk implements Streamable { String name ; long position ; long length ; byte [ ] content ; transient int contentLength ; private FileChunk ( ) { } private FileChunk ( String name , long position , long length , byte [ ] content , int contentLength ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } }<BUG2FIX>indexShard . performRecoveryFinalization ( false ) ;
public class FloatArray { public float [ ] items ; public int size ; public boolean ordered ; public FloatArray ( ) { } public FloatArray ( int capacity ) { } public FloatArray ( boolean ordered , int capacity ) { } public FloatArray ( FloatArray array ) { } public FloatArray ( float [ ] array ) { } public FloatArray ( boolean ordered , float [ ] array , int startIndex , int count ) { } public void add ( float value ) { } public void addAll ( FloatArray array ) { } public void addAll ( FloatArray array , int offset , int length ) { } public void addAll ( float [ ] array ) { } public void addAll ( float [ ] array , int offset , int length ) { float [ ] items = this . items ; <START_BUG> int sizeNeeded = ( ( size ) + length ) - offset ; <END_BUG> if ( sizeNeeded >= ( items . length ) ) items = resize ( Math . max ( 8 , ( ( int ) ( sizeNeeded * 1.75F ) ) ) ) ; System . arraycopy ( array , offset , items , size , length ) ; size += length ; } public float get ( int index ) { } public void set ( int index , float value ) { } public void insert ( int index , float value ) { } public void swap ( int first , int second ) { } public boolean contains ( float value ) { } public int indexOf ( float value ) { } public int lastIndexOf ( char value ) { } public boolean removeValue ( float value ) { } public float removeIndex ( int index ) { } public boolean removeAll ( FloatArray array ) { } public float pop ( ) { } public float peek ( ) { } public float first ( ) { } public void clear ( ) { } public void shrink ( ) { } public float [ ] ensureCapacity ( int additionalCapacity ) { } protected float [ ] resize ( int newSize ) { } public void sort ( ) { } public void reverse ( ) { } public void shuffle ( ) { } public void truncate ( int newSize ) { } public float random ( ) { } public float [ ] toArray ( ) { } public boolean equals ( Object object ) { } public String toString ( ) { } public String toString ( String separator ) { } }<BUG2FIX>int sizeNeeded = ( size ) + length ;
public class QueryPhase implements SearchPhase { private final FacetsPhase facetsPhase ; @ Inject public QueryPhase ( FacetsPhase facetsPhase ) { } @ Override public Map < String , ? extends SearchParseElement > parseElements ( ) { } @ Override public void preProcess ( SearchContext context ) { } public void execute ( SearchContext searchContext ) throws QueryPhaseExecutionException { try { searchContext . queryResult ( ) . from ( searchContext . from ( ) ) ; searchContext . queryResult ( ) . size ( searchContext . size ( ) ) ; Query query = searchContext . query ( ) ; if ( ( searchContext . types ( ) . length ) > 0 ) { if ( ( searchContext . types ( ) . length ) == 1 ) { String type = searchContext . types ( ) [ 0 ] ; DocumentMapper docMapper = searchContext . mapperService ( ) . documentMapper ( type ) ; Filter typeFilter = new org . elasticsearch . common . lucene . search . TermFilter ( docMapper . typeMapper ( ) . term ( docMapper . type ( ) ) ) ; typeFilter = searchContext . filterCache ( ) . cache ( typeFilter ) ; query = new FilteredQuery ( query , typeFilter ) ; } else { BooleanFilter booleanFilter = new BooleanFilter ( ) ; for ( String type : searchContext . types ( ) ) { DocumentMapper docMapper = searchContext . mapperService ( ) . documentMapper ( type ) ; Filter typeFilter = new org . elasticsearch . common . lucene . search . TermFilter ( docMapper . typeMapper ( ) . term ( docMapper . type ( ) ) ) ; typeFilter = searchContext . filterCache ( ) . cache ( typeFilter ) ; booleanFilter . add ( new FilterClause ( typeFilter , Occur . SHOULD ) ) ; } query = new FilteredQuery ( query , booleanFilter ) ; } } TopDocs topDocs ; int numDocs = ( searchContext . from ( ) ) + ( searchContext . size ( ) ) ; if ( numDocs == 0 ) { numDocs = 1 ; } boolean sort = false ; if ( ( searchContext . sort ( ) ) != null ) { <START_BUG> if ( ( searchContext . sort ( ) . getSort ( ) . length ) > 0 ) { <END_BUG> sort = true ; } else { SortField sortField = searchContext . sort ( ) . getSort ( ) [ 0 ] ; if ( ( ( sortField . getType ( ) ) == ( SortField . SCORE ) ) && ( ! ( sortField . getReverse ( ) ) ) ) { sort = false ; } else { sort = true ; } } } if ( sort ) { topDocs = searchContext . searcher ( ) . search ( query , null , numDocs , searchContext . sort ( ) ) ; } else { topDocs = searchContext . searcher ( ) . search ( query , numDocs ) ; } searchContext . queryResult ( ) . topDocs ( topDocs ) ; } catch ( Exception e ) { throw new QueryPhaseExecutionException ( searchContext , "Failed<seq2seq4repair_space>to<seq2seq4repair_space>execute<seq2seq4repair_space>main<seq2seq4repair_space>query" , e ) ; } facetsPhase . execute ( searchContext ) ; } }<BUG2FIX>if ( ( searchContext . sort ( ) . getSort ( ) . length ) > 1 ) {
public class SingleThreadBulkStress { public static void main ( String [ ] args ) throws Exception { Random random = new Random ( ) ; Settings settings = settingsBuilder ( ) . put ( "cluster.routing.schedule" , 200 , TimeUnit . MILLISECONDS ) . put ( "index.engine.robin.refreshInterval" , "-1" ) . put ( "gateway.type" , "none" ) . put ( SETTING_NUMBER_OF_SHARDS , 2 ) . put ( SETTING_NUMBER_OF_REPLICAS , 1 ) . build ( ) ; Node node1 = nodeBuilder ( ) . settings ( settingsBuilder ( ) . put ( settings ) . put ( "name" , "server1" ) ) . node ( ) ; Node node2 = nodeBuilder ( ) . settings ( settingsBuilder ( ) . put ( settings ) . put ( "name" , "server2" ) ) . node ( ) ; Node client = nodeBuilder ( ) . settings ( settingsBuilder ( ) . put ( settings ) . put ( "name" , "client" ) ) . client ( true ) . node ( ) ; Client client1 = client . client ( ) ; Thread . sleep ( 1000 ) ; client1 . admin ( ) . indices ( ) . create ( createIndexRequest ( "test" ) ) . actionGet ( ) ; Thread . sleep ( 5000 ) ; StopWatch stopWatch = new StopWatch ( ) . start ( ) ; int COUNT = 200000 ; <START_BUG> int BATCH = 1000 ; <END_BUG> System . out . println ( ( ( "Indexing<seq2seq4repair_space>[" + COUNT ) + "]<seq2seq4repair_space>..." ) ) ; int ITERS = COUNT / BATCH ; int i = 1 ; int counter = 0 ; for ( ; i <= ITERS ; i ++ ) { BulkRequestBuilder request = client1 . prepareBulk ( ) ; for ( int j = 0 ; j < BATCH ; j ++ ) { counter ++ ; request . add ( Requests . indexRequest ( "test" ) . type ( "type1" ) . id ( Integer . toString ( counter ) ) . source ( SingleThreadBulkStress . source ( Integer . toString ( counter ) , ( "test" + counter ) ) ) ) ; } BulkResponse response = request . execute ( ) . actionGet ( ) ; if ( response . hasFailures ( ) ) { System . err . println ( "failures..." ) ; } if ( ( ( i * BATCH ) % 10000 ) == 0 ) { System . out . println ( ( ( ( "Indexed<seq2seq4repair_space>" + ( i * 100 ) ) + "<seq2seq4repair_space>took<seq2seq4repair_space>" ) + ( stopWatch . stop ( ) . lastTaskTime ( ) ) ) ) ; stopWatch . start ( ) ; } } System . out . println ( ( ( ( "Indexing<seq2seq4repair_space>took<seq2seq4repair_space>" + ( stopWatch . totalTime ( ) ) ) + ",<seq2seq4repair_space>TPS<seq2seq4repair_space>" ) + ( ( ( double ) ( COUNT ) ) / ( stopWatch . totalTime ( ) . secondsFrac ( ) ) ) ) ) ; client . client ( ) . admin ( ) . indices ( ) . prepareRefresh ( ) . execute ( ) . actionGet ( ) ; System . out . println ( ( "Count:<seq2seq4repair_space>" + ( client . client ( ) . prepareCount ( ) . setQuery ( matchAllQuery ( ) ) . execute ( ) . actionGet ( ) . count ( ) ) ) ) ; client . close ( ) ; node1 . close ( ) ; node2 . close ( ) ; } private static XContentBuilder source ( String id , String nameValue ) throws IOException { } }<BUG2FIX>int BATCH = 100 ;
public class SourceFieldMapper extends AbstractFieldMapper < byte [ ] > implements InternalMapper , RootMapper { public static final String NAME = "_source" ; public static final String CONTENT_TYPE = "_source" ; public static class Defaults extends AbstractFieldMapper . Defaults { public static final String NAME = SourceFieldMapper . NAME ; public static final boolean ENABLED = true ; public static final long COMPRESS_THRESHOLD = - 1 ; public static final Index INDEX = Index . NO ; public static final Store STORE = Store . YES ; public static final boolean OMIT_NORMS = true ; public static final boolean OMIT_TERM_FREQ_AND_POSITIONS = true ; public static final String [ ] INCLUDES = Strings . EMPTY_ARRAY ; public static final String [ ] EXCLUDES = Strings . EMPTY_ARRAY ; } public static class Builder extends Mapper . Builder < SourceFieldMapper . Builder , SourceFieldMapper > { private boolean enabled = SourceFieldMapper . Defaults . ENABLED ; private long compressThreshold = SourceFieldMapper . Defaults . COMPRESS_THRESHOLD ; private Boolean compress = null ; private String [ ] includes = SourceFieldMapper . Defaults . INCLUDES ; private String [ ] excludes = SourceFieldMapper . Defaults . EXCLUDES ; public Builder ( ) { } public SourceFieldMapper . Builder enabled ( boolean enabled ) { } public SourceFieldMapper . Builder compress ( boolean compress ) { } public SourceFieldMapper . Builder compressThreshold ( long compressThreshold ) { } public SourceFieldMapper . Builder includes ( String [ ] includes ) { } public SourceFieldMapper . Builder excludes ( String [ ] excludes ) { } @ Override public SourceFieldMapper build ( BuilderContext context ) { } } public static class TypeParser implements Mapper . TypeParser { @ Override public Mapper . Builder parse ( String name , Map < String , Object > node , ParserContext parserContext ) throws MapperParsingException { } } private final boolean enabled ; private Boolean compress ; private long compressThreshold ; private String [ ] includes ; private String [ ] excludes ; public SourceFieldMapper ( ) { } protected SourceFieldMapper ( String name , boolean enabled , Boolean compress , long compressThreshold , String [ ] includes , String [ ] excludes ) { } public boolean enabled ( ) { } public ResetFieldSelector fieldSelector ( ) { } @ Override public void preParse ( ParseContext context ) throws IOException { } @ Override public void postParse ( ParseContext context ) throws IOException { } @ Override public void parse ( ParseContext context ) throws IOException { } @ Override public void validate ( ParseContext context ) throws MapperParsingException { } @ Override public boolean includeInObject ( ) { } @ Override protected Field parseCreateField ( ParseContext context ) throws IOException { if ( ! ( enabled ) ) { return null ; } if ( ( store ) == ( Store . NO ) ) { return null ; } if ( context . flyweight ( ) ) { return null ; } byte [ ] data = context . source ( ) ; int dataOffset = context . sourceOffset ( ) ; int dataLength = context . sourceLength ( ) ; boolean filtered = ( ( includes . length ) > 0 ) || ( ( excludes . length ) > 0 ) ; if ( filtered ) { <START_BUG> Tuple < XContentType , Map < String , Object > > mapTuple = XContentHelper . convertToMap ( data , dataOffset , dataLength ) ; <END_BUG> Map < String , Object > filteredSource = XContentMapValues . filter ( mapTuple . v2 ( ) , includes , excludes ) ; CachedStreamOutput . Entry cachedEntry = CachedStreamOutput . popEntry ( ) ; StreamOutput streamOutput ; if ( ( ( ( compress ) != null ) && ( compress ) ) && ( ( ( compressThreshold ) == ( - 1 ) ) || ( dataLength > ( compressThreshold ) ) ) ) { streamOutput = cachedEntry . cachedLZFBytes ( ) ; } else { streamOutput = cachedEntry . cachedBytes ( ) ; } XContentBuilder builder = XContentFactory . contentBuilder ( mapTuple . v1 ( ) , streamOutput ) . map ( filteredSource ) ; builder . close ( ) ; data = cachedEntry . bytes ( ) . copiedByteArray ( ) ; dataOffset = 0 ; dataLength = data . length ; CachedStreamOutput . pushEntry ( cachedEntry ) ; } else if ( ( ( ( compress ) != null ) && ( compress ) ) && ( ! ( LZF . isCompressed ( data , dataOffset , dataLength ) ) ) ) { if ( ( ( compressThreshold ) == ( - 1 ) ) || ( dataLength > ( compressThreshold ) ) ) { CachedStreamOutput . Entry cachedEntry = CachedStreamOutput . popEntry ( ) ; LZFStreamOutput streamOutput = cachedEntry . cachedLZFBytes ( ) ; streamOutput . writeBytes ( data , dataOffset , dataLength ) ; streamOutput . flush ( ) ; data = cachedEntry . bytes ( ) . copiedByteArray ( ) ; dataOffset = 0 ; dataLength = data . length ; CachedStreamOutput . pushEntry ( cachedEntry ) ; context . source ( data , dataOffset , dataLength ) ; } } return new Field ( names ( ) . indexName ( ) , data , dataOffset , dataLength ) ; } public byte [ ] value ( Document document ) { } public byte [ ] nativeValue ( Fieldable field ) { } @ Override public byte [ ] value ( Fieldable field ) { } @ Override public byte [ ] valueFromString ( String value ) { } @ Override public String valueAsString ( Fieldable field ) { } @ Override public String indexedValue ( String value ) { } @ Override protected String contentType ( ) { } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } @ Override public void merge ( Mapper mergeWith , MergeContext mergeContext ) throws MergeMappingException { } }<BUG2FIX>Tuple < XContentType , Map < String , Object > > mapTuple = XContentHelper . convertToMap ( data , dataOffset , dataLength , true ) ;
public interface Engine extends CloseableComponent , IndexShardComponent { static final String INDEX_CODEC = "index.codec" ; static ByteSizeValue INACTIVE_SHARD_INDEXING_BUFFER = ByteSizeValue . parseBytesSizeValue ( "500kb" ) ; TimeValue defaultRefreshInterval ( ) { } void enableGcDeletes ( boolean enableGcDeletes ) { } void updateIndexingBufferSize ( ByteSizeValue indexingBufferSize ) { } void addFailedEngineListener ( Engine . FailedEngineListener listener ) { } void start ( ) throws EngineException { } void create ( Engine . Create create ) throws EngineException { } void index ( Engine . Index index ) throws EngineException { } void delete ( Engine . Delete delete ) throws EngineException { } void delete ( Engine . DeleteByQuery delete ) throws EngineException { } Engine . GetResult get ( Engine . Get get ) throws EngineException { } Engine . Searcher acquireSearcher ( String source ) throws EngineException { } List < Segment > segments ( ) { } boolean refreshNeeded ( ) { } boolean possibleMergeNeeded ( ) { } void maybeMerge ( ) throws EngineException { } void refresh ( Engine . Refresh refresh ) throws EngineException { } void flush ( Engine . Flush flush ) throws EngineException , FlushNotAllowedEngineException { } void optimize ( Engine . Optimize optimize ) throws EngineException { } < T > T snapshot ( Engine . SnapshotHandler < T > snapshotHandler ) throws EngineException { } SnapshotIndexCommit snapshotIndex ( ) throws EngineException { } void recover ( Engine . RecoveryHandler recoveryHandler ) throws EngineException { } static interface FailedEngineListener { void onFailedEngine ( ShardId shardId , Throwable t ) { } } static interface RecoveryHandler { void phase1 ( SnapshotIndexCommit snapshot ) throws ElasticSearchException { } void phase2 ( Translog . Snapshot snapshot ) throws ElasticSearchException { } void phase3 ( Translog . Snapshot snapshot ) throws ElasticSearchException { } } static interface SnapshotHandler < T > { T snapshot ( SnapshotIndexCommit snapshotIndexCommit , Translog . Snapshot translogSnapshot ) throws EngineException { } } static interface Searcher extends Releasable { String source ( ) ; IndexReader reader ( ) { } IndexSearcher searcher ( ) { } } static class SimpleSearcher implements Engine . Searcher { private final String source ; private final IndexSearcher searcher ; public SimpleSearcher ( String source , IndexSearcher searcher ) { } @ Override public String source ( ) { <START_BUG> return this . source ( ) ; <END_BUG> } @ Override public IndexReader reader ( ) { } @ Override public IndexSearcher searcher ( ) { } @ Override public boolean release ( ) throws ElasticSearchException { } } static class Refresh { private final String source ; private boolean force = false ; public Refresh ( String source ) { } public Engine . Refresh force ( boolean force ) { } public boolean force ( ) { } public String source ( ) { return this . source ; } @ Override public String toString ( ) { } } static class Flush { public static enum Type { NEW_WRITER , COMMIT , COMMIT_TRANSLOG ; } private Engine . Flush . Type type = Engine . Flush . Type . COMMIT_TRANSLOG ; private boolean force = false ; private boolean waitIfOngoing = false ; public Engine . Flush . Type type ( ) { } public Engine . Flush type ( Engine . Flush . Type type ) { } public boolean force ( ) { } public Engine . Flush force ( boolean force ) { } public boolean waitIfOngoing ( ) { } public Engine . Flush waitIfOngoing ( boolean waitIfOngoing ) { } @ Override public String toString ( ) { } } static class Optimize { private boolean waitForMerge = true ; private int maxNumSegments = - 1 ; private boolean onlyExpungeDeletes = false ; private boolean flush = false ; public Optimize ( ) { } public boolean waitForMerge ( ) { } public Engine . Optimize waitForMerge ( boolean waitForMerge ) { } public int maxNumSegments ( ) { } public Engine . Optimize maxNumSegments ( int maxNumSegments ) { } public boolean onlyExpungeDeletes ( ) { } public Engine . Optimize onlyExpungeDeletes ( boolean onlyExpungeDeletes ) { } public boolean flush ( ) { } public Engine . Optimize flush ( boolean flush ) { } @ Override public String toString ( ) { } } static interface Operation { static enum Type { CREATE , INDEX , DELETE ; } static enum Origin { PRIMARY , REPLICA , RECOVERY ; } Engine . Operation . Type opType ( ) { } Engine . Operation . Origin origin ( ) { } } static interface IndexingOperation extends Engine . Operation { ParsedDocument parsedDoc ( ) { } List < Document > docs ( ) { } DocumentMapper docMapper ( ) { } } static class Create implements Engine . IndexingOperation { private final DocumentMapper docMapper ; private final Term uid ; private final ParsedDocument doc ; private long version = Versions . MATCH_ANY ; private VersionType versionType = VersionType . INTERNAL ; private Engine . Operation . Origin origin = Engine . Operation . Origin . PRIMARY ; private long startTime ; private long endTime ; public Create ( DocumentMapper docMapper , Term uid , ParsedDocument doc ) { } @ Override public DocumentMapper docMapper ( ) { } @ Override public Engine . Operation . Type opType ( ) { } public Engine . Create origin ( Engine . Operation . Origin origin ) { } @ Override public Engine . Operation . Origin origin ( ) { } @ Override public ParsedDocument parsedDoc ( ) { } public Term uid ( ) { } public String type ( ) { } public String id ( ) { } public String routing ( ) { } public long timestamp ( ) { } public long ttl ( ) { } public long version ( ) { } public Engine . Create version ( long version ) { } public VersionType versionType ( ) { }<BUG2FIX>return source ;
public class AllocationService extends AbstractComponent { private final AllocationDeciders allocationDeciders ; private final ShardsAllocators shardsAllocators ; public AllocationService ( ) { } public AllocationService ( Settings settings ) { } @ Inject public AllocationService ( Settings settings , AllocationDeciders allocationDeciders , ShardsAllocators shardsAllocators ) { } public Result applyStartedShards ( ClusterState clusterState , List < ? extends ShardRouting > startedShards ) { } public Result applyFailedShard ( ClusterState clusterState , ShardRouting failedShard ) { } public Result reroute ( ClusterState clusterState ) { } public Result rerouteWithNoReassign ( ClusterState clusterState ) { } private boolean reroute ( RoutingAllocation allocation ) { } private boolean electPrimaries ( RoutingNodes routingNodes ) { } private void applyNewNodes ( RoutingNodes routingNodes , Iterable < DiscoveryNode > liveNodes ) { for ( DiscoveryNode node : liveNodes ) { if ( ! ( routingNodes . nodesToShards ( ) . containsKey ( node . id ( ) ) ) ) { <START_BUG> RoutingNode routingNode = new RoutingNode ( node . id ( ) ) ; <END_BUG> routingNodes . nodesToShards ( ) . put ( node . id ( ) , routingNode ) ; } } } private boolean deassociateDeadNodes ( RoutingNodes routingNodes , Iterable < DiscoveryNode > liveNodes ) { } private boolean applyStartedShards ( RoutingNodes routingNodes , Iterable < ? extends ShardRouting > startedShardEntries ) { } private boolean applyFailedShard ( FailedRerouteAllocation allocation ) { } }<BUG2FIX>RoutingNode routingNode = new RoutingNode ( node ) ;
public class InternalIndicesService extends AbstractLifecycleComponent < IndicesService > implements IndicesService { private final NodeEnvironment nodeEnv ; private final ThreadPool threadPool ; private final InternalIndicesLifecycle indicesLifecycle ; private final IndicesAnalysisService indicesAnalysisService ; private final IndicesStore indicesStore ; private final Injector injector ; private final PluginsService pluginsService ; private final Map < String , Injector > indicesInjectors = new HashMap < String , Injector > ( ) ; private volatile ImmutableMap < String , IndexService > indices = ImmutableMap . of ( ) ; private final InternalIndicesService . OldShardsStats oldShardsStats = new InternalIndicesService . OldShardsStats ( ) ; @ Inject public InternalIndicesService ( Settings settings , NodeEnvironment nodeEnv , ThreadPool threadPool , IndicesLifecycle indicesLifecycle , IndicesAnalysisService indicesAnalysisService , IndicesStore indicesStore , Injector injector ) { } @ Override protected void doStart ( ) throws ElasticSearchException { } @ Override protected void doStop ( ) throws ElasticSearchException { ImmutableSet < String > indices = ImmutableSet . copyOf ( this . indices . keySet ( ) ) ; final CountDownLatch latch = new CountDownLatch ( indices . size ( ) ) ; final ExecutorService indicesStopExecutor = Executors . newFixedThreadPool ( 5 , EsExecutors . daemonThreadFactory ( "indices_shutdown" ) ) ; final ExecutorService shardsStopExecutor = Executors . newFixedThreadPool ( 5 , EsExecutors . daemonThreadFactory ( "shards_shutdown" ) ) ; for ( final String index : indices ) { indicesStopExecutor . execute ( new Runnable ( ) { @ Override public void run ( ) { try { removeIndex ( index , "shutdown" , shardsStopExecutor ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> logger . warn ( ( ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>delete<seq2seq4repair_space>index<seq2seq4repair_space>on<seq2seq4repair_space>stop<seq2seq4repair_space>[" + index ) + "]" ) , e ) ; } finally { latch . countDown ( ) ; } } } ) ; } try { latch . await ( ) ; } catch ( InterruptedException e ) { } finally { shardsStopExecutor . shutdown ( ) ; indicesStopExecutor . shutdown ( ) ; } } @ Override protected void doClose ( ) throws ElasticSearchException { } @ Override public IndicesLifecycle indicesLifecycle ( ) { } @ Override public NodeIndicesStats stats ( boolean includePrevious ) { } @ Override public NodeIndicesStats stats ( boolean includePrevious , CommonStatsFlags flags ) { } public boolean changesAllowed ( ) { } @ Override public UnmodifiableIterator < IndexService > iterator ( ) { } public boolean hasIndex ( String index ) { } public Set < String > indices ( ) { } public IndexService indexService ( String index ) { } @ Override public IndexService indexServiceSafe ( String index ) throws IndexMissingException { } public synchronized IndexService createIndex ( String sIndexName , Settings settings , String localNodeId ) throws ElasticSearchException { } @ Override public synchronized void removeIndex ( String index , String reason ) throws ElasticSearchException { } private void removeIndex ( String index , String reason , @ Nullable Executor executor ) throws ElasticSearchException { } static class OldShardsStats extends IndicesLifecycle . Listener { final SearchStats searchStats = new SearchStats ( ) ; final GetStats getStats = new GetStats ( ) ; final IndexingStats indexingStats = new IndexingStats ( ) ; final MergeStats mergeStats = new MergeStats ( ) ; final RefreshStats refreshStats = new RefreshStats ( ) ; final FlushStats flushStats = new FlushStats ( ) ; @ Override public synchronized void beforeIndexShardClosed ( ShardId shardId , @ Nullable IndexShard indexShard ) { } } }<BUG2FIX>} catch ( Throwable e ) {
public class RestGetIndexTemplateAction extends BaseRestHandler { private final SettingsFilter settingsFilter ; @ Inject public RestGetIndexTemplateAction ( Settings settings , Client client , RestController controller , SettingsFilter settingsFilter ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { ClusterStateRequest clusterStateRequest = Requests . clusterStateRequest ( ) . filterRoutingTable ( true ) . filterNodes ( true ) . filteredIndexTemplates ( request . param ( "name" ) ) . filteredIndices ( "_na" ) ; clusterStateRequest . listenerThreaded ( false ) ; client . admin ( ) . cluster ( ) . state ( clusterStateRequest , new org . elasticsearch . action . ActionListener < ClusterStateResponse > ( ) { @ Override public void onResponse ( ClusterStateResponse response ) { try { MetaData metaData = response . getState ( ) . metaData ( ) ; XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; for ( IndexTemplateMetaData indexMetaData : metaData . templates ( ) . values ( ) ) { builder . startObject ( indexMetaData . name ( ) , NONE ) ; builder . field ( "template" , indexMetaData . template ( ) ) ; builder . field ( "order" , indexMetaData . order ( ) ) ; builder . startObject ( "settings" ) ; Settings settings = settingsFilter . filterSettings ( indexMetaData . settings ( ) ) ; for ( Map . Entry < String , String > entry : settings . getAsMap ( ) . entrySet ( ) ) { builder . field ( entry . getKey ( ) , entry . getValue ( ) ) ; } builder . endObject ( ) ; builder . startObject ( "mappings" ) ; for ( Map . Entry < String , CompressedString > entry : indexMetaData . mappings ( ) . entrySet ( ) ) { byte [ ] mappingSource = entry . getValue ( ) . uncompressed ( ) ; XContentParser parser = XContentFactory . xContent ( mappingSource ) . createParser ( mappingSource ) ; Map < String , Object > mapping = parser . map ( ) ; if ( ( ( mapping . size ( ) ) == 1 ) && ( mapping . containsKey ( entry . getKey ( ) ) ) ) { mapping = ( ( Map < String , Object > ) ( mapping . get ( entry . getKey ( ) ) ) ) ; } builder . field ( entry . getKey ( ) ) ; builder . map ( mapping ) ; } builder . endObject ( ) ; builder . endObject ( ) ; } builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class ObjectFloatMap < K > { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; public int size ; K [ ] keyTable ; float [ ] valueTable ; int capacity ; int stashSize ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private ObjectFloatMap . Entries entries1 ; private ObjectFloatMap . Entries entries2 ; private ObjectFloatMap . Values values1 ; private ObjectFloatMap . Values values2 ; private ObjectFloatMap . Keys keys1 ; private ObjectFloatMap . Keys keys2 ; public ObjectFloatMap ( ) { } public ObjectFloatMap ( int initialCapacity ) { } public ObjectFloatMap ( int initialCapacity , float loadFactor ) { } public ObjectFloatMap ( ObjectFloatMap < ? extends K > map ) { } public void put ( K key , float value ) { } public void putAll ( ObjectFloatMap < K > map ) { } private void putResize ( K key , float value ) { } private void push ( K insertKey , float insertValue , int index1 , K key1 , int index2 , K key2 , int index3 , K key3 ) { } private void putStash ( K key , float value ) { } public float get ( K key , float defaultValue ) { } private float getStash ( K key , float defaultValue ) { } public float getAndIncrement ( K key , float defaultValue , float increment ) { } private float getAndIncrementStash ( K key , float defaultValue , float increment ) { } public float remove ( K key , float defaultValue ) { } float removeStash ( K key , float defaultValue ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean containsValue ( float value ) { } public boolean containsKey ( K key ) { } private boolean containsKeyStash ( K key ) { } public K findKey ( float value ) { } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( int h ) { } private int hash3 ( int h ) { } public String toString ( ) { } public ObjectFloatMap . Entries < K > entries ( ) { } public ObjectFloatMap . Values values ( ) { } public ObjectFloatMap . Keys < K > keys ( ) { } public static class Entry < K > { public K key ; public float value ; public String toString ( ) { } } private static class MapIterator < K > { public boolean hasNext ; final ObjectFloatMap < K > map ; int nextIndex ; int currentIndex ; boolean valid = true ; public MapIterator ( ObjectFloatMap < K > map ) { } public void reset ( ) { } void findNextIndex ( ) { } public void remove ( ) { if ( ( currentIndex ) < 0 ) throw new IllegalStateException ( "next<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>called<seq2seq4repair_space>before<seq2seq4repair_space>remove." ) ; if ( ( currentIndex ) >= ( map . capacity ) ) { map . removeStashIndex ( currentIndex ) ; <START_BUG> nextIndex = currentIndex ; <END_BUG> findNextIndex ( ) ; } else { map . keyTable [ currentIndex ] = null ; } currentIndex = - 1 ; ( map . size ) -- ; } } public static class Entries < K > extends ObjectFloatMap . MapIterator < K > implements Iterable < ObjectFloatMap . Entry < K > > , Iterator < ObjectFloatMap . Entry < K > > { private ObjectFloatMap . Entry < K > entry = new ObjectFloatMap . Entry ( ) ; public Entries ( ObjectFloatMap < K > map ) { } public ObjectFloatMap . Entry < K > next ( ) { } public boolean hasNext ( ) { } public Iterator < ObjectFloatMap . Entry < K > > iterator ( ) { } } public static class Values extends ObjectFloatMap . MapIterator < Object > { public Values ( ObjectFloatMap < ? > map ) { } public boolean hasNext ( ) { } public float next ( ) { } public FloatArray toArray ( ) { } } public static class Keys < K > extends ObjectFloatMap . MapIterator < K > implements Iterable < K > , Iterator < K > { public Keys ( ObjectFloatMap < K > map ) { } public boolean hasNext ( ) { } public K next ( ) { } public Iterator < K > iterator ( ) { } public Array < K > toArray ( ) { } } }<BUG2FIX>nextIndex = ( currentIndex ) - 1 ;
public class DiscoveryNodes implements Iterable < DiscoveryNode > { public static final DiscoveryNodes EMPTY_NODES = DiscoveryNodes . builder ( ) . build ( ) ; private final ImmutableOpenMap < String , DiscoveryNode > nodes ; private final ImmutableOpenMap < String , DiscoveryNode > dataNodes ; private final ImmutableOpenMap < String , DiscoveryNode > masterNodes ; private final String masterNodeId ; private final String localNodeId ; private DiscoveryNodes ( ImmutableOpenMap < String , DiscoveryNode > nodes , ImmutableOpenMap < String , DiscoveryNode > dataNodes , ImmutableOpenMap < String , DiscoveryNode > masterNodes , String masterNodeId , String localNodeId ) { } @ Override public UnmodifiableIterator < DiscoveryNode > iterator ( ) { } public boolean valid ( ) { } public boolean localNodeMaster ( ) { } public int size ( ) { } public int getSize ( ) { } public ImmutableOpenMap < String , DiscoveryNode > nodes ( ) { } public ImmutableOpenMap < String , DiscoveryNode > getNodes ( ) { } public ImmutableOpenMap < String , DiscoveryNode > dataNodes ( ) { } public ImmutableOpenMap < String , DiscoveryNode > getDataNodes ( ) { } public ImmutableOpenMap < String , DiscoveryNode > masterNodes ( ) { } public ImmutableOpenMap < String , DiscoveryNode > getMasterNodes ( ) { } public ImmutableOpenMap < String , DiscoveryNode > masterAndDataNodes ( ) { } public DiscoveryNode get ( String nodeId ) { } public boolean nodeExists ( String nodeId ) { } public String masterNodeId ( ) { } public String getMasterNodeId ( ) { } public String localNodeId ( ) { } public String getLocalNodeId ( ) { } public DiscoveryNode localNode ( ) { } public DiscoveryNode getLocalNode ( ) { } public DiscoveryNode masterNode ( ) { } public DiscoveryNode getMasterNode ( ) { } public DiscoveryNode findByAddress ( TransportAddress address ) { } public boolean isAllNodes ( String ... nodesIds ) { } public DiscoveryNode resolveNode ( String node ) { } public String [ ] resolveNodesIds ( String ... nodesIds ) { if ( isAllNodes ( nodesIds ) ) { int index = 0 ; nodesIds = new String [ nodes . size ( ) ] ; for ( DiscoveryNode node : this ) { nodesIds [ ( index ++ ) ] = node . id ( ) ; } return nodesIds ; } else { <START_BUG> ObjectOpenHashSet < String > resolvedNodesIds = new ObjectOpenHashSet < String > ( nodesIds . length ) ; <END_BUG> for ( String nodeId : nodesIds ) { if ( nodeId . equals ( "_local" ) ) { String localNodeId = localNodeId ( ) ; if ( localNodeId != null ) { resolvedNodesIds . add ( localNodeId ) ; } } else if ( nodeId . equals ( "_master" ) ) { String masterNodeId = masterNodeId ( ) ; if ( masterNodeId != null ) { resolvedNodesIds . add ( masterNodeId ) ; } } else if ( nodeExists ( nodeId ) ) { resolvedNodesIds . add ( nodeId ) ; } else { for ( DiscoveryNode node : this ) { if ( Regex . simpleMatch ( nodeId , node . name ( ) ) ) { resolvedNodesIds . add ( node . id ( ) ) ; } } for ( DiscoveryNode node : this ) { if ( Regex . simpleMatch ( nodeId , node . getHostAddress ( ) ) ) { resolvedNodesIds . add ( node . id ( ) ) ; } else if ( Regex . simpleMatch ( nodeId , node . getHostName ( ) ) ) { resolvedNodesIds . add ( node . id ( ) ) ; } } int index = nodeId . indexOf ( ':' ) ; if ( index != ( - 1 ) ) { String matchAttrName = nodeId . substring ( 0 , index ) ; String matchAttrValue = nodeId . substring ( ( index + 1 ) ) ; if ( "data" . equals ( matchAttrName ) ) { if ( Booleans . parseBoolean ( matchAttrValue , true ) ) { resolvedNodesIds . addAll ( dataNodes . keys ( ) ) ; } else { resolvedNodesIds . removeAll ( dataNodes . keys ( ) ) ; } } else if ( "master" . equals ( matchAttrName ) ) { if ( Booleans . parseBoolean ( matchAttrValue , true ) ) { resolvedNodesIds . addAll ( masterNodes . keys ( ) ) ; } else { resolvedNodesIds . removeAll ( masterNodes . keys ( ) ) ; } } else { for ( DiscoveryNode node : this ) { for ( Map . Entry < String , String > entry : node . attributes ( ) . entrySet ( ) ) { String attrName = entry . getKey ( ) ; String attrValue = entry . getValue ( ) ; if ( ( Regex . simpleMatch ( matchAttrName , attrName ) ) && ( Regex . simpleMatch ( matchAttrValue , attrValue ) ) ) { resolvedNodesIds . add ( node . id ( ) ) ; } } } } } } } return resolvedNodesIds . toArray ( String . class ) ; } } public DiscoveryNodes removeDeadMembers ( Set < String > newNodes , String masterNodeId ) { } public DiscoveryNodes newNode ( DiscoveryNode node ) { } public DiscoveryNodes . Delta delta ( DiscoveryNodes other ) { } @ Override public String toString ( ) { } public String prettyPrint ( ) { } public DiscoveryNodes . Delta emptyDelta ( ) { } public static class Delta { private final String localNodeId ; private final DiscoveryNode previousMasterNode ; private final DiscoveryNode newMasterNode ; private final ImmutableList < DiscoveryNode > removed ; private final ImmutableList < DiscoveryNode > added ; public Delta ( String localNodeId , ImmutableList < DiscoveryNode > removed , ImmutableList < DiscoveryNode > added ) { }<BUG2FIX>ObjectOpenHashSet < String > resolvedNodesIds = new ObjectOpenHashSet ( nodesIds . length ) ;
public class RestSuggestAction extends BaseRestHandler { @ Inject public RestSuggestAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { SuggestRequest suggestRequest = new SuggestRequest ( RestActions . splitIndices ( request . param ( "index" ) ) ) ; if ( request . hasParam ( "ignore_indices" ) ) { suggestRequest . ignoreIndices ( IgnoreIndices . fromString ( request . param ( "ignore_indices" ) ) ) ; } suggestRequest . listenerThreaded ( false ) ; try { BroadcastOperationThreading operationThreading = BroadcastOperationThreading . fromString ( request . param ( "operation_threading" ) , SINGLE_THREAD ) ; if ( operationThreading == ( BroadcastOperationThreading . NO_THREADS ) ) { operationThreading = BroadcastOperationThreading . SINGLE_THREAD ; } suggestRequest . operationThreading ( operationThreading ) ; if ( request . hasContent ( ) ) { suggestRequest . suggest ( request . content ( ) , request . contentUnsafe ( ) ) ; } else { String source = request . param ( "source" ) ; if ( source != null ) { suggestRequest . suggest ( source ) ; } else { throw new ElasticSearchIllegalArgumentException ( "no<seq2seq4repair_space>content<seq2seq4repair_space>or<seq2seq4repair_space>source<seq2seq4repair_space>provided<seq2seq4repair_space>to<seq2seq4repair_space>execute<seq2seq4repair_space>suggestion" ) ; } } suggestRequest . routing ( request . param ( "routing" ) ) ; suggestRequest . preference ( request . param ( "preference" ) ) ; } catch ( Exception e ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . BAD_REQUEST , builder . startObject ( ) . field ( "error" , e . getMessage ( ) ) . endObject ( ) ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } return ; } client . suggest ( suggestRequest , new org . elasticsearch . action . ActionListener < SuggestResponse > ( ) { @ Override public void onResponse ( SuggestResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; buildBroadcastShardsHeader ( builder , response ) ; Suggest suggest = response . getSuggest ( ) ; if ( suggest != null ) { suggest . toXContent ( builder , request ) ; } builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class FileHandle { protected File file ; protected FileType type ; protected FileHandle ( ) { } public FileHandle ( String fileName ) { } public FileHandle ( File file ) { } protected FileHandle ( String fileName , FileType type ) { } protected FileHandle ( File file , FileType type ) { } public String path ( ) { } public String name ( ) { } public String extension ( ) { } public String nameWithoutExtension ( ) { } public String pathWithoutExtension ( ) { } public FileType type ( ) { } public File file ( ) { } public InputStream read ( ) { } public BufferedInputStream read ( int bufferSize ) { } public Reader reader ( ) { } public Reader reader ( String charset ) { } public BufferedReader reader ( int bufferSize ) { } public BufferedReader reader ( int bufferSize , String charset ) { } public String readString ( ) { } public String readString ( String charset ) { } public byte [ ] readBytes ( ) { int length = ( ( int ) ( length ( ) ) ) ; if ( length == 0 ) length = 512 ; byte [ ] buffer = new byte [ length ] ; int position = 0 ; InputStream input = read ( ) ; try { while ( true ) { int count = input . read ( buffer , position , ( ( buffer . length ) - position ) ) ; if ( count == ( - 1 ) ) break ; position += count ; <START_BUG> if ( ( count == 0 ) && ( position == ( buffer . length ) ) ) { <END_BUG> byte [ ] newBuffer = new byte [ ( buffer . length ) * 2 ] ; System . arraycopy ( buffer , 0 , newBuffer , 0 , position ) ; buffer = newBuffer ; } } } catch ( IOException ex ) { throw new GdxRuntimeException ( ( "Error<seq2seq4repair_space>reading<seq2seq4repair_space>file:<seq2seq4repair_space>" + ( this ) ) , ex ) ; } finally { try { if ( input != null ) input . close ( ) ; } catch ( IOException ignored ) { } } if ( position < ( buffer . length ) ) { byte [ ] newBuffer = new byte [ position ] ; System . arraycopy ( buffer , 0 , newBuffer , 0 , position ) ; buffer = newBuffer ; } return buffer ; } public int readBytes ( byte [ ] bytes , int offset , int size ) { } public OutputStream write ( boolean append ) { } public void write ( InputStream input , boolean append ) { } public Writer writer ( boolean append ) { } public Writer writer ( boolean append , String charset ) { } public void writeString ( String string , boolean append ) { } public void writeString ( String string , boolean append , String charset ) { } public void writeBytes ( byte [ ] bytes , boolean append ) { } public void writeBytes ( byte [ ] bytes , int offset , int length , boolean append ) { } public FileHandle [ ] list ( ) { } public FileHandle [ ] list ( String suffix ) { } public boolean isDirectory ( ) { } public FileHandle child ( String name ) { } public FileHandle sibling ( String name ) { } public FileHandle parent ( ) { } public void mkdirs ( ) { } public boolean exists ( ) { } public boolean delete ( ) { } public boolean deleteDirectory ( ) { } public void copyTo ( FileHandle dest ) { } public void moveTo ( FileHandle dest ) { } public long length ( ) { } public long lastModified ( ) { } public String toString ( ) { } public static FileHandle tempFile ( String prefix ) { } public static FileHandle tempDirectory ( String prefix ) { } private static boolean deleteDirectory ( File file ) { } private static void copyFile ( FileHandle source , FileHandle dest ) { } private static void copyDirectory ( FileHandle sourceDir , FileHandle destDir ) { } }<BUG2FIX>if ( position == ( buffer . length ) ) {
public class TransportPercolateAction extends TransportBroadcastOperationAction < PercolateRequest , PercolateResponse , PercolateShardRequest , PercolateShardResponse > { private final PercolatorService percolatorService ; private final TransportGetAction getAction ; @ Inject public TransportPercolateAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportService transportService , PercolatorService percolatorService , TransportGetAction getAction , ActionFilters actionFilters ) { } @ Override protected void doExecute ( final PercolateRequest request , final ActionListener < PercolateResponse > listener ) { } @ Override protected String executor ( ) { } @ Override protected PercolateRequest newRequest ( ) { } @ Override protected ClusterBlockException checkGlobalBlock ( ClusterState state , PercolateRequest request ) { } @ Override protected ClusterBlockException checkRequestBlock ( ClusterState state , PercolateRequest request , String [ ] concreteIndices ) { } @ Override protected PercolateResponse newResponse ( PercolateRequest request , AtomicReferenceArray shardsResponses , ClusterState clusterState ) { } public static PercolateResponse reduce ( PercolateRequest request , AtomicReferenceArray shardsResponses , PercolatorService percolatorService ) { int successfulShards = 0 ; int failedShards = 0 ; List < PercolateShardResponse > shardResults = null ; List < ShardOperationFailedException > shardFailures = null ; byte percolatorTypeId = 0 ; for ( int i = 0 ; i < ( shardsResponses . length ( ) ) ; i ++ ) { Object shardResponse = shardsResponses . get ( i ) ; if ( shardResponse == null ) { } else if ( shardResponse instanceof BroadcastShardOperationFailedException ) { failedShards ++ ; if ( shardFailures == null ) { shardFailures = Lists . newArrayList ( ) ; } shardFailures . add ( new DefaultShardOperationFailedException ( ( ( BroadcastShardOperationFailedException ) ( shardResponse ) ) ) ) ; } else { PercolateShardResponse percolateShardResponse = ( ( PercolateShardResponse ) ( shardResponse ) ) ; successfulShards ++ ; if ( ! ( percolateShardResponse . isEmpty ( ) ) ) { if ( shardResults == null ) { percolatorTypeId = percolateShardResponse . percolatorTypeId ( ) ; shardResults = Lists . newArrayList ( ) ; } shardResults . add ( percolateShardResponse ) ; } } } if ( shardResults == null ) { long tookInMillis = ( System . currentTimeMillis ( ) ) - ( request . startTime ) ; PercolateResponse [ ] matches = ( request . onlyCount ( ) ) ? null : PercolateResponse . EMPTY ; return new PercolateResponse ( shardsResponses . length ( ) , successfulShards , failedShards , shardFailures , tookInMillis , matches ) ; } else { PercolatorService . ReduceResult result = percolatorService . reduce ( percolatorTypeId , shardResults ) ; long tookInMillis = ( System . currentTimeMillis ( ) ) - ( request . startTime ) ; <START_BUG> return new PercolateResponse ( shardsResponses . length ( ) , successfulShards , failedShards , shardFailures , result . matches ( ) , result . count ( ) , tookInMillis , result . reducedFacets ( ) , result . reducedAggregations ( ) ) ; <END_BUG> } } @ Override protected PercolateShardRequest newShardRequest ( ) { } @ Override protected PercolateShardRequest newShardRequest ( int numShards , ShardRouting shard , PercolateRequest request ) { } @ Override protected PercolateShardResponse newShardResponse ( ) { } @ Override protected GroupShardsIterator shards ( ClusterState clusterState , PercolateRequest request , String [ ] concreteIndices ) { } @ Override protected PercolateShardResponse shardOperation ( PercolateShardRequest request ) throws ElasticsearchException { } }<BUG2FIX>return new PercolateResponse ( shardsResponses . length ( ) , successfulShards , failedShards , shardFailures , result . matches ( ) , result . count ( ) , tookInMillis , result . reducedAggregations ( ) ) ;
public final class ClassReflection { public static Class forName ( String name ) throws ReflectionException { } public static String getSimpleName ( Class c ) { } public static boolean isInstance ( Class c , Object obj ) { } public static boolean isAssignableFrom ( Class c1 , Class c2 ) { Type c1Type = ReflectionCache . getType ( c1 ) ; Type c2Type = ReflectionCache . getType ( c2 ) ; <START_BUG> return c2Type . isAssignableFrom ( c1Type ) ; <END_BUG> } public static boolean isMemberClass ( Class c ) { } public static boolean isStaticClass ( Class c ) { } public static < T > T newInstance ( Class < T > c ) throws ReflectionException { } public static Constructor [ ] getConstructors ( Class c ) { } public static Constructor getConstructor ( Class c , Class ... parameterTypes ) throws ReflectionException { } public static Constructor getDeclaredConstructor ( Class c , Class ... parameterTypes ) throws ReflectionException { } public static Method [ ] getMethods ( Class c ) { } public static Method getMethod ( Class c , String name , Class ... parameterTypes ) throws ReflectionException { } public static Method [ ] getDeclaredMethods ( Class c ) { } public static Method getDeclaredMethod ( Class c , String name , Class ... parameterTypes ) throws ReflectionException { } public static Field [ ] getFields ( Class c ) { } public static Field getField ( Class c , String name ) throws ReflectionException { } public static Field [ ] getDeclaredFields ( Class c ) { } public static Field getDeclaredField ( Class c , String name ) throws ReflectionException { } }<BUG2FIX>return c1Type . isAssignableFrom ( c2Type ) ;
public class TimerTest extends GdxTest { @ Override public void create ( ) { new Timer ( ) . scheduleTask ( new Task ( ) { @ Override public void run ( ) { app . log ( "TimerTest" , "ping" ) ; } <START_BUG> } , 1 , 1 ) ; <END_BUG> } }<BUG2FIX>} , 0 , 1 ) ;
public class MessageChannelHandler extends SimpleChannelUpstreamHandler { protected final ESLogger logger ; protected final ThreadPool threadPool ; protected final TransportServiceAdapter transportServiceAdapter ; protected final NettyTransport transport ; public MessageChannelHandler ( NettyTransport transport , ESLogger logger ) { } @ Override public void writeComplete ( ChannelHandlerContext ctx , WriteCompletionEvent e ) throws Exception { } @ Override public void messageReceived ( ChannelHandlerContext ctx , MessageEvent e ) throws Exception { } protected void handleResponse ( Channel channel , StreamInput buffer , final TransportResponseHandler handler ) { } private void handlerResponseError ( StreamInput buffer , final TransportResponseHandler handler ) { } private void handleException ( final TransportResponseHandler handler , Throwable error ) { } protected String handleRequest ( Channel channel , StreamInput buffer , long requestId , Version version ) throws IOException { final String action = buffer . readString ( ) ; final NettyTransportChannel transportChannel = new NettyTransportChannel ( transport , action , channel , requestId , version ) ; try { <START_BUG> final TransportRequestHandler handler = transportServiceAdapter . handler ( action ) ; <END_BUG> if ( handler == null ) { throw new ActionNotFoundTransportException ( action ) ; } final TransportRequest request = handler . newInstance ( ) ; request . remoteAddress ( new InetSocketTransportAddress ( ( ( InetSocketAddress ) ( channel . getRemoteAddress ( ) ) ) ) ) ; request . readFrom ( buffer ) ; if ( ( handler . executor ( ) ) == ( Names . SAME ) ) { handler . messageReceived ( request , transportChannel ) ; } else { threadPool . executor ( handler . executor ( ) ) . execute ( new MessageChannelHandler . RequestHandler ( handler , request , transportChannel , action ) ) ; } } catch ( Throwable e ) { try { transportChannel . sendResponse ( e ) ; } catch ( IOException e1 ) { logger . warn ( ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>error<seq2seq4repair_space>message<seq2seq4repair_space>back<seq2seq4repair_space>to<seq2seq4repair_space>client<seq2seq4repair_space>for<seq2seq4repair_space>action<seq2seq4repair_space>[" + action ) + "]" ) , e ) ; logger . warn ( "Actual<seq2seq4repair_space>Exception" , e1 ) ; } } return action ; } @ Override public void exceptionCaught ( ChannelHandlerContext ctx , ExceptionEvent e ) throws Exception { } class ResponseHandler implements Runnable { private final TransportResponseHandler handler ; private final TransportResponse response ; public ResponseHandler ( TransportResponseHandler handler , TransportResponse response ) { } @ SuppressWarnings ( { "unchecked" } ) @ Override public void run ( ) { } } class RequestHandler extends AbstractRunnable { private final TransportRequestHandler handler ; private final TransportRequest request ; private final NettyTransportChannel transportChannel ; private final String action ; public RequestHandler ( TransportRequestHandler handler , TransportRequest request , NettyTransportChannel transportChannel , String action ) { } @ SuppressWarnings ( { "unchecked" } ) @ Override public void run ( ) { } @ Override public boolean isForceExecution ( ) { } } }<BUG2FIX>final TransportRequestHandler handler = transportServiceAdapter . handler ( action , version ) ;
public class PercolateRequest extends SingleCustomOperationRequest { private String index ; private String type ; private BytesReference source ; private boolean sourceUnsafe ; public PercolateRequest ( ) { } public PercolateRequest ( String index , String type ) { } public PercolateRequest index ( String index ) { } public PercolateRequest type ( String type ) { } public String index ( ) { } public String type ( ) { } @ Override public void beforeLocalFork ( ) { } public BytesReference source ( ) { } @ Required public PercolateRequest source ( Map source ) throws ElasticSearchGenerationException { } @ Required public PercolateRequest source ( Map source , XContentType contentType ) throws ElasticSearchGenerationException { } @ Required public PercolateRequest source ( String source ) { } @ Required public PercolateRequest source ( XContentBuilder sourceBuilder ) { } public PercolateRequest source ( byte [ ] source ) { } @ Required public PercolateRequest source ( byte [ ] source , int offset , int length ) { } @ Required public PercolateRequest source ( byte [ ] source , int offset , int length , boolean unsafe ) { } @ Required public PercolateRequest source ( BytesReference source , boolean unsafe ) { } @ Override public PercolateRequest preferLocal ( boolean preferLocal ) { } @ Override public ActionRequestValidationException validate ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { super . writeTo ( out ) ; out . writeUTF ( index ) ; out . writeUTF ( type ) ; <START_BUG> out . writeBytesReference ( source , true ) ; <END_BUG> } }<BUG2FIX>out . writeBytesReference ( source ) ;
public class TermsStringOrdinalsFacetExecutor extends FacetExecutor { private final WithOrdinals indexFieldData ; final CacheRecycler cacheRecycler ; private final ComparatorType comparatorType ; private final int size ; private final int shardSize ; private final int minCount ; private final ImmutableSet < BytesRef > excluded ; private final Matcher matcher ; final int ordinalsCacheAbove ; final List < TermsStringOrdinalsFacetExecutor . ReaderAggregator > aggregators ; long missing ; long total ; public TermsStringOrdinalsFacetExecutor ( IndexFieldData . WithOrdinals indexFieldData , int size , int shardSize , TermsFacet . ComparatorType comparatorType , boolean allTerms , SearchContext context , ImmutableSet < BytesRef > excluded , Pattern pattern , int ordinalsCacheAbove ) { } @ Override public TermsStringOrdinalsFacetExecutor . Collector collector ( ) { } @ Override public InternalFacet buildFacet ( String facetName ) { } class Collector extends FacetExecutor . Collector { private long missing ; private long total ; private BytesValues . WithOrdinals values ; private TermsStringOrdinalsFacetExecutor . ReaderAggregator current ; private Docs ordinals ; @ Override public void setNextReader ( AtomicReaderContext context ) throws IOException { if ( ( current ) != null ) { missing += current . counts . get ( 0 ) ; total += ( current . total ) - ( current . counts . get ( 0 ) ) ; if ( ( current . values . ordinals ( ) . getNumOrds ( ) ) > 0 ) { aggregators . add ( current ) ; } } <START_BUG> values = indexFieldData . load ( context ) . getBytesValues ( ) ; <END_BUG> current = new TermsStringOrdinalsFacetExecutor . ReaderAggregator ( values , ordinalsCacheAbove , cacheRecycler ) ; ordinals = values . ordinals ( ) ; } @ Override public void collect ( int doc ) throws IOException { } @ Override public void postCollection ( ) { } } public static final class ReaderAggregator { private final long maxOrd ; final BytesValues . WithOrdinals values ; final IntArray counts ; long position = 0 ; BytesRef current ; int total ; public ReaderAggregator ( BytesValues . WithOrdinals values , int ordinalsCacheLimit , CacheRecycler cacheRecycler ) { } final void onOrdinal ( int docId , long ordinal ) { } final void incrementMissing ( int numMissing ) { } public boolean nextPosition ( ) { } public BytesRef copyCurrent ( ) { } } public static class AggregatorPriorityQueue extends PriorityQueue < TermsStringOrdinalsFacetExecutor . ReaderAggregator > { public AggregatorPriorityQueue ( int size ) { } @ Override protected boolean lessThan ( TermsStringOrdinalsFacetExecutor . ReaderAggregator a , TermsStringOrdinalsFacetExecutor . ReaderAggregator b ) { } } }<BUG2FIX>values = indexFieldData . load ( context ) . getBytesValues ( false ) ;
final class ParentIdsFilter extends Filter { private final BytesRef parentTypeBr ; private final Object [ ] keys ; private final boolean [ ] allocated ; public ParentIdsFilter ( String parentType , Object [ ] keys , boolean [ ] allocated ) { } @ Override public DocIdSet getDocIdSet ( AtomicReaderContext context , Bits acceptDocs ) throws IOException { Terms terms = context . reader ( ) . terms ( UidFieldMapper . NAME ) ; if ( terms == null ) { return null ; } TermsEnum termsEnum = terms . iterator ( null ) ; BytesRef uidSpare = new BytesRef ( ) ; BytesRef idSpare = new BytesRef ( ) ; DocsEnum docsEnum = null ; FixedBitSet result = null ; for ( int i = 0 ; i < ( allocated . length ) ; i ++ ) { if ( ! ( allocated [ i ] ) ) { continue ; } idSpare . bytes = ( ( org . elasticsearch . common . bytes . HashedBytesArray ) ( keys [ i ] ) ) . toBytes ( ) ; idSpare . length = idSpare . bytes . length ; Uid . createUidAsBytes ( parentTypeBr , idSpare , uidSpare ) ; <START_BUG> if ( termsEnum . seekExact ( uidSpare , false ) ) { <END_BUG> int docId ; docsEnum = termsEnum . docs ( acceptDocs , docsEnum , FLAG_NONE ) ; if ( result == null ) { docId = docsEnum . nextDoc ( ) ; if ( docId != ( DocIdSetIterator . NO_MORE_DOCS ) ) { result = new FixedBitSet ( context . reader ( ) . maxDoc ( ) ) ; result . set ( docId ) ; } else { continue ; } } for ( docId = docsEnum . nextDoc ( ) ; docId < ( DocIdSetIterator . NO_MORE_DOCS ) ; docId = docsEnum . nextDoc ( ) ) { result . set ( docId ) ; } } } return result ; } }<BUG2FIX>if ( termsEnum . seekExact ( uidSpare ) ) {
public class Preloader { public interface PreloaderCallback { public void update ( Preloader . PreloaderState state ) { } public void error ( String file ) { } } public ObjectMap < String , ImageElement > images = new ObjectMap < String , ImageElement > ( ) ; public ObjectMap < String , Void > audio = new ObjectMap < String , Void > ( ) ; public ObjectMap < String , String > texts = new ObjectMap < String , String > ( ) ; public ObjectMap < String , Blob > binaries = new ObjectMap < String , Blob > ( ) ; public static class Asset { public Asset ( String url , AssetType type , long size , String mimeType ) { } public boolean succeed ; public boolean failed ; public long loaded ; public final String url ; public final AssetType type ; public final long size ; public final String mimeType ; } public static class PreloaderState { public PreloaderState ( Array < Preloader . Asset > assets ) { } public long getDownloadedSize ( ) { } public long getTotalSize ( ) { } public float getProgress ( ) { } public boolean hasEnded ( ) { } public final Array < Preloader . Asset > assets ; } public final String baseUrl ; public Preloader ( String newBaseURL ) { } public void preload ( final String assetFileUrl , final Preloader . PreloaderCallback callback ) { final AssetDownloader loader = new AssetDownloader ( ) ; loader . loadText ( ( ( baseUrl ) + assetFileUrl ) , new com . badlogic . gdx . backends . gwt . preloader . AssetDownloader . AssetLoaderListener < String > ( ) { @ Override public void onProgress ( double amount ) { } @ Override public void onFailure ( ) { callback . error ( assetFileUrl ) ; } @ Override public void onSuccess ( String result ) { String [ ] lines = result . split ( "\n" ) ; <START_BUG> Array < Preloader . Asset > assets = new Array < Preloader . Asset > ( lines . length ) ; <END_BUG> for ( String line : lines ) { String [ ] tokens = line . split ( ":" ) ; if ( ( tokens . length ) != 4 ) { throw new GdxRuntimeException ( "Invalid<seq2seq4repair_space>assets<seq2seq4repair_space>description<seq2seq4repair_space>file." ) ; } AssetType type = AssetType . Text ; if ( tokens [ 0 ] . equals ( "i" ) ) type = AssetType . Image ; if ( tokens [ 0 ] . equals ( "b" ) ) type = AssetType . Binary ; if ( tokens [ 0 ] . equals ( "a" ) ) type = AssetType . Audio ; if ( tokens [ 0 ] . equals ( "d" ) ) type = AssetType . Directory ; long size = Long . parseLong ( tokens [ 2 ] ) ; if ( ( type == ( AssetType . Audio ) ) && ( ! ( loader . isUseBrowserCache ( ) ) ) ) { size = 0 ; } assets . add ( new Preloader . Asset ( tokens [ 1 ] . trim ( ) , type , size , tokens [ 3 ] ) ) ; } final Preloader . PreloaderState state = new Preloader . PreloaderState ( assets ) ; for ( int i = 0 ; i < ( assets . size ) ; i ++ ) { final Preloader . Asset asset = assets . get ( i ) ; if ( contains ( asset . url ) ) { asset . loaded = asset . size ; asset . succeed = true ; continue ; } loader . load ( ( ( baseUrl ) + ( asset . url ) ) , asset . type , asset . mimeType , new com . badlogic . gdx . backends . gwt . preloader . AssetDownloader . AssetLoaderListener < Object > ( ) { @ Override public void onProgress ( double amount ) { asset . loaded = ( ( long ) ( amount ) ) ; callback . update ( state ) ; } @ Override public void onFailure ( ) { asset . failed = true ; callback . error ( asset . url ) ; callback . update ( state ) ; } @ Override public void onSuccess ( Object result ) { switch ( asset . type ) { case Text : texts . put ( asset . url , ( ( String ) ( result ) ) ) ; break ; case Image : images . put ( asset . url , ( ( ImageElement ) ( result ) ) ) ; break ; case Binary : binaries . put ( asset . url , ( ( Blob ) ( result ) ) ) ; break ; case Audio : audio . put ( asset . url , null ) ; break ; case Directory : break ; } asset . succeed = true ; callback . update ( state ) ; } } ) ; } callback . update ( state ) ; } } ) ; } public InputStream read ( String url ) { } public boolean contains ( String url ) { } public boolean isText ( String url ) { } public boolean isImage ( String url ) { } public boolean isBinary ( String url ) { } public boolean isAudio ( String url ) { } public FileHandle [ ] list ( String url ) { } public boolean isDirectory ( String url ) { } public long length ( String url ) { } }<BUG2FIX>Array < Preloader . Asset > assets = new Array < Preloader . Asset > ( ) ;
public class LocalIndexGateway extends AbstractIndexComponent implements IndexGateway { @ Inject public LocalIndexGateway ( Index index , @ IndexSettings Settings indexSettings ) { } @ Override public String type ( ) { } @ Override public Class < ? extends IndexShardGateway > shardGatewayClass ( ) { } @ Override public String toString ( ) { } @ Override <START_BUG> public void close ( boolean delete ) { <END_BUG> } }<BUG2FIX>public void close ( ) {
public class TransportGetSettingsAction extends TransportMasterNodeReadOperationAction < GetSettingsRequest , GetSettingsResponse > { private final SettingsFilter settingsFilter ; @ Inject public TransportGetSettingsAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool , SettingsFilter settingsFilter ) { } @ Override protected String transportAction ( ) { } @ Override protected String executor ( ) { } @ Override protected GetSettingsRequest newRequest ( ) { } @ Override protected GetSettingsResponse newResponse ( ) { } @ Override protected void masterOperation ( GetSettingsRequest request , ClusterState state , ActionListener < GetSettingsResponse > listener ) throws ElasticsearchException { <START_BUG> request . indices ( state . metaData ( ) . concreteIndices ( request . indices ( ) , request . indicesOptions ( ) ) ) ; <END_BUG> Builder < String , Settings > indexToSettingsBuilder = ImmutableOpenMap . builder ( ) ; for ( String concreteIndex : request . indices ( ) ) { IndexMetaData indexMetaData = state . getMetaData ( ) . index ( concreteIndex ) ; if ( indexMetaData == null ) { continue ; } Settings settings = settingsFilter . filterSettings ( indexMetaData . settings ( ) ) ; if ( ! ( CollectionUtils . isEmpty ( request . names ( ) ) ) ) { ImmutableSettings . Builder settingsBuilder = ImmutableSettings . builder ( ) ; for ( Map . Entry < String , String > entry : settings . getAsMap ( ) . entrySet ( ) ) { if ( Regex . simpleMatch ( request . names ( ) , entry . getKey ( ) ) ) { settingsBuilder . put ( entry . getKey ( ) , entry . getValue ( ) ) ; } } settings = settingsBuilder . build ( ) ; } indexToSettingsBuilder . put ( concreteIndex , settings ) ; } listener . onResponse ( new GetSettingsResponse ( indexToSettingsBuilder . build ( ) ) ) ; } }<BUG2FIX>request . indices ( state . metaData ( ) . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ) ;
public class GdxBuild { public static void main ( String [ ] args ) throws Exception { String JNI_DIR = "jni-new" ; String LIBS_DIR = "libs-new" ; String [ ] includes = new String [ ] { "**/MD5Jni.java" } ; new NativeCodeGenerator ( ) . generate ( "src" , "bin" , ( JNI_DIR + "/" ) , includes , null ) ; includes = new String [ ] { "**/Matrix4.java" } ; new NativeCodeGenerator ( ) . generate ( "src" , "bin" , ( JNI_DIR + "/" ) , includes , null ) ; includes = new String [ ] { "**/ETC1.java" } ; new NativeCodeGenerator ( ) . generate ( "src" , "bin" , ( JNI_DIR + "/etc1/" ) , includes , null ) ; includes = new String [ ] { "**/Gdx2DPixmap.java" } ; new NativeCodeGenerator ( ) . generate ( "src" , "bin" , ( JNI_DIR + "/gdx2d/" ) , includes , null ) ; String [ ] headerDirs = new String [ ] { "./" , "etc1/" , "gdx2d/" } ; BuildConfig config = new BuildConfig ( "gdx" , "../target/native" , LIBS_DIR , JNI_DIR ) ; BuildTarget target = BuildTarget . newDefaultTarget ( Windows , false ) ; target . compilerPrefix = "" ; target . excludeFromMasterBuildFile = true ; target . headerDirs = headerDirs ; new AntScriptGenerator ( ) . generate ( config , target ) ; <START_BUG> BuildExecutor . executeAnt ( ( JNI_DIR + "/build-windows32.xml" ) , "clean<seq2seq4repair_space>link<seq2seq4repair_space>-v" ) ; <END_BUG> } }<BUG2FIX>BuildExecutor . executeAnt ( ( JNI_DIR + "/build-windows32.xml" ) , "" ) ;
public class TermsStatsLongFacetCollector extends AbstractFacetCollector { private final ComparatorType comparatorType ; private final FieldDataCache fieldDataCache ; private final String keyFieldName ; private final String valueFieldName ; private final int size ; private final int numberOfShards ; private final FieldDataType keyFieldDataType ; private NumericFieldData keyFieldData ; private final FieldDataType valueFieldDataType ; private final SearchScript script ; private final TermsStatsLongFacetCollector . Aggregator aggregator ; public TermsStatsLongFacetCollector ( String facetName , String keyFieldName , String valueFieldName , int size , TermsStatsFacet . ComparatorType comparatorType , SearchContext context , String scriptLang , String script , Map < String , Object > params ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override protected void doSetNextReader ( AtomicReaderContext context ) throws IOException { keyFieldData = ( ( NumericFieldData ) ( fieldDataCache . cache ( keyFieldDataType , context . reader ( ) , keyFieldName ) ) ) ; if ( ( script ) != null ) { <START_BUG> script . setNextReader ( context . reader ( ) ) ; <END_BUG> } else { aggregator . valueFieldData = ( ( NumericFieldData ) ( fieldDataCache . cache ( valueFieldDataType , context . reader ( ) , valueFieldName ) ) ) ; } } @ Override protected void doCollect ( int doc ) throws IOException { } @ Override public Facet facet ( ) { } public static class Aggregator implements NumericFieldData . MissingLongValueInDocProc { final ExtTLongObjectHashMap < InternalTermsStatsLongFacet . LongEntry > entries = CacheRecycler . popLongObjectMap ( ) ; int missing ; NumericFieldData valueFieldData ; final TermsStatsLongFacetCollector . Aggregator . ValueAggregator valueAggregator = new TermsStatsLongFacetCollector . Aggregator . ValueAggregator ( ) ; @ Override public void onValue ( int docId , long value ) { } @ Override public void onMissing ( int docId ) { } public static class ValueAggregator implements NumericFieldData . DoubleValueInDocProc { LongEntry longEntry ; @ Override public void onValue ( int docId , double value ) { } } } public static class ScriptAggregator extends TermsStatsLongFacetCollector . Aggregator { private final SearchScript script ; public ScriptAggregator ( SearchScript script ) { } @ Override public void onValue ( int docId , long value ) { } } }<BUG2FIX>script . setNextReader ( context ) ;
public class RestTable { public static RestResponse buildResponse ( Table table , RestRequest request , RestChannel channel ) throws Exception { } public static RestResponse buildXContentBuilder ( Table table , RestRequest request , RestChannel channel ) throws Exception { } public static RestResponse buildTextPlainResponse ( Table table , RestRequest request , RestChannel channel ) { <START_BUG> boolean verbose = request . paramAsBoolean ( "v" , true ) ; <END_BUG> int [ ] width = RestTable . buildWidths ( table , request , verbose ) ; Set < String > displayHeaders = RestTable . buildDisplayHeaders ( table , request ) ; StringBuilder out = new StringBuilder ( ) ; if ( verbose ) { for ( int i = 0 ; i < ( width . length ) ; i ++ ) { String headerName = table . getHeaders ( ) . get ( i ) . value . toString ( ) ; if ( displayHeaders . contains ( headerName ) ) { RestTable . pad ( table . getHeaders ( ) . get ( i ) , width [ i ] , request , out ) ; out . append ( "<seq2seq4repair_space>" ) ; } } out . append ( "\n" ) ; } for ( List < Table . Cell > row : table . getRows ( ) ) { for ( int i = 0 ; i < ( width . length ) ; i ++ ) { String headerName = table . getHeaders ( ) . get ( i ) . value . toString ( ) ; if ( displayHeaders . contains ( headerName ) ) { RestTable . pad ( row . get ( i ) , width [ i ] , request , out ) ; out . append ( "<seq2seq4repair_space>" ) ; } } out . append ( "\n" ) ; } return new StringRestResponse ( RestStatus . OK , out . toString ( ) ) ; } private static Set < String > buildDisplayHeaders ( Table table , RestRequest request ) { } private static int [ ] buildWidths ( Table table , RestRequest request , boolean verbose ) { } private static void pad ( Table . Cell cell , int width , RestRequest request , StringBuilder out ) { } private static String renderValue ( RestRequest request , Object value ) { } }<BUG2FIX>boolean verbose = request . paramAsBoolean ( "v" , false ) ;
public class IntIntMap { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; private static final int EMPTY = 0 ; public int size ; int [ ] keyTable ; int [ ] valueTable ; int capacity ; int stashSize ; int zeroValue ; boolean hasZeroValue ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private IntIntMap . Entries entries1 ; private IntIntMap . Entries entries2 ; private IntIntMap . Values values1 ; private IntIntMap . Values values2 ; private IntIntMap . Keys keys1 ; private IntIntMap . Keys keys2 ; public IntIntMap ( ) { } public IntIntMap ( int initialCapacity ) { } public IntIntMap ( int initialCapacity , float loadFactor ) { } public IntIntMap ( IntIntMap map ) { } public void put ( int key , int value ) { } public void putAll ( IntIntMap map ) { } private void putResize ( int key , int value ) { } private void push ( int insertKey , int insertValue , int index1 , int key1 , int index2 , int key2 , int index3 , int key3 ) { } private void putStash ( int key , int value ) { } public int get ( int key , int defaultValue ) { } private int getStash ( int key , int defaultValue ) { } public int getAndIncrement ( int key , int defaultValue , int increment ) { } private int getAndIncrementStash ( int key , int defaultValue , int increment ) { } public int remove ( int key , int defaultValue ) { } int removeStash ( int key , int defaultValue ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean containsValue ( int value ) { } public boolean containsKey ( int key ) { } private boolean containsKeyStash ( int key ) { } public int findKey ( int value , int notFound ) { } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( int h ) { } private int hash3 ( int h ) { } public String toString ( ) { } public IntIntMap . Entries entries ( ) { } public IntIntMap . Values values ( ) { } public IntIntMap . Keys keys ( ) { } public static class Entry < K > { public int key ; public int value ; public String toString ( ) { } } private static class MapIterator < K > { static final int INDEX_ILLEGAL = - 2 ; static final int INDEX_ZERO = - 1 ; public boolean hasNext ; final IntIntMap map ; int nextIndex ; int currentIndex ; boolean valid = true ; public MapIterator ( IntIntMap map ) { } public void reset ( ) { } void findNextIndex ( ) { } public void remove ( ) { if ( ( ( currentIndex ) == ( IntIntMap . MapIterator . INDEX_ZERO ) ) && ( map . hasZeroValue ) ) { map . hasZeroValue = false ; } else if ( ( currentIndex ) < 0 ) { throw new IllegalStateException ( "next<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>called<seq2seq4repair_space>before<seq2seq4repair_space>remove." ) ; } else if ( ( currentIndex ) >= ( map . capacity ) ) { map . removeStashIndex ( currentIndex ) ; <START_BUG> nextIndex = currentIndex ; <END_BUG> findNextIndex ( ) ; } else { map . keyTable [ currentIndex ] = IntIntMap . EMPTY ; } currentIndex = IntIntMap . MapIterator . INDEX_ILLEGAL ; ( map . size ) -- ; } } public static class Entries extends IntIntMap . MapIterator implements Iterable < IntIntMap . Entry > , Iterator < IntIntMap . Entry > { private IntIntMap . Entry entry = new IntIntMap . Entry ( ) ; public Entries ( IntIntMap map ) { } public IntIntMap . Entry next ( ) { } public boolean hasNext ( ) { } public Iterator < IntIntMap . Entry > iterator ( ) { } } public static class Values extends IntIntMap . MapIterator < Object > { public Values ( IntIntMap map ) { } public boolean hasNext ( ) { } public int next ( ) { } public IntArray toArray ( ) { } } public static class Keys extends IntIntMap . MapIterator { public Keys ( IntIntMap map ) { } public boolean hasNext ( ) { } public int next ( ) { } public IntArray toArray ( ) { } } }<BUG2FIX>nextIndex = ( currentIndex ) - 1 ;
public class TransportIndexAction extends TransportShardReplicationOperationAction < IndexRequest , IndexRequest , IndexResponse > { private final AutoCreateIndex autoCreateIndex ; private final boolean allowIdGeneration ; private final TransportCreateIndexAction createIndexAction ; private final MappingUpdatedAction mappingUpdatedAction ; private final boolean waitForMappingChange ; @ Inject public TransportIndexAction ( Settings settings , TransportService transportService , ClusterService clusterService , IndicesService indicesService , ThreadPool threadPool , ShardStateAction shardStateAction , TransportCreateIndexAction createIndexAction , MappingUpdatedAction mappingUpdatedAction ) { } @ Override protected void doExecute ( final IndexRequest request , final ActionListener < IndexResponse > listener ) { if ( autoCreateIndex . shouldAutoCreate ( request . index ( ) , clusterService . state ( ) ) ) { request . beforeLocalFork ( ) ; createIndexAction . execute ( new org . elasticsearch . action . admin . indices . create . CreateIndexRequest ( request . index ( ) ) . cause ( "auto(index<seq2seq4repair_space>api)" ) . masterNodeTimeout ( request . timeout ( ) ) , new ActionListener < CreateIndexResponse > ( ) { @ Override public void onResponse ( CreateIndexResponse result ) { innerExecute ( request , listener ) ; } @ Override public void onFailure ( Throwable e ) { if ( ( ExceptionsHelper . unwrapCause ( e ) ) instanceof IndexAlreadyExistsException ) { try { innerExecute ( request , listener ) ; <START_BUG> } catch ( Exception e1 ) { <END_BUG> listener . onFailure ( e1 ) ; } } else { listener . onFailure ( e ) ; } } } ) ; } else { innerExecute ( request , listener ) ; } } @ Override protected boolean resolveRequest ( ClusterState state , IndexRequest request , ActionListener < IndexResponse > indexResponseActionListener ) { } private void innerExecute ( final IndexRequest request , final ActionListener < IndexResponse > listener ) { } @ Override protected boolean checkWriteConsistency ( ) { } @ Override protected IndexRequest newRequestInstance ( ) { } @ Override protected IndexRequest newReplicaRequestInstance ( ) { } @ Override protected IndexResponse newResponseInstance ( ) { } @ Override protected String transportAction ( ) { } @ Override protected String executor ( ) { } @ Override protected ClusterBlockException checkGlobalBlock ( ClusterState state , IndexRequest request ) { } @ Override protected ClusterBlockException checkRequestBlock ( ClusterState state , IndexRequest request ) { } @ Override protected ShardIterator shards ( ClusterState clusterState , IndexRequest request ) { } @ Override protected PrimaryResponse < IndexResponse , IndexRequest > shardOperationOnPrimary ( ClusterState clusterState , PrimaryOperationRequest shardRequest ) { } @ Override protected void postPrimaryOperation ( IndexRequest request , PrimaryResponse < IndexResponse , IndexRequest > response ) { } @ Override protected void shardOperationOnReplica ( ReplicaOperationRequest shardRequest ) { } private void updateMappingOnMaster ( final IndexRequest request ) { } }<BUG2FIX>} catch ( Throwable e1 ) {
public final class SortedSetDVBytesAtomicFieldData extends SortedSetDVAtomicFieldData implements AtomicFieldData . WithOrdinals < ScriptDocValues . Strings > { SortedSetDVBytesAtomicFieldData ( AtomicReader reader , String field ) { } @ Override public boolean isValuesOrdered ( ) { } @ Override public Strings getScriptValues ( ) { <START_BUG> return new ScriptDocValues . Strings ( getBytesValues ( ) ) ; <END_BUG> } }<BUG2FIX>return new ScriptDocValues . Strings ( getBytesValues ( false ) ) ;
public final class InternalContext { private Map < Object , ConstructionContext < ? > > constructionContexts = Maps . newHashMap ( ) ; private Dependency dependency ; @ SuppressWarnings ( "unchecked" ) public < T > ConstructionContext < T > getConstructionContext ( Object key ) { ConstructionContext < T > constructionContext = ( ( ConstructionContext < T > ) ( constructionContexts . get ( key ) ) ) ; if ( constructionContext == null ) { <START_BUG> constructionContext = new ConstructionContext < T > ( ) ; <END_BUG> constructionContexts . put ( key , constructionContext ) ; } return constructionContext ; } public Dependency getDependency ( ) { } public void setDependency ( Dependency dependency ) { } }<BUG2FIX>constructionContext = new ConstructionContext ( ) ;
public class BouncyAndroid extends AndroidApplication { @ Override public void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; <START_BUG> initialize ( new Bouncy ( ) , false , new FillResolutionStrategy ( ) , 16 ) ; <END_BUG> } }<BUG2FIX>initialize ( new Bouncy ( ) , false ) ;
public class RangeQueryParser extends AbstractIndexComponent implements XContentQueryParser { public static final String NAME = "range" ; @ Inject public RangeQueryParser ( Index index , @ IndexSettings Settings settings ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; XContentParser . Token token = parser . nextToken ( ) ; assert token == ( Token . FIELD_NAME ) ; String fieldName = parser . currentName ( ) ; String from = null ; String to = null ; boolean includeLower = true ; boolean includeUpper = true ; float boost = 1.0F ; String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else { if ( "from" . equals ( currentFieldName ) ) { from = parser . textOrNull ( ) ; } else if ( "to" . equals ( currentFieldName ) ) { to = parser . textOrNull ( ) ; } else if ( ( "include_lower" . equals ( currentFieldName ) ) || ( "includeLower" . equals ( currentFieldName ) ) ) { includeLower = parser . booleanValue ( ) ; } else if ( ( "include_upper" . equals ( currentFieldName ) ) || ( "includeUpper" . equals ( currentFieldName ) ) ) { includeUpper = parser . booleanValue ( ) ; } else if ( "boost" . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } else if ( "gt" . equals ( currentFieldName ) ) { from = parser . textOrNull ( ) ; includeLower = false ; } else if ( ( "gte" . equals ( currentFieldName ) ) || ( "ge" . equals ( currentFieldName ) ) ) { from = parser . textOrNull ( ) ; includeLower = true ; } else if ( "lt" . equals ( currentFieldName ) ) { to = parser . textOrNull ( ) ; includeUpper = false ; } else if ( ( "lte" . equals ( currentFieldName ) ) || ( "le" . equals ( currentFieldName ) ) ) { to = parser . textOrNull ( ) ; includeUpper = true ; } } } token = parser . nextToken ( ) ; assert token == ( Token . END_OBJECT ) ; Query query = null ; MapperService . SmartNameFieldMappers smartNameFieldMappers = parseContext . smartFieldMappers ( fieldName ) ; if ( smartNameFieldMappers != null ) { if ( smartNameFieldMappers . hasMapper ( ) ) { query = smartNameFieldMappers . mapper ( ) . rangeQuery ( from , to , includeLower , includeUpper ) ; } } if ( query == null ) { query = new TermRangeQuery ( fieldName , from , to , includeLower , includeUpper ) ; } query . setBoost ( boost ) ; <START_BUG> return wrapSmartNameQuery ( query , smartNameFieldMappers , parseContext . indexCache ( ) ) ; <END_BUG> } }<BUG2FIX>return wrapSmartNameQuery ( query , smartNameFieldMappers , parseContext ) ;
public interface EventListener { <START_BUG> public boolean handle ( Event event ) ; <END_BUG> }<BUG2FIX>public void handle ( Event event ) ;
public class AlphaTest extends GdxTest { SpriteBatch batch ; Texture texture ; @ Override public void create ( ) { } @ Override public void render ( ) { graphics . getGL10 ( ) . glClear ( GL_COLOR_BUFFER_BIT ) ; batch . begin ( ) ; <START_BUG> batch . draw ( texture , 0 , 0 , 256 , 256 , 0 , 0 , 256 , 256 , WHITE , false , false ) ; <END_BUG> batch . end ( ) ; } @ Override public boolean needsGL20 ( ) { } }<BUG2FIX>batch . draw ( texture , 0 , 0 , 256 , 256 , 0 , 0 , 256 , 256 , false , false ) ;
public class TransportNodesListGatewayStartedShards extends TransportNodesOperationAction < TransportNodesListGatewayStartedShards . Request , TransportNodesListGatewayStartedShards . NodesLocalGatewayStartedShards , TransportNodesListGatewayStartedShards . NodeRequest , TransportNodesListGatewayStartedShards . NodeLocalGatewayStartedShards > { private LocalGateway gateway ; @ Inject public TransportNodesListGatewayStartedShards ( Settings settings , ClusterName clusterName , ThreadPool threadPool , ClusterService clusterService , TransportService transportService ) { } TransportNodesListGatewayStartedShards initGateway ( LocalGateway gateway ) { } public ActionFuture < TransportNodesListGatewayStartedShards . NodesLocalGatewayStartedShards > list ( Set < String > nodesIds , @ Nullable TimeValue timeout ) { } @ Override protected String transportAction ( ) { } @ Override protected String transportNodeAction ( ) { } @ Override protected TransportNodesListGatewayStartedShards . Request newRequest ( ) { } @ Override protected TransportNodesListGatewayStartedShards . NodeRequest newNodeRequest ( ) { } @ Override protected TransportNodesListGatewayStartedShards . NodeRequest newNodeRequest ( String nodeId , TransportNodesListGatewayStartedShards . Request request ) { } @ Override protected TransportNodesListGatewayStartedShards . NodeLocalGatewayStartedShards newNodeResponse ( ) { } @ Override protected TransportNodesListGatewayStartedShards . NodesLocalGatewayStartedShards newResponse ( TransportNodesListGatewayStartedShards . Request request , AtomicReferenceArray responses ) { } @ Override protected TransportNodesListGatewayStartedShards . NodeLocalGatewayStartedShards nodeOperation ( TransportNodesListGatewayStartedShards . NodeRequest request ) throws ElasticSearchException { } @ Override protected boolean accumulateExceptions ( ) { } static class Request extends NodesOperationRequest { public Request ( ) { } public Request ( Set < String > nodesIds ) { } @ Override public TransportNodesListGatewayStartedShards . Request timeout ( TimeValue timeout ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { super . readFrom ( in ) ; } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } public static class NodesLocalGatewayStartedShards extends NodesOperationResponse < TransportNodesListGatewayStartedShards . NodeLocalGatewayStartedShards > { private FailedNodeException [ ] failures ; NodesLocalGatewayStartedShards ( ) { } public NodesLocalGatewayStartedShards ( ClusterName clusterName , TransportNodesListGatewayStartedShards . NodeLocalGatewayStartedShards [ ] nodes , FailedNodeException [ ] failures ) { } public FailedNodeException [ ] failures ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { super . readFrom ( in ) ; nodes = new TransportNodesListGatewayStartedShards . NodeLocalGatewayStartedShards [ in . readVInt ( ) ] ; for ( int i = 0 ; i < ( nodes . length ) ; i ++ ) { nodes [ i ] = new TransportNodesListGatewayStartedShards . NodeLocalGatewayStartedShards ( ) ; nodes [ i ] . readFrom ( in ) ; } } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } static class NodeRequest extends NodeOperationRequest { NodeRequest ( ) { } NodeRequest ( String nodeId ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { super . readFrom ( in ) ; } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } public static class NodeLocalGatewayStartedShards extends NodeOperationResponse { private LocalGatewayStartedShards state ; NodeLocalGatewayStartedShards ( ) { } public NodeLocalGatewayStartedShards ( DiscoveryNode node , LocalGatewayStartedShards state ) { } public LocalGatewayStartedShards state ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { super . readFrom ( in ) ; if ( in . readBoolean ( ) ) { <START_BUG> state = Builder . readFrom ( in , null ) ; <END_BUG> } } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } }<BUG2FIX>state = Builder . readFrom ( in ) ;
public class RestGatewaySnapshotAction extends BaseRestHandler { @ Inject public RestGatewaySnapshotAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { GatewaySnapshotRequest gatewaySnapshotRequest = new GatewaySnapshotRequest ( RestActions . splitIndices ( request . param ( "index" ) ) ) ; gatewaySnapshotRequest . listenerThreaded ( false ) ; if ( request . hasParam ( "ignore_indices" ) ) { gatewaySnapshotRequest . ignoreIndices ( IgnoreIndices . fromString ( request . param ( "ignore_indices" ) ) ) ; } client . admin ( ) . indices ( ) . gatewaySnapshot ( gatewaySnapshotRequest , new org . elasticsearch . action . ActionListener < GatewaySnapshotResponse > ( ) { @ Override public void onResponse ( GatewaySnapshotResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( "ok" , true ) ; buildBroadcastShardsHeader ( builder , response ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class CommitCompareListFragment extends DialogFragment implements OnItemClickListener { private DiffStyler diffStyler ; @ InjectView ( id . list ) private ListView list ; @ InjectView ( id . pb_loading ) private ProgressBar progress ; @ InjectExtra ( Intents . EXTRA_REPOSITORY ) private Repository repository ; @ InjectExtra ( Intents . EXTRA_BASE ) private String base ; @ InjectExtra ( Intents . EXTRA_HEAD ) private String head ; @ Inject private AvatarLoader avatars ; private HeaderFooterListAdapter < CommitFileListAdapter > adapter ; private RepositoryCommitCompare compare ; @ Override public void onCreate ( Bundle savedInstanceState ) { } @ Override public void onCreateOptionsMenu ( final Menu optionsMenu , final MenuInflater inflater ) { } @ Override public boolean onOptionsItemSelected ( final MenuItem item ) { } private void compareCommits ( ) { } private void updateList ( RepositoryCommitCompare compare ) { if ( ! ( isUsable ( ) ) ) return ; this . compare = compare ; ViewUtils . setGone ( progress , true ) ; ViewUtils . setGone ( list , false ) ; LayoutInflater inflater = getActivity ( ) . getLayoutInflater ( ) ; adapter . clearHeaders ( ) ; adapter . getWrappedAdapter ( ) . clear ( ) ; List < RepositoryCommit > commits = compare . getCommits ( ) ; if ( ( commits != null ) && ( ! ( commits . isEmpty ( ) ) ) ) { View commitHeader = inflater . inflate ( commit_details_header , null ) ; ( ( TextView ) ( commitHeader . findViewById ( tv_commit_summary ) ) ) . setText ( MessageFormat . format ( getString ( comparing_commits ) , commits . size ( ) ) ) ; <START_BUG> adapter . addHeader ( commitHeader , null , false ) ; <END_BUG> adapter . addHeader ( inflater . inflate ( list_divider , null ) ) ; CommitListAdapter commitAdapter = new CommitListAdapter ( layout . commit_item , inflater , commits , avatars ) ; for ( int i = 0 ; i < ( commits . size ( ) ) ; i ++ ) { RepositoryCommit commit = commits . get ( i ) ; View view = commitAdapter . getView ( i , null , null ) ; adapter . addHeader ( view , commit , true ) ; adapter . addHeader ( inflater . inflate ( list_divider , null ) ) ; } } CommitFileListAdapter rootAdapter = adapter . getWrappedAdapter ( ) ; rootAdapter . clear ( ) ; List < CommitFile > files = compare . getFiles ( ) ; if ( ( files != null ) && ( ! ( files . isEmpty ( ) ) ) ) { addFileStatHeader ( files , inflater ) ; for ( CommitFile file : files ) rootAdapter . addItem ( file ) ; } } private void addFileStatHeader ( List < CommitFile > files , LayoutInflater inflater ) { } @ Override public void onViewCreated ( View view , Bundle savedInstanceState ) { } @ Override public View onCreateView ( LayoutInflater inflater , ViewGroup container , Bundle savedInstanceState ) { } private void openCommit ( final RepositoryCommit commit ) { } private void openFile ( final CommitFile file ) { } private void openLine ( AdapterView < ? > parent , int position ) { } @ Override public void onItemClick ( AdapterView < ? > parent , View view , int position , long id ) { } }<BUG2FIX>adapter . addHeader ( commitHeader ) ;
public class TransportRecoveryAction extends TransportBroadcastOperationAction < RecoveryRequest , RecoveryResponse , TransportRecoveryAction . ShardRecoveryRequest , ShardRecoveryResponse > { private final IndicesService indicesService ; private final RecoveryTarget recoveryTarget ; @ Inject public TransportRecoveryAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportService transportService , IndicesService indicesService , RecoveryTarget recoveryTarget ) { } @ Override protected String transportAction ( ) { } @ Override protected String executor ( ) { } @ Override protected RecoveryRequest newRequest ( ) { } @ Override protected RecoveryResponse newResponse ( RecoveryRequest request , AtomicReferenceArray shardsResponses , ClusterState clusterState ) { } @ Override protected TransportRecoveryAction . ShardRecoveryRequest newShardRequest ( ) { } @ Override protected TransportRecoveryAction . ShardRecoveryRequest newShardRequest ( int numShards , ShardRouting shard , RecoveryRequest request ) { } @ Override protected ShardRecoveryResponse newShardResponse ( ) { } @ Override protected ShardRecoveryResponse shardOperation ( TransportRecoveryAction . ShardRecoveryRequest request ) throws ElasticsearchException { InternalIndexService indexService = ( ( InternalIndexService ) ( indicesService . indexServiceSafe ( request . index ( ) ) ) ) ; InternalIndexShard indexShard = ( ( InternalIndexShard ) ( indexService . shardSafe ( request . shardId ( ) ) ) ) ; ShardRouting shardRouting = indexShard . routingEntry ( ) ; ShardRecoveryResponse shardRecoveryResponse = new ShardRecoveryResponse ( shardRouting . index ( ) , shardRouting . id ( ) ) ; RecoveryState state ; RecoveryStatus recoveryStatus = indexShard . recoveryStatus ( ) ; if ( recoveryStatus == null ) { <START_BUG> recoveryStatus = recoveryTarget . recoveryStatus ( indexShard . shardId ( ) ) ; <END_BUG> } if ( recoveryStatus != null ) { state = recoveryStatus . recoveryState ( ) ; } else { IndexShardGatewayService gatewayService = indexService . shardInjector ( request . shardId ( ) ) . getInstance ( IndexShardGatewayService . class ) ; state = gatewayService . recoveryState ( ) ; } shardRecoveryResponse . recoveryState ( state ) ; return shardRecoveryResponse ; } @ Override protected GroupShardsIterator shards ( ClusterState state , RecoveryRequest request , String [ ] concreteIndices ) { } @ Override protected ClusterBlockException checkGlobalBlock ( ClusterState state , RecoveryRequest request ) { } @ Override protected ClusterBlockException checkRequestBlock ( ClusterState state , RecoveryRequest request , String [ ] concreteIndices ) { } public static class ShardRecoveryRequest extends BroadcastShardOperationRequest { ShardRecoveryRequest ( ) { } ShardRecoveryRequest ( String index , int shardId , RecoveryRequest request ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } }<BUG2FIX>recoveryStatus = recoveryTarget . recoveryStatus ( indexShard ) ;
public class MessageDispatcher { private static final String LOG_TAG = MessageDispatcher . class . getSimpleName ( ) ; private static final float NANOS_PER_SEC = 1.0E9F ; private static final MessageDispatcher instance = new MessageDispatcher ( ) ; private static final long START = TimeUtils . nanoTime ( ) ; private PriorityQueue < Telegram > queue = new PriorityQueue < Telegram > ( ) ; private final Pool < Telegram > pool ; private long timeGranularity ; private boolean debugEnabled ; private MessageDispatcher ( ) { } public static MessageDispatcher getInstance ( ) { } public static long getCurrentTime ( ) { } public float getTimeGranularity ( ) { } public void setTimeGranularity ( float timeGranularity ) { } public boolean isDebugEnabled ( ) { } public void setDebugEnabled ( boolean debugEnabled ) { } public void clear ( ) { } public void dispatchMessage ( float delay , Agent sender , Agent receiver , int msg , Object extraInfo ) { } public void dispatchDelayedMessages ( ) { if ( ( queue . size ( ) ) == 0 ) return ; long currentTime = MessageDispatcher . getCurrentTime ( ) ; do { final Telegram telegram = queue . peek ( ) ; <START_BUG> if ( ( telegram . getTimestamp ( ) ) < currentTime ) <END_BUG> break ; if ( debugEnabled ) { app . log ( MessageDispatcher . LOG_TAG , ( ( ( "Queued<seq2seq4repair_space>telegram<seq2seq4repair_space>ready<seq2seq4repair_space>for<seq2seq4repair_space>dispatch:<seq2seq4repair_space>Sent<seq2seq4repair_space>to<seq2seq4repair_space>" + ( telegram . receiver ) ) + ".<seq2seq4repair_space>Msg<seq2seq4repair_space>is<seq2seq4repair_space>" ) + ( telegram . message ) ) ) ; } discharge ( telegram ) ; queue . poll ( ) ; } while ( ( queue . size ( ) ) > 0 ) ; } private void discharge ( Telegram telegram ) { } }<BUG2FIX>if ( ( telegram . getTimestamp ( ) ) > currentTime )
public class IntMap < V > { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; private static final int EMPTY = 0 ; public int size ; int [ ] keyTable ; V [ ] valueTable ; int capacity ; int stashSize ; V zeroValue ; boolean hasZeroValue ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private IntMap . Entries entries1 ; private IntMap . Entries entries2 ; private IntMap . Values values1 ; private IntMap . Values values2 ; private IntMap . Keys keys1 ; private IntMap . Keys keys2 ; public IntMap ( ) { } public IntMap ( int initialCapacity ) { } public IntMap ( int initialCapacity , float loadFactor ) { } public IntMap ( IntMap < ? extends V > map ) { } public V put ( int key , V value ) { } public void putAll ( IntMap < V > map ) { } private void putResize ( int key , V value ) { } private void push ( int insertKey , V insertValue , int index1 , int key1 , int index2 , int key2 , int index3 , int key3 ) { } private void putStash ( int key , V value ) { } public V get ( int key ) { } public V get ( int key , V defaultValue ) { } private V getStash ( int key , V defaultValue ) { } public V remove ( int key ) { } V removeStash ( int key ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean containsValue ( Object value , boolean identity ) { } public boolean containsKey ( int key ) { } private boolean containsKeyStash ( int key ) { } public int findKey ( Object value , boolean identity , int notFound ) { } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( int h ) { } private int hash3 ( int h ) { } public String toString ( ) { } public IntMap . Entries < V > entries ( ) { } public IntMap . Values < V > values ( ) { } public IntMap . Keys keys ( ) { } public static class Entry < V > { public int key ; public V value ; public String toString ( ) { } } private static class MapIterator < V > { static final int INDEX_ILLEGAL = - 2 ; static final int INDEX_ZERO = - 1 ; public boolean hasNext ; final IntMap < V > map ; int nextIndex ; int currentIndex ; boolean valid = true ; public MapIterator ( IntMap < V > map ) { } public void reset ( ) { } void findNextIndex ( ) { } public void remove ( ) { if ( ( ( currentIndex ) == ( IntMap . MapIterator . INDEX_ZERO ) ) && ( map . hasZeroValue ) ) { map . zeroValue = null ; map . hasZeroValue = false ; } else if ( ( currentIndex ) < 0 ) { throw new IllegalStateException ( "next<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>called<seq2seq4repair_space>before<seq2seq4repair_space>remove." ) ; } else if ( ( currentIndex ) >= ( map . capacity ) ) { map . removeStashIndex ( currentIndex ) ; <START_BUG> nextIndex = ( currentIndex ) - 1 ; <END_BUG> findNextIndex ( ) ; } else { map . keyTable [ currentIndex ] = IntMap . EMPTY ; map . valueTable [ currentIndex ] = null ; } currentIndex = IntMap . MapIterator . INDEX_ILLEGAL ; ( map . size ) -- ; } } public static class Entries < V > extends IntMap . MapIterator < V > implements Iterable < IntMap . Entry < V > > , Iterator < IntMap . Entry < V > > { private IntMap . Entry < V > entry = new IntMap . Entry ( ) ; public Entries ( IntMap map ) { } public IntMap . Entry < V > next ( ) { } public boolean hasNext ( ) { } public Iterator < IntMap . Entry < V > > iterator ( ) { } } public static class Values < V > extends IntMap . MapIterator < V > implements Iterable < V > , Iterator < V > { public Values ( IntMap < V > map ) { } public boolean hasNext ( ) { } public V next ( ) { } public Iterator < V > iterator ( ) { } public Array < V > toArray ( ) { } } public static class Keys extends IntMap . MapIterator { public Keys ( IntMap map ) { } public int next ( ) { } public IntArray toArray ( ) { } } }<BUG2FIX>nextIndex = currentIndex ;
public class SuperJumperDesktop { public static void main ( String [ ] argv ) { <START_BUG> new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new SuperJumper ( ) , "Super<seq2seq4repair_space>Jumper" , 320 , 480 ) ; <END_BUG> } }<BUG2FIX>new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new SuperJumper ( ) , "Super<seq2seq4repair_space>Jumper" , 320 , 480 , false ) ;
public class MD5Test implements RenderListener { PerspectiveCamera camera ; MD5Model model ; MD5Animation anim ; MD5AnimationInfo animInfo ; MD5Joints skeleton ; MD5Renderer renderer ; SpriteBatch batch ; Font font ; @ Override public void surfaceCreated ( Application app ) { if ( ( model ) == null ) { model = MD5Loader . loadModel ( app . getFiles ( ) . readFile ( "data/zfat.md5mesh" , Internal ) ) ; anim = MD5Loader . loadAnimation ( app . getFiles ( ) . readFile ( "data/walk1.md5anim" , Internal ) ) ; skeleton = new MD5Joints ( ) ; skeleton . joints = new float [ anim . frames [ 0 ] . joints . length ] ; animInfo = new MD5AnimationInfo ( anim . frames . length , anim . secondsPerFrame ) ; <START_BUG> renderer = new MD5Renderer ( app . getGraphics ( ) , model , true , true ) ; <END_BUG> camera = new PerspectiveCamera ( ) ; camera . getPosition ( ) . set ( 0 , 25 , 100 ) ; camera . setFov ( 60 ) ; camera . setNear ( 1 ) ; camera . setFar ( 1000 ) ; camera . setViewport ( app . getGraphics ( ) . getWidth ( ) , app . getGraphics ( ) . getHeight ( ) ) ; batch = new SpriteBatch ( app . getGraphics ( ) ) ; font = app . getGraphics ( ) . newFont ( "Arial" , 12 , Plain , true ) ; app . getGraphics ( ) . getGL10 ( ) . glViewport ( 0 , 0 , app . getGraphics ( ) . getWidth ( ) , app . getGraphics ( ) . getHeight ( ) ) ; } } @ Override public void surfaceChanged ( Application app , int width , int height ) { } float angle = 0 ; @ Override public void render ( Application app ) { } @ Override public void dispose ( Application app ) { } }<BUG2FIX>renderer = new MD5Renderer ( app . getGraphics ( ) , model , false , true ) ;
public class Polygon { private float [ ] localVertices ; private float [ ] worldVertices ; private float x ; private float y ; private float originX ; private float originY ; private float rotation ; private float scaleX = 1 ; private float scaleY = 1 ; private boolean dirty = true ; private Rectangle bounds ; public Polygon ( ) { } public Polygon ( float [ ] vertices ) { } public float [ ] getVertices ( ) { } public float [ ] getTransformedVertices ( ) { if ( ! ( dirty ) ) return worldVertices ; dirty = false ; final float [ ] localVertices = this . localVertices ; <START_BUG> if ( ( ( worldVertices ) == null ) || ( ( worldVertices . length ) != ( localVertices . length ) ) ) <END_BUG> worldVertices = new float [ localVertices . length ] ; final float [ ] worldVertices = this . worldVertices ; final float positionX = x ; final float positionY = y ; final float originX = this . originX ; final float originY = this . originY ; final float scaleX = this . scaleX ; final float scaleY = this . scaleY ; final boolean scale = ( scaleX != 1 ) || ( scaleY != 1 ) ; final float rotation = this . rotation ; final float cos = MathUtils . cosDeg ( rotation ) ; final float sin = MathUtils . sinDeg ( rotation ) ; for ( int i = 0 , n = localVertices . length ; i < n ; i += 2 ) { float x = ( localVertices [ i ] ) - originX ; float y = ( localVertices [ ( i + 1 ) ] ) - originY ; if ( scale ) { x *= scaleX ; y *= scaleY ; } if ( rotation != 0 ) { float oldX = x ; x = ( cos * x ) - ( sin * y ) ; y = ( sin * oldX ) + ( cos * y ) ; } worldVertices [ i ] = ( positionX + x ) + originX ; worldVertices [ ( i + 1 ) ] = ( positionY + y ) + originY ; } return worldVertices ; } public void setOrigin ( float originX , float originY ) { } public void setPosition ( float x , float y ) { } public void setVertices ( float [ ] vertices ) { } public void translate ( float x , float y ) { } public void setRotation ( float degrees ) { } public void rotate ( float degrees ) { } public void setScale ( float scaleX , float scaleY ) { } public void scale ( float amount ) { } public void dirty ( ) { } public float area ( ) { } public Rectangle getBoundingRectangle ( ) { } public boolean contains ( float x , float y ) { } public float getX ( ) { } public float getY ( ) { } public float getOriginX ( ) { } public float getOriginY ( ) { } public float getRotation ( ) { } public float getScaleX ( ) { } public float getScaleY ( ) { } }<BUG2FIX>if ( ( ( worldVertices ) == null ) || ( ( worldVertices . length ) < ( localVertices . length ) ) )
} if ( ( includeDefaults || ( ( fieldType . omitNorms ( ) ) != ( defaultFieldType . omitNorms ( ) ) ) ) || ( ( normsLoading ) != null ) ) { builder . startObject ( "norms" ) ; if ( includeDefaults || ( ( fieldType . omitNorms ( ) ) != ( defaultFieldType . omitNorms ( ) ) ) ) { builder . field ( "enabled" , ( ! ( fieldType . omitNorms ( ) ) ) ) ; } if ( ( normsLoading ) != null ) { builder . field ( KEY , normsLoading ) ; } builder . endObject ( ) ; } if ( includeDefaults || ( ( fieldType . indexOptions ( ) ) != ( defaultFieldType . indexOptions ( ) ) ) ) { builder . field ( "index_options" , AbstractFieldMapper . indexOptionToString ( fieldType . indexOptions ( ) ) ) ; } if ( ( ( indexAnalyzer ) == null ) && ( ( searchAnalyzer ) == null ) ) { if ( includeDefaults ) { builder . field ( "analyzer" , "default" ) ; } } else if ( ( indexAnalyzer ) == null ) { if ( includeDefaults || ( ( ! ( searchAnalyzer . name ( ) . startsWith ( "_" ) ) ) && ( ! ( searchAnalyzer . name ( ) . equals ( "default" ) ) ) ) ) { builder . field ( "search_analyzer" , searchAnalyzer . name ( ) ) ; } } else if ( ( searchAnalyzer ) == null ) { if ( includeDefaults || ( ( ! ( indexAnalyzer . name ( ) . startsWith ( "_" ) ) ) && ( ! ( indexAnalyzer . name ( ) . equals ( "default" ) ) ) ) ) { builder . field ( "index_analyzer" , indexAnalyzer . name ( ) ) ; } } else if ( indexAnalyzer . name ( ) . equals ( searchAnalyzer . name ( ) ) ) { if ( includeDefaults || ( ( ! ( indexAnalyzer . name ( ) . startsWith ( "_" ) ) ) && ( ! ( indexAnalyzer . name ( ) . equals ( "default" ) ) ) ) ) { builder . field ( "analyzer" , indexAnalyzer . name ( ) ) ; } } else { if ( includeDefaults || ( ( ! ( indexAnalyzer . name ( ) . startsWith ( "_" ) ) ) && ( ! ( indexAnalyzer . name ( ) . equals ( "default" ) ) ) ) ) { builder . field ( "index_analyzer" , indexAnalyzer . name ( ) ) ; } if ( includeDefaults || ( ( ! ( searchAnalyzer . name ( ) . startsWith ( "_" ) ) ) && ( ! ( searchAnalyzer . name ( ) . equals ( "default" ) ) ) ) ) { builder . field ( "search_analyzer" , searchAnalyzer . name ( ) ) ; } } if ( ( postingsFormat ) != null ) { if ( includeDefaults || ( ! ( postingsFormat . name ( ) . equals ( defaultPostingFormat ( ) ) ) ) ) { builder . field ( "postings_format" , postingsFormat . name ( ) ) ; } } else if ( includeDefaults ) { String format = defaultPostingFormat ( ) ; if ( format == null ) { format = PostingsFormatService . DEFAULT_FORMAT ; } builder . field ( "postings_format" , format ) ; } if ( ( docValuesFormat ) != null ) { if ( includeDefaults || ( ! ( docValuesFormat . name ( ) . equals ( defaultDocValuesFormat ( ) ) ) ) ) { builder . field ( DOC_VALUES_FORMAT , docValuesFormat . name ( ) ) ; } } else if ( includeDefaults ) { String format = defaultDocValuesFormat ( ) ; if ( format == null ) { format = DocValuesFormatService . DEFAULT_FORMAT ; } builder . field ( DOC_VALUES_FORMAT , format ) ; } if ( ( similarity ( ) ) != null ) { builder . field ( "similarity" , similarity ( ) . name ( ) ) ; } else if ( includeDefaults ) { <START_BUG> builder . field ( "similariry" , DEFAULT_SIMILARITY ) ; <END_BUG> } if ( ( customFieldDataSettings ) != null ) { builder . field ( "fielddata" , ( ( Map ) ( customFieldDataSettings . getAsMap ( ) ) ) ) ; } else if ( includeDefaults ) { builder . field ( "fielddata" , ( ( Map ) ( fieldDataType . getSettings ( ) . getAsMap ( ) ) ) ) ; } multiFields . toXContent ( builder , params ) ; if ( ( copyTo ) != null ) { copyTo . toXContent ( builder , params ) ; } } protected static String indexOptionToString ( IndexOptions indexOption ) { } public static String termVectorOptionsToString ( FieldType fieldType ) { } protected static String indexTokenizeOptionToString ( boolean indexed , boolean tokenized ) { } protected abstract String contentType ( ) { } @ Override public void close ( ) { } @ Override public boolean isNumeric ( ) { } @ Override public boolean isSortable ( ) { } public boolean hasDocValues ( ) { } @ Override public Loading normsLoading ( Loading defaultLoading ) { } public static class MultiFields { public static AbstractFieldMapper . MultiFields empty ( ) { } public static class Builder { private final ImmutableOpenMap . Builder < String , Mapper . Builder > mapperBuilders = ImmutableOpenMap . builder ( ) ; private Type pathType = AbstractFieldMapper . Defaults . PATH_TYPE ; public AbstractFieldMapper . MultiFields . Builder pathType ( ContentPath . Type pathType ) { } public AbstractFieldMapper . MultiFields . Builder add ( Mapper . Builder builder ) { }<BUG2FIX>builder . field ( "similarity" , DEFAULT_SIMILARITY ) ;
public class SearchRepositoryListFragment extends ItemListFragment < SearchRepository > { @ Inject private IRepositorySearch search ; @ Inject private RepositoryService repos ; private String query ; @ Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; <START_BUG> setEmptyText ( getString ( no_repositories ) ) ; <END_BUG> } public SearchRepositoryListFragment setQuery ( final String query ) { } @ Override public void onListItemClick ( ListView l , View v , int position , long id ) { } @ Override public Loader < List < SearchRepository > > onCreateLoader ( int id , Bundle args ) { } @ Override public void onLoadFinished ( Loader < List < SearchRepository > > loader , List < SearchRepository > items ) { } @ Override protected ItemListAdapter < SearchRepository , ? extends ItemView > createAdapter ( List < SearchRepository > items ) { } }<BUG2FIX>setEmptyText ( no_repositories ) ;
public class JsonDoubleFieldMapper extends JsonNumberFieldMapper < Double > { public static final String JSON_TYPE = "double" ; public static class Defaults extends JsonNumberFieldMapper . Defaults { public static final Double NULL_VALUE = null ; } public static class Builder extends JsonNumberFieldMapper . Builder < JsonDoubleFieldMapper . Builder , JsonDoubleFieldMapper > { protected Double nullValue = JsonDoubleFieldMapper . Defaults . NULL_VALUE ; public Builder ( String name ) { } public JsonDoubleFieldMapper . Builder nullValue ( double nullValue ) { } @ Override public JsonDoubleFieldMapper build ( BuilderContext context ) { } } public static class TypeParser implements JsonTypeParser { @ Override public JsonMapper . Builder parse ( String name , JsonNode node , ParserContext parserContext ) throws MapperParsingException { } } private final Double nullValue ; private final String nullValueAsString ; protected JsonDoubleFieldMapper ( Names names , int precisionStep , Field . Index index , Field . Store store , float boost , boolean omitNorms , boolean omitTermFreqAndPositions , Double nullValue ) { } @ Override protected int maxPrecisionStep ( ) { } @ Override public Double value ( Fieldable field ) { byte [ ] value = field . getBinaryValue ( ) ; if ( value == null ) { <START_BUG> return Double . NaN ; <END_BUG> } return Numbers . bytesToDouble ( value ) ; } @ Override public String indexedValue ( String value ) { } @ Override public String indexedValue ( Double value ) { } @ Override public Object valueFromTerm ( String term ) { } @ Override public Object valueFromString ( String text ) { } @ Override public Query rangeQuery ( String lowerTerm , String upperTerm , boolean includeLower , boolean includeUpper ) { } @ Override public Filter rangeFilter ( String lowerTerm , String upperTerm , boolean includeLower , boolean includeUpper ) { } @ Override protected Field parseCreateField ( JsonParseContext jsonContext ) throws IOException { } @ Override public int sortType ( ) { } @ Override protected String jsonType ( ) { } @ Override protected void doJsonBody ( JsonBuilder builder ) throws IOException { } }<BUG2FIX>return null ;
public class JsonDateFieldMapper extends JsonNumberFieldMapper < Long > { public static final String JSON_TYPE = "date" ; public static class Defaults extends JsonNumberFieldMapper . Defaults { public static final FormatDateTimeFormatter DATE_TIME_FORMATTER = Joda . forPattern ( "dateOptionalTime" ) ; public static final String NULL_VALUE = null ; } public static class Builder extends JsonNumberFieldMapper . Builder < JsonDateFieldMapper . Builder , JsonDateFieldMapper > { protected String nullValue = JsonDateFieldMapper . Defaults . NULL_VALUE ; protected FormatDateTimeFormatter dateTimeFormatter = JsonDateFieldMapper . Defaults . DATE_TIME_FORMATTER ; public Builder ( String name ) { } public JsonDateFieldMapper . Builder nullValue ( String nullValue ) { } public JsonDateFieldMapper . Builder dateTimeFormatter ( FormatDateTimeFormatter dateTimeFormatter ) { } @ Override public JsonDateFieldMapper build ( BuilderContext context ) { } } public static class TypeParser implements JsonTypeParser { @ Override public JsonMapper . Builder parse ( String name , JsonNode node , ParserContext parserContext ) throws MapperParsingException { } } private final FormatDateTimeFormatter dateTimeFormatter ; private final String nullValue ; protected JsonDateFieldMapper ( Names names , FormatDateTimeFormatter dateTimeFormatter , int precisionStep , Field . Index index , Field . Store store , float boost , boolean omitNorms , boolean omitTermFreqAndPositions , String nullValue ) { } @ Override protected int maxPrecisionStep ( ) { } @ Override public Long value ( Fieldable field ) { byte [ ] value = field . getBinaryValue ( ) ; if ( value == null ) { <START_BUG> return Long . MIN_VALUE ; <END_BUG> } return Numbers . bytesToLong ( value ) ; } @ Override public Object valueForSearch ( Fieldable field ) { } @ Override public Object valueForSearch ( Object value ) { } @ Override public String valueAsString ( Fieldable field ) { } @ Override public String indexedValue ( String value ) { } @ Override public String indexedValue ( Long value ) { } @ Override public Object valueFromTerm ( String term ) { } @ Override public Object valueFromString ( String text ) { } @ Override public Query rangeQuery ( String lowerTerm , String upperTerm , boolean includeLower , boolean includeUpper ) { } @ Override public Filter rangeFilter ( String lowerTerm , String upperTerm , boolean includeLower , boolean includeUpper ) { } @ Override protected Field parseCreateField ( JsonParseContext jsonContext ) throws IOException { } @ Override public int sortType ( ) { } @ Override protected String jsonType ( ) { } @ Override protected void doJsonBody ( JsonBuilder builder ) throws IOException { } }<BUG2FIX>return null ;
public class Tree extends WidgetGroup { static boolean isMac = System . getProperty ( "os.name" ) . contains ( "Mac" ) ; Tree . TreeStyle style ; final Array < Tree . Node > rootNodes = new Array ( ) ; final Array < Tree . Node > selectedNodes = new Array ( ) ; float ySpacing = 4 ; float iconSpacingLeft = 2 ; float iconSpacingRight = 2 ; float padding = 0 ; float indentSpacing ; private float leftColumnWidth ; private float prefWidth ; private float prefHeight ; private boolean sizeInvalid = true ; boolean multiSelect = true ; boolean toggleSelect = true ; private Tree . Node foundNode ; Tree . Node overNode ; private ClickListener clickListener ; public Tree ( Skin skin ) { } public Tree ( Skin skin , String styleName ) { } public Tree ( Tree . TreeStyle style ) { } private void initialize ( ) { } public void setStyle ( Tree . TreeStyle style ) { } public void add ( Tree . Node node ) { } public void insert ( int index , Tree . Node node ) { } public void remove ( Tree . Node node ) { } public void clearChildren ( ) { } void fireChangeEvent ( ) { } public Array < Tree . Node > getNodes ( ) { } public void invalidate ( ) { } private void computeSize ( ) { } private void computeSize ( Array < Tree . Node > nodes , float indent ) { } public void layout ( ) { } private float layout ( Array < Tree . Node > nodes , float indent , float y ) { } public void draw ( SpriteBatch batch , float parentAlpha ) { } private void draw ( SpriteBatch batch , Array < Tree . Node > nodes , float indent ) { } public Tree . Node getNodeAt ( float y ) { } private float getNodeAt ( Array < Tree . Node > nodes , float y , float rowY ) { } void selectNodes ( Array < Tree . Node > nodes , float low , float high ) { for ( int i = 0 , n = nodes . size ; i < n ; i ++ ) { Tree . Node node = nodes . get ( i ) ; if ( ( node . actor . getY ( ) ) < low ) break ; if ( ! ( node . isSelectable ( ) ) ) continue ; <START_BUG> if ( ( ( node . actor . getY ( ) ) <= high ) && ( ! ( selectedNodes . contains ( node , true ) ) ) ) <END_BUG> selectedNodes . add ( node ) ; if ( node . expanded ) selectNodes ( node . children , low , high ) ; } } public Array < Tree . Node > getSelection ( ) { } public void setSelection ( Tree . Node node ) { } public void setSelection ( Array < Tree . Node > nodes ) { } public void addSelection ( Tree . Node node ) { } public void clearSelection ( ) { } public Tree . TreeStyle getStyle ( ) { } public Array < Tree . Node > getRootNodes ( ) { } public Tree . Node getOverNode ( ) { } public void setOverNode ( Tree . Node overNode ) { } public void setPadding ( float padding ) { } public void setYSpacing ( float ySpacing ) { } public void setIconSpacing ( float left , float right ) { } public float getPrefWidth ( ) { } public float getPrefHeight ( ) { } public void findExpandedObjects ( Array objects ) { } public void restoreExpandedObjects ( Array objects ) { } static boolean findExpandedObjects ( Array < Tree . Node > nodes , Array objects ) { } public Tree . Node findNode ( Object object ) { } static Tree . Node findNode ( Array < Tree . Node > nodes , Object object ) { } public void collapseAll ( ) { } static void collapseAll ( Array < Tree . Node > nodes ) { } public void expandAll ( ) { } static void expandAll ( Array < Tree . Node > nodes ) { } public ClickListener getClickListener ( ) { } public void setMultiSelect ( boolean multiSelect ) { } public void setToggleSelect ( boolean toggleSelect ) { } public static class Node { Actor actor ; Tree . Node parent ; final Array < Tree . Node > children = new Array ( 0 ) ; boolean selectable = true ; boolean expanded ; Drawable icon ; float height ; Object object ; public Node ( Actor actor ) { } public void setExpanded ( boolean expanded ) { } protected void addToTree ( Tree tree ) { } protected void removeFromTree ( Tree tree ) { } public void add ( Tree . Node node ) { } public void addAll ( Array < Tree . Node > nodes ) { } public void insert ( int index , Tree . Node node ) { } public void remove ( ) { } public void remove ( Tree . Node node ) { } public void removeAll ( ) { } public Tree getTree ( ) { } public Actor getActor ( ) { } public boolean isExpanded ( ) { } public Array < Tree . Node > getChildren ( ) { } public void updateChildren ( ) { } public Tree . Node getParent ( ) { } public void setIcon ( Drawable icon ) { } public Object getObject ( ) { } public void setObject ( Object object ) { } public Drawable getIcon ( ) { } public Tree . Node findNode ( Object object ) { }<BUG2FIX>if ( ( node . actor . getY ( ) ) <= high )
public class HasParentFilterParser implements FilterParser { public static final String NAME = "has_parent" ; @ Inject public HasParentFilterParser ( ) { } @ Override public String [ ] names ( ) { } @ Override public Filter parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; Query query = null ; boolean queryFound = false ; String parentType = null ; boolean cache = false ; CacheKeyFilter . Key cacheKey = null ; String filterName = null ; String currentFieldName = null ; XContentParser . Token token ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . START_OBJECT ) ) { if ( "query" . equals ( currentFieldName ) ) { String [ ] origTypes = QueryParseContext . setTypesWithPrevious ( ( parentType == null ? null : new String [ ] { parentType } ) ) ; try { query = parseContext . parseInnerQuery ( ) ; queryFound = true ; } finally { QueryParseContext . setTypes ( origTypes ) ; } } else if ( "filter" . equals ( currentFieldName ) ) { String [ ] origTypes = QueryParseContext . setTypesWithPrevious ( ( parentType == null ? null : new String [ ] { parentType } ) ) ; try { Filter innerFilter = parseContext . parseInnerFilter ( ) ; query = new org . elasticsearch . common . lucene . search . XConstantScoreQuery ( innerFilter ) ; queryFound = true ; } finally { QueryParseContext . setTypes ( origTypes ) ; } } else { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[has_parent]<seq2seq4repair_space>filter<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>support<seq2seq4repair_space>[" + currentFieldName ) + "]" ) ) ; } } else if ( token . isValue ( ) ) { if ( ( ( "type" . equals ( currentFieldName ) ) || ( "parent_type" . equals ( currentFieldName ) ) ) || ( "parentType" . equals ( currentFieldName ) ) ) { parentType = parser . text ( ) ; } else if ( "_scope" . equals ( currentFieldName ) ) { throw new QueryParsingException ( parseContext . index ( ) , "the<seq2seq4repair_space>[_scope]<seq2seq4repair_space>support<seq2seq4repair_space>in<seq2seq4repair_space>[has_parent]<seq2seq4repair_space>filter<seq2seq4repair_space>has<seq2seq4repair_space>been<seq2seq4repair_space>removed,<seq2seq4repair_space>use<seq2seq4repair_space>a<seq2seq4repair_space>filter<seq2seq4repair_space>as<seq2seq4repair_space>a<seq2seq4repair_space>facet_filter<seq2seq4repair_space>in<seq2seq4repair_space>the<seq2seq4repair_space>relevant<seq2seq4repair_space>global<seq2seq4repair_space>facet" ) ; } else if ( "_name" . equals ( currentFieldName ) ) { filterName = parser . text ( ) ; } else if ( "_cache" . equals ( currentFieldName ) ) { cache = parser . booleanValue ( ) ; } else if ( ( "_cache_key" . equals ( currentFieldName ) ) || ( "_cacheKey" . equals ( currentFieldName ) ) ) { cacheKey = new CacheKeyFilter . Key ( parser . text ( ) ) ; } else { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[has_parent]<seq2seq4repair_space>filter<seq2seq4repair_space>does<seq2seq4repair_space>not<seq2seq4repair_space>support<seq2seq4repair_space>[" + currentFieldName ) + "]" ) ) ; } } } if ( ! queryFound ) { throw new QueryParsingException ( parseContext . index ( ) , "[has_parent]<seq2seq4repair_space>filter<seq2seq4repair_space>requires<seq2seq4repair_space>'query'<seq2seq4repair_space>field" ) ; } if ( query == null ) { return null ; } if ( parentType == null ) { throw new QueryParsingException ( parseContext . index ( ) , "[has_parent]<seq2seq4repair_space>filter<seq2seq4repair_space>requires<seq2seq4repair_space>'parent_type'<seq2seq4repair_space>field" ) ; } DocumentMapper parentDocMapper = parseContext . mapperService ( ) . documentMapper ( parentType ) ; if ( parentDocMapper == null ) { throw new QueryParsingException ( parseContext . index ( ) , ( ( "[has_parent]<seq2seq4repair_space>filter<seq2seq4repair_space>configured<seq2seq4repair_space>'parent_type'<seq2seq4repair_space>[" + parentType ) + "]<seq2seq4repair_space>is<seq2seq4repair_space>not<seq2seq4repair_space>a<seq2seq4repair_space>valid<seq2seq4repair_space>type" ) ) ; } query = new org . elasticsearch . common . lucene . search . XFilteredQuery ( query , parseContext . cacheFilter ( parentDocMapper . typeFilter ( ) , null ) ) ; Set < String > parentTypes = new HashSet < String > ( 5 ) ; parentTypes . add ( parentType ) ; for ( DocumentMapper documentMapper : parseContext . mapperService ( ) ) { ParentFieldMapper parentFieldMapper = documentMapper . parentFieldMapper ( ) ; if ( parentFieldMapper . active ( ) ) { DocumentMapper parentTypeDocumentMapper = parseContext . mapperService ( ) . documentMapper ( parentFieldMapper . type ( ) ) ; if ( parentTypeDocumentMapper == null ) { parentTypes . add ( parentFieldMapper . type ( ) ) ; } } } Filter parentFilter ; if ( ( parentTypes . size ( ) ) == 1 ) { DocumentMapper documentMapper = parseContext . mapperService ( ) . documentMapper ( parentTypes . iterator ( ) . next ( ) ) ; parentFilter = parseContext . cacheFilter ( documentMapper . typeFilter ( ) , null ) ; } else { XBooleanFilter parentsFilter = new XBooleanFilter ( ) ; for ( String parentTypeStr : parentTypes ) { DocumentMapper documentMapper = parseContext . mapperService ( ) . documentMapper ( parentTypeStr ) ; Filter filter = parseContext . cacheFilter ( documentMapper . typeFilter ( ) , null ) ; parentsFilter . add ( filter , SHOULD ) ; } parentFilter = parentsFilter ; } Filter childrenFilter = parseContext . cacheFilter ( new org . elasticsearch . common . lucene . search . NotFilter ( parentFilter ) , null ) ; <START_BUG> Query parentConstantScoreQuery = new org . elasticsearch . index . search . child . ParentConstantScoreQuery ( query , parentType , childrenFilter , false ) ; <END_BUG> if ( filterName != null ) { parseContext . addNamedQuery ( filterName , parentConstantScoreQuery ) ; } boolean deleteByQuery = "delete_by_query" . equals ( SearchContext . current ( ) . source ( ) ) ; if ( deleteByQuery ) { return new org . elasticsearch . index . search . child . DeleteByQueryWrappingFilter ( parentConstantScoreQuery ) ; } else { return new org . elasticsearch . index . search . child . CustomQueryWrappingFilter ( parentConstantScoreQuery ) ; } } }<BUG2FIX>Query parentConstantScoreQuery = new org . elasticsearch . index . search . child . ParentConstantScoreQuery ( query , parentType , childrenFilter ) ;
public class ProjectiveTextureTest extends GdxTest { @ Override public boolean needsGL20 ( ) { } PerspectiveCamera cam ; PerspectiveCamera projector ; Texture texture ; Mesh plane ; Mesh cube ; Matrix4 planeTrans = new Matrix4 ( ) ; Matrix4 cubeTrans = new Matrix4 ( ) ; Matrix4 modelNormal = new Matrix4 ( ) ; ShaderProgram projTexShader ; Stage ui ; InputMultiplexer multiplexer = new InputMultiplexer ( ) ; PerspectiveCamController controller ; ImmediateModeRenderer20 renderer ; float angle = 0 ; @ Override public void create ( ) { } public void setupScene ( ) { } public void setupUI ( ) { ui = new Stage ( 480 , 320 , true ) ; Skin skin = new Skin ( files . internal ( "data/uiskin.json" ) , files . internal ( "data/uiskin.png" ) ) ; Button reload = new Button ( "Reload<seq2seq4repair_space>Shaders" , skin . getStyle ( ButtonStyle . class ) , "reload" ) ; ComboBox camera = new ComboBox ( new String [ ] { "Camera" , "Light" } , ui , skin . getStyle ( ComboBoxStyle . class ) , "camera" ) ; Label fps = new Label ( "fps:<seq2seq4repair_space>" , skin . getStyle ( LabelStyle . class ) , "fps" ) ; <START_BUG> Table table = new Table ( "container" ) ; <END_BUG> table . width = ui . width ( ) ; table . height = ui . height ( ) ; table . top ( ) . padTop ( 15 ) ; table . add ( reload ) . spaceRight ( 5 ) ; table . add ( camera ) . spaceRight ( 5 ) ; table . add ( fps ) ; ui . addActor ( table ) ; reload . setClickListener ( new ClickListener ( ) { @ Override public void click ( Actor button ) { ShaderProgram prog = new ShaderProgram ( files . internal ( "data/shaders/projtex-vert.glsl" ) . readString ( ) , files . internal ( "data/shaders/projtex-frag.glsl" ) . readString ( ) ) ; if ( ( prog . isCompiled ( ) ) == false ) { app . log ( "GLSL<seq2seq4repair_space>ERROR" , ( "Couldn\'t<seq2seq4repair_space>reload<seq2seq4repair_space>shaders:\n" + ( prog . getLog ( ) ) ) ) ; } else { projTexShader . dispose ( ) ; projTexShader = prog ; } } } ) ; } public void setupShaders ( ) { } @ Override public void render ( ) { } Vector3 position = new Vector3 ( ) ; private void renderMesh ( ShaderProgram shader , Matrix4 cam , Matrix4 projector , Matrix4 model , Mesh mesh , Color color ) { } }<BUG2FIX>Table table = new Table ( ) ;
public class TermsIpFacetCollector extends AbstractFacetCollector { private final FieldDataCache fieldDataCache ; private final String indexFieldName ; private final ComparatorType comparatorType ; private final int size ; private final int numberOfShards ; private final FieldDataType fieldDataType ; private LongFieldData fieldData ; private final TermsIpFacetCollector . StaticAggregatorValueProc aggregator ; private final SearchScript script ; public TermsIpFacetCollector ( String facetName , String fieldName , int size , TermsFacet . ComparatorType comparatorType , boolean allTerms , SearchContext context , String scriptLang , String script , Map < String , Object > params ) { } @ Override public void setScorer ( Scorer scorer ) throws IOException { } @ Override protected void doSetNextReader ( AtomicReaderContext context ) throws IOException { fieldData = ( ( LongFieldData ) ( fieldDataCache . cache ( fieldDataType , context . reader ( ) , indexFieldName ) ) ) ; if ( ( script ) != null ) { <START_BUG> script . setNextReader ( context . reader ( ) ) ; <END_BUG> } } @ Override protected void doCollect ( int doc ) throws IOException { } @ Override public Facet facet ( ) { } public static class AggregatorValueProc extends TermsIpFacetCollector . StaticAggregatorValueProc { private final SearchScript script ; public AggregatorValueProc ( TLongIntHashMap facets , SearchScript script ) { } @ Override public void onValue ( int docId , long value ) { } } public static class StaticAggregatorValueProc implements LongFieldData . ValueInDocProc , LongFieldData . ValueProc { private final TLongIntHashMap facets ; private int missing ; private int total ; public StaticAggregatorValueProc ( TLongIntHashMap facets ) { } @ Override public void onValue ( long value ) { } @ Override public void onValue ( int docId , long value ) { } @ Override public void onMissing ( int docId ) { } public final TLongIntHashMap facets ( ) { } public final int missing ( ) { } public final int total ( ) { } } }<BUG2FIX>script . setNextReader ( context ) ;
public class Analysis { public static boolean isNoStopwords ( Settings settings ) { } public static CharArraySet parseStemExclusion ( Settings settings , CharArraySet defaultStemExclusion , Version version ) { } public static final ImmutableMap < String , Set < ? > > namedStopWords = MapBuilder . < String , Set < ? > > newMapBuilder ( ) . put ( "_arabic_" , ArabicAnalyzer . getDefaultStopSet ( ) ) . put ( "_armenian_" , ArmenianAnalyzer . getDefaultStopSet ( ) ) . put ( "_basque_" , BasqueAnalyzer . getDefaultStopSet ( ) ) . put ( "_brazilian_" , BrazilianAnalyzer . getDefaultStopSet ( ) ) . put ( "_bulgarian_" , BulgarianAnalyzer . getDefaultStopSet ( ) ) . put ( "_catalan_" , CatalanAnalyzer . getDefaultStopSet ( ) ) . put ( "_czech_" , CzechAnalyzer . getDefaultStopSet ( ) ) . put ( "_danish_" , DanishAnalyzer . getDefaultStopSet ( ) ) . put ( "_dutch_" , DutchAnalyzer . getDefaultStopSet ( ) ) . put ( "_english_" , EnglishAnalyzer . getDefaultStopSet ( ) ) . put ( "_finnish_" , FinnishAnalyzer . getDefaultStopSet ( ) ) . put ( "_french_" , FrenchAnalyzer . getDefaultStopSet ( ) ) . put ( "_galician_" , GalicianAnalyzer . getDefaultStopSet ( ) ) . put ( "_german_" , GermanAnalyzer . getDefaultStopSet ( ) ) . put ( "_greek_" , GreekAnalyzer . getDefaultStopSet ( ) ) . put ( "_hindi_" , HindiAnalyzer . getDefaultStopSet ( ) ) . put ( "_hungarian_" , HungarianAnalyzer . getDefaultStopSet ( ) ) . put ( "_indonesian_" , IndonesianAnalyzer . getDefaultStopSet ( ) ) . put ( "_italian_" , ItalianAnalyzer . getDefaultStopSet ( ) ) . put ( "_norwegian_" , NorwegianAnalyzer . getDefaultStopSet ( ) ) . put ( "_persian_" , PersianAnalyzer . getDefaultStopSet ( ) ) . put ( "_portuguese_" , PortugueseAnalyzer . getDefaultStopSet ( ) ) . put ( "_romanian_" , RomanianAnalyzer . getDefaultStopSet ( ) ) . put ( "_russian_" , RussianAnalyzer . getDefaultStopSet ( ) ) . put ( "_spanish_" , SpanishAnalyzer . getDefaultStopSet ( ) ) . put ( "_swedish_" , SwedishAnalyzer . getDefaultStopSet ( ) ) . put ( "_turkish_" , TurkishAnalyzer . getDefaultStopSet ( ) ) . immutableMap ( ) ; public static CharArraySet parseArticles ( Environment env , Settings settings , Version version ) { } public static CharArraySet parseStopWords ( Environment env , Settings settings , CharArraySet defaultStopWords , Version version ) { } public static CharArraySet parseStopWords ( Environment env , Settings settings , CharArraySet defaultStopWords , Version version , boolean ignore_case ) { String value = settings . get ( "stopwords" ) ; if ( value != null ) { if ( "_none_" . equals ( value ) ) { return CharArraySet . EMPTY_SET ; } else { return Analysis . resolveNamedStopWords ( Strings . commaDelimitedListToSet ( value ) , version , ignore_case ) ; } } String [ ] stopWords = settings . getAsArray ( "stopwords" , null ) ; if ( stopWords != null ) { return Analysis . resolveNamedStopWords ( stopWords , version , ignore_case ) ; } List < String > pathLoadedStopWords = Analysis . getWordList ( env , settings , "stopwords" ) ; if ( pathLoadedStopWords != null ) { <START_BUG> return Analysis . resolveNamedStopWords ( stopWords , version , ignore_case ) ; <END_BUG> } return defaultStopWords ; } private static CharArraySet resolveNamedStopWords ( Collection < String > words , Version version , boolean ignore_case ) { } private static CharArraySet resolveNamedStopWords ( String [ ] words , Version version , boolean ignore_case ) { } public static CharArraySet getWordSet ( Environment env , Settings settings , String settingsPrefix , Version version ) { } public static List < String > getWordList ( Environment env , Settings settings , String settingPrefix ) { } public static List < String > loadWordList ( Reader reader , String comment ) throws IOException { } public static Reader getReaderFromFile ( Environment env , Settings settings , String settingPrefix ) { } }<BUG2FIX>return Analysis . resolveNamedStopWords ( pathLoadedStopWords , version , ignore_case ) ;
public class AllFieldMapper extends AbstractFieldMapper < Void > implements InternalMapper , RootMapper { public interface IncludeInAll extends Mapper { void includeInAll ( Boolean includeInAll ) { } void includeInAllIfNotSet ( Boolean includeInAll ) { } } public static final String NAME = "_all" ; public static final String CONTENT_TYPE = "_all" ; public static class Defaults extends AbstractFieldMapper . Defaults { public static final String NAME = AllFieldMapper . NAME ; public static final String INDEX_NAME = AllFieldMapper . NAME ; public static final boolean ENABLED = true ; } public static class Builder extends AbstractFieldMapper . Builder < AllFieldMapper . Builder , AllFieldMapper > { private boolean enabled = AllFieldMapper . Defaults . ENABLED ; public Builder ( ) { } public AllFieldMapper . Builder enabled ( boolean enabled ) { } @ Override public AllFieldMapper . Builder store ( Field . Store store ) { } @ Override public AllFieldMapper . Builder termVector ( Field . TermVector termVector ) { } @ Override protected AllFieldMapper . Builder indexAnalyzer ( NamedAnalyzer indexAnalyzer ) { } @ Override protected AllFieldMapper . Builder searchAnalyzer ( NamedAnalyzer searchAnalyzer ) { } @ Override public AllFieldMapper build ( BuilderContext context ) { } } public static class TypeParser implements Mapper . TypeParser { @ Override public Mapper . Builder parse ( String name , Map < String , Object > node , ParserContext parserContext ) throws MapperParsingException { } } private boolean enabled ; public AllFieldMapper ( ) { } protected AllFieldMapper ( String name , Field . Store store , Field . TermVector termVector , boolean omitNorms , boolean omitTermFreqAndPositions , NamedAnalyzer indexAnalyzer , NamedAnalyzer searchAnalyzer , boolean enabled ) { } public boolean enabled ( ) { } @ Override public Query queryStringTermQuery ( Term term ) { } @ Override public Query fieldQuery ( String value , QueryParseContext context ) { } @ Override public void preParse ( ParseContext context ) throws IOException { } @ Override public void postParse ( ParseContext context ) throws IOException { } @ Override public void parse ( ParseContext context ) throws IOException { } @ Override public void validate ( ParseContext context ) throws MapperParsingException { } @ Override public boolean includeInObject ( ) { <START_BUG> return false ; <END_BUG> } @ Override protected Fieldable parseCreateField ( ParseContext context ) throws IOException { } private Analyzer findAnalyzer ( ParseContext context ) { } @ Override public Void value ( Fieldable field ) { } @ Override public Void valueFromString ( String value ) { } @ Override public String valueAsString ( Fieldable field ) { } @ Override public Object valueForSearch ( Fieldable field ) { } @ Override protected String contentType ( ) { } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } @ Override public void merge ( Mapper mergeWith , MergeContext mergeContext ) throws MergeMappingException { } }<BUG2FIX>return true ;
public class PixmapTest extends GdxTest { @ Override public boolean needsGL20 ( ) { } Pixmap pixmap ; Texture texture ; SpriteBatch batch ; TextureRegion region ; public void create ( ) { pixmap = new Pixmap ( 800 , 480 , Format . RGBA8888 ) ; texture = new Texture ( 1024 , 1024 , Format . RGBA8888 ) ; texture . setFilter ( Nearest , Linear ) ; texture . setWrap ( ClampToEdge , ClampToEdge ) ; pixmap . setColor ( 1.0F , 0.0F , 0.0F , 1.0F ) ; pixmap . drawLine ( 0 , 0 , 100 , 100 ) ; pixmap . setColor ( 0.0F , 0.0F , 1.0F , 1.0F ) ; pixmap . drawLine ( 100 , 100 , 200 , 0 ) ; pixmap . setColor ( 0.0F , 1.0F , 0.0F , 1.0F ) ; pixmap . drawLine ( 100 , 0 , 100 , 100 ) ; pixmap . setColor ( 1.0F , 1.0F , 1.0F , 1.0F ) ; <START_BUG> pixmap . drawCircle ( 400 , 300 , 16 ) ; <END_BUG> texture . draw ( pixmap , 0 , 0 ) ; region = new TextureRegion ( texture , 0 , 0 , 800 , 480 ) ; batch = new SpriteBatch ( ) ; } public void render ( ) { } }<BUG2FIX>pixmap . drawCircle ( 400 , 300 , 100 ) ;
public class Pixmap implements Disposable { public static Map < Integer , Pixmap > pixmaps = new HashMap < Integer , Pixmap > ( ) ; static int nextId = 0 ; public enum Format { Alpha , Intensity , LuminanceAlpha , RGB565 , RGBA4444 , RGB888 , RGBA8888 ; } public enum Blending { None , SourceOver ; } public enum Filter { NearestNeighbour , BiLinear ; } int width ; int height ; Pixmap . Format format ; Canvas canvas ; Context2d context ; int id ; IntBuffer buffer ; int r = 255 ; int g = 255 ; int b = 255 ; float a ; String color = Pixmap . make ( r , g , b , a ) ; static Pixmap . Blending blending ; CanvasPixelArray pixels ; public Pixmap ( FileHandle file ) { } private static Composite getComposite ( ) { } public Pixmap ( ImageElement img ) { } public Pixmap ( int width , int height , Pixmap . Format format ) { } private void create ( int width , int height , Pixmap . Format format2 ) { } public static String make ( int r2 , int g2 , int b2 , float a2 ) { } public static void setBlending ( Pixmap . Blending blending ) { } public static Pixmap . Blending getBlending ( ) { } public static void setFilter ( Pixmap . Filter filter ) { } public Pixmap . Format getFormat ( ) { } public int getGLInternalFormat ( ) { } public int getGLFormat ( ) { } public int getGLType ( ) { } public int getWidth ( ) { } public int getHeight ( ) { } public Buffer getPixels ( ) { } @ Override public void dispose ( ) { } public CanvasElement getCanvasElement ( ) { } public void setColor ( int color ) { } public void setColor ( float r , float g , float b , float a ) { } public void setColor ( Color color ) { } public void fill ( ) { } public void drawLine ( int x , int y , int x2 , int y2 ) { } public void drawRectangle ( int x , int y , int width , int height ) { } public void drawPixmap ( Pixmap pixmap , int x , int y ) { } public void drawPixmap ( Pixmap pixmap , int x , int y , int srcx , int srcy , int srcWidth , int srcHeight ) { } public void drawPixmap ( Pixmap pixmap , int srcx , int srcy , int srcWidth , int srcHeight , int dstx , int dsty , int dstWidth , int dstHeight ) { } public void fillRectangle ( int x , int y , int width , int height ) { } public void drawCircle ( int x , int y , int radius ) { } public void fillCircle ( int x , int y , int radius ) { } <START_BUG> public void fillTriangle ( int x1 , int y1 , int x2 , int y2 , int x3 , int y3 , int radius ) { <END_BUG> context . beginPath ( ) ; context . moveTo ( x1 , y1 ) ; context . lineTo ( x2 , y2 ) ; context . lineTo ( x3 , y3 ) ; context . lineTo ( x1 , y1 ) ; context . fill ( ) ; context . closePath ( ) ; } public int getPixel ( int x , int y ) { } public void drawPixel ( int x , int y ) { } public void drawPixel ( int x , int y , int color ) { } }<BUG2FIX>public void fillTriangle ( int x1 , int y1 , int x2 , int y2 , int x3 , int y3 ) {
public class ObjectIntMap < K > { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; public int size ; K [ ] keyTable ; int [ ] valueTable ; int capacity ; int stashSize ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private ObjectIntMap . Entries entries1 ; private ObjectIntMap . Entries entries2 ; private ObjectIntMap . Values values1 ; private ObjectIntMap . Values values2 ; private ObjectIntMap . Keys keys1 ; private ObjectIntMap . Keys keys2 ; public ObjectIntMap ( ) { } public ObjectIntMap ( int initialCapacity ) { } public ObjectIntMap ( int initialCapacity , float loadFactor ) { } public ObjectIntMap ( ObjectIntMap < ? extends K > map ) { } public void put ( K key , int value ) { } public void putAll ( ObjectIntMap < K > map ) { } private void putResize ( K key , int value ) { } private void push ( K insertKey , int insertValue , int index1 , K key1 , int index2 , K key2 , int index3 , K key3 ) { } private void putStash ( K key , int value ) { } public int get ( K key , int defaultValue ) { } private int getStash ( K key , int defaultValue ) { } public int getAndIncrement ( K key , int defaultValue , int increment ) { } private int getAndIncrementStash ( K key , int defaultValue , int increment ) { } public int remove ( K key , int defaultValue ) { } int removeStash ( K key , int defaultValue ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean containsValue ( int value ) { } public boolean containsKey ( K key ) { } private boolean containsKeyStash ( K key ) { } public K findKey ( int value ) { } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( int h ) { } private int hash3 ( int h ) { } public String toString ( ) { } public ObjectIntMap . Entries < K > entries ( ) { } public ObjectIntMap . Values values ( ) { } public ObjectIntMap . Keys < K > keys ( ) { } public static class Entry < K > { public K key ; public int value ; public String toString ( ) { } } private static class MapIterator < K > { public boolean hasNext ; final ObjectIntMap < K > map ; int nextIndex ; int currentIndex ; boolean valid = true ; public MapIterator ( ObjectIntMap < K > map ) { } public void reset ( ) { } void findNextIndex ( ) { } public void remove ( ) { if ( ( currentIndex ) < 0 ) throw new IllegalStateException ( "next<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>called<seq2seq4repair_space>before<seq2seq4repair_space>remove." ) ; if ( ( currentIndex ) >= ( map . capacity ) ) { map . removeStashIndex ( currentIndex ) ; <START_BUG> nextIndex = currentIndex ; <END_BUG> findNextIndex ( ) ; } else { map . keyTable [ currentIndex ] = null ; } currentIndex = - 1 ; ( map . size ) -- ; } } public static class Entries < K > extends ObjectIntMap . MapIterator < K > implements Iterable < ObjectIntMap . Entry < K > > , Iterator < ObjectIntMap . Entry < K > > { private ObjectIntMap . Entry < K > entry = new ObjectIntMap . Entry ( ) ; public Entries ( ObjectIntMap < K > map ) { } public ObjectIntMap . Entry < K > next ( ) { } public boolean hasNext ( ) { } public Iterator < ObjectIntMap . Entry < K > > iterator ( ) { } } public static class Values extends ObjectIntMap . MapIterator < Object > { public Values ( ObjectIntMap < ? > map ) { } public boolean hasNext ( ) { } public int next ( ) { } public IntArray toArray ( ) { } } public static class Keys < K > extends ObjectIntMap . MapIterator < K > implements Iterable < K > , Iterator < K > { public Keys ( ObjectIntMap < K > map ) { } public boolean hasNext ( ) { } public K next ( ) { } public Iterator < K > iterator ( ) { } public Array < K > toArray ( ) { } } }<BUG2FIX>nextIndex = ( currentIndex ) - 1 ;
public class ClusterChangedEvent { private final String source ; private final ClusterState previousState ; private final ClusterState state ; private final Delta nodesDelta ; public ClusterChangedEvent ( String source , ClusterState state , ClusterState previousState ) { } public String source ( ) { } public ClusterState state ( ) { } public ClusterState previousState ( ) { } public boolean routingTableChanged ( ) { } public boolean indexRoutingTableChanged ( String index ) { } public List < String > indicesCreated ( ) { } public List < String > indicesDeleted ( ) { } public boolean metaDataChanged ( ) { } public boolean indexMetaDataChanged ( IndexMetaData current ) { MetaData previousMetaData = previousState . metaData ( ) ; if ( previousMetaData == null ) { return true ; } IndexMetaData previousIndexMetaData = previousMetaData . index ( current . index ( ) ) ; if ( previousIndexMetaData == current ) { return false ; } <START_BUG> return false ; <END_BUG> } public boolean blocksChanged ( ) { } public boolean localNodeMaster ( ) { } public Delta nodesDelta ( ) { } public boolean nodesRemoved ( ) { } public boolean nodesAdded ( ) { } public boolean nodesChanged ( ) { } }<BUG2FIX>return true ;
@ Override public void setupSuiteScopeCluster ( ) throws Exception { } @ After public void afterEachTest ( ) throws IOException { } private static Bucket getBucket ( DateHistogram histogram , DateTime key ) { } private static Bucket getBucket ( DateHistogram histogram , DateTime key , String format ) { } @ Test public void singleValuedField ( ) throws Exception { } @ Test public void singleValuedField_WithPostTimeZone ( ) throws Exception { } @ Test public void singleValuedField_OrderedByKeyAsc ( ) throws Exception { } @ Test public void singleValuedField_OrderedByKeyDesc ( ) throws Exception { } @ Test public void singleValuedField_OrderedByCountAsc ( ) throws Exception { } @ Test public void singleValuedField_OrderedByCountDesc ( ) throws Exception { } @ Test public void singleValuedField_WithSubAggregation ( ) throws Exception { } @ Test public void singleValuedField_WithSubAggregation_Inherited ( ) throws Exception { } @ Test public void singleValuedField_OrderedBySubAggregationAsc ( ) throws Exception { } @ Test public void singleValuedField_OrderedBySubAggregationDesc ( ) throws Exception { } @ Test public void singleValuedField_OrderedByMultiValuedSubAggregationAsc_Inherited ( ) throws Exception { } @ Test public void singleValuedField_OrderedByMultiValuedSubAggregationDesc ( ) throws Exception { } @ Test public void singleValuedField_WithValueScript ( ) throws Exception { } @ Test public void multiValuedField ( ) throws Exception { } @ Test public void multiValuedField_OrderedByKeyDesc ( ) throws Exception { } @ Test public void multiValuedField_WithValueScript ( ) throws Exception { } @ Test public void multiValuedField_WithValueScript_WithInheritedSubAggregator ( ) throws Exception { } @ Test public void script_SingleValue ( ) throws Exception { } @ Test public void script_SingleValue_WithSubAggregator_Inherited ( ) throws Exception { } @ Test public void script_MultiValued ( ) throws Exception { } @ Test public void script_MultiValued_WithAggregatorInherited ( ) throws Exception { } @ Test public void unmapped ( ) throws Exception { } @ Test public void partiallyUnmapped ( ) throws Exception { } @ Test public void emptyAggregation ( ) throws Exception { } @ Test public void singleValue_WithPreZone ( ) throws Exception { } @ Test public void singleValue_WithPreZone_WithAadjustLargeInterval ( ) throws Exception { } @ Override public Settings indexSettings ( ) { } @ Test public void singleValueField_WithExtendedBounds ( ) throws Exception { String pattern = "yyyy-MM-dd" ; int interval = randomIntBetween ( 1 , 2 ) ; long intervalMillis = ( ( ( interval * 24 ) * 60 ) * 60 ) * 1000 ; DateTime base = new DateTime ( DateTimeZone . UTC ) . dayOfMonth ( ) . roundFloorCopy ( ) ; DateTime baseKey = new DateTime ( ( intervalMillis * ( ( base . getMillis ( ) ) / intervalMillis ) ) , DateTimeZone . UTC ) ; createIndex ( "idx2" ) ; int numOfBuckets = randomIntBetween ( 3 , 6 ) ; int emptyBucketIndex = randomIntBetween ( 1 , ( numOfBuckets - 2 ) ) ; long [ ] docCounts = new long [ numOfBuckets ] ; List < IndexRequestBuilder > builders = new ArrayList < > ( ) ; for ( int i = 0 ; i < numOfBuckets ; i ++ ) { if ( i == emptyBucketIndex ) { docCounts [ i ] = 0 ; } else { int docCount = randomIntBetween ( 1 , 3 ) ; for ( int j = 0 ; j < docCount ; j ++ ) { DateTime date = baseKey . plusDays ( ( ( i * interval ) + ( randomIntBetween ( 0 , ( interval - 1 ) ) ) ) ) ; builders . add ( indexDoc ( "idx2" , date , j ) ) ; } docCounts [ i ] = docCount ; } } indexRandom ( true , builders ) ; ensureSearchable ( "idx2" ) ; DateTime lastDataBucketKey = baseKey . plusDays ( ( ( numOfBuckets - 1 ) * interval ) ) ; int addedBucketsLeft = randomIntBetween ( 0 , numOfBuckets ) ; DateTime boundsMinKey ; if ( frequently ( ) ) { boundsMinKey = baseKey . minusDays ( ( addedBucketsLeft * interval ) ) ; } else { <START_BUG> boundsMinKey = baseKey . plus ( ( addedBucketsLeft * interval ) ) ; <END_BUG> addedBucketsLeft = 0 ; } DateTime boundsMin = boundsMinKey . plusDays ( randomIntBetween ( 0 , ( interval - 1 ) ) ) ; int addedBucketsRight = randomIntBetween ( 0 , numOfBuckets ) ; int boundsMaxKeyDelta = addedBucketsRight * interval ; if ( rarely ( ) ) { addedBucketsRight = 0 ; boundsMaxKeyDelta = - boundsMaxKeyDelta ; } DateTime boundsMaxKey = lastDataBucketKey . plusDays ( boundsMaxKeyDelta ) ; DateTime boundsMax = boundsMaxKey . plusDays ( randomIntBetween ( 0 , ( interval - 1 ) ) ) ; boolean invalidBoundsError = boundsMin . isAfter ( boundsMax ) ; int bucketsCount = ( numOfBuckets + addedBucketsLeft ) + addedBucketsRight ; long [ ] extendedValueCounts = new long [ bucketsCount ] ; System . arraycopy ( docCounts , 0 , extendedValueCounts , addedBucketsLeft , docCounts . length ) ; SearchResponse response = null ; try { response = client ( ) . prepareSearch ( "idx2" ) . addAggregation ( dateHistogram ( "histo" ) . field ( "date" ) . interval ( DateHistogram . Interval . days ( interval ) ) . minDocCount ( 0 ) . extendedBounds ( DateHistogramTests . format ( boundsMin , pattern ) , DateHistogramTests . format ( boundsMax , pattern ) ) . format ( pattern ) ) . execute ( ) . actionGet ( ) ; if ( invalidBoundsError ) { fail ( "Expected<seq2seq4repair_space>an<seq2seq4repair_space>exception<seq2seq4repair_space>to<seq2seq4repair_space>be<seq2seq4repair_space>thrown<seq2seq4repair_space>when<seq2seq4repair_space>bounds.min<seq2seq4repair_space>is<seq2seq4repair_space>greater<seq2seq4repair_space>than<seq2seq4repair_space>bounds.max" ) ; return ; } } catch ( Exception e ) { if ( invalidBoundsError ) { return ; } else { throw e ; } } assertSearchResponse ( response ) ; DateHistogram histo = response . getAggregations ( ) . get ( "histo" ) ; assertThat ( histo , notNullValue ( ) ) ; assertThat ( histo . getName ( ) , equalTo ( "histo" ) ) ; assertThat ( histo . getBuckets ( ) . size ( ) , equalTo ( bucketsCount ) ) ;<BUG2FIX>boundsMinKey = baseKey . plusDays ( ( addedBucketsLeft * interval ) ) ;
public class SkeletonModelViewer implements ApplicationListener { PerspectiveCamera cam ; SkeletonModel model ; Texture texture = null ; boolean hasNormals = false ; BoundingBox bounds = new BoundingBox ( ) ; ImmediateModeRenderer10 renderer ; float angle = 0 ; String fileName ; String textureFileName ; SkeletonAnimation anim ; float animTime = 0 ; SpriteBatch batch ; BitmapFont font ; public SkeletonModelViewer ( String fileName , String textureFileName ) { } @ Override public void create ( ) { } private boolean hasNormals ( ) { } @ Override public void resume ( ) { } float [ ] lightColor = new float [ ] { 1 , 1 , 1 , 0 } ; float [ ] lightPosition = new float [ ] { 2 , 5 , 10 , 0 } ; @ Override public void render ( ) { gl . glClearColor ( 0.2F , 0.2F , 0.2F , 1.0F ) ; gl . glClear ( ( ( GL10 . GL_COLOR_BUFFER_BIT ) | ( GL10 . GL_DEPTH_BUFFER_BIT ) ) ) ; gl . glEnable ( GL_DEPTH_TEST ) ; cam . update ( ) ; cam . apply ( gl10 ) ; drawAxes ( ) ; if ( hasNormals ) { gl . glEnable ( GL_LIGHTING ) ; gl . glEnable ( GL_COLOR_MATERIAL ) ; gl . glEnable ( GL_LIGHT0 ) ; gl10 . glLightfv ( GL_LIGHT0 , GL_DIFFUSE , lightColor , 0 ) ; gl10 . glLightfv ( GL_LIGHT0 , GL_POSITION , lightPosition , 0 ) ; } if ( ( texture ) != null ) { gl . glEnable ( GL_TEXTURE_2D ) ; gl . glEnable ( GL_BLEND ) ; gl . glBlendFunc ( GL_SRC_ALPHA , GL_ONE_MINUS_SRC_ALPHA ) ; } angle += 45 * ( graphics . getDeltaTime ( ) ) ; gl10 . glRotatef ( angle , 0 , 1 , 0 ) ; <START_BUG> animTime += ( graphics . getDeltaTime ( ) ) / 10 ; <END_BUG> if ( ( animTime ) > ( anim . totalDuration ) ) { animTime = 0 ; } model . setAnimation ( anim . name , animTime , false ) ; model . render ( ) ; if ( ( texture ) != null ) { gl . glDisable ( GL_TEXTURE_2D ) ; } if ( hasNormals ) { gl . glDisable ( GL_LIGHTING ) ; } batch . begin ( ) ; font . draw ( batch , ( "fps:<seq2seq4repair_space>" + ( graphics . getFramesPerSecond ( ) ) ) , 20 , 30 ) ; batch . end ( ) ; } private void drawAxes ( ) { } @ Override public void resize ( int width , int height ) { } @ Override public void pause ( ) { } @ Override public void dispose ( ) { } public static void main ( String [ ] argv ) { } }<BUG2FIX>animTime += graphics . getDeltaTime ( ) ;
public class TransportClusterStateAction extends TransportMasterNodeOperationAction < ClusterStateRequest , ClusterStateResponse > { private final ClusterName clusterName ; @ Inject public TransportClusterStateAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool , ClusterName clusterName ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected ClusterStateRequest newRequest ( ) { } @ Override protected ClusterStateResponse newResponse ( ) { } @ Override protected boolean localExecute ( ClusterStateRequest request ) { } @ Override protected ClusterStateResponse masterOperation ( ClusterStateRequest request , ClusterState state ) throws ElasticSearchException { ClusterState currentState = clusterService . state ( ) ; ClusterState . Builder builder = newClusterStateBuilder ( ) ; if ( ! ( request . filterNodes ( ) ) ) { builder . nodes ( currentState . nodes ( ) ) ; } if ( ! ( request . filterRoutingTable ( ) ) ) { builder . routingTable ( currentState . routingTable ( ) ) ; builder . allocationExplanation ( currentState . allocationExplanation ( ) ) ; } if ( ! ( request . filterBlocks ( ) ) ) { builder . blocks ( currentState . blocks ( ) ) ; } if ( ! ( request . filterMetaData ( ) ) ) { MetaData . Builder mdBuilder = newMetaDataBuilder ( ) ; if ( ( ( request . filteredIndices ( ) . length ) == 0 ) && ( ( request . filteredIndexTemplates ( ) . length ) == 0 ) ) { mdBuilder . metaData ( currentState . metaData ( ) ) ; } if ( ( request . filteredIndices ( ) . length ) > 0 ) { String [ ] indices = currentState . metaData ( ) . concreteIndicesIgnoreMissing ( request . filteredIndices ( ) ) ; for ( String filteredIndex : indices ) { IndexMetaData indexMetaData = currentState . metaData ( ) . index ( filteredIndex ) ; if ( indexMetaData != null ) { <START_BUG> mdBuilder . put ( indexMetaData ) ; <END_BUG> } } } if ( ( request . filteredIndexTemplates ( ) . length ) > 0 ) { for ( String templateName : request . filteredIndexTemplates ( ) ) { IndexTemplateMetaData indexTemplateMetaData = currentState . metaData ( ) . templates ( ) . get ( templateName ) ; if ( indexTemplateMetaData != null ) { mdBuilder . put ( indexTemplateMetaData ) ; } } } builder . metaData ( mdBuilder ) ; } return new ClusterStateResponse ( clusterName , builder . build ( ) ) ; } }<BUG2FIX>mdBuilder . put ( indexMetaData , false ) ;
public class LwjglApplication implements Application { protected final LwjglGraphics graphics ; protected OpenALAudio audio ; protected final LwjglFiles files ; protected final LwjglInput input ; protected final LwjglNet net ; protected final ApplicationListener listener ; protected Thread mainLoopThread ; protected boolean running = true ; protected final Array < Runnable > runnables = new Array ( ) ; protected final Array < Runnable > executedRunnables = new Array ( ) ; protected final Array < LifecycleListener > lifecycleListeners = new Array < LifecycleListener > ( ) ; protected int logLevel = LOG_INFO ; public LwjglApplication ( ApplicationListener listener , String title , int width , int height , boolean useGL2 ) { } public LwjglApplication ( ApplicationListener listener ) { } public LwjglApplication ( ApplicationListener listener , LwjglApplicationConfiguration config ) { } public LwjglApplication ( ApplicationListener listener , boolean useGL2 , Canvas canvas ) { } public LwjglApplication ( ApplicationListener listener , LwjglApplicationConfiguration config , Canvas canvas ) { } public LwjglApplication ( ApplicationListener listener , LwjglApplicationConfiguration config , LwjglGraphics graphics ) { } private static LwjglApplicationConfiguration createConfig ( String title , int width , int height , boolean useGL2 ) { } private void initialize ( ) { } void mainLoop ( ) { } public boolean executeRunnables ( ) { } @ Override public ApplicationListener getApplicationListener ( ) { } @ Override public Audio getAudio ( ) { } @ Override public Files getFiles ( ) { } @ Override public LwjglGraphics getGraphics ( ) { } @ Override public Input getInput ( ) { } @ Override public Net getNet ( ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } public void stop ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } Map < String , Preferences > preferences = new HashMap < String , Preferences > ( ) ; @ Override public Preferences getPreferences ( String name ) { } @ Override public Clipboard getClipboard ( ) { } @ Override public void postRunnable ( Runnable runnable ) { } @ Override public void debug ( String tag , String message ) { } @ Override public void debug ( String tag , String message , Throwable exception ) { } @ Override public void log ( String tag , String message ) { } @ Override <START_BUG> public void log ( String tag , String message , Exception exception ) { <END_BUG> if ( ( logLevel ) >= ( LOG_INFO ) ) { System . out . println ( ( ( tag + ":<seq2seq4repair_space>" ) + message ) ) ; exception . printStackTrace ( System . out ) ; } } @ Override public void error ( String tag , String message ) { } @ Override public void error ( String tag , String message , Throwable exception ) { } @ Override public void setLogLevel ( int logLevel ) { } @ Override public int getLogLevel ( ) { } @ Override public void exit ( ) { } @ Override public void addLifecycleListener ( LifecycleListener listener ) { } @ Override public void removeLifecycleListener ( LifecycleListener listener ) { } }<BUG2FIX>public void log ( String tag , String message , Throwable exception ) {
return ; } Class actualType = value . getClass ( ) ; if ( ( ( ( ( ( ( ( ( ( actualType . isPrimitive ( ) ) || ( actualType == ( String . class ) ) ) || ( actualType == ( Integer . class ) ) ) || ( actualType == ( Boolean . class ) ) ) || ( actualType == ( Float . class ) ) ) || ( actualType == ( Long . class ) ) ) || ( actualType == ( Double . class ) ) ) || ( actualType == ( Short . class ) ) ) || ( actualType == ( Byte . class ) ) ) || ( actualType == ( Character . class ) ) ) { writeObjectStart ( actualType , null ) ; writeValue ( "value" , value ) ; writeObjectEnd ( ) ; return ; } if ( value instanceof Json . Serializable ) { writeObjectStart ( actualType , knownType ) ; ( ( Json . Serializable ) ( value ) ) . write ( this ) ; writeObjectEnd ( ) ; return ; } Json . Serializer serializer = classToSerializer . get ( actualType ) ; if ( serializer != null ) { serializer . write ( this , value , knownType ) ; return ; } if ( value instanceof Array ) { if ( ( ( knownType != null ) && ( actualType != knownType ) ) && ( actualType != ( Array . class ) ) ) throw new SerializationException ( ( ( ( ( "Serialization<seq2seq4repair_space>of<seq2seq4repair_space>an<seq2seq4repair_space>Array<seq2seq4repair_space>other<seq2seq4repair_space>than<seq2seq4repair_space>the<seq2seq4repair_space>known<seq2seq4repair_space>type<seq2seq4repair_space>is<seq2seq4repair_space>not<seq2seq4repair_space>supported.\n" + "Known<seq2seq4repair_space>type:<seq2seq4repair_space>" ) + knownType ) + "\nActual<seq2seq4repair_space>type:<seq2seq4repair_space>" ) + actualType ) ) ; writeArrayStart ( ) ; Array array = ( ( Array ) ( value ) ) ; for ( int i = 0 , n = array . size ; i < n ; i ++ ) writeValue ( array . get ( i ) , elementType , null ) ; writeArrayEnd ( ) ; return ; } if ( value instanceof Collection ) { if ( ( ( knownType != null ) && ( actualType != knownType ) ) && ( actualType != ( ArrayList . class ) ) ) throw new SerializationException ( ( ( ( ( "Serialization<seq2seq4repair_space>of<seq2seq4repair_space>a<seq2seq4repair_space>Collection<seq2seq4repair_space>other<seq2seq4repair_space>than<seq2seq4repair_space>the<seq2seq4repair_space>known<seq2seq4repair_space>type<seq2seq4repair_space>is<seq2seq4repair_space>not<seq2seq4repair_space>supported.\n" + "Known<seq2seq4repair_space>type:<seq2seq4repair_space>" ) + knownType ) + "\nActual<seq2seq4repair_space>type:<seq2seq4repair_space>" ) + actualType ) ) ; writeArrayStart ( ) ; for ( Object item : ( ( Collection ) ( value ) ) ) writeValue ( item , elementType , null ) ; writeArrayEnd ( ) ; return ; } if ( actualType . isArray ( ) ) { if ( elementType == null ) elementType = actualType . getComponentType ( ) ; int length = ArrayReflection . getLength ( value ) ; writeArrayStart ( ) ; for ( int i = 0 ; i < length ; i ++ ) writeValue ( ArrayReflection . get ( value , i ) , elementType , null ) ; writeArrayEnd ( ) ; return ; } if ( value instanceof OrderedMap ) { if ( knownType == null ) knownType = OrderedMap . class ; writeObjectStart ( actualType , knownType ) ; OrderedMap map = ( ( OrderedMap ) ( value ) ) ; for ( Object key : map . orderedKeys ( ) ) { writer . name ( convertToString ( key ) ) ; writeValue ( map . get ( key ) , elementType , null ) ; } writeObjectEnd ( ) ; return ; } if ( value instanceof ArrayMap ) { if ( knownType == null ) knownType = ArrayMap . class ; writeObjectStart ( actualType , knownType ) ; ArrayMap map = ( ( ArrayMap ) ( value ) ) ; for ( int i = 0 , n = map . size ; i < n ; i ++ ) { writer . name ( convertToString ( map . keys [ i ] ) ) ; writeValue ( map . values [ i ] , elementType , null ) ; } writeObjectEnd ( ) ; return ; } if ( value instanceof ObjectMap ) { if ( knownType == null ) <START_BUG> knownType = OrderedMap . class ; <END_BUG> writeObjectStart ( actualType , knownType ) ; for ( Entry entry : ( ( ObjectMap < ? , ? > ) ( value ) ) . entries ( ) ) { writer . name ( convertToString ( entry . key ) ) ; writeValue ( entry . value , elementType , null ) ; } writeObjectEnd ( ) ; return ; } if ( value instanceof Map ) { if ( knownType == null ) knownType = HashMap . class ; writeObjectStart ( actualType , knownType ) ; for ( Map . Entry entry : ( ( Map < ? , ? > ) ( value ) ) . entrySet ( ) ) { writer . name ( convertToString ( entry . getKey ( ) ) ) ; writeValue ( entry . getValue ( ) , elementType , null ) ; } writeObjectEnd ( ) ; return ; } if ( ClassReflection . isAssignableFrom ( Enum . class , actualType ) ) { if ( ( knownType == null ) || ( ! ( knownType . equals ( actualType ) ) ) ) { if ( ( actualType . getEnumConstants ( ) ) == null ) actualType = actualType . getSuperclass ( ) ; writeObjectStart ( actualType , null ) ; writer . name ( "value" ) ; writer . value ( value ) ; writeObjectEnd ( ) ; } else { writer . value ( value ) ; } return ; } writeObjectStart ( actualType , knownType ) ; writeFields ( value ) ; writeObjectEnd ( ) ; } catch ( IOException ex ) { throw new SerializationException ( ex ) ; }<BUG2FIX>knownType = ObjectMap . class ;
public class RestIndicesAliasesAction extends BaseRestHandler { @ Inject public RestIndicesAliasesAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { IndicesAliasesRequest indicesAliasesRequest = new IndicesAliasesRequest ( ) ; indicesAliasesRequest . listenerThreaded ( false ) ; XContentParser parser = null ; try { indicesAliasesRequest . timeout ( request . paramAsTime ( "timeout" , timeValueSeconds ( 10 ) ) ) ; parser = XContentFactory . xContent ( request . content ( ) ) . createParser ( request . content ( ) ) ; XContentParser . Token token = parser . nextToken ( ) ; if ( token == null ) { throw new ElasticSearchIllegalArgumentException ( "No<seq2seq4repair_space>action<seq2seq4repair_space>is<seq2seq4repair_space>specified" ) ; } while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . START_ARRAY ) ) { while ( ( token = parser . nextToken ( ) ) != ( Token . END_ARRAY ) ) { if ( token == ( Token . FIELD_NAME ) ) { String action = parser . currentName ( ) ; AliasAction . Type type ; if ( "add" . equals ( action ) ) { type = Type . ADD ; } else if ( "remove" . equals ( action ) ) { type = Type . REMOVE ; } else { throw new ElasticSearchIllegalArgumentException ( ( ( "Alias<seq2seq4repair_space>action<seq2seq4repair_space>[" + action ) + "]<seq2seq4repair_space>not<seq2seq4repair_space>supported" ) ) ; } String index = null ; String alias = null ; Map < String , Object > filter = null ; String routing = null ; boolean routingSet = false ; String indexRouting = null ; boolean indexRoutingSet = false ; String searchRouting = null ; boolean searchRoutingSet = false ; String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else if ( token == ( Token . VALUE_STRING ) ) { if ( "index" . equals ( currentFieldName ) ) { index = parser . text ( ) ; } else if ( "alias" . equals ( currentFieldName ) ) { alias = parser . text ( ) ; } else if ( "routing" . equals ( currentFieldName ) ) { routing = parser . textOrNull ( ) ; routingSet = true ; } else if ( ( ( "indexRouting" . equals ( currentFieldName ) ) || ( "index-routing" . equals ( currentFieldName ) ) ) || ( "index_routing" . equals ( currentFieldName ) ) ) { indexRouting = parser . textOrNull ( ) ; indexRoutingSet = true ; } else if ( ( ( "searchRouting" . equals ( currentFieldName ) ) || ( "search-routing" . equals ( currentFieldName ) ) ) || ( "search_routing" . equals ( currentFieldName ) ) ) { searchRouting = parser . textOrNull ( ) ; searchRoutingSet = true ; } } else if ( token == ( Token . START_OBJECT ) ) { if ( "filter" . equals ( currentFieldName ) ) { filter = parser . mapOrdered ( ) ; } } } if ( index == null ) { throw new ElasticSearchIllegalArgumentException ( ( ( "Alias<seq2seq4repair_space>action<seq2seq4repair_space>[" + action ) + "]<seq2seq4repair_space>requires<seq2seq4repair_space>an<seq2seq4repair_space>[index]<seq2seq4repair_space>to<seq2seq4repair_space>be<seq2seq4repair_space>set" ) ) ; } if ( alias == null ) { throw new ElasticSearchIllegalArgumentException ( ( ( "Alias<seq2seq4repair_space>action<seq2seq4repair_space>[" + action ) + "]<seq2seq4repair_space>requires<seq2seq4repair_space>an<seq2seq4repair_space>[alias]<seq2seq4repair_space>to<seq2seq4repair_space>be<seq2seq4repair_space>set" ) ) ; } if ( type == ( Type . ADD ) ) { AliasAction aliasAction = newAddAliasAction ( index , alias ) . filter ( filter ) ; if ( routingSet ) { aliasAction . routing ( routing ) ; } if ( indexRoutingSet ) { aliasAction . indexRouting ( indexRouting ) ; } if ( searchRoutingSet ) { aliasAction . searchRouting ( searchRouting ) ; } indicesAliasesRequest . addAliasAction ( aliasAction ) ; } else if ( type == ( Type . REMOVE ) ) { indicesAliasesRequest . removeAlias ( index , alias ) ; } } } } } } catch ( Exception e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . warn ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>response" , e1 ) ; } return ; } finally { parser . close ( ) ; } client . admin ( ) . indices ( ) . aliases ( indicesAliasesRequest , new org . elasticsearch . action . ActionListener < IndicesAliasesResponse > ( ) { @ Override public void onResponse ( IndicesAliasesResponse response ) { try { XContentBuilder builder = restContentBuilder ( request ) ; builder . startObject ( ) . field ( "ok" , true ) . field ( "acknowledged" , response . isAcknowledged ( ) ) . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
try { try { validate ( request , currentState ) ; <START_BUG> } catch ( Exception e ) { <END_BUG><BUG2FIX>} catch ( Throwable e ) {
public class LZFCompressor implements Compressor { static final byte [ ] LUCENE_HEADER = new byte [ ] { 'L' , 'Z' , 'F' , 0 } ; public static final String TYPE = "lzf" ; private ChunkEncoder encoder ; private ChunkDecoder decoder ; public LZFCompressor ( ) { } @ Override public String type ( ) { } @ Override public void configure ( Settings settings ) { } @ Override public boolean isCompressed ( BytesReference bytes ) { } @ Override public boolean isCompressed ( byte [ ] data , int offset , int length ) { } @ Override public boolean isCompressed ( ChannelBuffer buffer ) { } @ Override public boolean isCompressed ( IndexInput in ) throws IOException { } @ Override public byte [ ] uncompress ( byte [ ] data , int offset , int length ) throws IOException { } @ Override public byte [ ] compress ( byte [ ] data , int offset , int length ) throws IOException { } @ Override public CompressedStreamInput streamInput ( StreamInput in ) throws IOException { } @ Override public CompressedStreamOutput streamOutput ( StreamOutput out ) throws IOException { <START_BUG> return new LZFCompressedStreamOutput ( out , encoder ) ; <END_BUG> } @ Override public CompressedIndexInput indexInput ( IndexInput in ) throws IOException { } }<BUG2FIX>return new LZFCompressedStreamOutput ( out ) ;
public class SimpleIdCache extends AbstractIndexComponent implements IdCache , SegmentReader . CoreClosedListener { private final ConcurrentMap < Object , SimpleIdReaderCache > idReaders ; private final boolean reuse ; IndexService indexService ; @ Inject public SimpleIdCache ( Index index , @ IndexSettings Settings indexSettings ) { } @ Override public void setIndexService ( IndexService indexService ) { } @ Override public void close ( ) throws ElasticSearchException { } @ Override public void clear ( ) { } @ Override public void onClose ( SegmentReader owner ) { } @ Override public void clear ( IndexReader reader ) { } @ Override public IdReaderCache reader ( AtomicReader reader ) { } @ SuppressWarnings ( { "unchecked" } ) @ Override public Iterator < IdReaderCache > iterator ( ) { } @ SuppressWarnings ( { "StringEquality" } ) @ Override public void refresh ( List < AtomicReaderContext > atomicReaderContexts ) throws Exception { if ( refreshNeeded ( atomicReaderContexts ) ) { synchronized ( idReaders ) { if ( ! ( refreshNeeded ( atomicReaderContexts ) ) ) { return ; } Map < Object , Map < String , SimpleIdCache . TypeBuilder > > builders = new HashMap < Object , Map < String , SimpleIdCache . TypeBuilder > > ( ) ; Map < Object , IndexReader > cacheToReader = new HashMap < Object , IndexReader > ( ) ; NavigableSet < HashedBytesArray > parentTypes = new TreeSet < HashedBytesArray > ( UTF8SortedAsUnicodeComparator . utf8SortedAsUnicodeSortOrder ) ; BytesRef spare = new BytesRef ( ) ; for ( String type : indexService . mapperService ( ) . types ( ) ) { ParentFieldMapper parentFieldMapper = indexService . mapperService ( ) . documentMapper ( type ) . parentFieldMapper ( ) ; if ( parentFieldMapper != null ) { parentTypes . add ( new HashedBytesArray ( Strings . toUTF8Bytes ( parentFieldMapper . type ( ) , spare ) ) ) ; } } for ( AtomicReaderContext context : atomicReaderContexts ) { AtomicReader reader = context . reader ( ) ; if ( idReaders . containsKey ( reader . getCoreCacheKey ( ) ) ) { continue ; } if ( reader instanceof SegmentReader ) { ( ( SegmentReader ) ( reader ) ) . addCoreClosedListener ( this ) ; } Map < String , SimpleIdCache . TypeBuilder > readerBuilder = new HashMap < String , SimpleIdCache . TypeBuilder > ( ) ; builders . put ( reader . getCoreCacheKey ( ) , readerBuilder ) ; cacheToReader . put ( reader . getCoreCacheKey ( ) , context . reader ( ) ) ; Terms terms = reader . terms ( NAME ) ; if ( terms != null ) { TermsEnum termsEnum = terms . iterator ( null ) ; DocsEnum docsEnum = null ; uid : for ( BytesRef term = termsEnum . next ( ) ; term != null ; term = termsEnum . next ( ) ) { HashedBytesArray [ ] typeAndId = Uid . splitUidIntoTypeAndId ( term ) ; if ( ! ( parentTypes . contains ( typeAndId [ 0 ] ) ) ) { do { HashedBytesArray nextParent = parentTypes . ceiling ( typeAndId [ 0 ] ) ; if ( nextParent == null ) { break uid ; } <START_BUG> TermsEnum . SeekStatus status = termsEnum . seekCeil ( nextParent . toBytesRef ( ) , false ) ; <END_BUG> if ( status == ( SeekStatus . END ) ) { break uid ; } else if ( status == ( SeekStatus . NOT_FOUND ) ) { term = termsEnum . term ( ) ; typeAndId = Uid . splitUidIntoTypeAndId ( term ) ; } else if ( status == ( SeekStatus . FOUND ) ) { assert false : "Seek<seq2seq4repair_space>status<seq2seq4repair_space>should<seq2seq4repair_space>never<seq2seq4repair_space>be<seq2seq4repair_space>FOUND,<seq2seq4repair_space>because<seq2seq4repair_space>we<seq2seq4repair_space>seek<seq2seq4repair_space>only<seq2seq4repair_space>the<seq2seq4repair_space>type<seq2seq4repair_space>part" ; term = termsEnum . term ( ) ; typeAndId = Uid . splitUidIntoTypeAndId ( term ) ; } } while ( ! ( parentTypes . contains ( typeAndId [ 0 ] ) ) ) ; } String type = typeAndId [ 0 ] . toUtf8 ( ) ; SimpleIdCache . TypeBuilder typeBuilder = readerBuilder . get ( type ) ; if ( typeBuilder == null ) { typeBuilder = new SimpleIdCache . TypeBuilder ( reader ) ; readerBuilder . put ( type , typeBuilder ) ; } HashedBytesArray idAsBytes = checkIfCanReuse ( builders , typeAndId [ 1 ] ) ; docsEnum = termsEnum . docs ( null , docsEnum , 0 ) ; for ( int docId = docsEnum . nextDoc ( ) ; docId != ( DocsEnum . NO_MORE_DOCS ) ; docId = docsEnum . nextDoc ( ) ) { typeBuilder . idToDoc . put ( idAsBytes , docId ) ; typeBuilder . docToId [ docId ] = idAsBytes ; } } } } for ( AtomicReaderContext context : atomicReaderContexts ) { AtomicReader reader = context . reader ( ) ; if ( idReaders . containsKey ( reader . getCoreCacheKey ( ) ) ) { continue ; } Map < String , SimpleIdCache . TypeBuilder > readerBuilder = builders . get ( reader . getCoreCacheKey ( ) ) ; Terms terms = reader . terms ( ParentFieldMapper . NAME ) ; if ( terms != null ) { TermsEnum termsEnum = terms . iterator ( null ) ; DocsEnum docsEnum = null ; for ( BytesRef term = termsEnum . next ( ) ; term != null ; term = termsEnum . next ( ) ) { HashedBytesArray [ ] typeAndId = Uid . splitUidIntoTypeAndId ( term ) ; SimpleIdCache . TypeBuilder typeBuilder = readerBuilder . get ( typeAndId [ 0 ] . toUtf8 ( ) ) ; if ( typeBuilder == null ) { typeBuilder = new SimpleIdCache . TypeBuilder ( reader ) ; readerBuilder . put ( typeAndId [ 0 ] . toUtf8 ( ) , typeBuilder ) ; } HashedBytesArray idAsBytes = checkIfCanReuse ( builders , typeAndId [ 1 ] ) ; boolean added = false ; docsEnum = termsEnum . docs ( null , docsEnum , 0 ) ;<BUG2FIX>TermsEnum . SeekStatus status = termsEnum . seekCeil ( nextParent . toBytesRef ( ) ) ;
public class MetaDataUpdateSettingsService extends AbstractComponent implements ClusterStateListener { private final ClusterService clusterService ; @ Inject public MetaDataUpdateSettingsService ( Settings settings , ClusterService clusterService ) { } @ Override public void clusterChanged ( ClusterChangedEvent event ) { if ( ! ( event . state ( ) . nodes ( ) . localNodeMaster ( ) ) ) { return ; } for ( final IndexMetaData indexMetaData : event . state ( ) . metaData ( ) ) { String autoExpandReplicas = indexMetaData . settings ( ) . get ( SETTING_AUTO_EXPAND_REPLICAS ) ; if ( autoExpandReplicas != null ) { try { final int numberOfReplicas = ( event . state ( ) . nodes ( ) . dataNodes ( ) . size ( ) ) - 1 ; int min ; int max ; try { min = Integer . parseInt ( autoExpandReplicas . substring ( 0 , autoExpandReplicas . indexOf ( '-' ) ) ) ; String sMax = autoExpandReplicas . substring ( ( ( autoExpandReplicas . indexOf ( '-' ) ) + 1 ) ) ; if ( sMax . equals ( "all" ) ) { max = ( event . state ( ) . nodes ( ) . dataNodes ( ) . size ( ) ) - 1 ; } else { max = Integer . parseInt ( sMax ) ; } } catch ( Exception e ) { <START_BUG> logger . warn ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>set<seq2seq4repair_space>[{}],<seq2seq4repair_space>wrong<seq2seq4repair_space>format<seq2seq4repair_space>[{}]" , SETTING_AUTO_EXPAND_REPLICAS , autoExpandReplicas ) ; <END_BUG> continue ; } if ( numberOfReplicas == ( indexMetaData . numberOfReplicas ( ) ) ) { continue ; } if ( ( numberOfReplicas >= min ) && ( numberOfReplicas <= max ) ) { Settings settings = ImmutableSettings . settingsBuilder ( ) . put ( SETTING_NUMBER_OF_REPLICAS , numberOfReplicas ) . build ( ) ; updateSettings ( settings , new String [ ] { indexMetaData . index ( ) } , new MetaDataUpdateSettingsService . Listener ( ) { @ Override public void onSuccess ( ) { logger . info ( "[{}]<seq2seq4repair_space>auto<seq2seq4repair_space>expanded<seq2seq4repair_space>replicas<seq2seq4repair_space>to<seq2seq4repair_space>[{}]" , indexMetaData . index ( ) , numberOfReplicas ) ; } @ Override public void onFailure ( Throwable t ) { logger . warn ( "[{}]<seq2seq4repair_space>fail<seq2seq4repair_space>to<seq2seq4repair_space>auto<seq2seq4repair_space>expand<seq2seq4repair_space>replicas<seq2seq4repair_space>to<seq2seq4repair_space>[{}]" , indexMetaData . index ( ) , numberOfReplicas ) ; } } ) ; } } catch ( Exception e ) { logger . warn ( "[{}]<seq2seq4repair_space>failed<seq2seq4repair_space>to<seq2seq4repair_space>parse<seq2seq4repair_space>auto<seq2seq4repair_space>expand<seq2seq4repair_space>replicas" , e , indexMetaData . index ( ) ) ; } } } } public void updateSettings ( final Settings pSettings , final String [ ] indices , final MetaDataUpdateSettingsService . Listener listener ) { } public static interface Listener { void onSuccess ( ) { } void onFailure ( Throwable t ) { } } }<BUG2FIX>logger . warn ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>set<seq2seq4repair_space>[{}],<seq2seq4repair_space>wrong<seq2seq4repair_space>format<seq2seq4repair_space>[{}]" , e , SETTING_AUTO_EXPAND_REPLICAS , autoExpandReplicas ) ;
public class IOSNet implements Net { public static class InputStreamNetStreamImpl extends InputStream { private final Stream stream ; public InputStreamNetStreamImpl ( Stream stream ) { } @ Override public int read ( ) throws IOException { } } public static class OutputStreamNetStreamImpl extends OutputStream { private Stream stream ; public OutputStreamNetStreamImpl ( Stream stream ) { } @ Override public void write ( int b ) throws IOException { } } static class IosHttpResponse implements HttpResponse { private HttpWebResponse webResponse ; public IosHttpResponse ( HttpWebResponse webResponse ) { } @ Override public HttpStatus getStatus ( ) { } @ Override public String getResultAsString ( ) { } @ Override public InputStream getResultAsStream ( ) { } @ Override public byte [ ] getResult ( ) { } } final UIApplication uiApp ; final ExecutorService executorService ; public IOSNet ( IOSApplication app ) { } @ Override public void sendHttpRequest ( final HttpRequest httpRequest , final HttpResponseListener httpResultListener ) { Future < ? > processHttpRequestFuture = executorService . submit ( new Runnable ( ) { @ Override public void run ( ) { try { String url = httpRequest . getUrl ( ) ; String method = httpRequest . getMethod ( ) ; if ( method . equalsIgnoreCase ( GET ) ) { String value = httpRequest . getContent ( ) ; if ( ( value != null ) && ( ! ( "" . equals ( value ) ) ) ) url += "?" + value ; } HttpWebRequest httpWebRequest = ( ( HttpWebRequest ) ( WebRequest . Create ( url ) ) ) ; int timeOut = httpRequest . getTimeOut ( ) ; if ( timeOut > 0 ) httpWebRequest . set_Timeout ( timeOut ) ; else httpWebRequest . set_Timeout ( ( - 1 ) ) ; httpWebRequest . set_Method ( method ) ; Map < String , String > headers = httpRequest . getHeaders ( ) ; WebHeaderCollection webHeaderCollection = new WebHeaderCollection ( ) ; for ( String key : headers . keySet ( ) ) webHeaderCollection . Add ( key , headers . get ( key ) ) ; httpWebRequest . set_Headers ( webHeaderCollection ) ; <START_BUG> if ( ( method . equalsIgnoreCase ( POST ) ) || ( method . equalsIgnoreCase ( PUT ) ) ) { <END_BUG> InputStream contentAsStream = httpRequest . getContentStream ( ) ; String contentAsString = httpRequest . getContent ( ) ; if ( contentAsStream != null ) { httpWebRequest . set_ContentLength ( contentAsStream . available ( ) ) ; Stream stream = httpWebRequest . GetRequestStream ( ) ; StreamUtils . copyStream ( contentAsStream , new IOSNet . OutputStreamNetStreamImpl ( stream ) ) ; stream . Close ( ) ; } else if ( contentAsString != null ) { byte [ ] data = contentAsString . getBytes ( ) ; httpWebRequest . set_ContentLength ( data . length ) ; Stream stream = httpWebRequest . GetRequestStream ( ) ; stream . Write ( data , 0 , data . length ) ; stream . Close ( ) ; } } final HttpWebResponse httpWebResponse = ( ( HttpWebResponse ) ( httpWebRequest . GetResponse ( ) ) ) ; app . postRunnable ( new Runnable ( ) { @ Override public void run ( ) { httpResultListener . handleHttpResponse ( new IOSNet . IosHttpResponse ( httpWebResponse ) ) ; } } ) ; } catch ( final Exception e ) { app . postRunnable ( new Runnable ( ) { @ Override public void run ( ) { httpResultListener . failed ( e ) ; } } ) ; } } } ) ; } @ Override public ServerSocket newServerSocket ( Protocol protocol , int port , ServerSocketHints hints ) { } @ Override public Socket newClientSocket ( Protocol protocol , String host , int port , SocketHints hints ) { } @ Override public void openURI ( String URI ) { } }<BUG2FIX>if ( method . equalsIgnoreCase ( POST ) ) {
public class RestOptimizeAction extends BaseRestHandler { @ Inject public RestOptimizeAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { OptimizeRequest optimizeRequest = new OptimizeRequest ( RestActions . splitIndices ( request . param ( "index" ) ) ) ; optimizeRequest . listenerThreaded ( false ) ; if ( request . hasParam ( "ignore_indices" ) ) { optimizeRequest . ignoreIndices ( IgnoreIndices . fromString ( request . param ( "ignore_indices" ) ) ) ; } try { optimizeRequest . waitForMerge ( request . paramAsBoolean ( "wait_for_merge" , optimizeRequest . waitForMerge ( ) ) ) ; optimizeRequest . maxNumSegments ( request . paramAsInt ( "max_num_segments" , optimizeRequest . maxNumSegments ( ) ) ) ; optimizeRequest . onlyExpungeDeletes ( request . paramAsBoolean ( "only_expunge_deletes" , optimizeRequest . onlyExpungeDeletes ( ) ) ) ; optimizeRequest . flush ( request . paramAsBoolean ( "flush" , optimizeRequest . flush ( ) ) ) ; optimizeRequest . refresh ( request . paramAsBoolean ( "refresh" , optimizeRequest . refresh ( ) ) ) ; BroadcastOperationThreading operationThreading = BroadcastOperationThreading . fromString ( request . param ( "operation_threading" ) , SINGLE_THREAD ) ; if ( operationThreading == ( BroadcastOperationThreading . NO_THREADS ) ) { operationThreading = BroadcastOperationThreading . THREAD_PER_SHARD ; } optimizeRequest . operationThreading ( operationThreading ) ; } catch ( Exception e ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . BAD_REQUEST , builder . startObject ( ) . field ( "error" , e . getMessage ( ) ) . endObject ( ) ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } return ; } client . admin ( ) . indices ( ) . optimize ( optimizeRequest , new org . elasticsearch . action . ActionListener < OptimizeResponse > ( ) { @ Override public void onResponse ( OptimizeResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( "ok" , true ) ; buildBroadcastShardsHeader ( builder , response ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class TransportIndicesStatusAction extends TransportBroadcastOperationAction < IndicesStatusRequest , IndicesStatusResponse , TransportIndicesStatusAction . IndexShardStatusRequest , ShardStatus > { private final RecoveryTarget peerRecoveryTarget ; @ Inject public TransportIndicesStatusAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportService transportService , IndicesService indicesService , RecoveryTarget peerRecoveryTarget ) { } @ Override protected String transportAction ( ) { } @ Override protected String transportShardAction ( ) { } @ Override protected IndicesStatusRequest newRequest ( ) { } @ Override protected boolean ignoreNonActiveExceptions ( ) { } @ Override protected GroupShardsIterator shards ( IndicesStatusRequest request , ClusterState clusterState ) { } @ Override protected ShardRouting nextShardOrNull ( ShardsIterator shardIt ) { } @ Override protected boolean hasNextShard ( ShardsIterator shardIt ) { } @ Override protected IndicesStatusResponse newResponse ( IndicesStatusRequest request , AtomicReferenceArray shardsResponses , ClusterState clusterState ) { } @ Override protected TransportIndicesStatusAction . IndexShardStatusRequest newShardRequest ( ) { } @ Override protected TransportIndicesStatusAction . IndexShardStatusRequest newShardRequest ( ShardRouting shard , IndicesStatusRequest request ) { } @ Override protected ShardStatus newShardResponse ( ) { } @ Override protected ShardStatus shardOperation ( TransportIndicesStatusAction . IndexShardStatusRequest request ) throws ElasticSearchException { InternalIndexService indexService = ( ( InternalIndexService ) ( indicesService . indexServiceSafe ( request . index ( ) ) ) ) ; InternalIndexShard indexShard = ( ( InternalIndexShard ) ( indexService . shardSafe ( request . shardId ( ) ) ) ) ; ShardStatus shardStatus = new ShardStatus ( indexShard . routingEntry ( ) ) ; shardStatus . state = indexShard . state ( ) ; try { shardStatus . storeSize = indexShard . store ( ) . estimateSize ( ) ; } catch ( IOException e ) { } if ( ( indexShard . state ( ) ) == ( IndexShardState . STARTED ) ) { shardStatus . translogId = indexShard . translog ( ) . currentId ( ) ; shardStatus . translogOperations = indexShard . translog ( ) . size ( ) ; Engine . Searcher searcher = indexShard . searcher ( ) ; try { shardStatus . docs = new DocsStatus ( ) ; shardStatus . docs . numDocs = searcher . reader ( ) . numDocs ( ) ; shardStatus . docs . maxDoc = searcher . reader ( ) . maxDoc ( ) ; shardStatus . docs . deletedDocs = searcher . reader ( ) . numDeletedDocs ( ) ; } finally { searcher . release ( ) ; } } RecoveryStatus peerRecoveryStatus = indexShard . peerRecoveryStatus ( ) ; if ( peerRecoveryStatus == null ) { peerRecoveryStatus = peerRecoveryTarget . peerRecoveryStatus ( indexShard . shardId ( ) ) ; } if ( peerRecoveryStatus != null ) { PeerRecoveryStatus . Stage stage ; switch ( peerRecoveryStatus . stage ( ) ) { case INIT : stage = Stage . INIT ; break ; case INDEX : stage = Stage . INDEX ; break ; case TRANSLOG : stage = Stage . TRANSLOG ; break ; case FINALIZE : stage = Stage . FINALIZE ; break ; case DONE : stage = Stage . DONE ; break ; default : stage = Stage . INIT ; } shardStatus . peerRecoveryStatus = new PeerRecoveryStatus ( stage , peerRecoveryStatus . startTime ( ) , peerRecoveryStatus . time ( ) , peerRecoveryStatus . phase1TotalSize ( ) , peerRecoveryStatus . phase1ExistingTotalSize ( ) , peerRecoveryStatus . currentFilesSize ( ) , peerRecoveryStatus . currentTranslogOperations ( ) ) ; } IndexShardGatewayService gatewayService = indexService . shardInjector ( request . shardId ( ) ) . getInstance ( IndexShardGatewayService . class ) ; org . elasticsearch . index . gateway . RecoveryStatus gatewayRecoveryStatus = gatewayService . recoveryStatus ( ) ; if ( gatewayRecoveryStatus != null ) { GatewayRecoveryStatus . Stage stage ; switch ( gatewayRecoveryStatus . stage ( ) ) { case INIT : stage = GatewayRecoveryStatus . Stage . INIT ; break ; case INDEX : stage = GatewayRecoveryStatus . Stage . INDEX ; break ; case TRANSLOG : stage = GatewayRecoveryStatus . Stage . TRANSLOG ; break ; case DONE : stage = GatewayRecoveryStatus . Stage . DONE ; break ; default : stage = GatewayRecoveryStatus . Stage . INIT ; } shardStatus . gatewayRecoveryStatus = new GatewayRecoveryStatus ( stage , gatewayRecoveryStatus . startTime ( ) , gatewayRecoveryStatus . time ( ) , gatewayRecoveryStatus . index ( ) . totalSize ( ) , gatewayRecoveryStatus . index ( ) . existingTotalSize ( ) , gatewayRecoveryStatus . index ( ) . currentFilesSize ( ) , gatewayRecoveryStatus . translog ( ) . currentTranslogOperations ( ) ) ; } SnapshotStatus snapshotStatus = gatewayService . snapshotStatus ( ) ; if ( snapshotStatus != null ) { GatewaySnapshotStatus . Stage stage ; switch ( snapshotStatus . stage ( ) ) { case DONE : stage = GatewaySnapshotStatus . Stage . DONE ; break ; case FAILURE : stage = GatewaySnapshotStatus . Stage . FAILURE ; break ; case TRANSLOG : stage = GatewaySnapshotStatus . Stage . TRANSLOG ; break ; case FINALIZE : stage = GatewaySnapshotStatus . Stage . FINALIZE ; break ; case INDEX : stage = GatewaySnapshotStatus . Stage . INDEX ; break ; default : stage = GatewaySnapshotStatus . Stage . NONE ; break ; } <START_BUG> shardStatus . gatewaySnapshotStatus = new GatewaySnapshotStatus ( stage , snapshotStatus . startTime ( ) , snapshotStatus . time ( ) , snapshotStatus . index ( ) . totalSize ( ) , snapshotStatus . translog ( ) . currentTranslogOperations ( ) ) ; <END_BUG> } return shardStatus ; } public static class IndexShardStatusRequest extends BroadcastShardOperationRequest { IndexShardStatusRequest ( ) { } IndexShardStatusRequest ( String index , int shardId ) { } } }<BUG2FIX>shardStatus . gatewaySnapshotStatus = new GatewaySnapshotStatus ( stage , snapshotStatus . startTime ( ) , snapshotStatus . time ( ) , snapshotStatus . index ( ) . totalSize ( ) ) ;
public class RobinEngine extends AbstractIndexShardComponent implements Engine { private volatile ByteSizeValue indexingBufferSize ; private volatile int termIndexInterval ; private volatile int termIndexDivisor ; private volatile int indexConcurrency ; private volatile boolean compoundOnFlush = true ; private long gcDeletesInMillis ; private volatile boolean enableGcDeletes = true ; private volatile String codecName ; private final ThreadPool threadPool ; private final ShardIndexingService indexingService ; private final IndexSettingsService indexSettingsService ; @ Nullable private final InternalIndicesWarmer warmer ; private final Store store ; private final SnapshotDeletionPolicy deletionPolicy ; private final Translog translog ; private final MergePolicyProvider mergePolicyProvider ; private final MergeSchedulerProvider mergeScheduler ; private final AnalysisService analysisService ; private final SimilarityService similarityService ; private final CodecService codecService ; private final ReadWriteLock rwl = new ReentrantReadWriteLock ( ) ; private volatile IndexWriter indexWriter ; private final SearcherFactory searcherFactory = new RobinEngine . RobinSearchFactory ( ) ; private volatile SearcherManager searcherManager ; private volatile boolean closed = false ; private volatile boolean dirty = false ; private volatile boolean possibleMergeNeeded = false ; private final AtomicBoolean optimizeMutex = new AtomicBoolean ( ) ; private volatile boolean flushNeeded = false ; private final AtomicInteger flushing = new AtomicInteger ( ) ; private final Lock flushLock = new ReentrantLock ( ) ; private final RobinEngine . RecoveryCounter onGoingRecoveries = new RobinEngine . RecoveryCounter ( ) ; private final ConcurrentMap < HashedBytesRef , RobinEngine . VersionValue > versionMap ; private final Object [ ] dirtyLocks ; private final Object refreshMutex = new Object ( ) ; private final RobinEngine . ApplySettings applySettings = new RobinEngine . ApplySettings ( ) ; private volatile boolean failOnMergeFailure ; private Throwable failedEngine = null ; private final Object failedEngineMutex = new Object ( ) ; private final CopyOnWriteArrayList < FailedEngineListener > failedEngineListeners = new CopyOnWriteArrayList < FailedEngineListener > ( ) ; private final AtomicLong translogIdGenerator = new AtomicLong ( ) ; private SegmentInfos lastCommittedSegmentInfos ; @ Inject public RobinEngine ( ShardId shardId , @ IndexSettings Settings indexSettings , ThreadPool threadPool , IndexSettingsService indexSettingsService , ShardIndexingService indexingService , @ Nullable IndicesWarmer warmer , Store store , SnapshotDeletionPolicy deletionPolicy , Translog translog , MergePolicyProvider mergePolicyProvider , MergeSchedulerProvider mergeScheduler , AnalysisService analysisService , SimilarityService similarityService , CodecService codecService ) throws EngineException { } @ Override public void updateIndexingBufferSize ( ByteSizeValue indexingBufferSize ) { } @ Override public void addFailedEngineListener ( FailedEngineListener listener ) { } @ Override public void start ( ) throws EngineException { } private void readLastCommittedSegmentsInfo ( ) throws IOException { } @ Override public TimeValue defaultRefreshInterval ( ) { } @ Override public void enableGcDeletes ( boolean enableGcDeletes ) { } public GetResult get ( Get get ) throws EngineException { } @ Override public void create ( Create create ) throws EngineException { } private void innerCreate ( Create create , IndexWriter writer ) throws IOException { } @ Override public void index ( Index index ) throws EngineException { } private void innerIndex ( Index index , IndexWriter writer ) throws IOException { } @ Override public void delete ( Delete delete ) throws EngineException { } private void innerDelete ( Delete delete , IndexWriter writer ) throws IOException { } @ Override public void delete ( DeleteByQuery delete ) throws EngineException { } @ Override public final Searcher acquireSearcher ( String source ) throws EngineException { SearcherManager manager = this . searcherManager ; if ( manager == null ) { throw new EngineClosedException ( shardId ) ; } try { IndexSearcher searcher = manager . acquire ( ) ; return newSearcher ( source , searcher , manager ) ; <START_BUG> } catch ( IOException ex ) { <END_BUG> logger . error ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>acquire<seq2seq4repair_space>searcher,<seq2seq4repair_space>source<seq2seq4repair_space>{}" , ex , source ) ; throw new EngineException ( shardId , ex . getMessage ( ) ) ; } } protected Searcher newSearcher ( String source , IndexSearcher searcher , SearcherManager manager ) { } @ Override public boolean refreshNeeded ( ) { } @ Override public boolean possibleMergeNeeded ( ) { } @ Override public void refresh ( Refresh refresh ) throws EngineException { } @ Override public void flush ( Flush flush ) throws EngineException { } private void ensureOpen ( ) { } private void refreshVersioningTable ( long time ) { } @ Override public void maybeMerge ( ) throws EngineException { } @ Override public void optimize ( Optimize optimize ) throws EngineException { } @ Override public < T > T snapshot ( SnapshotHandler < T > snapshotHandler ) throws EngineException { } @ Override public SnapshotIndexCommit snapshotIndex ( ) throws EngineException { } @ Override public void recover ( RecoveryHandler recoveryHandler ) throws EngineException { } @ Override public SegmentsStats segmentsStats ( ) { } @ Override public List < Segment > segments ( ) { } @ Override public void close ( ) throws ElasticSearchException { } class FailEngineOnMergeFailure implements MergeSchedulerProvider . FailureListener { @ Override public void onFailedMerge ( MergePolicy . MergeException e ) { } } private void failEngine ( Throwable failure ) { } private void innerClose ( ) { } private HashedBytesRef versionKey ( Term uid ) { } private Object dirtyLock ( BytesRef uid ) { } private Object dirtyLock ( Term uid ) { } private long loadCurrentVersionFromIndex ( Term uid ) throws IOException { } private static boolean isMergedSegment ( AtomicReader reader ) { } private IndexWriter createWriter ( ) throws IOException { } public static final String INDEX_TERM_INDEX_INTERVAL = "index.term_index_interval" ; public static final String INDEX_TERM_INDEX_DIVISOR = "index.term_index_divisor" ; public static final String INDEX_INDEX_CONCURRENCY = "index.index_concurrency" ; public static final String INDEX_COMPOUND_ON_FLUSH = "index.compound_on_flush" ; public static final String INDEX_GC_DELETES = "index.gc_deletes" ; public static final String INDEX_FAIL_ON_MERGE_FAILURE = "index.fail_on_merge_failure" ; class ApplySettings implements IndexSettingsService . Listener { @ Override public void onRefreshSettings ( Settings settings ) { } } private SearcherManager buildSearchManager ( IndexWriter indexWriter ) throws IOException { } static class RobinSearcher implements Searcher { private final String source ; private final IndexSearcher searcher ; private final SearcherManager manager ;<BUG2FIX>} catch ( Throwable ex ) {
public class TmxMapLoader extends SynchronousAssetLoader < TiledMap , TmxMapLoader . Parameters > { public static class Parameters extends AssetLoaderParameters < TiledMap > { boolean yUp = true ; } protected static final int FLAG_FLIP_HORIZONTALLY = - 2147483648 ; protected static final int FLAG_FLIP_VERTICALLY = 1073741824 ; protected static final int FLAG_FLIP_DIAGONALLY = 536870912 ; protected static final int MASK_CLEAR = - 536870912 ; protected XmlReader xml = new XmlReader ( ) ; protected Element root ; protected boolean yUp ; protected int mapWidthInPixels ; protected int mapHeightInPixels ; public TmxMapLoader ( ) { } public TmxMapLoader ( FileHandleResolver resolver ) { } public TiledMap load ( String fileName ) { } public TiledMap load ( String fileName , boolean yUp ) { } @ Override public TiledMap load ( AssetManager assetManager , String fileName , TmxMapLoader . Parameters parameter ) { } @ Override public Array < AssetDescriptor > getDependencies ( String fileName , TmxMapLoader . Parameters parameter ) { } protected TiledMap loadTilemap ( Element root , FileHandle tmxFile , ImageResolver imageResolver ) { } protected Array < FileHandle > loadTilesets ( Element root , FileHandle tmxFile ) throws IOException { } protected void loadTileSet ( TiledMap map , Element element , FileHandle tmxFile , ImageResolver imageResolver ) { if ( element . getName ( ) . equals ( "tileset" ) ) { String name = element . get ( "name" , null ) ; int firstgid = element . getIntAttribute ( "firstgid" , 1 ) ; int tilewidth = element . getIntAttribute ( "tilewidth" , 0 ) ; int tileheight = element . getIntAttribute ( "tileheight" , 0 ) ; int spacing = element . getIntAttribute ( "spacing" , 0 ) ; int margin = element . getIntAttribute ( "margin" , 0 ) ; String source = element . getAttribute ( "source" , null ) ; FileHandle image = null ; if ( source != null ) { FileHandle tsx = TmxMapLoader . getRelativeFileHandle ( tmxFile , source ) ; try { element = xml . parse ( tsx ) ; name = element . get ( "name" , null ) ; tilewidth = element . getIntAttribute ( "tilewidth" , 0 ) ; tileheight = element . getIntAttribute ( "tileheight" , 0 ) ; spacing = element . getIntAttribute ( "spacing" , 0 ) ; margin = element . getIntAttribute ( "margin" , 0 ) ; String imageSource = element . getChildByName ( "image" ) . getAttribute ( "source" ) ; image = TmxMapLoader . getRelativeFileHandle ( tsx , imageSource ) ; } catch ( IOException e ) { throw new GdxRuntimeException ( "Error<seq2seq4repair_space>parsing<seq2seq4repair_space>external<seq2seq4repair_space>tileset." ) ; } } else { String imageSource = element . getChildByName ( "image" ) . getAttribute ( "source" ) ; image = TmxMapLoader . getRelativeFileHandle ( tmxFile , imageSource ) ; } TextureRegion texture = imageResolver . getImage ( image . path ( ) ) ; TiledMapTileSet tileset = new TiledMapTileSet ( ) ; tileset . setName ( name ) ; int stopWidth = ( texture . getRegionWidth ( ) ) - tilewidth ; int stopHeight = ( texture . getRegionHeight ( ) ) - tileheight ; int id = firstgid ; for ( int y = margin ; y <= stopHeight ; y += tileheight + spacing ) { for ( int x = margin ; x <= stopWidth ; x += tilewidth + spacing ) { <START_BUG> TextureRegion tileRegion = new TextureRegion ( new TextureRegion ( texture , x , y , tilewidth , tileheight ) ) ; <END_BUG> if ( ! ( yUp ) ) { tileRegion . flip ( false , true ) ; } TiledMapTile tile = new com . badlogic . gdx . maps . tiled . tiles . StaticTiledMapTile ( tileRegion ) ; tile . setId ( id ) ; tileset . putTile ( ( id ++ ) , tile ) ; } } Array < Element > tileElements = element . getChildrenByName ( "tile" ) ; for ( Element tileElement : tileElements ) { int localtid = tileElement . getIntAttribute ( "id" , 0 ) ; TiledMapTile tile = tileset . getTile ( ( firstgid + localtid ) ) ; if ( tile != null ) { Element properties = tileElement . getChildByName ( "properties" ) ; if ( properties != null ) { loadProperties ( tile . getProperties ( ) , properties ) ; } } } Element properties = element . getChildByName ( "properties" ) ; if ( properties != null ) { loadProperties ( tileset . getProperties ( ) , properties ) ; } map . getTileSets ( ) . addTileSet ( tileset ) ; } } protected void loadTileLayer ( TiledMap map , Element element ) { } protected void loadObjectGroup ( TiledMap map , Element element ) { } protected void loadObject ( MapLayer layer , Element element ) { } protected void loadProperties ( MapProperties properties , Element element ) { } protected static FileHandle getRelativeFileHandle ( FileHandle file , String path ) { } protected static int unsignedByteToInt ( byte b ) { } }<BUG2FIX>TextureRegion tileRegion = new TextureRegion ( texture , x , y , tilewidth , tileheight ) ;
public class TextureLoader extends AsynchronousAssetLoader < Texture , TextureLoader . TextureParameter > { public static class TextureLoaderInfo { String filename ; TextureData data ; Texture texture ; } TextureLoader . TextureLoaderInfo info = new TextureLoader . TextureLoaderInfo ( ) ; public TextureLoader ( FileHandleResolver resolver ) { } @ Override public void loadAsync ( AssetManager manager , String fileName , FileHandle file , TextureLoader . TextureParameter parameter ) { info . filename = fileName ; <START_BUG> if ( ( parameter == null ) || ( ( parameter != null ) && ( ( parameter . textureData ) == null ) ) ) { <END_BUG> Pixmap pixmap = null ; Format format = null ; boolean genMipMaps = false ; info . texture = null ; if ( parameter != null ) { format = parameter . format ; genMipMaps = parameter . genMipMaps ; info . texture = parameter . texture ; } if ( ! ( fileName . contains ( ".etc1" ) ) ) { if ( fileName . contains ( ".cim" ) ) pixmap = PixmapIO . readCIM ( file ) ; else pixmap = new Pixmap ( file ) ; info . data = new com . badlogic . gdx . graphics . glutils . FileTextureData ( file , pixmap , format , genMipMaps ) ; } else { info . data = new com . badlogic . gdx . graphics . glutils . ETC1TextureData ( file , genMipMaps ) ; } } else { info . data = parameter . textureData ; if ( ! ( info . data . isPrepared ( ) ) ) info . data . prepare ( ) ; info . texture = parameter . texture ; } } @ Override public Texture loadSync ( AssetManager manager , String fileName , FileHandle file , TextureLoader . TextureParameter parameter ) { } @ Override public Array < AssetDescriptor > getDependencies ( String fileName , FileHandle file , TextureLoader . TextureParameter parameter ) { } public static class TextureParameter extends AssetLoaderParameters < Texture > { public Format format = null ; public boolean genMipMaps = false ; public Texture texture = null ; public TextureData textureData = null ; public TextureFilter minFilter = TextureFilter . Nearest ; public TextureFilter magFilter = TextureFilter . Nearest ; public TextureWrap wrapU = TextureWrap . ClampToEdge ; public TextureWrap wrapV = TextureWrap . ClampToEdge ; } }<BUG2FIX>if ( ( parameter == null ) || ( ( parameter . textureData ) == null ) ) {
public void glBlendFunc ( int sfactor , int dfactor ) { } public void glBlendFuncSeparate ( int srcRGB , int dstRGB , int srcAlpha , int dstAlpha ) { } public void glBufferData ( int target , int size , Buffer data , int usage ) { } public void glBufferSubData ( int target , int offset , int size , Buffer data ) { } public int glCheckFramebufferStatus ( int target ) { } public void glClear ( int mask ) { } public void glClearColor ( float red , float green , float blue , float alpha ) { } public void glClearDepthf ( float depth ) { } public void glClearStencil ( int s ) { } public void glColorMask ( boolean red , boolean green , boolean blue , boolean alpha ) { } public void glCompileShader ( int shader ) { } public void glCompressedTexImage2D ( int target , int level , int internalformat , int width , int height , int border , int imageSize , Buffer data ) { } public void glCompressedTexSubImage2D ( int target , int level , int xoffset , int yoffset , int width , int height , int format , int imageSize , Buffer data ) { } public void glCopyTexImage2D ( int target , int level , int internalformat , int x , int y , int width , int height , int border ) { } public void glCopyTexSubImage2D ( int target , int level , int xoffset , int yoffset , int x , int y , int width , int height ) { } public int glCreateProgram ( ) { } public int glCreateShader ( int type ) { } public void glCullFace ( int mode ) { } public void glDeleteBuffers ( int n , IntBuffer buffers ) { } public void glDeleteFramebuffers ( int n , IntBuffer framebuffers ) { } public void glDeleteProgram ( int program ) { } public void glDeleteRenderbuffers ( int n , IntBuffer renderbuffers ) { } public void glDeleteShader ( int shader ) { } public void glDeleteTextures ( int n , IntBuffer textures ) { } public void glDepthFunc ( int func ) { } public void glDepthMask ( boolean flag ) { } public void glDepthRangef ( float zNear , float zFar ) { } public void glDetachShader ( int program , int shader ) { } public void glDisable ( int cap ) { } public void glDisableVertexAttribArray ( int index ) { } public void glDrawArrays ( int mode , int first , int count ) { } public void glDrawElements ( int mode , int count , int type , Buffer indices ) { } public void glEnable ( int cap ) { } public void glEnableVertexAttribArray ( int index ) { } public void glFinish ( ) { } public void glFlush ( ) { } public void glFramebufferRenderbuffer ( int target , int attachment , int renderbuffertarget , int renderbuffer ) { } public void glFramebufferTexture2D ( int target , int attachment , int textarget , int texture , int level ) { } public void glFrontFace ( int mode ) { } public void glGenBuffers ( int n , IntBuffer buffers ) { } public void glGenFramebuffers ( int n , IntBuffer framebuffers ) { } public void glGenRenderbuffers ( int n , IntBuffer renderbuffers ) { } public void glGenTextures ( int n , IntBuffer textures ) { } public void glGenerateMipmap ( int target ) { } public String glGetActiveAttrib ( int program , int index , IntBuffer size , Buffer type ) { } public String glGetActiveUniform ( int program , int index , IntBuffer size , Buffer type ) { IntBuffer typeTmp = BufferUtils . createIntBuffer ( 2 ) ; String name = org . lwjgl . opengl . GL20 . glGetActiveUniform ( program , index , 256 , typeTmp ) ; size . put ( typeTmp . get ( 0 ) ) ; if ( type instanceof IntBuffer ) <START_BUG> ( ( IntBuffer ) ( type ) ) . put ( typeTmp . get ( 0 ) ) ; <END_BUG> return name ; } public void glGetAttachedShaders ( int program , int maxcount , Buffer count , IntBuffer shaders ) { } public int glGetAttribLocation ( int program , String name ) { } public void glGetBooleanv ( int pname , Buffer params ) { } public void glGetBufferParameteriv ( int target , int pname , IntBuffer params ) { } public int glGetError ( ) { } public void glGetFloatv ( int pname , FloatBuffer params ) { } public void glGetFramebufferAttachmentParameteriv ( int target , int attachment , int pname , IntBuffer params ) { } public void glGetIntegerv ( int pname , IntBuffer params ) { } public String glGetProgramInfoLog ( int program ) { } public void glGetProgramiv ( int program , int pname , IntBuffer params ) { } public void glGetRenderbufferParameteriv ( int target , int pname , IntBuffer params ) { } public String glGetShaderInfoLog ( int shader ) { } public void glGetShaderPrecisionFormat ( int shadertype , int precisiontype , IntBuffer range , IntBuffer precision ) { } public void glGetShaderiv ( int shader , int pname , IntBuffer params ) { } public String glGetString ( int name ) { } public void glGetTexParameterfv ( int target , int pname , FloatBuffer params ) { } public void glGetTexParameteriv ( int target , int pname , IntBuffer params ) { } public int glGetUniformLocation ( int program , String name ) { } public void glGetUniformfv ( int program , int location , FloatBuffer params ) { } public void glGetUniformiv ( int program , int location , IntBuffer params ) { } public void glGetVertexAttribPointerv ( int index , int pname , Buffer pointer ) { } public void glGetVertexAttribfv ( int index , int pname , FloatBuffer params ) { }<BUG2FIX>( ( IntBuffer ) ( type ) ) . put ( typeTmp . get ( 1 ) ) ;
public abstract class SearchContext implements Releasable { private static ThreadLocal < SearchContext > current = new ThreadLocal < > ( ) ; public static void setCurrent ( SearchContext value ) { } public static void removeCurrent ( ) { } public static SearchContext current ( ) { } <START_BUG> public abstract boolean clearAndRelease ( ) ; <END_BUG> public abstract void preProcess ( ) { } public abstract Filter searchFilter ( String [ ] types ) { } public abstract long id ( ) { } public abstract String source ( ) { } public abstract ShardSearchRequest request ( ) { } public abstract SearchType searchType ( ) { } public abstract SearchContext searchType ( SearchType searchType ) { } public abstract SearchShardTarget shardTarget ( ) { } public abstract int numberOfShards ( ) { } public abstract boolean hasTypes ( ) { } public abstract String [ ] types ( ) { } public abstract float queryBoost ( ) { } public abstract SearchContext queryBoost ( float queryBoost ) { } public abstract long nowInMillis ( ) { } public abstract Scroll scroll ( ) { } public abstract SearchContext scroll ( Scroll scroll ) { } public abstract SearchContextAggregations aggregations ( ) { } public abstract SearchContext aggregations ( SearchContextAggregations aggregations ) { } public abstract SearchContextFacets facets ( ) { } public abstract SearchContext facets ( SearchContextFacets facets ) { } public abstract SearchContextHighlight highlight ( ) { } public abstract void highlight ( SearchContextHighlight highlight ) { } public abstract SuggestionSearchContext suggest ( ) { } public abstract void suggest ( SuggestionSearchContext suggest ) { } public abstract List < RescoreSearchContext > rescore ( ) { } public abstract void addRescore ( RescoreSearchContext rescore ) { } public abstract boolean hasFieldDataFields ( ) { } public abstract FieldDataFieldsContext fieldDataFields ( ) { } public abstract boolean hasScriptFields ( ) { } public abstract ScriptFieldsContext scriptFields ( ) { } public abstract boolean hasPartialFields ( ) { } public abstract PartialFieldsContext partialFields ( ) { } public abstract boolean sourceRequested ( ) { } public abstract boolean hasFetchSourceContext ( ) { } public abstract FetchSourceContext fetchSourceContext ( ) { } public abstract SearchContext fetchSourceContext ( FetchSourceContext fetchSourceContext ) { } public abstract ContextIndexSearcher searcher ( ) { } public abstract IndexShard indexShard ( ) { } public abstract MapperService mapperService ( ) { } public abstract AnalysisService analysisService ( ) { } public abstract IndexQueryParserService queryParserService ( ) { } public abstract SimilarityService similarityService ( ) { } public abstract ScriptService scriptService ( ) { } public abstract CacheRecycler cacheRecycler ( ) { } public abstract PageCacheRecycler pageCacheRecycler ( ) { } public abstract BigArrays bigArrays ( ) { } public abstract FilterCache filterCache ( ) { } public abstract DocSetCache docSetCache ( ) { } public abstract IndexFieldDataService fieldData ( ) { } public abstract long timeoutInMillis ( ) { } public abstract void timeoutInMillis ( long timeoutInMillis ) { } public abstract SearchContext minimumScore ( float minimumScore ) { } public abstract Float minimumScore ( ) { } public abstract SearchContext sort ( Sort sort ) { } public abstract Sort sort ( ) { } public abstract SearchContext trackScores ( boolean trackScores ) { } public abstract boolean trackScores ( ) { } public abstract SearchContext parsedPostFilter ( ParsedFilter postFilter ) { } public abstract ParsedFilter parsedPostFilter ( ) { } public abstract Filter aliasFilter ( ) { } public abstract SearchContext parsedQuery ( ParsedQuery query ) { } public abstract ParsedQuery parsedQuery ( ) { } public abstract Query query ( ) { } public abstract boolean queryRewritten ( ) { } public abstract SearchContext updateRewriteQuery ( Query rewriteQuery ) { } public abstract int from ( ) { } public abstract SearchContext from ( int from ) { } public abstract int size ( ) { } public abstract SearchContext size ( int size ) { } public abstract boolean hasFieldNames ( ) { } public abstract List < String > fieldNames ( ) { } public abstract void emptyFieldNames ( ) { } public abstract boolean explain ( ) { } public abstract void explain ( boolean explain ) { } @ Nullable public abstract List < String > groupStats ( ) { } public abstract void groupStats ( List < String > groupStats ) { } public abstract boolean version ( ) { } public abstract void version ( boolean version ) { } public abstract int [ ] docIdsToLoad ( ) { } public abstract int docIdsToLoadFrom ( ) { } public abstract int docIdsToLoadSize ( ) { } public abstract SearchContext docIdsToLoad ( int [ ] docIdsToLoad , int docsIdsToLoadFrom , int docsIdsToLoadSize ) { } public abstract void accessed ( long accessTime ) { } public abstract long lastAccessTime ( ) { } public abstract long keepAlive ( ) { } public abstract void keepAlive ( long keepAlive ) { } public abstract void lastEmittedDoc ( ScoreDoc doc ) { } public abstract ScoreDoc lastEmittedDoc ( ) { } public abstract SearchLookup lookup ( ) { } public abstract DfsSearchResult dfsResult ( ) { } public abstract QuerySearchResult queryResult ( ) { } public abstract FetchSearchResult fetchResult ( ) { } public abstract void addReleasable ( Releasable releasable ) { } public abstract void clearReleasables ( ) { } public abstract ScanContext scanContext ( ) { } public abstract SmartNameFieldMappers smartFieldMappers ( String name ) { } public abstract FieldMappers smartNameFieldMappers ( String name ) { } public abstract FieldMapper smartNameFieldMapper ( String name ) { } public abstract SmartNameObjectMapper smartNameObjectMapper ( String name ) { } public abstract boolean useSlowScroll ( ) { } public abstract SearchContext useSlowScroll ( boolean useSlowScroll ) { } }<BUG2FIX>public abstract void clearAndRelease ( ) ;
public abstract class Screen { private final String [ ] chars = new String [ ] { "ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789" , ".,!?:;\"\'+-=/\\<<seq2seq4repair_space>" } ; protected static Random random = new Random ( ) ; private Metagun metagun ; public SpriteBatch spriteBatch ; public void removed ( ) { } public final void init ( Metagun metagun ) { } protected void setScreen ( Screen screen ) { } public void draw ( TextureRegion region , int x , int y ) { int width = region . getRegionWidth ( ) ; if ( width < 0 ) width = - width ; <START_BUG> spriteBatch . draw ( region , x , y , width , ( - ( region . getRegionHeight ( ) ) ) ) ; <END_BUG> } public void drawString ( String string , int x , int y ) { } public abstract void render ( ) { } public void tick ( Input input ) { } }<BUG2FIX>spriteBatch . draw ( region , x , y , width , region . getRegionHeight ( ) ) ;
public class ScrollPane2Test extends GdxTest { Stage stage ; Skin skin ; public void create ( ) { } public void render ( ) { } public void resize ( int width , int height ) { <START_BUG> stage . getViewport ( ) . update ( width , height ) ; <END_BUG> } @ Override public void dispose ( ) { } }<BUG2FIX>stage . getViewport ( ) . update ( width , height , true ) ;
public abstract class BlobStoreIndexShardGateway extends AbstractIndexShardComponent implements IndexShardGateway { protected final ThreadPool threadPool ; protected final InternalIndexShard indexShard ; protected final Store store ; protected final ByteSizeValue chunkSize ; protected final BlobStore blobStore ; protected final BlobPath shardPath ; protected final ImmutableBlobContainer blobContainer ; private volatile RecoveryStatus recoveryStatus ; private volatile SnapshotStatus lastSnapshotStatus ; private volatile SnapshotStatus currentSnapshotStatus ; protected BlobStoreIndexShardGateway ( ShardId shardId , @ IndexSettings Settings indexSettings , ThreadPool threadPool , IndexGateway indexGateway , IndexShard indexShard , Store store ) { } @ Override public RecoveryStatus recoveryStatus ( ) { } @ Override public String toString ( ) { } @ Override public boolean requiresSnapshot ( ) { } @ Override public boolean requiresSnapshotScheduling ( ) { } @ Override public SnapshotLock obtainSnapshotLock ( ) throws Exception { } @ Override public void close ( ) throws ElasticSearchException { } @ Override public SnapshotStatus lastSnapshotStatus ( ) { } @ Override public SnapshotStatus currentSnapshotStatus ( ) { } @ Override public SnapshotStatus snapshot ( final Snapshot snapshot ) throws IndexShardGatewaySnapshotFailedException { } private void doSnapshot ( final Snapshot snapshot ) throws IndexShardGatewaySnapshotFailedException { } @ Override public void recover ( boolean indexShouldExists , RecoveryStatus recoveryStatus ) throws IndexShardGatewayRecoveryException { } private void recoverTranslog ( CommitPoint commitPoint , ImmutableMap < String , BlobMetaData > blobs ) throws IndexShardGatewayRecoveryException { if ( commitPoint . translogFiles ( ) . isEmpty ( ) ) { recoveryStatus . start ( ) . startTime ( System . currentTimeMillis ( ) ) ; recoveryStatus . updateStage ( START ) ; indexShard . postRecovery ( "post<seq2seq4repair_space>recovery<seq2seq4repair_space>from<seq2seq4repair_space>gateway,<seq2seq4repair_space>no<seq2seq4repair_space>translog" ) ; recoveryStatus . start ( ) . time ( ( ( System . currentTimeMillis ( ) ) - ( recoveryStatus . start ( ) . startTime ( ) ) ) ) ; recoveryStatus . start ( ) . checkIndexTime ( indexShard . checkIndexTook ( ) ) ; return ; } try { recoveryStatus . start ( ) . startTime ( System . currentTimeMillis ( ) ) ; recoveryStatus . updateStage ( START ) ; indexShard . performRecoveryPrepareForTranslog ( ) ; recoveryStatus . start ( ) . time ( ( ( System . currentTimeMillis ( ) ) - ( recoveryStatus . start ( ) . startTime ( ) ) ) ) ; recoveryStatus . start ( ) . checkIndexTime ( indexShard . checkIndexTook ( ) ) ; recoveryStatus . updateStage ( TRANSLOG ) ; recoveryStatus . translog ( ) . startTime ( System . currentTimeMillis ( ) ) ; final AtomicReference < Throwable > failure = new AtomicReference < Throwable > ( ) ; final CountDownLatch latch = new CountDownLatch ( 1 ) ; final Iterator < CommitPoint . FileInfo > transIt = commitPoint . translogFiles ( ) . iterator ( ) ; blobContainer . readBlob ( transIt . next ( ) . name ( ) , new BlobContainer . ReadBlobListener ( ) { BytesStreamOutput bos = new BytesStreamOutput ( ) ; boolean ignore = false ; @ Override public synchronized void onPartial ( byte [ ] data , int offset , int size ) throws IOException { if ( ignore ) { return ; } bos . write ( data , offset , size ) ; if ( ( bos . size ( ) ) < 4 ) { return ; } BytesStreamInput si = new BytesStreamInput ( bos . bytes ( ) ) ; int position ; while ( true ) { try { position = si . position ( ) ; if ( ( position + 4 ) > ( bos . size ( ) ) ) { break ; } int opSize = si . readInt ( ) ; int curPos = si . position ( ) ; if ( ( ( si . position ( ) ) + opSize ) > ( bos . size ( ) ) ) { break ; } Translog . Operation operation = TranslogStreams . readTranslogOperation ( si ) ; if ( ( ( si . position ( ) ) - curPos ) != opSize ) { logger . warn ( "mismatch<seq2seq4repair_space>in<seq2seq4repair_space>size,<seq2seq4repair_space>expected<seq2seq4repair_space>[{}],<seq2seq4repair_space>got<seq2seq4repair_space>[{}]" , opSize , ( ( si . position ( ) ) - curPos ) ) ; } recoveryStatus . translog ( ) . addTranslogOperations ( 1 ) ; indexShard . performRecoveryOperation ( operation ) ; if ( ( si . position ( ) ) >= ( bos . size ( ) ) ) { position = si . position ( ) ; break ; } <START_BUG> } catch ( Exception e ) { <END_BUG> logger . warn ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>retrieve<seq2seq4repair_space>translog<seq2seq4repair_space>after<seq2seq4repair_space>[{}]<seq2seq4repair_space>operations,<seq2seq4repair_space>ignoring<seq2seq4repair_space>the<seq2seq4repair_space>rest,<seq2seq4repair_space>considered<seq2seq4repair_space>corrupted" , e , recoveryStatus . translog ( ) . currentTranslogOperations ( ) ) ; ignore = true ; latch . countDown ( ) ; return ; } } BytesStreamOutput newBos = new BytesStreamOutput ( ) ; int leftOver = ( bos . size ( ) ) - position ; if ( leftOver > 0 ) { newBos . write ( bos . bytes ( ) . array ( ) , position , leftOver ) ; } bos = newBos ; } @ Override public synchronized void onCompleted ( ) { if ( ignore ) { return ; } if ( ! ( transIt . hasNext ( ) ) ) { latch . countDown ( ) ; return ; } blobContainer . readBlob ( transIt . next ( ) . name ( ) , this ) ; } @ Override public void onFailure ( Throwable t ) { failure . set ( t ) ; latch . countDown ( ) ; } } ) ; latch . await ( ) ; if ( ( failure . get ( ) ) != null ) { throw failure . get ( ) ; } indexShard . performRecoveryFinalization ( true ) ; recoveryStatus . translog ( ) . time ( ( ( System . currentTimeMillis ( ) ) - ( recoveryStatus . translog ( ) . startTime ( ) ) ) ) ; } catch ( Throwable e ) { throw new IndexShardGatewayRecoveryException ( shardId , "Failed<seq2seq4repair_space>to<seq2seq4repair_space>recover<seq2seq4repair_space>translog" , e ) ; } }<BUG2FIX>} catch ( Throwable e ) {
if . put ( templates . get ( i ) . settings ( ) ) ; } indexSettingsBuilder . put ( request . settings ) ; if ( request . index . equals ( INDEX_NAME ) ) { indexSettingsBuilder . put ( SETTING_NUMBER_OF_SHARDS , 1 ) ; } else { if ( ( indexSettingsBuilder . get ( SETTING_NUMBER_OF_SHARDS ) ) == null ) { if ( request . index . equals ( riverIndexName ) ) { indexSettingsBuilder . put ( SETTING_NUMBER_OF_SHARDS , settings . getAsInt ( SETTING_NUMBER_OF_SHARDS , 1 ) ) ; } else { indexSettingsBuilder . put ( SETTING_NUMBER_OF_SHARDS , settings . getAsInt ( SETTING_NUMBER_OF_SHARDS , 5 ) ) ; } } } if ( request . index . equals ( INDEX_NAME ) ) { indexSettingsBuilder . put ( SETTING_NUMBER_OF_REPLICAS , 0 ) ; indexSettingsBuilder . put ( SETTING_AUTO_EXPAND_REPLICAS , "0-all" ) ; } else { if ( ( indexSettingsBuilder . get ( SETTING_NUMBER_OF_REPLICAS ) ) == null ) { if ( request . index . equals ( riverIndexName ) ) { indexSettingsBuilder . put ( SETTING_NUMBER_OF_REPLICAS , settings . getAsInt ( SETTING_NUMBER_OF_REPLICAS , 1 ) ) ; } else { indexSettingsBuilder . put ( SETTING_NUMBER_OF_REPLICAS , settings . getAsInt ( SETTING_NUMBER_OF_REPLICAS , 1 ) ) ; } } } if ( ( ( settings . get ( SETTING_AUTO_EXPAND_REPLICAS ) ) != null ) && ( ( indexSettingsBuilder . get ( SETTING_AUTO_EXPAND_REPLICAS ) ) == null ) ) { indexSettingsBuilder . put ( SETTING_AUTO_EXPAND_REPLICAS , settings . get ( SETTING_AUTO_EXPAND_REPLICAS ) ) ; } indexSettingsBuilder . put ( SETTING_VERSION_CREATED , CURRENT ) ; Settings actualIndexSettings = indexSettingsBuilder . build ( ) ; indicesService . createIndex ( request . index , actualIndexSettings , clusterService . state ( ) . nodes ( ) . localNode ( ) . id ( ) ) ; IndexService indexService = indicesService . indexServiceSafe ( request . index ) ; MapperService mapperService = indexService . mapperService ( ) ; if ( mappings . containsKey ( DEFAULT_MAPPING ) ) { try { mapperService . merge ( DEFAULT_MAPPING , XContentFactory . jsonBuilder ( ) . map ( mappings . get ( DEFAULT_MAPPING ) ) . string ( ) , false ) ; } catch ( Exception e ) { indicesService . deleteIndex ( request . index , "failed<seq2seq4repair_space>on<seq2seq4repair_space>parsing<seq2seq4repair_space>default<seq2seq4repair_space>mapping<seq2seq4repair_space>on<seq2seq4repair_space>index<seq2seq4repair_space>creation" ) ; throw new MapperParsingException ( ( ( "mapping<seq2seq4repair_space>[" + ( MapperService . DEFAULT_MAPPING ) ) + "]" ) , e ) ; } } for ( Map . Entry < String , Map < String , Object > > entry : mappings . entrySet ( ) ) { if ( entry . getKey ( ) . equals ( DEFAULT_MAPPING ) ) { continue ; } try { mapperService . merge ( entry . getKey ( ) , XContentFactory . jsonBuilder ( ) . map ( entry . getValue ( ) ) . string ( ) , true ) ; } catch ( Exception e ) { indicesService . deleteIndex ( request . index , "failed<seq2seq4repair_space>on<seq2seq4repair_space>parsing<seq2seq4repair_space>mappings<seq2seq4repair_space>on<seq2seq4repair_space>index<seq2seq4repair_space>creation" ) ; throw new MapperParsingException ( ( ( "mapping<seq2seq4repair_space>[" + ( entry . getKey ( ) ) ) + "]" ) , e ) ; } } Map < String , MappingMetaData > mappingsMetaData = Maps . newHashMap ( ) ; for ( DocumentMapper mapper : mapperService ) { MappingMetaData mappingMd = new MappingMetaData ( mapper ) ; mappingsMetaData . put ( mapper . type ( ) , mappingMd ) ; } final IndexMetaData . IndexMetaData . Builder indexMetaDataBuilder = newIndexMetaDataBuilder ( request . index ) . settings ( actualIndexSettings ) ; for ( MappingMetaData mappingMd : mappingsMetaData . values ( ) ) { indexMetaDataBuilder . putMapping ( mappingMd ) ; } for ( Map . Entry < String , Custom > customEntry : customs . entrySet ( ) ) { indexMetaDataBuilder . putCustom ( customEntry . getKey ( ) , customEntry . getValue ( ) ) ; } indexMetaDataBuilder . state ( request . state ) ; final IndexMetaData . IndexMetaData indexMetaData = indexMetaDataBuilder . build ( ) ; MetaData newMetaData = MetaData . newMetaDataBuilder ( ) . metaData ( currentState . metaData ( ) ) . put ( indexMetaData , false ) . build ( ) ; logger . info ( "[{}]<seq2seq4repair_space>creating<seq2seq4repair_space>index,<seq2seq4repair_space>cause<seq2seq4repair_space>[{}],<seq2seq4repair_space>shards<seq2seq4repair_space>[{}]/[{}],<seq2seq4repair_space>mappings<seq2seq4repair_space>{}" , request . index , request . cause , indexMetaData . numberOfShards ( ) , indexMetaData . numberOfReplicas ( ) , mappings . keySet ( ) ) ; ClusterBlocks . Builder blocks = ClusterBlocks . builder ( ) . blocks ( currentState . blocks ( ) ) ; if ( ! ( request . blocks . isEmpty ( ) ) ) { for ( ClusterBlock block : request . blocks ) { blocks . addIndexBlock ( request . index , block ) ; } } if ( ( request . state ) == ( State . CLOSE ) ) { blocks . addIndexBlock ( request . index , INDEX_CLOSED_BLOCK ) ; } ClusterState updatedState = ClusterState . newClusterStateBuilder ( ) . state ( currentState ) . blocks ( blocks ) . metaData ( newMetaData ) . build ( ) ; if ( ( request . state ) == ( State . OPEN ) ) { RoutingTable . Builder routingTableBuilder = RoutingTable . builder ( ) . routingTable ( updatedState . routingTable ( ) ) . addAsNew ( updatedState . metaData ( ) . index ( request . index ) ) ; RoutingAllocation . Result routingResult = allocationService . reroute ( ClusterState . newClusterStateBuilder ( ) . state ( updatedState ) . routingTable ( routingTableBuilder ) . build ( ) ) ; updatedState = ClusterState . newClusterStateBuilder ( ) . state ( updatedState ) . routingResult ( routingResult ) . build ( ) ; } final AtomicInteger counter = new AtomicInteger ( currentState . nodes ( ) . size ( ) ) ; final NodeIndexCreatedAction . Listener nodeIndexCreatedListener = new NodeIndexCreatedAction . Listener ( ) { @ Override public void onNodeIndexCreated ( String index , String nodeId ) { if ( index . equals ( request . index ) ) { if ( ( counter . decrementAndGet ( ) ) == 0 ) { listener . onResponse ( new MetaDataCreateIndexService . Response ( true , indexMetaData ) ) ; nodeIndexCreatedAction . remove ( this ) ; } } } } ; nodeIndexCreatedAction . add ( nodeIndexCreatedListener ) ; listener . future = threadPool . schedule ( request . timeout , SAME , new Runnable ( ) { @ Override public void run ( ) { listener . onResponse ( new MetaDataCreateIndexService . Response ( false , indexMetaData ) ) ; nodeIndexCreatedAction . remove ( nodeIndexCreatedListener ) ; } } ) ; return updatedState ; <START_BUG> } catch ( Exception e ) { <END_BUG><BUG2FIX>} catch ( Throwable e ) {
public abstract class AbstractThreadPool extends AbstractComponent implements ThreadPool { protected volatile boolean started ; protected ExecutorService executorService ; protected ScheduledExecutorService scheduledExecutorService ; protected ExecutorService cached ; protected AbstractThreadPool ( Settings settings ) { } public abstract String getType ( ) { } @ Override public ThreadPoolInfo info ( ) { } @ Override public ThreadPoolStats stats ( ) { } @ Override public boolean isStarted ( ) { } @ Override public Executor cached ( ) { } @ Override public ScheduledFuture < ? > schedule ( Runnable command , long delay , TimeUnit unit ) { } @ Override public < V > ScheduledFuture < V > schedule ( Callable < V > callable , long delay , TimeUnit unit ) { } @ Override public ScheduledFuture < ? > scheduleAtFixedRate ( Runnable command , long initialDelay , long period , TimeUnit unit ) { } @ Override public ScheduledFuture < ? > scheduleWithFixedDelay ( Runnable command , long initialDelay , long delay , TimeUnit unit ) { } @ Override public ScheduledFuture < ? > scheduleWithFixedDelay ( Runnable command , TimeValue interval ) { } @ Override public void shutdown ( ) { } @ Override public void shutdownNow ( ) { started = false ; if ( ! ( executorService . isTerminated ( ) ) ) { executorService . shutdownNow ( ) ; } <START_BUG> if ( ! ( executorService . isTerminated ( ) ) ) { <END_BUG> scheduledExecutorService . shutdownNow ( ) ; } if ( ! ( cached . isTerminated ( ) ) ) { cached . shutdownNow ( ) ; } } @ Override public boolean awaitTermination ( long timeout , TimeUnit unit ) throws InterruptedException { } @ Override public ScheduledFuture < ? > schedule ( Runnable command , TimeValue delay ) { } @ Override public void execute ( Runnable command ) { } protected static class FutureCallable < T > implements Callable < T > { private final Callable < T > callable ; private final FutureListener < T > listener ; public FutureCallable ( Callable < T > callable , FutureListener < T > listener ) { } @ Override public T call ( ) throws Exception { } } protected static class FutureRunnable < T > implements Runnable { private final Runnable runnable ; private final T result ; private final FutureListener < T > listener ; private FutureRunnable ( Runnable runnable , T result , FutureListener < T > listener ) { } @ Override public void run ( ) { } } }<BUG2FIX>if ( ! ( scheduledExecutorService . isTerminated ( ) ) ) {
public class TransportCountAction extends TransportBroadcastOperationAction < CountRequest , CountResponse , ShardCountRequest , ShardCountResponse > { private final IndicesService indicesService ; private final ScriptService scriptService ; private final CacheRecycler cacheRecycler ; private final PageCacheRecycler pageCacheRecycler ; private final BigArrays bigArrays ; @ Inject public TransportCountAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportService transportService , IndicesService indicesService , ScriptService scriptService , CacheRecycler cacheRecycler , PageCacheRecycler pageCacheRecycler , BigArrays bigArrays ) { } @ Override protected void doExecute ( CountRequest request , ActionListener < CountResponse > listener ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected CountRequest newRequest ( ) { } @ Override protected ShardCountRequest newShardRequest ( ) { } @ Override protected ShardCountRequest newShardRequest ( ShardRouting shard , CountRequest request ) { } @ Override protected ShardCountResponse newShardResponse ( ) { } @ Override protected GroupShardsIterator shards ( ClusterState clusterState , CountRequest request , String [ ] concreteIndices ) { } @ Override protected ClusterBlockException checkGlobalBlock ( ClusterState state , CountRequest request ) { } @ Override protected ClusterBlockException checkRequestBlock ( ClusterState state , CountRequest countRequest , String [ ] concreteIndices ) { } @ Override protected CountResponse newResponse ( CountRequest request , AtomicReferenceArray shardsResponses , ClusterState clusterState ) { } @ Override protected ShardCountResponse shardOperation ( ShardCountRequest request ) throws ElasticsearchException { IndexService indexService = indicesService . indexServiceSafe ( request . index ( ) ) ; IndexShard indexShard = indexService . shardSafe ( request . shardId ( ) ) ; SearchShardTarget shardTarget = new SearchShardTarget ( clusterService . localNode ( ) . id ( ) , request . index ( ) , request . shardId ( ) ) ; SearchContext context = new org . elasticsearch . search . internal . DefaultSearchContext ( 0 , new ShardSearchRequest ( ) . types ( request . types ( ) ) . filteringAliases ( request . filteringAliases ( ) ) . nowInMillis ( request . nowInMillis ( ) ) , shardTarget , indexShard . acquireSearcher ( "count" ) , indexService , indexShard , scriptService , cacheRecycler , pageCacheRecycler , bigArrays ) ; SearchContext . setCurrent ( context ) ; try { if ( ( request . minScore ( ) ) != ( - 1 ) ) { context . minimumScore ( request . minScore ( ) ) ; } BytesReference source = request . querySource ( ) ; if ( ( source != null ) && ( ( source . length ( ) ) > 0 ) ) { try { QueryParseContext . setTypes ( request . types ( ) ) ; context . parsedQuery ( indexService . queryParserService ( ) . parseQuery ( source ) ) ; } finally { QueryParseContext . removeTypes ( ) ; } } context . preProcess ( ) ; try { long count = Lucene . count ( context . searcher ( ) , context . query ( ) ) ; return new ShardCountResponse ( request . index ( ) , request . shardId ( ) , count ) ; } catch ( Exception e ) { throw new org . elasticsearch . search . query . QueryPhaseExecutionException ( context , "failed<seq2seq4repair_space>to<seq2seq4repair_space>execute<seq2seq4repair_space>count" , e ) ; } } finally { <START_BUG> context . release ( ) ; <END_BUG> SearchContext . removeCurrent ( ) ; } } }<BUG2FIX>context . close ( ) ;
public class DiscoveryModule extends AbstractModule { private final Settings settings ; public DiscoveryModule ( Settings settings ) { } @ Override protected void configure ( ) { <START_BUG> Class < ? extends Module > defaultDiscoveryModule = null ; <END_BUG> if ( settings . getAsBoolean ( "node.local" , false ) ) { defaultDiscoveryModule = LocalDiscoveryModule . class ; } else { try { Classes . getDefaultClassLoader ( ) . loadClass ( "org.elasticsearch.discovery.jgroups.JgroupsDiscovery" ) ; defaultDiscoveryModule = ( ( Class < ? extends Module > ) ( Classes . getDefaultClassLoader ( ) . loadClass ( "org.elasticsearch.discovery.jgroups.JgroupsDiscoveryModule" ) ) ) ; } catch ( ClassNotFoundException e ) { defaultDiscoveryModule = LocalDiscoveryModule . class ; } } Class < ? extends Module > moduleClass = settings . getAsClass ( "discovery.type" , defaultDiscoveryModule , "org.elasticsearch.discovery." , "DiscoveryModule" ) ; createModule ( moduleClass , settings ) . configure ( binder ( ) ) ; bind ( DiscoveryService . class ) . asEagerSingleton ( ) ; } }<BUG2FIX>Class < ? extends Module > defaultDiscoveryModule ;
public final class EngineSearcherTotalHitsMatcher extends TypeSafeMatcher < Engine . Searcher > { private final Query query ; private final int totalHits ; public EngineSearcherTotalHitsMatcher ( Query query , int totalHits ) { } @ Override public boolean matchesSafely ( Engine . Searcher searcher ) { try { <START_BUG> long count = Lucene . count ( searcher . searcher ( ) , query , ( - 1.0F ) ) ; <END_BUG> return count == ( totalHits ) ; } catch ( IOException e ) { return false ; } } @ Override public void describeTo ( Description description ) { } public static Matcher < Engine . Searcher > engineSearcherTotalHits ( Query query , int totalHits ) { } public static Matcher < Engine . Searcher > engineSearcherTotalHits ( int totalHits ) { } }<BUG2FIX>long count = Lucene . count ( searcher . searcher ( ) , query ) ;
public class TransportSearchAction extends TransportAction < SearchRequest , SearchResponse > { private final ClusterService clusterService ; private final TransportSearchDfsQueryThenFetchAction dfsQueryThenFetchAction ; private final TransportSearchQueryThenFetchAction queryThenFetchAction ; private final TransportSearchDfsQueryAndFetchAction dfsQueryAndFetchAction ; private final TransportSearchQueryAndFetchAction queryAndFetchAction ; private final TransportSearchScanAction scanAction ; private final TransportSearchCountAction countAction ; private final boolean optimizeSingleShard ; @ Inject public TransportSearchAction ( Settings settings , ThreadPool threadPool , TransportService transportService , ClusterService clusterService , TransportSearchDfsQueryThenFetchAction dfsQueryThenFetchAction , TransportSearchQueryThenFetchAction queryThenFetchAction , TransportSearchDfsQueryAndFetchAction dfsQueryAndFetchAction , TransportSearchQueryAndFetchAction queryAndFetchAction , TransportSearchScanAction scanAction , TransportSearchCountAction countAction ) { } @ Override protected void doExecute ( SearchRequest searchRequest , ActionListener < SearchResponse > listener ) { if ( ( ( optimizeSingleShard ) && ( ( searchRequest . searchType ( ) ) != ( SCAN ) ) ) && ( ( searchRequest . searchType ( ) ) != ( COUNT ) ) ) { try { ClusterState clusterState = clusterService . state ( ) ; <START_BUG> String [ ] concreteIndices = clusterState . metaData ( ) . concreteIndices ( searchRequest . indices ( ) , searchRequest . indicesOptions ( ) ) ; <END_BUG> Map < String , Set < String > > routingMap = clusterState . metaData ( ) . resolveSearchRouting ( searchRequest . routing ( ) , searchRequest . indices ( ) ) ; int shardCount = clusterService . operationRouting ( ) . searchShardsCount ( clusterState , searchRequest . indices ( ) , concreteIndices , routingMap , searchRequest . preference ( ) ) ; if ( shardCount == 1 ) { searchRequest . searchType ( QUERY_AND_FETCH ) ; } } catch ( IndexMissingException e ) { } catch ( Exception e ) { logger . debug ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>optimize<seq2seq4repair_space>search<seq2seq4repair_space>type,<seq2seq4repair_space>continue<seq2seq4repair_space>as<seq2seq4repair_space>normal" , e ) ; } } if ( ( searchRequest . searchType ( ) ) == ( DFS_QUERY_THEN_FETCH ) ) { dfsQueryThenFetchAction . execute ( searchRequest , listener ) ; } else if ( ( searchRequest . searchType ( ) ) == ( SearchType . SearchType . QUERY_THEN_FETCH ) ) { queryThenFetchAction . execute ( searchRequest , listener ) ; } else if ( ( searchRequest . searchType ( ) ) == ( SearchType . SearchType . DFS_QUERY_AND_FETCH ) ) { dfsQueryAndFetchAction . execute ( searchRequest , listener ) ; } else if ( ( searchRequest . searchType ( ) ) == ( SearchType . SearchType . QUERY_AND_FETCH ) ) { queryAndFetchAction . execute ( searchRequest , listener ) ; } else if ( ( searchRequest . searchType ( ) ) == ( SearchType . SearchType . SCAN ) ) { scanAction . execute ( searchRequest , listener ) ; } else if ( ( searchRequest . searchType ( ) ) == ( SearchType . SearchType . COUNT ) ) { countAction . execute ( searchRequest , listener ) ; } } private class TransportHandler extends BaseTransportRequestHandler < SearchRequest > { @ Override public SearchRequest newInstance ( ) { } @ Override public void messageReceived ( SearchRequest request , final TransportChannel channel ) throws Exception { } @ Override public String executor ( ) { } } }<BUG2FIX>String [ ] concreteIndices = clusterState . metaData ( ) . concreteIndices ( searchRequest . indicesOptions ( ) , searchRequest . indices ( ) ) ;
public class PublishIndexerClusterStateAction extends AbstractComponent { public static interface NewClusterStateListener { void onNewClusterState ( IndexerClusterState clusterState ) { } } private final TransportService transportService ; private final ClusterService clusterService ; private final PublishIndexerClusterStateAction . NewClusterStateListener listener ; public PublishIndexerClusterStateAction ( Settings settings , TransportService transportService , ClusterService clusterService , PublishIndexerClusterStateAction . NewClusterStateListener listener ) { } public void close ( ) { } public void publish ( IndexerClusterState clusterState ) { } private class PublishClusterStateRequest implements Streamable { private IndexerClusterState clusterState ; private PublishClusterStateRequest ( ) { } private PublishClusterStateRequest ( IndexerClusterState clusterState ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { <START_BUG> clusterState = Builder . readFrom ( in , settings ) ; <END_BUG> } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } private class PublishClusterStateRequestHandler extends BaseTransportRequestHandler < PublishIndexerClusterStateAction . PublishClusterStateRequest > { static final String ACTION = "indexer/state/publish" ; @ Override public PublishIndexerClusterStateAction . PublishClusterStateRequest newInstance ( ) { } @ Override public void messageReceived ( PublishIndexerClusterStateAction . PublishClusterStateRequest request , TransportChannel channel ) throws Exception { } @ Override public boolean spawn ( ) { } } }<BUG2FIX>clusterState = Builder . readFrom ( in ) ;
public abstract class HasChildFilter extends Filter implements ScopePhase . CollectorPhase { final Query childQuery ; final String scope ; final String parentType ; final String childType ; final SearchContext searchContext ; protected HasChildFilter ( Query childQuery , String scope , String parentType , String childType , SearchContext searchContext ) { } public Query query ( ) { } public String scope ( ) { } @ Override public String toString ( ) { } public static HasChildFilter create ( Query childQuery , String scope , String parentType , String childType , SearchContext searchContext , String executionType ) { } static class Bitset extends HasChildFilter { private Map < Object , FixedBitSet > parentDocs ; public Bitset ( Query childQuery , String scope , String parentType , String childType , SearchContext searchContext ) { } public boolean requiresProcessing ( ) { } public Collector collector ( ) { } public void processCollector ( Collector collector ) { } public void clear ( ) { } public DocIdSet getDocIdSet ( IndexReader reader ) throws IOException { if ( ( parentDocs ) == null ) { throw new ElasticSearchIllegalStateException ( "has_child<seq2seq4repair_space>filter/query<seq2seq4repair_space>hasn't<seq2seq4repair_space>executed<seq2seq4repair_space>properly" ) ; } return parentDocs . get ( reader . getCoreCacheKey ( ) ) ; } } static class Uid extends HasChildFilter { THashSet < HashedBytesArray > collectedUids ; Uid ( Query childQuery , String scope , String parentType , String childType , SearchContext searchContext ) { } public boolean requiresProcessing ( ) { } public Collector collector ( ) { } public void processCollector ( Collector collector ) { } public DocIdSet getDocIdSet ( IndexReader reader ) throws IOException { if ( ( collectedUids ) == null ) { throw new ElasticSearchIllegalStateException ( "has_child<seq2seq4repair_space>filter/query<seq2seq4repair_space>hasn't<seq2seq4repair_space>executed<seq2seq4repair_space>properly" ) ; } IdReaderTypeCache idReaderTypeCache = searchContext . idCache ( ) . reader ( reader ) . type ( parentType ) ; if ( idReaderTypeCache != null ) { return new HasChildFilter . Uid . ParentDocSet ( reader , collectedUids , idReaderTypeCache ) ; } else { <START_BUG> return DocIdSet . EMPTY_DOCIDSET ; <END_BUG> } } public void clear ( ) { } static class ParentDocSet extends GetDocSet { final IndexReader reader ; final THashSet < HashedBytesArray > parents ; final IdReaderTypeCache typeCache ; ParentDocSet ( IndexReader reader , THashSet < HashedBytesArray > parents , IdReaderTypeCache typeCache ) { } public boolean get ( int doc ) { } } static class UidCollector extends NoopCollector { final String parentType ; final SearchContext context ; final THashSet < HashedBytesArray > collectedUids ; private IdReaderTypeCache typeCache ; UidCollector ( String parentType , SearchContext context , THashSet < HashedBytesArray > collectedUids ) { } @ Override public void collect ( int doc ) throws IOException { } @ Override public void setNextReader ( IndexReader reader , int docBase ) throws IOException { } } } }<BUG2FIX>return null ;
public class FiltersFunctionScoreQuery extends Query { public static class FilterFunction { public final Filter filter ; public final ScoreFunction function ; public FilterFunction ( Filter filter , ScoreFunction function ) { } @ Override public boolean equals ( Object o ) { if ( ( this ) == o ) return true ; if ( ( o == null ) || ( ( getClass ( ) ) != ( o . getClass ( ) ) ) ) return false ; FiltersFunctionScoreQuery . FilterFunction that = ( ( FiltersFunctionScoreQuery . FilterFunction ) ( o ) ) ; if ( ( filter ) != null ? ! ( filter . equals ( that . filter ) ) : ( that . filter ) != null ) return false ; if ( ( function ) != null ? ! ( function . equals ( that . function ) ) : ( that . function ) != null ) return false ; return true ; } @ Override public int hashCode ( ) { } } public static enum ScoreMode { First , Avg , Max , Sum , Min , Multiply ; } Query subQuery ; final FiltersFunctionScoreQuery . FilterFunction [ ] filterFunctions ; final FiltersFunctionScoreQuery . ScoreMode scoreMode ; final float maxBoost ; protected CombineFunction combineFunction ; public FiltersFunctionScoreQuery ( Query subQuery , FiltersFunctionScoreQuery . ScoreMode scoreMode , FiltersFunctionScoreQuery . FilterFunction [ ] filterFunctions , float maxBoost ) { } public FiltersFunctionScoreQuery setCombineFunction ( CombineFunction combineFunction ) { } public Query getSubQuery ( ) { } public FiltersFunctionScoreQuery . FilterFunction [ ] getFilterFunctions ( ) { } @ Override public Query rewrite ( IndexReader reader ) throws IOException { } @ Override public void extractTerms ( Set < Term > terms ) { } @ Override public Weight createWeight ( IndexSearcher searcher ) throws IOException { } class CustomBoostFactorWeight extends Weight { final Weight subQueryWeight ; final Bits [ ] docSets ; public CustomBoostFactorWeight ( Weight subQueryWeight , int filterFunctionLength ) throws IOException { } public Query getQuery ( ) { } @ Override public float getValueForNormalization ( ) throws IOException { } @ Override public void normalize ( float norm , float topLevelBoost ) { } @ Override public Scorer scorer ( AtomicReaderContext context , boolean scoreDocsInOrder , boolean topScorer , Bits acceptDocs ) throws IOException { } @ Override public Explanation explain ( AtomicReaderContext context , int doc ) throws IOException { } } static class CustomBoostFactorScorer extends Scorer { private final float subQueryBoost ; private final Scorer scorer ; private final FiltersFunctionScoreQuery . FilterFunction [ ] filterFunctions ; private final FiltersFunctionScoreQuery . ScoreMode scoreMode ; private final float maxBoost ; private final Bits [ ] docSets ; private final CombineFunction scoreCombiner ; private CustomBoostFactorScorer ( FiltersFunctionScoreQuery . CustomBoostFactorWeight w , Scorer scorer , FiltersFunctionScoreQuery . ScoreMode scoreMode , FiltersFunctionScoreQuery . FilterFunction [ ] filterFunctions , float maxBoost , Bits [ ] docSets , CombineFunction scoreCombiner ) throws IOException { } @ Override public int docID ( ) { } @ Override public int advance ( int target ) throws IOException { } @ Override public int nextDoc ( ) throws IOException { } @ Override public float score ( ) throws IOException { } @ Override public int freq ( ) throws IOException { } @ Override public long cost ( ) { } } public String toString ( String field ) { } public boolean equals ( Object o ) { <START_BUG> if ( ( getClass ( ) ) != ( o . getClass ( ) ) ) <END_BUG> return false ; FiltersFunctionScoreQuery other = ( ( FiltersFunctionScoreQuery ) ( o ) ) ; if ( ( this . getBoost ( ) ) != ( other . getBoost ( ) ) ) return false ; if ( ! ( this . subQuery . equals ( other . subQuery ) ) ) { return false ; } return Arrays . equals ( this . filterFunctions , other . filterFunctions ) ; } public int hashCode ( ) { } }<BUG2FIX>if ( ( o == null ) || ( ( getClass ( ) ) != ( o . getClass ( ) ) ) )
public class SimpleNumericTests extends ElasticsearchTestCase { @ Test public void testNumericDetectionEnabled ( ) throws Exception { } @ Test public void testNumericDetectionDefault ( ) throws Exception { } @ Test public void testIgnoreMalformedOption ( ) throws Exception { } @ Test public void testCoerceOption ( ) throws Exception { } public void testDocValues ( ) throws Exception { } public void testDocValuesOnNested ( ) throws Exception { } @ Test public void testPrecisionStepDefaultsDetected ( ) throws Exception { } @ Test public void testPrecisionStepDefaultsMapped ( ) throws Exception { } @ Test public void testPrecisionStepExplicit ( ) throws Exception { } private static void assertPrecisionStepEquals ( int expected , IndexableField field ) throws IOException { assertNotNull ( field ) ; assertThat ( field , instanceOf ( Field . class ) ) ; assertEquals ( expected , ( ( Field ) ( field ) ) . fieldType ( ) . numericPrecisionStep ( ) ) ; <START_BUG> TokenStream ts = field . tokenStream ( null ) ; <END_BUG> assertThat ( ts , instanceOf ( NumericTokenStream . class ) ) ; assertEquals ( expected , ( ( NumericTokenStream ) ( ts ) ) . getPrecisionStep ( ) ) ; } }<BUG2FIX>TokenStream ts = field . tokenStream ( null , null ) ;
public class MetagunAndroid extends AndroidApplication { @ Override public void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; <START_BUG> initialize ( new Metagun ( ) , false ) ; <END_BUG> } }<BUG2FIX>initialize ( new Metagun ( ) ) ;
final class LwjglFiles implements Files { private final String externalPath = ( System . getProperty ( "user.home" ) ) + "/" ; public FileHandle getFileHandle ( String filename , FileType type ) { File file = null ; if ( ( type == ( FileType . Absolute ) ) || ( type == ( FileType . Internal ) ) ) file = new File ( filename ) ; else file = new File ( ( ( this . externalPath ) + filename ) ) ; if ( ! ( file . exists ( ) ) ) file = new File ( ( "resources/" + filename ) ) ; if ( ( file . exists ( ) ) == false ) throw new GdxRuntimeException ( ( ( "File<seq2seq4repair_space>'" + filename ) + "'<seq2seq4repair_space>doesn't<seq2seq4repair_space>exist" ) ) ; else <START_BUG> return new LwjglFileHandle ( file ) ; <END_BUG> } public String [ ] listDirectory ( String directory , FileType type ) { } public boolean makeDirectory ( String directory , FileType type ) { } public InputStream readFile ( String fileName , FileType type ) { } public OutputStream writeFile ( String filename , FileType type ) { } }<BUG2FIX>return new LwjglFileHandle ( file , type ) ;
public class Type { String name ; Class clazz ; Class superClass ; Set < Class > assignables = new HashSet < Class > ( ) ; boolean isAbstract ; boolean isInterface ; boolean isPrimitive ; boolean isEnum ; boolean isArray ; boolean isMemberClass ; boolean isStatic ; Field [ ] fields ; Method [ ] methods ; Constructor constructor ; Class componentType ; Object [ ] enumConstants ; public Object newInstance ( ) { } public String getName ( ) { } public Class getClassOfType ( ) { } public Type getSuperclass ( ) { try { <START_BUG> return ( superClass ) == null ? null : ReflectionCache . forName ( superClass . getName ( ) ) ; <END_BUG> } catch ( ClassNotFoundException e ) { return null ; } } public boolean isAssignableFrom ( Type otherType ) { } public Field getField ( String name ) { } public Field [ ] getFields ( ) { } public Field [ ] getDeclaredFields ( ) { } public Method getMethod ( String name , Class ... parameterTypes ) throws NoSuchMethodException { } public Method [ ] getMethods ( ) { } public Method [ ] getDeclaredMethods ( ) { } public Constructor getDeclaredConstructor ( ) throws NoSuchMethodException { } public boolean isAbstract ( ) { } public boolean isInterface ( ) { } public boolean isPrimitive ( ) { } public boolean isEnum ( ) { } public boolean isArray ( ) { } public boolean isMemberClass ( ) { } public boolean isStatic ( ) { } public Class getComponentType ( ) { } public int getArrayLength ( Object obj ) { } public Object getArrayElement ( Object obj , int i ) { } public void setArrayElement ( Object obj , int i , Object value ) { } public Object [ ] getEnumConstants ( ) { } @ Override public String toString ( ) { } }<BUG2FIX>return ReflectionCache . forName ( superClass . getName ( ) ) ;
public class Dialog extends Window { public static float fadeDuration = 0.4F ; Table contentTable ; Table buttonTable ; private Skin skin ; ObjectMap < Actor , Object > values = new ObjectMap ( ) ; public Dialog ( String title , Skin skin ) { } public Dialog ( String title , Skin skin , String windowStyleName ) { } public Dialog ( String title , WindowStyle windowStyle ) { } private void initialize ( ) { setModal ( true ) ; defaults ( ) . space ( 6 ) ; <START_BUG> add ( ( contentTable = new Table ( skin ) ) ) . expand ( ) . fill ( ) ; <END_BUG> row ( ) ; add ( ( buttonTable = new Table ( skin ) ) ) ; contentTable . defaults ( ) . space ( 6 ) ; buttonTable . defaults ( ) . space ( 6 ) ; buttonTable . addListener ( new ChangeListener ( ) { public void changed ( ChangeEvent event , Actor actor ) { while ( ( actor . getParent ( ) ) != ( buttonTable ) ) actor = actor . getParent ( ) ; result ( values . get ( actor ) ) ; hide ( ) ; } } ) ; } public void draw ( SpriteBatch batch , float parentAlpha ) { } public Table getContentTable ( ) { } public Table getButtonTable ( ) { } public Dialog text ( String text ) { } public Dialog text ( String text , LabelStyle labelStyle ) { } public Dialog text ( Label label ) { } public Dialog button ( String text ) { } public Dialog button ( String text , Object object ) { } public Dialog button ( String text , Object object , TextButtonStyle buttonStyle ) { } public Dialog button ( Button button ) { } public Dialog button ( Button button , Object object ) { } public Dialog show ( Stage stage ) { } public void hide ( ) { } public void setObject ( Actor actor , Object object ) { } public Dialog key ( final int keycode , final Object object ) { } protected void result ( Object object ) { } }<BUG2FIX>add ( ( contentTable = new Table ( skin ) ) ) . expand ( ) ;
public abstract class FollowersFragment extends PagedUserFragment { @ Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; <START_BUG> setEmptyText ( getString ( no_followers ) ) ; <END_BUG> } @ Override protected int getLoadingMessage ( ) { } @ Override public void onLoadFinished ( Loader < List < User > > loader , List < User > items ) { } }<BUG2FIX>setEmptyText ( no_followers ) ;
public class AllocationService extends AbstractComponent { private final AllocationDeciders allocationDeciders ; private final ShardsAllocators shardsAllocators ; public AllocationService ( ) { } public AllocationService ( Settings settings ) { } @ Inject public AllocationService ( Settings settings , AllocationDeciders allocationDeciders , ShardsAllocators shardsAllocators ) { } public Result applyStartedShards ( ClusterState clusterState , List < ? extends ShardRouting > startedShards ) { } public Result applyFailedShard ( ClusterState clusterState , ShardRouting failedShard ) { } public Result reroute ( ClusterState clusterState ) { } public Result rerouteWithNoReassign ( ClusterState clusterState ) { } private boolean reroute ( RoutingAllocation allocation ) { } private boolean moveShards ( RoutingAllocation allocation ) { } private boolean electPrimaries ( RoutingNodes routingNodes ) { } private void applyNewNodes ( RoutingNodes routingNodes , Iterable < DiscoveryNode > liveNodes ) { for ( DiscoveryNode node : liveNodes ) { if ( ! ( routingNodes . nodesToShards ( ) . containsKey ( node . id ( ) ) ) ) { <START_BUG> RoutingNode routingNode = new RoutingNode ( node ) ; <END_BUG> routingNodes . nodesToShards ( ) . put ( node . id ( ) , routingNode ) ; } } } private boolean deassociateDeadNodes ( RoutingNodes routingNodes , Iterable < DiscoveryNode > liveNodes ) { } private boolean applyStartedShards ( RoutingNodes routingNodes , Iterable < ? extends ShardRouting > startedShardEntries ) { } private boolean applyFailedShard ( FailedRerouteAllocation allocation ) { } }<BUG2FIX>RoutingNode routingNode = new RoutingNode ( node . id ( ) , node ) ;
public class RestClusterGetSettingsAction extends BaseRestHandler { @ Inject public RestClusterGetSettingsAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { ClusterStateRequest clusterStateRequest = Requests . clusterStateRequest ( ) . listenerThreaded ( false ) . filterRoutingTable ( true ) . filterNodes ( true ) ; client . admin ( ) . cluster ( ) . state ( clusterStateRequest , new org . elasticsearch . action . ActionListener < ClusterStateResponse > ( ) { @ Override public void onResponse ( ClusterStateResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; builder . startObject ( "persistent" ) ; for ( Map . Entry < String , String > entry : response . getState ( ) . metaData ( ) . persistentSettings ( ) . getAsMap ( ) . entrySet ( ) ) { builder . field ( entry . getKey ( ) , entry . getValue ( ) ) ; } builder . endObject ( ) ; builder . startObject ( "transient" ) ; for ( Map . Entry < String , String > entry : response . getState ( ) . metaData ( ) . transientSettings ( ) . getAsMap ( ) . entrySet ( ) ) { builder . field ( entry . getKey ( ) , entry . getValue ( ) ) ; } builder . endObject ( ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class TextButtonTest extends GdxTest { private Stage stage ; private Skin skin ; @ Override public void create ( ) { stage = new Stage ( 0 , 0 , false , new SpriteBatch ( ) ) ; input . setInputProcessor ( stage ) ; <START_BUG> skin = new Skin ( files . internal ( "data/uiskin.json" ) , files . internal ( "data/uiskin.png" ) ) ; <END_BUG> for ( int i = 0 ; i < 500 ; i ++ ) { TextButton t = new TextButton ( ( "Button" + i ) , skin ) ; t . setX ( MathUtils . random ( 0 , graphics . getWidth ( ) ) ) ; t . setY ( MathUtils . random ( 0 , graphics . getHeight ( ) ) ) ; t . setWidth ( MathUtils . random ( 50 , 200 ) ) ; t . setHeight ( MathUtils . random ( 0 , 100 ) ) ; stage . addActor ( t ) ; } } @ Override public void render ( ) { } @ Override public void resize ( int width , int height ) { } @ Override public void dispose ( ) { } }<BUG2FIX>skin = new Skin ( files . internal ( "data/uiskin.json" ) ) ;
public class RoutingFieldMapper extends AbstractFieldMapper < String > implements org . elasticsearch . index . mapper . RoutingFieldMapper { public static final String CONTENT_TYPE = "_routing" ; public static class Defaults extends AbstractFieldMapper . Defaults { public static final String NAME = "_routing" ; public static final Index INDEX = Index . NOT_ANALYZED ; public static final Store STORE = Store . YES ; public static final boolean OMIT_NORMS = true ; public static final boolean OMIT_TERM_FREQ_AND_POSITIONS = true ; public static final boolean REQUIRED = false ; public static final String PATH = null ; } public static class Builder extends AbstractFieldMapper . Builder < RoutingFieldMapper . Builder , RoutingFieldMapper > { private boolean required = RoutingFieldMapper . Defaults . REQUIRED ; private String path = RoutingFieldMapper . Defaults . PATH ; public Builder ( ) { } public RoutingFieldMapper . Builder required ( boolean required ) { } public RoutingFieldMapper . Builder path ( String path ) { } @ Override public RoutingFieldMapper build ( BuilderContext context ) { } } private boolean required ; private final String path ; protected RoutingFieldMapper ( ) { } protected RoutingFieldMapper ( Field . Store store , Field . Index index , boolean required , String path ) { } public void markAsRequired ( ) { <START_BUG> this . required = required ; <END_BUG> } @ Override public boolean required ( ) { } @ Override public String path ( ) { } @ Override public String value ( Document document ) { } @ Override public String value ( Fieldable field ) { } @ Override public String valueFromString ( String value ) { } @ Override public String valueAsString ( Fieldable field ) { } @ Override public String indexedValue ( String value ) { } public void validate ( ParseContext context , String routing ) throws MapperParsingException { } @ Override protected Field parseCreateField ( ParseContext context ) throws IOException { } @ Override protected String contentType ( ) { } @ Override public void toXContent ( XContentBuilder builder , Params params ) throws IOException { } @ Override public void merge ( XContentMapper mergeWith , MergeContext mergeContext ) throws MergeMappingException { } }<BUG2FIX>this . required = true ;
public class TransportSearchScrollScanAction extends AbstractComponent { private final ThreadPool threadPool ; private final ClusterService clusterService ; private final SearchServiceTransportAction searchService ; private final SearchPhaseController searchPhaseController ; @ Inject public TransportSearchScrollScanAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , SearchServiceTransportAction searchService , SearchPhaseController searchPhaseController ) { } public void execute ( SearchScrollRequest request , ParsedScrollId scrollId , ActionListener < SearchResponse > listener ) { } private class AsyncAction { private final SearchScrollRequest request ; private final ActionListener < SearchResponse > listener ; private final ParsedScrollId scrollId ; private final DiscoveryNodes nodes ; private volatile AtomicArray < ShardSearchFailure > shardFailures ; private final AtomicArray < QueryFetchSearchResult > queryFetchResults ; private final AtomicInteger successfulOps ; private final AtomicInteger counter ; private final long startTime = System . currentTimeMillis ( ) ; private AsyncAction ( SearchScrollRequest request , ParsedScrollId scrollId , ActionListener < SearchResponse > listener ) { } protected final ShardSearchFailure [ ] buildShardFailures ( ) { } protected final void addShardFailure ( final int shardIndex , ShardSearchFailure failure ) { } public void start ( ) { } private void executePhase ( final int shardIndex , DiscoveryNode node , final long searchId ) { } private void finishHim ( ) { try { innerFinishHim ( ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> ReduceSearchPhaseException failure = new ReduceSearchPhaseException ( "fetch" , "" , e , buildShardFailures ( ) ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>reduce<seq2seq4repair_space>search" , failure ) ; } listener . onFailure ( failure ) ; } } private void innerFinishHim ( ) throws IOException { } } }<BUG2FIX>} catch ( Throwable e ) {
public class TransportRefreshAction extends TransportBroadcastOperationAction < RefreshRequest , RefreshResponse , ShardRefreshRequest , ShardRefreshResponse > { private final IndicesService indicesService ; @ Inject public TransportRefreshAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportService transportService , IndicesService indicesService ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected RefreshRequest newRequest ( ) { } @ Override protected RefreshResponse newResponse ( RefreshRequest request , AtomicReferenceArray shardsResponses , ClusterState clusterState ) { } @ Override protected ShardRefreshRequest newShardRequest ( ) { } @ Override protected ShardRefreshRequest newShardRequest ( int numShards , ShardRouting shard , RefreshRequest request ) { } @ Override protected ShardRefreshResponse newShardResponse ( ) { } @ Override protected ShardRefreshResponse shardOperation ( ShardRefreshRequest request ) throws ElasticsearchException { } @ Override protected GroupShardsIterator shards ( ClusterState clusterState , RefreshRequest request , String [ ] concreteIndices ) { logger . trace ( "resolving<seq2seq4repair_space>shards<seq2seq4repair_space>to<seq2seq4repair_space>refresh<seq2seq4repair_space>based<seq2seq4repair_space>on<seq2seq4repair_space>cluster<seq2seq4repair_space>state<seq2seq4repair_space>version<seq2seq4repair_space>[{}]" , clusterState . version ( ) ) ; <START_BUG> return clusterState . routingTable ( ) . allAssignedShardsGrouped ( concreteIndices , true ) ; <END_BUG> } @ Override protected ClusterBlockException checkGlobalBlock ( ClusterState state , RefreshRequest request ) { } @ Override protected ClusterBlockException checkRequestBlock ( ClusterState state , RefreshRequest countRequest , String [ ] concreteIndices ) { } }<BUG2FIX>return clusterState . routingTable ( ) . allAssignedShardsGrouped ( concreteIndices , true , true ) ;
public class GetResult implements Iterable < GetField > , Streamable , ToXContent { private String index ; private String type ; private String id ; private long version ; private boolean exists ; private Map < String , GetField > fields ; private Map < String , Object > sourceAsMap ; private BytesReference source ; private byte [ ] sourceAsBytes ; GetResult ( ) { } public GetResult ( String index , String type , String id , long version , boolean exists , BytesReference source , Map < String , GetField > fields ) { } public boolean exists ( ) { } public boolean isExists ( ) { } public String index ( ) { } public String getIndex ( ) { } public String type ( ) { } public String getType ( ) { } public String id ( ) { } public String getId ( ) { } public long version ( ) { } public long getVersion ( ) { } public byte [ ] source ( ) { } public BytesReference sourceRef ( ) { } public BytesReference internalSourceRef ( ) { } public boolean isSourceEmpty ( ) { } public String sourceAsString ( ) { } @ SuppressWarnings ( { "unchecked" } ) public Map < String , Object > sourceAsMap ( ) throws ElasticSearchParseException { } public Map < String , Object > getSource ( ) { } public Map < String , GetField > fields ( ) { } public Map < String , GetField > getFields ( ) { } public GetField field ( String name ) { } @ Override public Iterator < GetField > iterator ( ) { } static final class Fields { static final XContentBuilderString _INDEX = new XContentBuilderString ( "_index" ) ; static final XContentBuilderString _TYPE = new XContentBuilderString ( "_type" ) ; static final XContentBuilderString _ID = new XContentBuilderString ( "_id" ) ; static final XContentBuilderString _VERSION = new XContentBuilderString ( "_version" ) ; static final XContentBuilderString EXISTS = new XContentBuilderString ( "exists" ) ; static final XContentBuilderString FIELDS = new XContentBuilderString ( "fields" ) ; } public XContentBuilder toXContentEmbedded ( XContentBuilder builder , Params params ) throws IOException { } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { } public static GetResult readGetResult ( StreamInput in ) throws IOException { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { out . writeUTF ( index ) ; out . writeOptionalUTF ( type ) ; out . writeUTF ( id ) ; out . writeLong ( version ) ; out . writeBoolean ( exists ) ; if ( exists ) { <START_BUG> out . writeBytesReference ( source , true ) ; <END_BUG> if ( ( fields ) == null ) { out . writeVInt ( 0 ) ; } else { out . writeVInt ( fields . size ( ) ) ; for ( GetField field : fields . values ( ) ) { field . writeTo ( out ) ; } } } } }<BUG2FIX>out . writeBytesReference ( source ) ;
public class MetaDataMappingService extends AbstractComponent { private final ClusterService clusterService ; private final IndicesService indicesService ; private final NodeMappingCreatedAction mappingCreatedAction ; private final BlockingQueue < MetaDataMappingService . MappingTask > refreshOrUpdateQueue = ConcurrentCollections . newBlockingQueue ( ) ; @ Inject public MetaDataMappingService ( Settings settings , ClusterService clusterService , IndicesService indicesService , NodeMappingCreatedAction mappingCreatedAction ) { } static class MappingTask { final String index ; final String indexUUID ; MappingTask ( String index , final String indexUUID ) { } } static class RefreshTask extends MetaDataMappingService . MappingTask { final String [ ] types ; RefreshTask ( String index , final String indexUUID , String [ ] types ) { } } static class UpdateTask extends MetaDataMappingService . MappingTask { final String type ; final CompressedString mappingSource ; final MetaDataMappingService . Listener listener ; UpdateTask ( String index , String indexUUID , String type , CompressedString mappingSource , MetaDataMappingService . Listener listener ) { } } ClusterState executeRefreshOrUpdate ( final ClusterState currentState ) throws Exception { } public void refreshMapping ( final String index , final String indexUUID , final String ... types ) { } public void updateMapping ( final String index , final String indexUUID , final String type , final CompressedString mappingSource , final MetaDataMappingService . Listener listener ) { } public void removeMapping ( final DeleteMappingClusterStateUpdateRequest request , final ClusterStateUpdateListener listener ) { clusterService . submitStateUpdateTask ( ( ( "remove-mapping<seq2seq4repair_space>[" + ( request . type ( ) ) ) + "]" ) , HIGH , new AckedClusterStateUpdateTask ( ) { @ Override public boolean mustAck ( DiscoveryNode discoveryNode ) { return true ; } @ Override public void onAllNodesAcked ( @ Nullable Throwable t ) { listener . onResponse ( new ClusterStateUpdateResponse ( true ) ) ; } @ Override public void onAckTimeout ( ) { <START_BUG> listener . onResponse ( new ClusterStateUpdateResponse ( true ) ) ; <END_BUG> } @ Override public TimeValue ackTimeout ( ) { return request . ackTimeout ( ) ; } @ Override public TimeValue timeout ( ) { return request . masterNodeTimeout ( ) ; } @ Override public void onFailure ( String source , Throwable t ) { listener . onFailure ( t ) ; } @ Override public ClusterState execute ( ClusterState currentState ) { if ( ( request . indices ( ) . length ) == 0 ) { throw new org . elasticsearch . indices . IndexMissingException ( new Index ( "_all" ) ) ; } MetaData . Builder builder = MetaData . newMetaDataBuilder ( ) . metaData ( currentState . metaData ( ) ) ; boolean changed = false ; String latestIndexWithout = null ; for ( String indexName : request . indices ( ) ) { IndexMetaData indexMetaData = currentState . metaData ( ) . index ( indexName ) ; if ( indexMetaData != null ) { if ( indexMetaData . mappings ( ) . containsKey ( request . type ( ) ) ) { builder . put ( IndexMetaData . newIndexMetaDataBuilder ( indexMetaData ) . removeMapping ( request . type ( ) ) ) ; changed = true ; } else { latestIndexWithout = indexMetaData . index ( ) ; } } } if ( ! changed ) { throw new org . elasticsearch . indices . TypeMissingException ( new Index ( latestIndexWithout ) , request . type ( ) ) ; } logger . info ( "[{}]<seq2seq4repair_space>remove_mapping<seq2seq4repair_space>[{}]" , request . indices ( ) , request . type ( ) ) ; return ClusterState . builder ( ) . state ( currentState ) . metaData ( builder ) . build ( ) ; } @ Override public void clusterStateProcessed ( String source , ClusterState oldState , ClusterState newState ) { } } ) ; } public void putMapping ( final MetaDataMappingService . PutRequest request , final MetaDataMappingService . Listener listener ) { } public static interface Listener { void onResponse ( MetaDataMappingService . Response response ) { } void onFailure ( Throwable t ) { } } public static class PutRequest { final String [ ] indices ; final String mappingType ; final String mappingSource ; boolean ignoreConflicts = false ; TimeValue timeout = TimeValue . timeValueSeconds ( 10 ) ; TimeValue masterTimeout = MasterNodeOperationRequest . DEFAULT_MASTER_NODE_TIMEOUT ; public PutRequest ( String [ ] indices , String mappingType , String mappingSource ) { } public MetaDataMappingService . PutRequest ignoreConflicts ( boolean ignoreConflicts ) { } public MetaDataMappingService . PutRequest timeout ( TimeValue timeout ) { } public MetaDataMappingService . PutRequest masterTimeout ( TimeValue masterTimeout ) { } } public static class Response { private final boolean acknowledged ; public Response ( boolean acknowledged ) { } public boolean acknowledged ( ) { } } private class CountDownListener implements NodeMappingCreatedAction . Listener { private final CountDown countDown ; private final MetaDataMappingService . Listener listener ; private final long minClusterStateVersion ; public CountDownListener ( int countDown , long minClusterStateVersion , MetaDataMappingService . Listener listener ) { } @ Override public void onNodeMappingCreated ( NodeMappingCreatedAction . NodeMappingCreatedResponse response ) { } public void decrementCounter ( ) { } @ Override public void onTimeout ( ) { } } }<BUG2FIX>listener . onResponse ( new ClusterStateUpdateResponse ( false ) ) ;
public class Label extends Widget { private static final Color tempColor = new Color ( ) ; private Label . LabelStyle style ; private final TextBounds bounds = new TextBounds ( ) ; private final StringBuilder text = new StringBuilder ( ) ; private StringBuilder tempText ; private BitmapFontCache cache ; private int labelAlign = Align . left ; private HAlignment lineAlign = HAlignment . LEFT ; private boolean wrap ; private float lastPrefHeight ; private boolean sizeInvalid = true ; private float fontScaleX = 1 ; private float fontScaleY = 1 ; private boolean ellipse ; public Label ( CharSequence text , Skin skin ) { } public Label ( CharSequence text , Skin skin , String styleName ) { } public Label ( CharSequence text , Skin skin , String fontName , Color color ) { } public Label ( CharSequence text , Skin skin , String fontName , String colorName ) { } public Label ( CharSequence text , Label . LabelStyle style ) { } public void setStyle ( Label . LabelStyle style ) { } public Label . LabelStyle getStyle ( ) { } public void setText ( CharSequence newText ) { } public boolean textEquals ( CharSequence other ) { } <START_BUG> public CharSequence getText ( ) { <END_BUG> return text ; } public void invalidate ( ) { } private void scaleAndComputeSize ( ) { } private void computeSize ( ) { } public void layout ( ) { } public void draw ( Batch batch , float parentAlpha ) { } public float getPrefWidth ( ) { } public float getPrefHeight ( ) { } public TextBounds getTextBounds ( ) { } public void setWrap ( boolean wrap ) { } public void setAlignment ( int alignment ) { } public void setAlignment ( int labelAlign , int lineAlign ) { } public void setFontScale ( float fontScale ) { } public void setFontScale ( float fontScaleX , float fontScaleY ) { } public float getFontScaleX ( ) { } public void setFontScaleX ( float fontScaleX ) { } public float getFontScaleY ( ) { } public void setFontScaleY ( float fontScaleY ) { } public void setEllipse ( boolean ellipse ) { } protected BitmapFontCache getBitmapFontCache ( ) { } public static class LabelStyle { public BitmapFont font ; public Color fontColor ; public Drawable background ; public LabelStyle ( ) { } public LabelStyle ( BitmapFont font , Color fontColor ) { } public LabelStyle ( Label . LabelStyle style ) { } } }<BUG2FIX>public StringBuilder getText ( ) {
public HighlightBuilder highlightQuery ( QueryBuilder highlightQuery ) { } public HighlightBuilder noMatchSize ( Integer noMatchSize ) { } public HighlightBuilder phraseLimit ( Integer phraseLimit ) { } public HighlightBuilder options ( Map < String , Object > options ) { } public HighlightBuilder forceSource ( boolean forceSource ) { } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { builder . startObject ( "highlight" ) ; if ( ( tagsSchema ) != null ) { builder . field ( "tags_schema" , tagsSchema ) ; } if ( ( preTags ) != null ) { builder . array ( "pre_tags" , preTags ) ; } if ( ( postTags ) != null ) { builder . array ( "post_tags" , postTags ) ; } if ( ( order ) != null ) { builder . field ( "order" , order ) ; } if ( ( encoder ) != null ) { builder . field ( "encoder" , encoder ) ; } if ( ( requireFieldMatch ) != null ) { builder . field ( "require_field_match" , requireFieldMatch ) ; } if ( ( highlighterType ) != null ) { builder . field ( "type" , highlighterType ) ; } if ( ( fragmenter ) != null ) { builder . field ( "fragmenter" , fragmenter ) ; } if ( ( highlightQuery ) != null ) { builder . field ( "highlight_query" , highlightQuery ) ; } if ( ( noMatchSize ) != null ) { builder . field ( "no_match_size" , noMatchSize ) ; } if ( ( phraseLimit ) != null ) { builder . field ( "phrase_limit" , phraseLimit ) ; } if ( ( ( options ) != null ) && ( ( options . size ( ) ) > 0 ) ) { builder . field ( "options" , options ) ; } if ( ( forceSource ) != null ) { builder . field ( "force_source" , forceSource ) ; } if ( ( fields ) != null ) { builder . startObject ( "fields" ) ; for ( HighlightBuilder . Field field : fields ) { builder . startObject ( field . name ( ) ) ; if ( ( field . preTags ) != null ) { builder . field ( "pre_tags" , field . preTags ) ; } if ( ( field . postTags ) != null ) { builder . field ( "post_tags" , field . postTags ) ; } if ( ( field . fragmentSize ) != ( - 1 ) ) { builder . field ( "fragment_size" , field . fragmentSize ) ; } if ( ( field . numOfFragments ) != ( - 1 ) ) { builder . field ( "number_of_fragments" , field . numOfFragments ) ; } if ( ( field . fragmentOffset ) != ( - 1 ) ) { builder . field ( "fragment_offset" , field . fragmentOffset ) ; } if ( ( field . highlightFilter ) != null ) { builder . field ( "highlight_filter" , field . highlightFilter ) ; } if ( ( field . order ) != null ) { builder . field ( "order" , field . order ) ; } if ( ( field . requireFieldMatch ) != null ) { builder . field ( "require_field_match" , field . requireFieldMatch ) ; } if ( ( field . boundaryMaxScan ) != ( - 1 ) ) { builder . field ( "boundary_max_scan" , field . boundaryMaxScan ) ; } if ( ( field . boundaryChars ) != null ) { builder . field ( "boundary_chars" , field . boundaryChars ) ; } if ( ( field . highlighterType ) != null ) { builder . field ( "type" , field . highlighterType ) ; } if ( ( field . fragmenter ) != null ) { builder . field ( "fragmenter" , field . fragmenter ) ; } if ( ( field . highlightQuery ) != null ) { builder . field ( "highlight_query" , field . highlightQuery ) ; } if ( ( field . noMatchSize ) != null ) { builder . field ( "no_match_size" , field . noMatchSize ) ; } if ( ( field . matchedFields ) != null ) { builder . field ( "matched_fields" , field . matchedFields ) ; } if ( ( field . phraseLimit ) != null ) { builder . field ( "phrase_limit" , field . phraseLimit ) ; } if ( ( ( field . options ) != null ) && ( ( field . options . size ( ) ) > 0 ) ) { builder . field ( "options" , field . options ) ; } if ( ( field . forceSource ) != null ) { <START_BUG> builder . field ( "force_source" , forceSource ) ; <END_BUG> } builder . endObject ( ) ; } builder . endObject ( ) ; } builder . endObject ( ) ; return builder ; } public static class Field { final String name ; String [ ] preTags ; String [ ] postTags ; int fragmentSize = - 1 ; int fragmentOffset = - 1 ; int numOfFragments = - 1 ; Boolean highlightFilter ; String order ; Boolean requireFieldMatch ; int boundaryMaxScan = - 1 ; char [ ] boundaryChars ; String highlighterType ; String fragmenter ; QueryBuilder highlightQuery ; Integer noMatchSize ; String [ ] matchedFields ; Integer phraseLimit ; Map < String , Object > options ; Boolean forceSource ; public Field ( String name ) { } public String name ( ) { } public HighlightBuilder . Field preTags ( String ... preTags ) { } public HighlightBuilder . Field postTags ( String ... postTags ) { } public HighlightBuilder . Field fragmentSize ( int fragmentSize ) { } public HighlightBuilder . Field fragmentOffset ( int fragmentOffset ) { } public HighlightBuilder . Field numOfFragments ( int numOfFragments ) { }<BUG2FIX>builder . field ( "force_source" , field . forceSource ) ;
public class UISimpleTest extends GdxTest { Skin skin ; Stage stage ; SpriteBatch batch ; @ Override public void create ( ) { } @ Override public void render ( ) { } @ Override public void resize ( int width , int height ) { <START_BUG> stage . getViewport ( ) . update ( width , height ) ; <END_BUG> } @ Override public void dispose ( ) { } }<BUG2FIX>stage . getViewport ( ) . update ( width , height , true ) ;
public class TransportMultiPercolateAction extends HandledTransportAction < MultiPercolateRequest , MultiPercolateResponse > { private final ClusterService clusterService ; private final PercolatorService percolatorService ; private final TransportMultiGetAction multiGetAction ; private final TransportShardMultiPercolateAction shardMultiPercolateAction ; @ Inject public TransportMultiPercolateAction ( Settings settings , ThreadPool threadPool , TransportShardMultiPercolateAction shardMultiPercolateAction , ClusterService clusterService , TransportService transportService , PercolatorService percolatorService , TransportMultiGetAction multiGetAction , ActionFilters actionFilters ) { } @ Override public MultiPercolateRequest newRequestInstance ( ) { } @ Override protected void doExecute ( final MultiPercolateRequest request , final ActionListener < MultiPercolateResponse > listener ) { final ClusterState clusterState = clusterService . state ( ) ; clusterState . blocks ( ) . globalBlockedRaiseException ( READ ) ; final List < Object > percolateRequests = new ArrayList ( request . requests ( ) . size ( ) ) ; final IntArrayList getRequestSlots = new IntArrayList ( ) ; List < GetRequest > existingDocsRequests = new ArrayList < > ( ) ; for ( int slot = 0 ; slot < ( request . requests ( ) . size ( ) ) ; slot ++ ) { PercolateRequest percolateRequest = request . requests ( ) . get ( slot ) ; percolateRequest . startTime = System . currentTimeMillis ( ) ; percolateRequests . add ( percolateRequest ) ; if ( ( percolateRequest . getRequest ( ) ) != null ) { existingDocsRequests . add ( percolateRequest . getRequest ( ) ) ; getRequestSlots . add ( slot ) ; } } if ( ! ( existingDocsRequests . isEmpty ( ) ) ) { <START_BUG> final MultiGetRequest multiGetRequest = new MultiGetRequest ( ) ; <END_BUG> for ( GetRequest getRequest : existingDocsRequests ) { multiGetRequest . add ( new MultiGetRequest . Item ( getRequest . index ( ) , getRequest . type ( ) , getRequest . id ( ) ) . routing ( getRequest . routing ( ) ) ) ; } multiGetAction . execute ( multiGetRequest , new ActionListener < MultiGetResponse > ( ) { @ Override public void onResponse ( MultiGetResponse multiGetItemResponses ) { for ( int i = 0 ; i < ( multiGetItemResponses . getResponses ( ) . length ) ; i ++ ) { MultiGetItemResponse itemResponse = multiGetItemResponses . getResponses ( ) [ i ] ; int slot = getRequestSlots . get ( i ) ; if ( ! ( itemResponse . isFailed ( ) ) ) { GetResponse getResponse = itemResponse . getResponse ( ) ; if ( getResponse . isExists ( ) ) { PercolateRequest originalRequest = ( ( PercolateRequest ) ( percolateRequests . get ( slot ) ) ) ; percolateRequests . set ( slot , new PercolateRequest ( originalRequest , getResponse . getSourceAsBytesRef ( ) ) ) ; } else { logger . trace ( "mpercolate<seq2seq4repair_space>existing<seq2seq4repair_space>doc,<seq2seq4repair_space>item[{}]<seq2seq4repair_space>doesn't<seq2seq4repair_space>exist" , slot ) ; percolateRequests . set ( slot , new org . elasticsearch . index . engine . DocumentMissingException ( null , getResponse . getType ( ) , getResponse . getId ( ) ) ) ; } } else { logger . trace ( "mpercolate<seq2seq4repair_space>existing<seq2seq4repair_space>doc,<seq2seq4repair_space>item[{}]<seq2seq4repair_space>failure<seq2seq4repair_space>{}" , slot , itemResponse . getFailure ( ) ) ; percolateRequests . set ( slot , itemResponse . getFailure ( ) ) ; } } new TransportMultiPercolateAction . ASyncAction ( percolateRequests , listener , clusterState ) . run ( ) ; } @ Override public void onFailure ( Throwable e ) { listener . onFailure ( e ) ; } } ) ; } else { new TransportMultiPercolateAction . ASyncAction ( percolateRequests , listener , clusterState ) . run ( ) ; } } private class ASyncAction { final ActionListener < MultiPercolateResponse > finalListener ; final Map < ShardId , TransportShardMultiPercolateAction . Request > requestsByShard ; final List < Object > percolateRequests ; final Map < ShardId , IntArrayList > shardToSlots ; final AtomicInteger expectedOperations ; final AtomicArray < Object > reducedResponses ; final AtomicReferenceArray < AtomicInteger > expectedOperationsPerItem ; final AtomicReferenceArray < AtomicReferenceArray > responsesByItemAndShard ; ASyncAction ( List < Object > percolateRequests , ActionListener < MultiPercolateResponse > finalListener , ClusterState clusterState ) { } void run ( ) { } @ SuppressWarnings ( "unchecked" ) void onShardResponse ( ShardId shardId , TransportShardMultiPercolateAction . Response response ) { } @ SuppressWarnings ( "unchecked" ) void onShardFailure ( ShardId shardId , Throwable e ) { } void reduce ( int slot ) { } void finish ( ) { } } }<BUG2FIX>final MultiGetRequest multiGetRequest = new MultiGetRequest ( request ) ;
private final Object mutex = new Object ( ) ; private final IndicesClusterStateService . FailedEngineHandler failedEngineHandler = new IndicesClusterStateService . FailedEngineHandler ( ) ; private final boolean sendRefreshMapping ; private final AtomicLong recoveryIdGenerator = new AtomicLong ( ) ; @ Inject public IndicesClusterStateService ( Settings settings , IndicesService indicesService , ClusterService clusterService , ThreadPool threadPool , RecoveryTarget recoveryTarget , ShardStateAction shardStateAction , NodeIndexDeletedAction nodeIndexDeletedAction , NodeMappingRefreshAction nodeMappingRefreshAction ) { } @ Override protected void doStart ( ) throws ElasticsearchException { } @ Override protected void doStop ( ) throws ElasticsearchException { } @ Override protected void doClose ( ) throws ElasticsearchException { } @ Override public void clusterChanged ( final ClusterChangedEvent event ) { } private void sendIndexLifecycleEvents ( final ClusterChangedEvent event ) { } private void cleanMismatchedIndexUUIDs ( final ClusterChangedEvent event ) { } private void applyCleanedIndices ( final ClusterChangedEvent event ) { } private void applyDeletedIndices ( final ClusterChangedEvent event ) { } private void applyDeletedShards ( final ClusterChangedEvent event ) { } private void applyNewIndices ( final ClusterChangedEvent event ) { } private void applySettings ( ClusterChangedEvent event ) { } private void applyMappings ( ClusterChangedEvent event ) { } private boolean processMapping ( String index , MapperService mapperService , String mappingType , CompressedString mappingSource ) { } private boolean aliasesChanged ( ClusterChangedEvent event ) { } private void applyAliases ( ClusterChangedEvent event ) { } private void processAliases ( String index , ObjectContainer < AliasMetaData > aliases , IndexAliasesService indexAliasesService ) { } private void applyNewOrUpdatedShards ( final ClusterChangedEvent event ) throws ElasticsearchException { if ( ! ( indicesService . changesAllowed ( ) ) ) { return ; } RoutingTable routingTable = event . state ( ) . routingTable ( ) ; RoutingNodes . RoutingNodeIterator routingNode = event . state ( ) . readOnlyRoutingNodes ( ) . routingNodeIter ( event . state ( ) . nodes ( ) . localNodeId ( ) ) ; if ( routingNode == null ) { failedShards . clear ( ) ; return ; } DiscoveryNodes nodes = event . state ( ) . nodes ( ) ; for ( final ShardRouting shardRouting : routingNode ) { final IndexService indexService = indicesService . indexService ( shardRouting . index ( ) ) ; if ( indexService == null ) { continue ; } final IndexMetaData indexMetaData = event . state ( ) . metaData ( ) . index ( shardRouting . index ( ) ) ; if ( indexMetaData == null ) { continue ; } final int shardId = shardRouting . id ( ) ; if ( ( ! ( indexService . hasShard ( shardId ) ) ) && ( shardRouting . started ( ) ) ) { if ( ! ( failedShards . containsKey ( shardRouting . shardId ( ) ) ) ) { logger . warn ( "[{}][{}]<seq2seq4repair_space>master<seq2seq4repair_space>[{}]<seq2seq4repair_space>marked<seq2seq4repair_space>shard<seq2seq4repair_space>as<seq2seq4repair_space>started,<seq2seq4repair_space>but<seq2seq4repair_space>shard<seq2seq4repair_space>has<seq2seq4repair_space>not<seq2seq4repair_space>been<seq2seq4repair_space>created,<seq2seq4repair_space>mark<seq2seq4repair_space>shard<seq2seq4repair_space>as<seq2seq4repair_space>failed" , shardRouting . index ( ) , shardId , nodes . masterNode ( ) ) ; failedShards . put ( shardRouting . shardId ( ) , new IndicesClusterStateService . FailedShard ( shardRouting . version ( ) ) ) ; if ( ( nodes . masterNode ( ) ) != null ) { shardStateAction . shardFailed ( shardRouting , indexMetaData . getUUID ( ) , ( ( "master<seq2seq4repair_space>" + ( nodes . masterNode ( ) ) ) + "<seq2seq4repair_space>marked<seq2seq4repair_space>shard<seq2seq4repair_space>as<seq2seq4repair_space>started,<seq2seq4repair_space>but<seq2seq4repair_space>shard<seq2seq4repair_space>has<seq2seq4repair_space>not<seq2seq4repair_space>been<seq2seq4repair_space>created,<seq2seq4repair_space>mark<seq2seq4repair_space>shard<seq2seq4repair_space>as<seq2seq4repair_space>failed" ) , nodes . masterNode ( ) ) ; } } continue ; } if ( indexService . hasShard ( shardId ) ) { InternalIndexShard indexShard = ( ( InternalIndexShard ) ( indexService . shard ( shardId ) ) ) ; ShardRouting currentRoutingEntry = indexShard . routingEntry ( ) ; if ( ( ( currentRoutingEntry . initializing ( ) ) && ( shardRouting . initializing ( ) ) ) && ( ! ( currentRoutingEntry . equals ( shardRouting ) ) ) ) { logger . debug ( "[{}][{}]<seq2seq4repair_space>removing<seq2seq4repair_space>shard<seq2seq4repair_space>(different<seq2seq4repair_space>instance<seq2seq4repair_space>of<seq2seq4repair_space>it<seq2seq4repair_space>allocated<seq2seq4repair_space>on<seq2seq4repair_space>this<seq2seq4repair_space>node,<seq2seq4repair_space>current<seq2seq4repair_space>[{}],<seq2seq4repair_space>global<seq2seq4repair_space>[{}])" , shardRouting . index ( ) , shardRouting . id ( ) , currentRoutingEntry , shardRouting ) ; recoveryTarget . cancelRecovery ( indexShard ) ; indexService . removeShard ( shardRouting . id ( ) , "removing<seq2seq4repair_space>shard<seq2seq4repair_space>(different<seq2seq4repair_space>instance<seq2seq4repair_space>of<seq2seq4repair_space>it<seq2seq4repair_space>allocated<seq2seq4repair_space>on<seq2seq4repair_space>this<seq2seq4repair_space>node)" ) ; } else if ( isPeerRecovery ( shardRouting ) ) { <START_BUG> RecoveryStatus recoveryStatus = recoveryTarget . recoveryStatus ( indexShard . shardId ( ) ) ; <END_BUG> if ( ( recoveryStatus != null ) && ( ( recoveryStatus . stage ( ) ) != ( Stage . DONE ) ) ) { DiscoveryNode sourceNode = findSourceNodeForPeerRecovery ( routingTable , nodes , shardRouting ) ; if ( ! ( recoveryStatus . sourceNode ( ) . equals ( sourceNode ) ) ) { logger . debug ( "[{}][{}]<seq2seq4repair_space>removing<seq2seq4repair_space>shard<seq2seq4repair_space>(recovery<seq2seq4repair_space>source<seq2seq4repair_space>changed),<seq2seq4repair_space>current<seq2seq4repair_space>[{}],<seq2seq4repair_space>global<seq2seq4repair_space>[{}])" , shardRouting . index ( ) , shardRouting . id ( ) , currentRoutingEntry , shardRouting ) ; recoveryTarget . cancelRecovery ( indexShard ) ; indexService . removeShard ( shardRouting . id ( ) , "removing<seq2seq4repair_space>shard<seq2seq4repair_space>(recovery<seq2seq4repair_space>source<seq2seq4repair_space>node<seq2seq4repair_space>changed)" ) ; } } } } if ( indexService . hasShard ( shardId ) ) { InternalIndexShard indexShard = ( ( InternalIndexShard ) ( indexService . shard ( shardId ) ) ) ; if ( ! ( shardRouting . equals ( indexShard . routingEntry ( ) ) ) ) { indexShard . routingEntry ( shardRouting ) ; indexService . shardInjector ( shardId ) . getInstance ( IndexShardGatewayService . class ) . routingStateChanged ( ) ; } } if ( shardRouting . initializing ( ) ) { applyInitializingShard ( routingTable , nodes , indexMetaData , routingTable . index ( shardRouting . index ( ) ) . shard ( shardRouting . id ( ) ) , shardRouting ) ; } } } private void cleanFailedShards ( final ClusterChangedEvent event ) { } private void applyInitializingShard ( final RoutingTable routingTable , final DiscoveryNodes nodes , final IndexMetaData indexMetaData , final IndexShardRoutingTable indexShardRouting , final ShardRouting shardRouting ) throws ElasticsearchException { } private DiscoveryNode findSourceNodeForPeerRecovery ( RoutingTable routingTable , DiscoveryNodes nodes , ShardRouting shardRouting ) { } private boolean isPeerRecovery ( ShardRouting shardRouting ) { } private class PeerRecoveryListener implements RecoveryTarget . RecoveryListener { private final StartRecoveryRequest request ; private final ShardRouting shardRouting ; private final IndexService indexService ;<BUG2FIX>RecoveryStatus recoveryStatus = recoveryTarget . recoveryStatus ( indexShard ) ;
public class UxAndroid extends AndroidApplication { String IP = null ; int PORT = 0 ; RemoteSender sender ; @ Override public void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; Bundle bundle = getIntent ( ) . getExtras ( ) ; IP = bundle . getString ( "ip" ) ; PORT = Integer . parseInt ( bundle . getString ( "port" ) ) ; Log . d ( "UxAndroid" , ( ( ( "ip:<seq2seq4repair_space>" + ( IP ) ) + ",<seq2seq4repair_space>port:<seq2seq4repair_space>" ) + ( PORT ) ) ) ; initialize ( new ApplicationListener ( ) { BitmapFont font ; SpriteBatch batch ; @ Override public void create ( ) { new Thread ( new Runnable ( ) { @ Override public void run ( ) { try { RemoteSender sender = new RemoteSender ( IP , PORT ) ; synchronized ( UxAndroid . this ) { UxAndroid . this . sender = sender ; } } catch ( GdxRuntimeException e ) { } } } ) . start ( ) ; batch = new SpriteBatch ( ) ; font = new BitmapFont ( ) ; } @ Override public void resume ( ) { } @ Override public void resize ( int width , int height ) { batch . getProjectionMatrix ( ) . setToOrtho2D ( 0 , 0 , width , height ) ; } @ Override public void render ( ) { boolean connected = false ; synchronized ( UxAndroid . this ) { if ( ( sender ) != null ) { sender . sendUpdate ( ) ; connected = sender . isConnected ( ) ; } } gl . glClear ( GL_COLOR_BUFFER_BIT ) ; batch . begin ( ) ; if ( connected ) { font . draw ( batch , ( ( ( ( ( ( ( "accel:" + ( input . getAccelerometerX ( ) ) ) + ",<seq2seq4repair_space>" ) + ( input . getAccelerometerY ( ) ) ) + ",<seq2seq4repair_space>" ) + ( input . getAccelerometerZ ( ) ) ) + ",<seq2seq4repair_space>fps:<seq2seq4repair_space>" ) + ( graphics . getFramesPerSecond ( ) ) ) , 10 , 20 ) ; } else { font . draw ( batch , ( ( ( "No<seq2seq4repair_space>connection<seq2seq4repair_space>to<seq2seq4repair_space>" + ( IP ) ) + ":" ) + ( PORT ) ) , 10 , 20 ) ; } batch . end ( ) ; } @ Override public void pause ( ) { } @ Override public void dispose ( ) { } <START_BUG> } , false ) ; <END_BUG> } }<BUG2FIX>} ) ;
public static final native int btSparseSdf3_nprobes_get ( long jarg1 , btSparseSdf3 jarg1_ ) { } public static final native void btSparseSdf3_nqueries_set ( long jarg1 , btSparseSdf3 jarg1_ , int jarg2 ) { } public static final native int btSparseSdf3_nqueries_get ( long jarg1 , btSparseSdf3 jarg1_ ) { } public static final native void btSparseSdf3_Initialize__SWIG_0 ( long jarg1 , btSparseSdf3 jarg1_ , int jarg2 , int jarg3 ) { } public static final native void btSparseSdf3_Initialize__SWIG_1 ( long jarg1 , btSparseSdf3 jarg1_ , int jarg2 ) { } public static final native void btSparseSdf3_Initialize__SWIG_2 ( long jarg1 , btSparseSdf3 jarg1_ ) { } public static final native void btSparseSdf3_Reset ( long jarg1 , btSparseSdf3 jarg1_ ) { } public static final native void btSparseSdf3_GarbageCollect__SWIG_0 ( long jarg1 , btSparseSdf3 jarg1_ , int jarg2 ) { } public static final native void btSparseSdf3_GarbageCollect__SWIG_1 ( long jarg1 , btSparseSdf3 jarg1_ ) { } public static final native int btSparseSdf3_RemoveReferences ( long jarg1 , btSparseSdf3 jarg1_ , long jarg2 , btCollisionShape jarg2_ ) { } public static final native float btSparseSdf3_Evaluate ( long jarg1 , btSparseSdf3 jarg1_ , Vector3 jarg2 , long jarg3 , btCollisionShape jarg3_ , Vector3 jarg4 , float jarg5 ) { } public static final native void btSparseSdf3_BuildCell ( long jarg1 , btSparseSdf3 jarg1_ , long jarg2 ) { } public static final native float btSparseSdf3_DistanceToShape ( Vector3 jarg1 , long jarg2 , btCollisionShape jarg2_ ) { } public static final native long btSparseSdf3_Decompose ( float jarg1 ) { } public static final native float btSparseSdf3_Lerp ( float jarg1 , float jarg2 , float jarg3 ) { } public static final native long btSparseSdf3_Hash ( int jarg1 , int jarg2 , int jarg3 , long jarg4 , btCollisionShape jarg4_ ) { } public static final native long new_btSparseSdf3 ( ) { } public static final native void delete_btSparseSdf3 ( long jarg1 ) { } public static final native void btSoftBodyWorldInfo_air_density_set ( long jarg1 , btSoftBodyWorldInfo jarg1_ , float jarg2 ) { } public static final native float btSoftBodyWorldInfo_air_density_get ( long jarg1 , btSoftBodyWorldInfo jarg1_ ) { } public static final native void btSoftBodyWorldInfo_water_density_set ( long jarg1 , btSoftBodyWorldInfo jarg1_ , float jarg2 ) { } public static final native float btSoftBodyWorldInfo_water_density_get ( long jarg1 , btSoftBodyWorldInfo jarg1_ ) { } public static final native void btSoftBodyWorldInfo_water_offset_set ( long jarg1 , btSoftBodyWorldInfo jarg1_ , float jarg2 ) { } public static final native float btSoftBodyWorldInfo_water_offset_get ( long jarg1 , btSoftBodyWorldInfo jarg1_ ) { } public static final native void btSoftBodyWorldInfo_maxDisplacement_set ( long jarg1 , btSoftBodyWorldInfo jarg1_ , float jarg2 ) { } public static final native float btSoftBodyWorldInfo_maxDisplacement_get ( long jarg1 , btSoftBodyWorldInfo jarg1_ ) { } public static final native void btSoftBodyWorldInfo_water_normal_set ( long jarg1 , btSoftBodyWorldInfo jarg1_ , long jarg2 , btVector3 jarg2_ ) { } public static final native long btSoftBodyWorldInfo_water_normal_get ( long jarg1 , btSoftBodyWorldInfo jarg1_ ) { } public static final native void btSoftBodyWorldInfo_broadphase_set ( long jarg1 , btSoftBodyWorldInfo jarg1_ , long jarg2 , btBroadphaseInterface jarg2_ ) { } public static final native long btSoftBodyWorldInfo_broadphase_get ( long jarg1 , btSoftBodyWorldInfo jarg1_ ) { } public static final native void btSoftBodyWorldInfo_dispatcher_set ( long jarg1 , btSoftBodyWorldInfo jarg1_ , long jarg2 , btDispatcher jarg2_ ) { } public static final native long btSoftBodyWorldInfo_dispatcher_get ( long jarg1 , btSoftBodyWorldInfo jarg1_ ) { } public static final native void btSoftBodyWorldInfo_gravity_set ( long jarg1 , btSoftBodyWorldInfo jarg1_ , long jarg2 , btVector3 jarg2_ ) { } public static final native long btSoftBodyWorldInfo_gravity_get ( long jarg1 , btSoftBodyWorldInfo jarg1_ ) { } public static final native void btSoftBodyWorldInfo_sparsesdf_set ( long jarg1 , btSoftBodyWorldInfo jarg1_ , long jarg2 , btSparseSdf3 jarg2_ ) { } public static final native long btSoftBodyWorldInfo_sparsesdf_get ( long jarg1 , btSoftBodyWorldInfo jarg1_ ) { } public static final native long new_btSoftBodyWorldInfo ( ) { } public static final native void delete_btSoftBodyWorldInfo ( long jarg1 ) { } <START_BUG> public static final native void btSoftBody_collisionDisabledObjects_set ( long jarg1 , btSoftBody jarg1_ , long jarg2 , btCollisionObjectConstArray jarg2_ ) ; <END_BUG> public static final native long btSoftBody_collisionDisabledObjects_get ( long jarg1 , btSoftBody jarg1_ ) { } public static final native void btSoftBody_softBodySolver_set ( long jarg1 , btSoftBody jarg1_ , long jarg2 , btSoftBodySolver jarg2_ ) { } public static final native long btSoftBody_softBodySolver_get ( long jarg1 , btSoftBody jarg1_ ) { } public static final native void btSoftBody_cfg_set ( long jarg1 , btSoftBody jarg1_ , long jarg2 ) { } public static final native long btSoftBody_cfg_get ( long jarg1 , btSoftBody jarg1_ ) { } public static final native void btSoftBody_sst_set ( long jarg1 , btSoftBody jarg1_ , long jarg2 ) { } public static final native long btSoftBody_sst_get ( long jarg1 , btSoftBody jarg1_ ) { } public static final native void btSoftBody_pose_set ( long jarg1 , btSoftBody jarg1_ , long jarg2 ) { } public static final native long btSoftBody_pose_get ( long jarg1 , btSoftBody jarg1_ ) { } public static final native void btSoftBody_tag_set ( long jarg1 , btSoftBody jarg1_ , long jarg2 ) { } public static final native long btSoftBody_tag_get ( long jarg1 , btSoftBody jarg1_ ) { } public static final native void btSoftBody_worldInfo_set ( long jarg1 , btSoftBody jarg1_ , long jarg2 , btSoftBodyWorldInfo jarg2_ ) { } public static final native long btSoftBody_worldInfo_get ( long jarg1 , btSoftBody jarg1_ ) { } public static final native void btSoftBody_notes_set ( long jarg1 , btSoftBody jarg1_ , long jarg2 ) { } public static final native long btSoftBody_notes_get ( long jarg1 , btSoftBody jarg1_ ) { } public static final native void btSoftBody_nodes_set ( long jarg1 , btSoftBody jarg1_ , long jarg2 ) { } public static final native long btSoftBody_nodes_get ( long jarg1 , btSoftBody jarg1_ ) { } public static final native void btSoftBody_links_set ( long jarg1 , btSoftBody jarg1_ , long jarg2 ) { } public static final native long btSoftBody_links_get ( long jarg1 , btSoftBody jarg1_ ) { }<BUG2FIX>public static final native void btSoftBody_collisionDisabledObjects_set ( long jarg1 , btSoftBody jarg1_ , long jarg2 ) ;
public class SoundTest extends GdxTest { Sound sound ; float volume = 0.5F ; long soundId = 0 ; Stage ui ; BitmapFont font ; SpriteBatch batch ; @ Override public void create ( ) { sound = audio . newSound ( files . getFileHandle ( "data/shotgun.wav" , Internal ) ) ; Skin skin = new Skin ( files . internal ( "data/uiskin.json" ) , files . internal ( "data/uiskin.png" ) ) ; ui = new Stage ( graphics . getWidth ( ) , graphics . getHeight ( ) , true ) ; Button play = new Button ( "Play" , skin ) ; Button stop = new Button ( "Stop" , skin ) ; final Slider pitch = new Slider ( 0.1F , 4 , 0.1F , skin ) ; pitch . setValue ( 1 ) ; final Label pitchValue = new Label ( "1.0" , skin ) ; final Slider volume = new Slider ( 0.1F , 1 , 0.1F , skin ) ; volume . setValue ( 1 ) ; final Label volumeValue = new Label ( "1.0" , skin ) ; <START_BUG> Table table = new Table ( "ui" ) ; <END_BUG> final Slider pan = new Slider ( ( - 1.0F ) , 1.0F , 0.1F , skin ) ; pan . setValue ( 0 ) ; final Label panValue = new Label ( "0.0" , skin ) ; table . width = graphics . getWidth ( ) ; table . height = graphics . getHeight ( ) ; table . align ( ( ( Align . CENTER ) | ( Align . TOP ) ) ) ; table . add ( play ) ; table . add ( stop ) ; table . row ( ) ; table . add ( new Label ( "Pitch" , skin ) ) ; table . add ( pitch ) ; table . add ( pitchValue ) ; table . row ( ) ; table . add ( new Label ( "Volume" , skin ) ) ; table . add ( volume ) ; table . add ( volumeValue ) ; table . row ( ) ; table . add ( new Label ( "Pan" , skin ) ) ; table . add ( pan ) ; table . add ( panValue ) ; ui . addActor ( table ) ; play . setClickListener ( new ClickListener ( ) { @ Override public void click ( Actor actor ) { soundId = sound . play ( ) ; sound . setPitch ( soundId , pitch . getValue ( ) ) ; sound . setPan ( soundId , pan . getValue ( ) , volume . getValue ( ) ) ; } } ) ; stop . setClickListener ( new ClickListener ( ) { @ Override public void click ( Actor actor ) { sound . stop ( soundId ) ; } } ) ; pitch . setValueChangedListener ( new ValueChangedListener ( ) { @ Override public void changed ( Slider slider , float value ) { sound . setPitch ( soundId , value ) ; pitchValue . setText ( ( "" + value ) ) ; } } ) ; volume . setValueChangedListener ( new ValueChangedListener ( ) { @ Override public void changed ( Slider slider , float value ) { sound . setVolume ( soundId , value ) ; volumeValue . setText ( ( "" + value ) ) ; } } ) ; pan . setValueChangedListener ( new ValueChangedListener ( ) { @ Override public void changed ( Slider slider , float value ) { sound . setPan ( soundId , value , volume . getValue ( ) ) ; panValue . setText ( ( "" + value ) ) ; } } ) ; input . setInputProcessor ( ui ) ; } @ Override public void render ( ) { } @ Override public boolean needsGL20 ( ) { } }<BUG2FIX>Table table = new Table ( ) ;
public abstract class GwtApplication implements Application , EntryPoint { private ApplicationListener listener ; private GwtApplicationConfiguration config ; private GwtGraphics graphics ; private GwtInput input ; private GwtNet net ; private Panel root = null ; private TextArea log = null ; private int logLevel = LOG_ERROR ; private Array < Runnable > runnables = new Array < Runnable > ( ) ; private Array < Runnable > runnablesHelper = new Array < Runnable > ( ) ; private Array < LifecycleListener > lifecycleListeners = new Array < LifecycleListener > ( ) ; private int lastWidth ; private int lastHeight ; Preloader preloader ; private static GwtApplication . AgentInfo agentInfo ; private ObjectMap < String , Preferences > prefs = new ObjectMap < String , Preferences > ( ) ; public abstract GwtApplicationConfiguration getConfig ( ) { } public String getPreloaderBaseURL ( ) { } @ Override public void onModuleLoad ( ) { } void setupLoop ( ) { } void mainLoop ( ) { } public Panel getRootPanel ( ) { } long loadStart = TimeUtils . nanoTime ( ) ; public Preloader createPreloader ( ) { } public PreloaderCallback getPreloaderCallback ( ) { } @ Override public Graphics getGraphics ( ) { } @ Override public Audio getAudio ( ) { } @ Override public Input getInput ( ) { } @ Override public Files getFiles ( ) { } @ Override public Net getNet ( ) { } private void checkLogLabel ( ) { } @ Override public void log ( String tag , String message ) { } @ Override <START_BUG> public void log ( String tag , String message , Exception exception ) { <END_BUG> if ( ( logLevel ) >= ( LOG_INFO ) ) { checkLogLabel ( ) ; log . setText ( ( ( ( ( ( ( ( ( log . getText ( ) ) + "\n" ) + tag ) + ":<seq2seq4repair_space>" ) + message ) + "\n" ) + ( exception . getMessage ( ) ) ) + "\n" ) ) ; log . setCursorPos ( ( ( log . getText ( ) . length ( ) ) - 1 ) ) ; System . out . println ( ( ( ( ( tag + ":<seq2seq4repair_space>" ) + message ) + "\n" ) + ( exception . getMessage ( ) ) ) ) ; System . out . println ( getStackTrace ( exception ) ) ; } } @ Override public void error ( String tag , String message ) { } @ Override public void error ( String tag , String message , Throwable exception ) { } @ Override public void debug ( String tag , String message ) { } @ Override public void debug ( String tag , String message , Throwable exception ) { } private String getStackTrace ( Throwable e ) { } @ Override public void setLogLevel ( int logLevel ) { } @ Override public int getLogLevel ( ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } @ Override public Preferences getPreferences ( String name ) { } @ Override public Clipboard getClipboard ( ) { } @ Override public void postRunnable ( Runnable runnable ) { } @ Override public void exit ( ) { } public static GwtApplication . AgentInfo agentInfo ( ) { } private static native GwtApplication . AgentInfo computeAgentInfo ( ) { } public static class AgentInfo extends JavaScriptObject { public final native boolean isFirefox ( ) { } public final native boolean isChrome ( ) { } public final native boolean isSafari ( ) { } public final native boolean isOpera ( ) { } public final native boolean isIE ( ) { } public final native boolean isMacOS ( ) { } public final native boolean isLinux ( ) { } public final native boolean isWindows ( ) { } protected AgentInfo ( ) { } } public String getBaseUrl ( ) { } public Preloader getPreloader ( ) { } @ Override public void addLifecycleListener ( LifecycleListener listener ) { } @ Override public void removeLifecycleListener ( LifecycleListener listener ) { } public static native void consoleLog ( String message ) { } }<BUG2FIX>public void log ( String tag , String message , Throwable exception ) {
protected static final int FLAG_FLIP_DIAGONALLY = 536870912 ; protected static final int MASK_CLEAR = - 536870912 ; protected XmlReader xml = new XmlReader ( ) ; protected Element root ; protected boolean yUp ; protected int mapWidthInPixels ; protected int mapHeightInPixels ; protected AtlasTiledMap map ; private interface AtlasResolver { public TextureAtlas getAtlas ( String name ) { } public static class DirectAtlasResolver implements AtlasTiledMapLoader . AtlasResolver { private final ObjectMap < String , TextureAtlas > atlases ; public DirectAtlasResolver ( ObjectMap < String , TextureAtlas > atlases ) { } @ Override public TextureAtlas getAtlas ( String name ) { } } public static class AssetManagerAtlasResolver implements AtlasTiledMapLoader . AtlasResolver { private final AssetManager assetManager ; public AssetManagerAtlasResolver ( AssetManager assetManager ) { } @ Override public TextureAtlas getAtlas ( String name ) { } } } public AtlasTiledMapLoader ( ) { } public AtlasTiledMapLoader ( FileHandleResolver resolver ) { } public TiledMap load ( String fileName ) { } @ Override public Array < AssetDescriptor > getDependencies ( String fileName , AtlasTiledMapLoader . AtlasTiledMapLoaderParameters parameter ) { } public AtlasTiledMap load ( String fileName , AtlasTiledMapLoader . AtlasTiledMapLoaderParameters parameter ) { } protected Array < FileHandle > loadAtlases ( Element root , FileHandle tmxFile ) throws IOException { } @ Override public void loadAsync ( AssetManager manager , String fileName , AtlasTiledMapLoader . AtlasTiledMapLoaderParameters parameter ) { } @ Override public AtlasTiledMap loadSync ( AssetManager manager , String fileName , AtlasTiledMapLoader . AtlasTiledMapLoaderParameters parameter ) { } protected AtlasTiledMap loadMap ( Element root , FileHandle tmxFile , AtlasTiledMapLoader . AtlasResolver resolver , AtlasTiledMapLoader . AtlasTiledMapLoaderParameters parameter ) { } protected void loadTileset ( AtlasTiledMap map , Element element , FileHandle tmxFile , AtlasTiledMapLoader . AtlasResolver resolver , AtlasTiledMapLoader . AtlasTiledMapLoaderParameters parameter ) { if ( element . getName ( ) . equals ( "tileset" ) ) { String name = element . get ( "name" , null ) ; int firstgid = element . getIntAttribute ( "firstgid" , 1 ) ; int tilewidth = element . getIntAttribute ( "tilewidth" , 0 ) ; int tileheight = element . getIntAttribute ( "tileheight" , 0 ) ; int spacing = element . getIntAttribute ( "spacing" , 0 ) ; int margin = element . getIntAttribute ( "margin" , 0 ) ; String source = element . getAttribute ( "source" , null ) ; String imageSource = "" ; int imageWidth = 0 ; int imageHeight = 0 ; FileHandle image = null ; if ( source != null ) { FileHandle tsx = AtlasTiledMapLoader . getRelativeFileHandle ( tmxFile , source ) ; try { element = xml . parse ( tsx ) ; name = element . get ( "name" , null ) ; tilewidth = element . getIntAttribute ( "tilewidth" , 0 ) ; tileheight = element . getIntAttribute ( "tileheight" , 0 ) ; spacing = element . getIntAttribute ( "spacing" , 0 ) ; margin = element . getIntAttribute ( "margin" , 0 ) ; imageSource = element . getChildByName ( "image" ) . getAttribute ( "source" ) ; imageWidth = element . getChildByName ( "image" ) . getIntAttribute ( "width" , 0 ) ; imageHeight = element . getChildByName ( "image" ) . getIntAttribute ( "height" , 0 ) ; } catch ( IOException e ) { throw new GdxRuntimeException ( "Error<seq2seq4repair_space>parsing<seq2seq4repair_space>external<seq2seq4repair_space>tileset." ) ; } } else { imageSource = element . getChildByName ( "image" ) . getAttribute ( "source" ) ; imageWidth = element . getChildByName ( "image" ) . getIntAttribute ( "width" , 0 ) ; imageHeight = element . getChildByName ( "image" ) . getIntAttribute ( "height" , 0 ) ; } TextureAtlas atlas = null ; String regionsName = "" ; if ( map . getProperties ( ) . containsKey ( ( "atlas_" + name ) ) ) { FileHandle atlasHandle = AtlasTiledMapLoader . getRelativeFileHandle ( tmxFile , map . getProperties ( ) . get ( ( "atlas_" + name ) , String . class ) ) ; atlasHandle = resolve ( atlasHandle . path ( ) ) ; atlas = resolver . getAtlas ( atlasHandle . path ( ) ) ; regionsName = atlasHandle . nameWithoutExtension ( ) ; <START_BUG> if ( parameter . forceTextureFilters ) { <END_BUG> for ( Texture texture : atlas . getTextures ( ) ) { texture . setFilter ( parameter . textureMinFilter , parameter . textureMagFilter ) ; } } } TiledMapTileSet tileset = new TiledMapTileSet ( ) ; MapProperties props = tileset . getProperties ( ) ; tileset . setName ( name ) ; props . put ( "firstgid" , firstgid ) ; props . put ( "imagesource" , imageSource ) ; props . put ( "imagewidth" , imageWidth ) ; props . put ( "imageheight" , imageHeight ) ; props . put ( "tilewidth" , tilewidth ) ; props . put ( "tileheight" , tileheight ) ; props . put ( "margin" , margin ) ; props . put ( "spacing" , spacing ) ; Array < AtlasRegion > regions = atlas . findRegions ( regionsName ) ; for ( AtlasRegion region : regions ) { StaticTiledMapTile tile = new StaticTiledMapTile ( region ) ; if ( region != null ) { if ( ! ( yUp ) ) { region . flip ( false , true ) ; } int tileid = firstgid + ( region . index ) ; tile . setId ( tileid ) ; tileset . putTile ( tileid , tile ) ; } } Array < Element > tileElements = element . getChildrenByName ( "tile" ) ; for ( Element tileElement : tileElements ) { int localtid = tileElement . getIntAttribute ( "id" , 0 ) ; TiledMapTile tile = tileset . getTile ( ( firstgid + localtid ) ) ; if ( tile != null ) { Element properties = tileElement . getChildByName ( "properties" ) ; if ( properties != null ) { loadProperties ( tile . getProperties ( ) , properties ) ; } }<BUG2FIX>if ( ( parameter != null ) && ( parameter . forceTextureFilters ) ) {
public class IOSApplication implements Application { public static abstract class Delegate extends UIApplicationDelegate . Adapter { private IOSApplication app ; protected abstract IOSApplication createApplication ( ) { } @ Override public boolean didFinishLaunching ( UIApplication application , NSDictionary launchOptions ) { } @ Override public void didBecomeActive ( UIApplication application ) { } @ Override public void willResignActive ( UIApplication application ) { } @ Override public void willTerminate ( UIApplication application ) { } } UIApplication uiApp ; UIWindow uiWindow ; ApplicationListener listener ; IOSApplicationConfiguration config ; IOSGraphics graphics ; IOSAudio audio ; IOSFiles files ; IOSInput input ; IOSNet net ; int logLevel = Application . LOG_DEBUG ; float displayScaleFactor ; Array < Runnable > runnables = new Array < Runnable > ( ) ; Array < Runnable > executedRunnables = new Array < Runnable > ( ) ; Array < LifecycleListener > lifecycleListeners = new Array < LifecycleListener > ( ) ; public IOSApplication ( ApplicationListener listener , IOSApplicationConfiguration config ) { } final boolean didFinishLaunching ( UIApplication uiApp , NSDictionary options ) { } public UIViewController getUIViewController ( ) { } CGSize getBounds ( UIViewController viewController ) { } final void didBecomeActive ( UIApplication uiApp ) { } final void willResignActive ( UIApplication uiApp ) { } final void willTerminate ( UIApplication uiApp ) { } @ Override public ApplicationListener getApplicationListener ( ) { } @ Override public Graphics getGraphics ( ) { } @ Override public Audio getAudio ( ) { } @ Override public Input getInput ( ) { } @ Override public Files getFiles ( ) { } @ Override public Net getNet ( ) { } @ Override public void log ( String tag , String message ) { } @ Override <START_BUG> public void log ( String tag , String message , Exception exception ) { <END_BUG> if ( ( logLevel ) > ( LOG_NONE ) ) { System . out . println ( ( ( ( "[info]<seq2seq4repair_space>" + tag ) + ":<seq2seq4repair_space>" ) + message ) ) ; exception . printStackTrace ( ) ; } } @ Override public void error ( String tag , String message ) { } @ Override public void error ( String tag , String message , Throwable exception ) { } @ Override public void debug ( String tag , String message ) { } @ Override public void debug ( String tag , String message , Throwable exception ) { } @ Override public void setLogLevel ( int logLevel ) { } @ Override public int getLogLevel ( ) { } @ Override public ApplicationType getType ( ) { } @ Override public int getVersion ( ) { } @ Override public long getJavaHeap ( ) { } @ Override public long getNativeHeap ( ) { } @ Override public Preferences getPreferences ( String name ) { } @ Override public void postRunnable ( Runnable runnable ) { } public void processRunnables ( ) { } @ Override public void exit ( ) { } @ Override public Clipboard getClipboard ( ) { } @ Override public void addLifecycleListener ( LifecycleListener listener ) { } @ Override public void removeLifecycleListener ( LifecycleListener listener ) { } }<BUG2FIX>public void log ( String tag , String message , Throwable exception ) {
public class ThreadPoolStats implements Iterable < ThreadPoolStats . Stats > , Streamable , ToXContent { public static class Stats implements Streamable , ToXContent { private String name ; private int threads ; private int queue ; private int active ; private long rejected ; private int largest ; private long completed ; Stats ( ) { } public Stats ( String name , int threads , int queue , int active , long rejected , int largest , long completed ) { } public String name ( ) { } public String getName ( ) { } public int threads ( ) { } public int getThreads ( ) { } public int queue ( ) { } public int getQueue ( ) { } public int active ( ) { } public int getActive ( ) { } public long rejected ( ) { } public long getRejected ( ) { } public int largest ( ) { } public int getLargest ( ) { } public long completed ( ) { } public long getCompleted ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } @ Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { builder . startObject ( name , NONE ) ; if ( ( threads ) != ( - 1 ) ) { builder . field ( ThreadPoolStats . Fields . THREADS , threads ) ; } if ( ( queue ) != ( - 1 ) ) { builder . field ( ThreadPoolStats . Fields . QUEUE , queue ) ; } if ( ( active ) != ( - 1 ) ) { builder . field ( ThreadPoolStats . Fields . ACTIVE , active ) ; } if ( ( rejected ) != ( - 1 ) ) { builder . field ( ThreadPoolStats . Fields . REJECTED , rejected ) ; } if ( ( largest ) != ( - 1 ) ) { <START_BUG> builder . field ( ThreadPoolStats . Fields . LARGEST , rejected ) ; <END_BUG> } if ( ( completed ) != ( - 1 ) ) { builder . field ( ThreadPoolStats . Fields . COMPLETED , completed ) ; } builder . endObject ( ) ; return builder ; } } private List < ThreadPoolStats . Stats > stats ; ThreadPoolStats ( ) { } public ThreadPoolStats ( List < ThreadPoolStats . Stats > stats ) { } @ Override public Iterator < ThreadPoolStats . Stats > iterator ( ) { } public static ThreadPoolStats readThreadPoolStats ( StreamInput in ) throws IOException { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { } static final class Fields { static final XContentBuilderString THREAD_POOL = new XContentBuilderString ( "thread_pool" ) ; static final XContentBuilderString THREADS = new XContentBuilderString ( "threads" ) ; static final XContentBuilderString QUEUE = new XContentBuilderString ( "queue" ) ; static final XContentBuilderString ACTIVE = new XContentBuilderString ( "active" ) ; static final XContentBuilderString REJECTED = new XContentBuilderString ( "rejected" ) ; static final XContentBuilderString LARGEST = new XContentBuilderString ( "largest" ) ; static final XContentBuilderString COMPLETED = new XContentBuilderString ( "completed" ) ; } @ Override public XContentBuilder toXContent ( XContentBuilder builder , ToXContent . Params params ) throws IOException { } }<BUG2FIX>builder . field ( ThreadPoolStats . Fields . LARGEST , largest ) ;
public class Material implements Iterable < Material . Attribute > , Comparator < Material . Attribute > { public static abstract class Attribute { protected static long register ( final String type ) { } public final long type ; protected Attribute ( final long type ) { } public abstract Material . Attribute copy ( ) { } protected abstract boolean equals ( Material . Attribute other ) { } @ Override public boolean equals ( Object obj ) { if ( obj == null ) return false ; if ( obj == ( this ) ) return true ; if ( ! ( obj instanceof Material . Attribute ) ) return false ; final Material . Attribute other = ( ( Material . Attribute ) ( obj ) ) ; <START_BUG> if ( ( this . type ) != ( other . type ) ) <END_BUG> return false ; return equals ( other ) ; } @ Override public String toString ( ) { } } private static final Array < String > types = new Array < String > ( ) ; private static int counter = 0 ; protected static final long getAttributeType ( final String alias ) { } protected static final String getAttributeAlias ( final long type ) { } protected static final long register ( final String alias ) { } public String id ; protected long mask ; protected final Array < Material . Attribute > attributes = new Array < Material . Attribute > ( ) ; protected boolean sorted = true ; public Material ( ) { } public Material ( final String id ) { } public Material ( final Material . Attribute ... attributes ) { } public Material ( final String id , final Material . Attribute ... attributes ) { } public Material ( final Array < Material . Attribute > attributes ) { } public Material ( final String id , final Array < Material . Attribute > attributes ) { } public Material ( final Material copyFrom ) { } public Material ( final String id , final Material copyFrom ) { } private final void enable ( final long mask ) { } private final void disable ( final long mask ) { } public final long getMask ( ) { } public final boolean has ( final long type ) { } protected int indexOf ( final long type ) { } public final void set ( final Material . Attribute attribute ) { } public final void set ( final Material . Attribute ... attributes ) { } public final void set ( final Iterable < Material . Attribute > attributes ) { } public final void remove ( final long mask ) { } public final Material . Attribute get ( final long type ) { } public final Array < Material . Attribute > get ( final Array < Material . Attribute > out , final long type ) { } public final void clear ( ) { } public int size ( ) { } public final Material copy ( ) { } @ Override public final int compare ( final Material . Attribute arg0 , final Material . Attribute arg1 ) { } public final void sort ( ) { } public final boolean same ( final Material other , boolean compareValues ) { } public final boolean same ( final Material other ) { } public final boolean equals ( final Material other ) { } @ Override public final boolean equals ( final Object obj ) { return obj instanceof Material ? equals ( ( ( Material ) ( obj ) ) ) : false ; } @ Override public final Iterator < Material . Attribute > iterator ( ) { } }<BUG2FIX>if ( ( other . type ) != ( other . type ) )
public class World { private final long addr ; protected final HashMap < Long , Body > bodies = new HashMap < Long , Body > ( ) ; protected final HashMap < Long , Fixture > fixtures = new HashMap < Long , Fixture > ( ) ; protected final HashMap < Long , Joint > joints = new HashMap < Long , Joint > ( ) ; protected ContactFilter contactFilter = null ; protected ContactListener contactListener = null ; public World ( Vector2 gravity , boolean doSleep ) { } private native long newWorld ( float gravityX , float gravityY , boolean doSleep ) { } public void setDestructionListener ( DestructionListener listener ) { } public void setContactFilter ( ContactFilter filter ) { } void setContactListener ( ContactListener listener ) { } public Body createBody ( BodyDef def ) { } private native long jniCreateBody ( long addr , int type , float positionX , float positionY , float angle , float linearVelocityX , float linearVelocityY , float angularVelocity , float linearDamping , float angularDamping , boolean allowSleep , boolean awake , boolean fixedRotation , boolean bullet , boolean active , float intertiaScale ) { } public void destroyBody ( Body body ) { <START_BUG> jniDestroyBody ( body . addr , body . addr ) ; <END_BUG> this . bodies . remove ( body . addr ) ; for ( int i = 0 ; i < ( body . getFixtureList ( ) . size ( ) ) ; i ++ ) this . fixtures . remove ( body . getFixtureList ( ) . get ( i ) . addr ) ; for ( int i = 0 ; i < ( body . getJointList ( ) . size ( ) ) ; i ++ ) this . joints . remove ( body . getJointList ( ) . get ( i ) . joint . addr ) ; } private native void jniDestroyBody ( long addr , long bodyAddr ) { } public Joint createJoint ( JointDef def ) { } private long createProperJoint ( JointDef def ) { } private native long jniCreateDistanceJoint ( long addr , long bodyA , long bodyB , boolean collideConnected , float localAnchorAX , float localAnchorAY , float localAnchorBX , float localAnchorBY , float length , float frequencyHz , float dampingRatio ) { } private native long jniCreateFrictionJoint ( long addr , long bodyA , long bodyB , boolean collideConnected , float localAnchorAX , float localAnchorAY , float localAnchorBX , float localAnchorBY , float maxForce , float maxTorque ) { } private native long jniCreateGearJoint ( long addr , long bodyA , long bodyB , boolean collideConnected , long joint1 , long joint2 , float ratio ) { } private native long jniCreateLineJoint ( long addr , long bodyA , long bodyB , boolean collideConnected , float localAnchorAX , float localAnchorAY , float localAnchorBX , float localAnchorBY , float localAxisAX , float localAxisAY , boolean enableLimit , float lowerTranslation , float upperTranslation , boolean enableMotor , float maxMotorForce , float motorSpeed ) { } private native long jniCreateMouseJoint ( long addr , long bodyA , long bodyB , boolean collideConnected , float targetX , float targetY , float maxForce , float frequencyHz , float dampingRatio ) { } private native long jniCreatePrismaticJoint ( long addr , long bodyA , long bodyB , boolean collideConnected , float localAnchorAX , float localAnchorAY , float localAnchorBX , float localAnchorBY , float localAxisAX , float localAxisAY , float referenceAngle , boolean enableLimit , float lowerTranslation , float upperTranslation , boolean enableMotor , float maxMotorForce , float motorSpeed ) { } private native long jniCreatePulleyJoint ( long addr , long bodyA , long bodyB , boolean collideConnected , float groundAnchorAX , float groundAnchorAY , float groundAnchorBX , float groundAnchorBY , float localAnchorAX , float localAnchorAY , float localAnchorBX , float localAnchorBY , float lengthA , float maxLengthA , float lengthB , float maxLengthB , float ratio ) { } private native long jniCreateRevoluteJoint ( long addr , long bodyA , long bodyB , boolean collideConnected , float localAnchorAX , float localAnchorAY , float localAnchorBX , float localAnchorBY , float referenceAngle , boolean enableLimit , float lowerAngle , float upperAngle , boolean enableMotor , float motorSpeed , float maxMotorTorque ) { } private native long jniCreateWeldJoint ( long addr , long bodyA , long bodyB , boolean collideConnected , float localAnchorAX , float localAnchorAY , float localAnchorBX , float localAnchorBY , float referenceAngle ) { } public void destroyJoint ( Joint joint ) { } private native void jniDestroyJoint ( long addr , long jointAddr ) { } public void step ( float timeStep , int velocityIterations , int positionIterations ) { } private native void jniStep ( long addr , float timeStep , int velocityIterations , int positionIterations ) { } public void clearForces ( ) { } private native void jniClearForces ( long addr ) { } public void setWarmStarting ( boolean flag ) { } private native void jniSetWarmStarting ( long addr , boolean flag ) { } public void setContinuousPhysics ( boolean flag ) { } private native void jniSetContiousPhysics ( long addr , boolean flag ) { } public int getProxyCount ( ) { } private native int jniGetProxyCount ( long addr ) { } public int getBodyCount ( ) { } private native int jniGetBodyCount ( long addr ) { } public int getJointCount ( ) { } private native int jniGetJointcount ( long addr ) { } public int getContactCount ( ) { } private native int jniGetContactCount ( long addr ) { } public void setGravity ( Vector2 gravity ) { } private native void jniSetGravity ( long addr , float gravityX , float gravityY ) { } final float [ ] tmpGravity = new float [ 2 ] ; final Vector2 gravity = new Vector2 ( ) ; public Vector2 getGravity ( ) { }<BUG2FIX>jniDestroyBody ( addr , body . addr ) ;
public class RestFilterChainTests extends ElasticsearchTestCase { @ Test public void testRestFilters ( ) throws InterruptedException { RestController restController = new RestController ( ImmutableSettings . EMPTY ) ; int numFilters = randomInt ( 10 ) ; Set < Integer > orders = new HashSet < > ( numFilters ) ; while ( ( orders . size ( ) ) < numFilters ) { orders . add ( randomInt ( 10 ) ) ; } List < RestFilter > filters = new ArrayList < > ( ) ; for ( Integer order : orders ) { RestFilterChainTests . TestFilter testFilter = new RestFilterChainTests . TestFilter ( order , randomFrom ( RestFilterChainTests . Operation . values ( ) ) ) ; filters . add ( testFilter ) ; restController . registerFilter ( testFilter ) ; } ArrayList < RestFilter > restFiltersByOrder = Lists . newArrayList ( filters ) ; Collections . sort ( restFiltersByOrder , new Comparator < RestFilter > ( ) { @ Override public int compare ( RestFilter o1 , RestFilter o2 ) { <START_BUG> return Integer . compare ( o2 . order ( ) , o1 . order ( ) ) ; <END_BUG> } } ) ; List < RestFilter > expectedRestFilters = Lists . newArrayList ( ) ; for ( RestFilter filter : restFiltersByOrder ) { RestFilterChainTests . TestFilter testFilter = ( ( RestFilterChainTests . TestFilter ) ( filter ) ) ; expectedRestFilters . add ( testFilter ) ; if ( ! ( ( testFilter . callback ) == ( RestFilterChainTests . Operation . CONTINUE_PROCESSING ) ) ) { break ; } } restController . registerHandler ( GET , "/" , new RestHandler ( ) { @ Override public void handleRequest ( RestRequest request , RestChannel channel ) throws Exception { channel . sendResponse ( new RestFilterChainTests . TestResponse ( ) ) ; } } ) ; FakeRestRequest fakeRestRequest = new FakeRestRequest ( ) ; RestFilterChainTests . FakeRestChannel fakeRestChannel = new RestFilterChainTests . FakeRestChannel ( fakeRestRequest , 1 ) ; restController . dispatchRequest ( fakeRestRequest , fakeRestChannel ) ; assertThat ( fakeRestChannel . await ( ) , equalTo ( true ) ) ; List < RestFilterChainTests . TestFilter > testFiltersByLastExecution = Lists . newArrayList ( ) ; for ( RestFilter restFilter : filters ) { testFiltersByLastExecution . add ( ( ( RestFilterChainTests . TestFilter ) ( restFilter ) ) ) ; } Collections . sort ( testFiltersByLastExecution , new Comparator < RestFilterChainTests . TestFilter > ( ) { @ Override public int compare ( RestFilterChainTests . TestFilter o1 , RestFilterChainTests . TestFilter o2 ) { return Long . compare ( o1 . executionToken , o2 . executionToken ) ; } } ) ; ArrayList < RestFilterChainTests . TestFilter > finalTestFilters = Lists . newArrayList ( ) ; for ( RestFilter filter : testFiltersByLastExecution ) { RestFilterChainTests . TestFilter testFilter = ( ( RestFilterChainTests . TestFilter ) ( filter ) ) ; finalTestFilters . add ( testFilter ) ; if ( ! ( ( testFilter . callback ) == ( RestFilterChainTests . Operation . CONTINUE_PROCESSING ) ) ) { break ; } } assertThat ( finalTestFilters . size ( ) , equalTo ( expectedRestFilters . size ( ) ) ) ; for ( int i = 0 ; i < ( finalTestFilters . size ( ) ) ; i ++ ) { RestFilterChainTests . TestFilter testFilter = finalTestFilters . get ( i ) ; assertThat ( testFilter , equalTo ( expectedRestFilters . get ( i ) ) ) ; assertThat ( testFilter . runs . get ( ) , equalTo ( 1 ) ) ; } } @ Test public void testTooManyContinueProcessing ( ) throws InterruptedException { } private static class FakeRestChannel extends RestChannel { private final CountDownLatch latch ; AtomicInteger responses = new AtomicInteger ( ) ; AtomicInteger errors = new AtomicInteger ( ) ; protected FakeRestChannel ( RestRequest request , int responseCount ) { } @ Override public XContentBuilder newBuilder ( ) throws IOException { } @ Override public XContentBuilder newBuilder ( @ Nullable BytesReference autoDetectSource ) throws IOException { } @ Override protected BytesStreamOutput newBytesOutput ( ) { } @ Override public RestRequest request ( ) { } @ Override public void sendResponse ( RestResponse response ) { } public boolean await ( ) throws InterruptedException { } } private static enum Operation implements RestFilterChainTests . Callback { CONTINUE_PROCESSING ( ) { @ Override public void execute ( RestRequest request , RestChannel channel , RestFilterChain filterChain ) throws Exception { } } , CHANNEL_RESPONSE ( ) { @ Override public void execute ( RestRequest request , RestChannel channel , RestFilterChain filterChain ) throws Exception { } } ; } private static interface Callback { void execute ( RestRequest request , RestChannel channel , RestFilterChain filterChain ) throws Exception { } } private final AtomicInteger counter = new AtomicInteger ( ) ; private class TestFilter extends RestFilter { private final int order ; private final RestFilterChainTests . Callback callback ; AtomicInteger runs = new AtomicInteger ( ) ; volatile int executionToken = Integer . MAX_VALUE ; TestFilter ( int order , RestFilterChainTests . Callback callback ) { } @ Override public void process ( RestRequest request , RestChannel channel , RestFilterChain filterChain ) throws Exception { } @ Override public int order ( ) { } @ Override public String toString ( ) { } } private static class TestResponse extends RestResponse { @ Override public String contentType ( ) { } @ Override public boolean contentThreadSafe ( ) { } @ Override public BytesReference content ( ) { } @ Override public RestStatus status ( ) { } } }<BUG2FIX>return Integer . compare ( o1 . order ( ) , o2 . order ( ) ) ;
public class IntSet { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; private static final int EMPTY = 0 ; public int size ; int [ ] keyTable ; int capacity ; int stashSize ; boolean hasZeroValue ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private IntSet . IntSetIterator iterator1 ; private IntSet . IntSetIterator iterator2 ; public IntSet ( ) { } public IntSet ( int initialCapacity ) { } public IntSet ( int initialCapacity , float loadFactor ) { } public IntSet ( IntSet map ) { } public boolean add ( int key ) { } public void addAll ( IntArray array ) { } public void addAll ( IntArray array , int offset , int length ) { } public void addAll ( int ... array ) { } public void addAll ( int [ ] array , int offset , int length ) { } public void addAll ( IntSet set ) { } private void addResize ( int key ) { } private void push ( int insertKey , int index1 , int key1 , int index2 , int key2 , int index3 , int key3 ) { } private void addStash ( int key ) { } public boolean remove ( int key ) { } boolean removeStash ( int key ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean contains ( int key ) { } private boolean containsKeyStash ( int key ) { } public int first ( ) { if ( hasZeroValue ) return 0 ; int [ ] keyTable = this . keyTable ; <START_BUG> for ( int i = 0 , n = ( capacity ) + ( stashSize ) ; i < n ; ) <END_BUG> if ( ( keyTable [ i ] ) != ( IntSet . EMPTY ) ) return keyTable [ i ] ; throw new IllegalStateException ( "IntSet<seq2seq4repair_space>is<seq2seq4repair_space>empty." ) ; } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( int h ) { } private int hash3 ( int h ) { } public String toString ( ) { } public IntSet . IntSetIterator iterator ( ) { } public static IntSet with ( int ... array ) { } public static class Entry < V > { public int key ; public V value ; public String toString ( ) { } } public static class IntSetIterator { static final int INDEX_ILLEGAL = - 2 ; static final int INDEX_ZERO = - 1 ; public boolean hasNext ; final IntSet set ; int nextIndex ; int currentIndex ; boolean valid = true ; public IntSetIterator ( IntSet set ) { } public void reset ( ) { } void findNextIndex ( ) { } public void remove ( ) { } public int next ( ) { } public IntArray toArray ( ) { } } }<BUG2FIX>for ( int i = 0 , n = ( capacity ) + ( stashSize ) ; i < n ; i ++ )
public final class Intersector { public static float getLowestPositiveRoot ( float a , float b , float c ) { } private static final Vector3 v0 = new Vector3 ( ) ; private static final Vector3 v1 = new Vector3 ( ) ; private static final Vector3 v2 = new Vector3 ( ) ; public static boolean isPointInTriangle ( Vector3 point , Vector3 t1 , Vector3 t2 , Vector3 t3 ) { } public static boolean intersectSegmentPlane ( Vector3 start , Vector3 end , Plane plane , Vector3 intersection ) { } public static int pointLineSide ( Vector2 linePoint1 , Vector2 linePoint2 , Vector2 point ) { } public static int pointLineSide ( float linePoint1X , float linePoint1Y , float linePoint2X , float linePoint2Y , float pointX , float pointY ) { } public static boolean isPointInPolygon ( List < Vector2 > polygon , Vector2 point ) { } public static float distanceLinePoint ( Vector2 start , Vector2 end , Vector2 point ) { Intersector . tmp . set ( end . x , end . y , 0 ) ; <START_BUG> float l2 = Intersector . tmp . sub ( start . y , start . y , 0 ) . len2 ( ) ; <END_BUG> if ( l2 == 0.0F ) return point . dst ( start ) ; Intersector . tmp . set ( point . x , point . y , 0 ) ; Intersector . tmp . sub ( start . x , start . y , 0 ) ; Intersector . tmp2 . set ( end . x , end . y , 0 ) ; Intersector . tmp2 . sub ( start . x , start . y , 0 ) ; float t = ( Intersector . tmp . dot ( Intersector . tmp2 ) ) / l2 ; if ( t < 0.0F ) return point . dst ( start ) ; else if ( t > 1.0F ) return point . dst ( end ) ; Intersector . tmp . set ( end . x , end . y , 0 ) ; Intersector . tmp . sub ( start . x , start . y , 0 ) . mul ( t ) . add ( start . x , start . y , 0 ) ; return Intersector . tmp2 . set ( point . x , point . y , 0 ) . dst ( Intersector . tmp ) ; } public static float distanceLinePoint ( float startX , float startY , float endX , float endY , float pointX , float pointY ) { } public static boolean intersectSegmentCircle ( Vector2 start , Vector2 end , Vector2 center , float squareRadius ) { } public static float intersectSegmentCircleDisplace ( Vector2 start , Vector2 end , Vector2 point , float radius , Vector2 displacement ) { } public static boolean intersectRayPlane ( Ray ray , Plane plane , Vector3 intersection ) { } private static final Plane p = new Plane ( new Vector3 ( ) , 0 ) ; private static final Vector3 i = new Vector3 ( ) ; public static boolean intersectRayTriangle ( Ray ray , Vector3 t1 , Vector3 t2 , Vector3 t3 , Vector3 intersection ) { } private static final Vector3 dir = new Vector3 ( ) ; private static final Vector3 start = new Vector3 ( ) ; public static boolean intersectRaySphere ( Ray ray , Vector3 center , float radius , Vector3 intersection ) { } public static boolean intersectRayBoundsFast ( Ray ray , BoundingBox box ) { } static Vector3 tmp = new Vector3 ( ) ; static Vector3 best = new Vector3 ( ) ; static Vector3 tmp1 = new Vector3 ( ) ; static Vector3 tmp2 = new Vector3 ( ) ; static Vector3 tmp3 = new Vector3 ( ) ; public static boolean intersectRayTriangles ( Ray ray , float [ ] triangles , Vector3 intersection ) { } public static boolean intersectRayTriangles ( Ray ray , float [ ] vertices , short [ ] indices , int vertexSize , Vector3 intersection ) { } public static boolean intersectRayTriangles ( Ray ray , List < Vector3 > triangles , Vector3 intersection ) { } public static boolean intersectRectangles ( Rectangle a , Rectangle b ) { } public static boolean intersectLines ( Vector2 p1 , Vector2 p2 , Vector2 p3 , Vector2 p4 , Vector2 intersection ) { } public static boolean intersectSegments ( Vector2 p1 , Vector2 p2 , Vector2 p3 , Vector2 p4 , Vector2 intersection ) { } static float det ( float a , float b , float c , float d ) { } static double detd ( double a , double b , double c , double d ) { } public static boolean overlapCircles ( Circle c1 , Circle c2 ) { } public static boolean overlapRectangles ( Rectangle r1 , Rectangle r2 ) { } public static boolean overlapCircleRectangle ( Circle c , Rectangle r ) { } public static boolean overlapConvexPolygons ( Polygon p1 , Polygon p2 ) { } public static boolean overlapConvexPolygons ( Polygon p1 , Polygon p2 , Vector2 separation ) { } static boolean separateConvexPolygons ( float [ ] verts1 , float [ ] verts2 , Vector2 separation ) { } }<BUG2FIX>float l2 = Intersector . tmp . sub ( start . x , start . y , 0 ) . len2 ( ) ;
public class BumperElement extends FieldElement { Body pegBody ; Collection pegBodySet ; float radius ; float cx ; float cy ; float kick ; public void finishCreate ( Map params , World world ) { } @ Override public Collection getBodies ( ) { } @ Override public boolean shouldCallTick ( ) { } Vector2 impulseForBall ( Body ball ) { } @ Override public void handleCollision ( Body ball , Body bodyHit , Field field ) { Vector2 impulse = this . impulseForBall ( ball ) ; if ( impulse != null ) { <START_BUG> ball . applyLinearImpulse ( impulse , ball . getWorldCenter ( ) , true ) ; <END_BUG> flashForFrames ( 3 ) ; } } @ Override public void draw ( IFieldRenderer renderer ) { } }<BUG2FIX>ball . applyLinearImpulse ( impulse , ball . getWorldCenter ( ) ) ;
public class TribeTests extends ElasticsearchIntegrationTest { private TestCluster cluster2 ; private Node tribeNode ; private Client tribeClient ; @ Before public void setupSecondCluster ( ) { <START_BUG> cluster2 = new TestCluster ( randomLong ( ) , 2 , ( ( cluster ( ) . getClusterName ( ) ) + "-2" ) ) ; <END_BUG> cluster2 . beforeTest ( getRandom ( ) , getPerTestTransportClientRatio ( ) ) ; cluster2 . ensureAtLeastNumNodes ( 2 ) ; Settings settings = ImmutableSettings . builder ( ) . put ( "tribe.t1.cluster.name" , cluster ( ) . getClusterName ( ) ) . put ( "tribe.t2.cluster.name" , cluster2 . getClusterName ( ) ) . build ( ) ; tribeNode = org . elasticsearch . node . NodeBuilder . nodeBuilder ( ) . settings ( settings ) . node ( ) ; tribeClient = tribeNode . client ( ) ; } @ After public void tearDownSecondCluster ( ) { } @ Test public void testTribeOnOneCluster ( ) throws Exception { } private void awaitSameNodeCounts ( ) throws Exception { } private int countDataNodesForTribe ( String tribeName , DiscoveryNodes nodes ) { } }<BUG2FIX>cluster2 = new TestCluster ( randomLong ( ) , 2 , 2 , ( ( cluster ( ) . getClusterName ( ) ) + "-2" ) ) ;
public class ValueDateHistogramFacetExecutor extends FacetExecutor { private final IndexNumericFieldData keyIndexFieldData ; private final IndexNumericFieldData valueIndexFieldData ; private final ComparatorType comparatorType ; final TimeZoneRounding tzRounding ; final Recycler . V < LongObjectOpenHashMap < InternalFullDateHistogramFacet . FullEntry > > entries ; public ValueDateHistogramFacetExecutor ( IndexNumericFieldData keyIndexFieldData , IndexNumericFieldData valueIndexFieldData , TimeZoneRounding tzRounding , DateHistogramFacet . ComparatorType comparatorType , CacheRecycler cacheRecycler ) { } @ Override public ValueDateHistogramFacetExecutor . Collector collector ( ) { } @ Override public InternalFacet buildFacet ( String facetName ) { ArrayList < InternalFullDateHistogramFacet . FullEntry > entries1 = new ArrayList ( entries . v ( ) . size ( ) ) ; final boolean [ ] states = entries . v ( ) . allocated ; final Object [ ] values = entries . v ( ) . values ; for ( int i = 0 ; i < ( states . length ) ; i ++ ) { if ( states [ i ] ) { InternalFullDateHistogramFacet . FullEntry value = ( ( InternalFullDateHistogramFacet . FullEntry ) ( values [ i ] ) ) ; entries1 . add ( value ) ; } } <START_BUG> entries . release ( ) ; <END_BUG> return new InternalFullDateHistogramFacet ( facetName , comparatorType , entries1 ) ; } class Collector extends FacetExecutor . Collector { private final ValueDateHistogramFacetExecutor . DateHistogramProc histoProc ; private LongValues keyValues ; public Collector ( ) { } @ Override public void setNextReader ( AtomicReaderContext context ) throws IOException { } @ Override public void collect ( int doc ) throws IOException { } @ Override public void postCollection ( ) { } } public static class DateHistogramProc extends LongFacetAggregatorBase { final LongObjectOpenHashMap < InternalFullDateHistogramFacet . FullEntry > entries ; private final TimeZoneRounding tzRounding ; DoubleValues valueValues ; final ValueDateHistogramFacetExecutor . DateHistogramProc . ValueAggregator valueAggregator = new ValueDateHistogramFacetExecutor . DateHistogramProc . ValueAggregator ( ) ; public DateHistogramProc ( TimeZoneRounding tzRounding , LongObjectOpenHashMap < InternalFullDateHistogramFacet . FullEntry > entries ) { } @ Override public void onValue ( int docId , long value ) { } public static final class ValueAggregator extends DoubleFacetAggregatorBase { FullEntry entry ; @ Override public void onValue ( int docId , double value ) { } } } }<BUG2FIX>entries . close ( ) ;
public class RestCountAction extends BaseRestHandler { @ Inject public RestCountAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { CountRequest countRequest = new CountRequest ( RestActions . splitIndices ( request . param ( "index" ) ) ) ; if ( request . hasParam ( "ignore_indices" ) ) { countRequest . ignoreIndices ( IgnoreIndices . fromString ( request . param ( "ignore_indices" ) ) ) ; } countRequest . listenerThreaded ( false ) ; try { BroadcastOperationThreading operationThreading = BroadcastOperationThreading . fromString ( request . param ( "operation_threading" ) , SINGLE_THREAD ) ; if ( operationThreading == ( BroadcastOperationThreading . NO_THREADS ) ) { operationThreading = BroadcastOperationThreading . SINGLE_THREAD ; } countRequest . operationThreading ( operationThreading ) ; if ( request . hasContent ( ) ) { countRequest . query ( request . content ( ) , request . contentUnsafe ( ) ) ; } else { String source = request . param ( "source" ) ; if ( source != null ) { countRequest . query ( source ) ; } else { BytesReference querySource = RestActions . parseQuerySource ( request ) ; if ( querySource != null ) { countRequest . query ( querySource , false ) ; } } } countRequest . routing ( request . param ( "routing" ) ) ; countRequest . minScore ( request . paramAsFloat ( "min_score" , DEFAULT_MIN_SCORE ) ) ; countRequest . types ( splitTypes ( request . param ( "type" ) ) ) ; countRequest . preference ( request . param ( "preference" ) ) ; } catch ( Exception e ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . BAD_REQUEST , builder . startObject ( ) . field ( "error" , e . getMessage ( ) ) . endObject ( ) ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } return ; } client . count ( countRequest , new org . elasticsearch . action . ActionListener < CountResponse > ( ) { @ Override public void onResponse ( CountResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( "count" , response . getCount ( ) ) ; buildBroadcastShardsHeader ( builder , response ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class MapperQueryParser extends QueryParser { public static final ImmutableMap < String , FieldQueryExtension > fieldQueryExtensions ; private final QueryParseContext parseContext ; private QueryParserSettings settings ; private Analyzer quoteAnalyzer ; private boolean forcedAnalyzer ; private boolean forcedQuoteAnalyzer ; private FieldMapper currentMapper ; private boolean analyzeWildcard ; private String quoteFieldSuffix ; public MapperQueryParser ( QueryParseContext parseContext ) { } public MapperQueryParser ( QueryParserSettings settings , QueryParseContext parseContext ) { } public void reset ( QueryParserSettings settings ) { } @ Override Query handleBareFuzzy ( String qfield , Token fuzzySlop , String termImage ) throws ParseException { } @ Override protected Query newTermQuery ( Term term ) { } @ Override protected Query newMatchAllDocsQuery ( ) { } @ Override public Query getFieldQuery ( String field , String queryText , boolean quoted ) throws ParseException { FieldQueryExtension fieldQueryExtension = MapperQueryParser . fieldQueryExtensions . get ( field ) ; if ( fieldQueryExtension != null ) { return fieldQueryExtension . query ( parseContext , queryText ) ; } Collection < String > fields = extractMultiFields ( field ) ; if ( fields != null ) { if ( ( fields . size ( ) ) == 1 ) { return getFieldQuerySingle ( fields . iterator ( ) . next ( ) , queryText , quoted ) ; } if ( settings . useDisMax ( ) ) { DisjunctionMaxQuery disMaxQuery = new DisjunctionMaxQuery ( settings . tieBreaker ( ) ) ; boolean added = false ; for ( String mField : fields ) { Query q = getFieldQuerySingle ( mField , queryText , quoted ) ; if ( q != null ) { added = true ; applyBoost ( mField , q ) ; disMaxQuery . add ( q ) ; } } if ( ! added ) { return null ; } return disMaxQuery ; } else { List < BooleanClause > clauses = new ArrayList < BooleanClause > ( ) ; for ( String mField : fields ) { <START_BUG> Query q = getFieldQuerySingle ( mField , queryText , true ) ; <END_BUG> if ( q != null ) { applyBoost ( mField , q ) ; clauses . add ( new BooleanClause ( q , Occur . SHOULD ) ) ; } } if ( ( clauses . size ( ) ) == 0 ) return null ; return getBooleanQuery ( clauses , true ) ; } } else { return getFieldQuerySingle ( field , queryText , quoted ) ; } } private Query getFieldQuerySingle ( String field , String queryText , boolean quoted ) throws ParseException { } @ Override protected Query getFieldQuery ( String field , String queryText , int slop ) throws ParseException { } @ Override protected Query getRangeQuery ( String field , String part1 , String part2 , boolean startInclusive , boolean endInclusive ) throws ParseException { } private Query getRangeQuerySingle ( String field , String part1 , String part2 , boolean startInclusive , boolean endInclusive ) { } protected Query getFuzzyQuery ( String field , String termStr , String minSimilarity ) throws ParseException { } private Query getFuzzyQuerySingle ( String field , String termStr , String minSimilarity ) throws ParseException { } @ Override protected Query newFuzzyQuery ( Term term , float minimumSimilarity , int prefixLength ) { } @ Override protected Query getPrefixQuery ( String field , String termStr ) throws ParseException { } private Query getPrefixQuerySingle ( String field , String termStr ) throws ParseException { } private Query getPossiblyAnalyzedPrefixQuery ( String field , String termStr ) throws ParseException { } @ Override protected Query getWildcardQuery ( String field , String termStr ) throws ParseException { } private Query getWildcardQuerySingle ( String field , String termStr ) throws ParseException { } private Query getPossiblyAnalyzedWildcardQuery ( String field , String termStr ) throws ParseException { } @ Override protected Query getRegexpQuery ( String field , String termStr ) throws ParseException { } private Query getRegexpQuerySingle ( String field , String termStr ) throws ParseException { } @ Override protected Query getBooleanQuery ( List < BooleanClause > clauses , boolean disableCoord ) throws ParseException { } private void applyBoost ( String field , Query q ) { } private void applySlop ( Query q , int slop ) { } private Collection < String > extractMultiFields ( String field ) { } }<BUG2FIX>Query q = getFieldQuerySingle ( mField , queryText , quoted ) ;
public class PublishClusterStateAction extends AbstractComponent { public static interface NewClusterStateListener { void onNewClusterState ( ClusterState clusterState ) { } } private final TransportService transportService ; private final DiscoveryNodesProvider nodesProvider ; private final PublishClusterStateAction . NewClusterStateListener listener ; public PublishClusterStateAction ( Settings settings , TransportService transportService , DiscoveryNodesProvider nodesProvider , PublishClusterStateAction . NewClusterStateListener listener ) { } public void close ( ) { } public void publish ( ClusterState clusterState ) { } class PublishClusterStateRequest implements Streamable { BytesReference clusterStateInBytes ; private PublishClusterStateRequest ( ) { } private PublishClusterStateRequest ( byte [ ] clusterStateInBytes ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { <START_BUG> out . writeBytesReference ( clusterStateInBytes , true ) ; <END_BUG> } } private class PublishClusterStateRequestHandler extends BaseTransportRequestHandler < PublishClusterStateAction . PublishClusterStateRequest > { static final String ACTION = "discovery/zen/publish" ; @ Override public PublishClusterStateAction . PublishClusterStateRequest newInstance ( ) { } @ Override public void messageReceived ( PublishClusterStateAction . PublishClusterStateRequest request , TransportChannel channel ) throws Exception { } @ Override public String executor ( ) { } } }<BUG2FIX>out . writeBytesReference ( clusterStateInBytes ) ;
public class MipMapGenerator { private MipMapGenerator ( ) { } private static boolean useHWMipMap = true ; public static void setUseHardwareMipMap ( boolean useHWMipMap ) { } public static void generateMipMap ( Pixmap pixmap , int textureWidth , int textureHeight ) { } public static void generateMipMap ( int target , Pixmap pixmap , int textureWidth , int textureHeight ) { if ( ! ( MipMapGenerator . useHWMipMap ) ) { MipMapGenerator . generateMipMapCPU ( target , pixmap , textureWidth , textureHeight ) ; return ; } <START_BUG> if ( ( ( ( app . getType ( ) ) == ( ApplicationType . Android ) ) || ( ( app . getType ( ) ) == ( ApplicationType . WebGL ) ) ) || ( ( app . getType ( ) ) == ( ApplicationType . iOS ) ) ) { <END_BUG> if ( graphics . isGL20Available ( ) ) MipMapGenerator . generateMipMapGLES20 ( target , pixmap ) ; else MipMapGenerator . generateMipMapCPU ( target , pixmap , textureWidth , textureHeight ) ; } else { MipMapGenerator . generateMipMapDesktop ( target , pixmap , textureWidth , textureHeight ) ; } } private static void generateMipMapGLES20 ( int target , Pixmap pixmap ) { } private static void generateMipMapDesktop ( int target , Pixmap pixmap , int textureWidth , int textureHeight ) { } private static void generateMipMapCPU ( int target , Pixmap pixmap , int textureWidth , int textureHeight ) { } }<BUG2FIX>if ( ( ( app . getType ( ) ) == ( ApplicationType . Android ) ) || ( ( app . getType ( ) ) == ( ApplicationType . WebGL ) ) ) {
public class RestRefreshAction extends BaseRestHandler { @ Inject public RestRefreshAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { RefreshRequest refreshRequest = new RefreshRequest ( RestActions . splitIndices ( request . param ( "index" ) ) ) ; refreshRequest . listenerThreaded ( false ) ; if ( request . hasParam ( "ignore_indices" ) ) { refreshRequest . ignoreIndices ( IgnoreIndices . fromString ( request . param ( "ignore_indices" ) ) ) ; } BroadcastOperationThreading operationThreading = BroadcastOperationThreading . fromString ( request . param ( "operation_threading" ) , SINGLE_THREAD ) ; if ( operationThreading == ( BroadcastOperationThreading . NO_THREADS ) ) { operationThreading = BroadcastOperationThreading . THREAD_PER_SHARD ; } refreshRequest . operationThreading ( operationThreading ) ; client . admin ( ) . indices ( ) . refresh ( refreshRequest , new org . elasticsearch . action . ActionListener < RefreshResponse > ( ) { @ Override public void onResponse ( RefreshResponse response ) { try { XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; builder . field ( "ok" , true ) ; buildBroadcastShardsHeader ( builder , response ) ; builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class IndexingMemoryController extends AbstractLifecycleComponent < IndexingMemoryController > { private final ThreadPool threadPool ; private final IndicesService indicesService ; private final ByteSizeValue indexingBuffer ; private final ByteSizeValue minShardIndexBufferSize ; private final ByteSizeValue maxShardIndexBufferSize ; private final TimeValue inactiveTime ; private final TimeValue interval ; private final IndexingMemoryController . Listener listener = new IndexingMemoryController . Listener ( ) ; private final Map < ShardId , IndexingMemoryController . ShardIndexingStatus > shardsIndicesStatus = Maps . newHashMap ( ) ; private volatile ScheduledFuture scheduler ; private final Object mutex = new Object ( ) ; @ Inject public IndexingMemoryController ( Settings settings , ThreadPool threadPool , IndicesService indicesService ) { } @ Override protected void doStart ( ) throws ElasticSearchException { } @ Override protected void doStop ( ) throws ElasticSearchException { } @ Override protected void doClose ( ) throws ElasticSearchException { } class ShardsIndicesStatusChecker implements Runnable { @ Override public void run ( ) { } } class Listener extends IndicesLifecycle . Listener { @ Override public void afterIndexShardCreated ( IndexShard indexShard ) { } @ Override <START_BUG> public void afterIndexShardClosed ( ShardId shardId , boolean delete ) { <END_BUG> synchronized ( mutex ) { calcAndSetShardIndexingBuffer ( ( ( ( ( "removed_shard[" + ( shardId . index ( ) . name ( ) ) ) + "][" ) + ( shardId . id ( ) ) ) + "]" ) ) ; shardsIndicesStatus . remove ( shardId ) ; } } } private void calcAndSetShardIndexingBuffer ( String reason ) { } private ByteSizeValue calcShardIndexingBuffer ( int shardsCount ) { } private int countShards ( ) { } static class ShardIndexingStatus { long translogId = - 1 ; int translogNumberOfOperations = - 1 ; boolean inactiveIndexing = false ; long time = - 1 ; } }<BUG2FIX>public void afterIndexShardClosed ( ShardId shardId ) {
public class TransportAliasesExistAction extends TransportMasterNodeReadOperationAction < GetAliasesRequest , AliasesExistResponse > { @ Inject public TransportAliasesExistAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool ) { } @ Override protected String transportAction ( ) { } @ Override protected String executor ( ) { } @ Override protected GetAliasesRequest newRequest ( ) { } @ Override protected AliasesExistResponse newResponse ( ) { } @ Override protected void masterOperation ( GetAliasesRequest request , ClusterState state , ActionListener < AliasesExistResponse > listener ) throws ElasticsearchException { <START_BUG> String [ ] concreteIndices = state . metaData ( ) . concreteIndices ( request . indices ( ) , request . indicesOptions ( ) ) ; <END_BUG> request . indices ( concreteIndices ) ; boolean result = state . metaData ( ) . hasAliases ( request . aliases ( ) , request . indices ( ) ) ; listener . onResponse ( new AliasesExistResponse ( result ) ) ; } }<BUG2FIX>String [ ] concreteIndices = state . metaData ( ) . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ;
public abstract class TransportBroadcastOperationAction < Request extends BroadcastOperationRequest , Response extends BroadcastOperationResponse , ShardRequest extends BroadcastShardOperationRequest , ShardResponse extends BroadcastShardOperationResponse > extends TransportAction < Request , Response > { protected final ClusterService clusterService ; protected final TransportService transportService ; protected final ThreadPool threadPool ; final String transportAction ; final String transportShardAction ; final String executor ; protected TransportBroadcastOperationAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportService transportService ) { } @ Override protected void doExecute ( Request request , ActionListener < Response > listener ) { } protected abstract String transportAction ( ) { } protected abstract String executor ( ) { } protected abstract Request newRequest ( ) { } protected abstract Response newResponse ( Request request , AtomicReferenceArray shardsResponses , ClusterState clusterState ) { } protected abstract ShardRequest newShardRequest ( ) { } protected abstract ShardRequest newShardRequest ( ShardRouting shard , Request request ) { } protected abstract ShardResponse newShardResponse ( ) { } protected abstract ShardResponse shardOperation ( ShardRequest request ) throws ElasticSearchException { } protected abstract GroupShardsIterator shards ( ClusterState clusterState , Request request , String [ ] concreteIndices ) { } protected boolean accumulateExceptions ( ) { } protected boolean ignoreException ( Throwable t ) { } protected boolean ignoreNonActiveExceptions ( ) { } protected boolean ignoreIllegalShardState ( ) { } protected abstract ClusterBlockException checkGlobalBlock ( ClusterState state , Request request ) { } protected abstract ClusterBlockException checkRequestBlock ( ClusterState state , Request request , String [ ] concreteIndices ) { } class AsyncBroadcastAction { private final Request request ; private final ActionListener < Response > listener ; private final ClusterState clusterState ; private final DiscoveryNodes nodes ; private final GroupShardsIterator shardsIts ; private final int expectedOps ; private final AtomicInteger counterOps = new AtomicInteger ( ) ; private final AtomicInteger indexCounter = new AtomicInteger ( ) ; private final AtomicReferenceArray shardsResponses ; AsyncBroadcastAction ( Request request , ActionListener < Response > listener ) { } public void start ( ) { } void performOperation ( final ShardIterator shardIt , boolean localAsync ) { } void performOperation ( final ShardIterator shardIt , final ShardRouting shard , boolean localAsync ) { if ( shard == null ) { onOperation ( null , shardIt , null ) ; } else { final ShardRequest shardRequest = newShardRequest ( shard , request ) ; if ( shard . currentNodeId ( ) . equals ( nodes . localNodeId ( ) ) ) { if ( localAsync ) { threadPool . executor ( executor ) . execute ( new Runnable ( ) { @ Override public void run ( ) { try { onOperation ( shard , shardOperation ( shardRequest ) ) ; } catch ( Exception e ) { onOperation ( shard , shardIt , e ) ; } } } ) ; } else { try { onOperation ( shard , shardOperation ( shardRequest ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onOperation ( shard , shardIt , e ) ; } } } else { DiscoveryNode node = nodes . get ( shard . currentNodeId ( ) ) ; if ( node == null ) { onOperation ( shard , shardIt , null ) ; } else { transportService . sendRequest ( node , transportShardAction , shardRequest , new BaseTransportResponseHandler < ShardResponse > ( ) { @ Override public ShardResponse newInstance ( ) { return newShardResponse ( ) ; } @ Override public String executor ( ) { return Names . SAME ; } @ Override public void handleResponse ( ShardResponse response ) { onOperation ( shard , response ) ; } @ Override public void handleException ( TransportException e ) { onOperation ( shard , shardIt , e ) ; } } ) ; } } } } @ SuppressWarnings ( { "unchecked" } ) void onOperation ( ShardRouting shard , ShardResponse response ) { } @ SuppressWarnings ( { "unchecked" } ) void onOperation ( @ Nullable ShardRouting shard , final ShardIterator shardIt , Throwable t ) { } void finishHim ( ) { } } class TransportHandler extends BaseTransportRequestHandler < Request > { @ Override public Request newInstance ( ) { } @ Override public String executor ( ) { } @ Override public void messageReceived ( Request request , final TransportChannel channel ) throws Exception { } } class ShardTransportHandler extends BaseTransportRequestHandler < ShardRequest > { @ Override public ShardRequest newInstance ( ) { } @ Override public String executor ( ) { } @ Override public void messageReceived ( final ShardRequest request , final TransportChannel channel ) throws Exception { } } }<BUG2FIX>} catch ( Throwable e ) {
public class ValidateQueryRequest extends BroadcastOperationRequest { private static final XContentType contentType = Requests . CONTENT_TYPE ; private BytesReference querySource ; private boolean querySourceUnsafe ; private boolean explain ; private String [ ] types = Strings . EMPTY_ARRAY ; ValidateQueryRequest ( ) { } public ValidateQueryRequest ( String ... indices ) { } @ Override public ActionRequestValidationException validate ( ) { } @ Override public ValidateQueryRequest operationThreading ( BroadcastOperationThreading operationThreading ) { } @ Override protected void beforeStart ( ) { } @ Override public ValidateQueryRequest listenerThreaded ( boolean threadedListener ) { } public ValidateQueryRequest indices ( String ... indices ) { } BytesReference querySource ( ) { } @ Required public ValidateQueryRequest query ( QueryBuilder queryBuilder ) { } @ Required public ValidateQueryRequest query ( Map querySource ) { } @ Required public ValidateQueryRequest query ( XContentBuilder builder ) { } @ Required public ValidateQueryRequest query ( String querySource ) { } @ Required public ValidateQueryRequest query ( byte [ ] querySource ) { } @ Required public ValidateQueryRequest query ( byte [ ] querySource , int offset , int length , boolean unsafe ) { } @ Required public ValidateQueryRequest query ( BytesReference querySource , boolean unsafe ) { } String [ ] types ( ) { } public ValidateQueryRequest types ( String ... types ) { } public void explain ( boolean explain ) { } public boolean explain ( ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { } @ Override public void writeTo ( StreamOutput out ) throws IOException { super . writeTo ( out ) ; <START_BUG> out . writeBytesReference ( querySource , true ) ; <END_BUG> out . writeVInt ( types . length ) ; for ( String type : types ) { out . writeUTF ( type ) ; } out . writeBoolean ( explain ) ; } @ Override public String toString ( ) { } }<BUG2FIX>out . writeBytesReference ( querySource ) ;
public class GdxSetup { public void build ( String outputDir , String appName , String packageName , String mainClass ) { Project project = new Project ( ) ; String packageDir = packageName . replace ( '.' , '/' ) ; project . files . add ( new ProjectFile ( "build.gradle" , true ) ) ; project . files . add ( new ProjectFile ( "settings.gradle" ) ) ; project . files . add ( new ProjectFile ( "gradlew" , false ) ) ; project . files . add ( new ProjectFile ( "gradlew.bat" , false ) ) ; project . files . add ( new ProjectFile ( "gradle/wrapper/gradle-wrapper.jar" , false ) ) ; project . files . add ( new ProjectFile ( "gradle/wrapper/gradle-wrapper.properties" , false ) ) ; project . files . add ( new ProjectFile ( "core/build.gradle" ) ) ; project . files . add ( new ProjectFile ( "core/src/MainClass" , ( ( ( ( "core/src/" + packageDir ) + "/" ) + mainClass ) + ".java" ) , true ) ) ; project . files . add ( new ProjectFile ( "core/CoreGdxDefinition" , ( ( ( ( "core/src/" + packageDir ) + "/" ) + mainClass ) + ".gwt.xml" ) , true ) ) ; project . files . add ( new ProjectFile ( "desktop/build.gradle" ) ) ; project . files . add ( new ProjectFile ( "desktop/src/DesktopLauncher" , ( ( "desktop/src/" + packageDir ) + "/desktop/DesktopLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "android/assets/badlogic.jpg" , false ) ) ; <START_BUG> project . files . add ( new ProjectFile ( "android/res/values/strings.xml" , false ) ) ; <END_BUG> project . files . add ( new ProjectFile ( "android/res/values/styles.xml" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-hdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-mdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-xhdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/res/drawable-xxhdpi/ic_launcher.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/src/AndroidLauncher" , ( ( "android/src/" + packageDir ) + "/android/AndroidLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "android/AndroidManifest.xml" ) ) ; project . files . add ( new ProjectFile ( "android/build.gradle" ) ) ; project . files . add ( new ProjectFile ( "android/ic_launcher-web.png" , false ) ) ; project . files . add ( new ProjectFile ( "android/proguard-project.txt" , false ) ) ; project . files . add ( new ProjectFile ( "android/project.properties" , false ) ) ; project . files . add ( new ProjectFile ( "gwt/build.gradle" ) ) ; project . files . add ( new ProjectFile ( "gwt/src/GwtLauncher" , ( ( "gwt/src/" + packageDir ) + "/client/GwtLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "gwt/GdxDefinition" , ( ( "gwt/src/" + packageDir ) + "/GdxDefinition.gwt.xml" ) , true ) ) ; project . files . add ( new ProjectFile ( "gwt/war/index" , ( "gwt/webapp/" + "index.html" ) , true ) ) ; project . files . add ( new ProjectFile ( "gwt/war/WEB-INF/web.xml" , "gwt/webapp/WEB-INF/web.xml" , true ) ) ; project . files . add ( new ProjectFile ( "ios/src/IOSLauncher" , ( ( "ios/src/" + packageDir ) + "/IOSLauncher.java" ) , true ) ) ; project . files . add ( new ProjectFile ( "ios/build.gradle" ) ) ; Map < String , String > values = new HashMap < String , String > ( ) ; values . put ( "%APP_NAME%" , appName ) ; values . put ( "%PACKAGE%" , packageName ) ; values . put ( "%MAIN_CLASS%" , mainClass ) ; copyAndReplace ( outputDir , project , values ) ; new File ( outputDir , "gradlew" ) . setExecutable ( true ) ; } private void copyAndReplace ( String outputDir , Project project , Map < String , String > values ) { } private byte [ ] readResource ( String resource ) { } private String readResourceAsString ( String resource ) { } private void writeFile ( File outFile , byte [ ] bytes ) { } private void writeFile ( File outFile , String text ) { } private void copyFile ( ProjectFile file , File out , Map < String , String > values ) { } private String replace ( String txt , Map < String , String > values ) { } private static void printHelp ( ) { } private static Map < String , String > parseArgs ( String [ ] args ) { } public static void main ( String [ ] args ) { } }<BUG2FIX>project . files . add ( new ProjectFile ( "android/res/values/strings.xml" ) ) ;
public class FrameBuffer implements Disposable { private static final Map < Application , List < FrameBuffer > > buffers = new HashMap < Application , List < FrameBuffer > > ( ) ; protected Texture colorTexture ; private static int defaultFramebufferHandle ; private static boolean defaultFramebufferHandleInitialized = false ; private int framebufferHandle ; private int depthbufferHandle ; protected final int width ; protected final int height ; protected final boolean hasDepth ; protected final Format format ; public FrameBuffer ( Pixmap . Format format , int width , int height , boolean hasDepth ) { } protected void setupTexture ( ) { } private void build ( ) { if ( ! ( graphics . isGL20Available ( ) ) ) throw new GdxRuntimeException ( "GL2<seq2seq4repair_space>is<seq2seq4repair_space>required." ) ; GL20 gl = graphics . getGL20 ( ) ; if ( ! ( FrameBuffer . defaultFramebufferHandleInitialized ) ) { FrameBuffer . defaultFramebufferHandleInitialized = true ; if ( ( app . getType ( ) ) == ( ApplicationType . iOS ) ) { IntBuffer intbuf = ByteBuffer . allocateDirect ( ( ( 16 * ( Integer . SIZE ) ) / 8 ) ) . order ( ByteOrder . nativeOrder ( ) ) . asIntBuffer ( ) ; gl . glGetIntegerv ( GL_FRAMEBUFFER_BINDING , intbuf ) ; <START_BUG> FrameBuffer . defaultFramebufferHandle = intbuf . get ( 0 ) ; <END_BUG> } else { FrameBuffer . defaultFramebufferHandle = 0 ; } } setupTexture ( ) ; IntBuffer handle = BufferUtils . newIntBuffer ( 1 ) ; gl . glGenFramebuffers ( 1 , handle ) ; framebufferHandle = handle . get ( 0 ) ; if ( hasDepth ) { handle . clear ( ) ; gl . glGenRenderbuffers ( 1 , handle ) ; depthbufferHandle = handle . get ( 0 ) ; } gl . glBindTexture ( GL_TEXTURE_2D , colorTexture . getTextureObjectHandle ( ) ) ; if ( hasDepth ) { gl . glBindRenderbuffer ( GL_RENDERBUFFER , depthbufferHandle ) ; gl . glRenderbufferStorage ( GL_RENDERBUFFER , GL_DEPTH_COMPONENT16 , colorTexture . getWidth ( ) , colorTexture . getHeight ( ) ) ; } gl . glBindFramebuffer ( GL_FRAMEBUFFER , framebufferHandle ) ; gl . glFramebufferTexture2D ( GL_FRAMEBUFFER , GL_COLOR_ATTACHMENT0 , GL_TEXTURE_2D , colorTexture . getTextureObjectHandle ( ) , 0 ) ; if ( hasDepth ) { gl . glFramebufferRenderbuffer ( GL_FRAMEBUFFER , GL_DEPTH_ATTACHMENT , GL_RENDERBUFFER , depthbufferHandle ) ; } int result = gl . glCheckFramebufferStatus ( GL_FRAMEBUFFER ) ; gl . glBindRenderbuffer ( GL_RENDERBUFFER , 0 ) ; gl . glBindTexture ( GL_TEXTURE_2D , 0 ) ; gl . glBindFramebuffer ( GL_FRAMEBUFFER , FrameBuffer . defaultFramebufferHandle ) ; if ( result != ( GL20 . GL_FRAMEBUFFER_COMPLETE ) ) { colorTexture . dispose ( ) ; if ( hasDepth ) { handle . clear ( ) ; handle . put ( depthbufferHandle ) ; handle . flip ( ) ; gl . glDeleteRenderbuffers ( 1 , handle ) ; } colorTexture . dispose ( ) ; handle . clear ( ) ; handle . put ( framebufferHandle ) ; handle . flip ( ) ; gl . glDeleteFramebuffers ( 1 , handle ) ; if ( result == ( GL20 . GL_FRAMEBUFFER_INCOMPLETE_ATTACHMENT ) ) throw new IllegalStateException ( "frame<seq2seq4repair_space>buffer<seq2seq4repair_space>couldn't<seq2seq4repair_space>be<seq2seq4repair_space>constructed:<seq2seq4repair_space>incomplete<seq2seq4repair_space>attachment" ) ; if ( result == ( GL20 . GL_FRAMEBUFFER_INCOMPLETE_DIMENSIONS ) ) throw new IllegalStateException ( "frame<seq2seq4repair_space>buffer<seq2seq4repair_space>couldn't<seq2seq4repair_space>be<seq2seq4repair_space>constructed:<seq2seq4repair_space>incomplete<seq2seq4repair_space>dimensions" ) ; if ( result == ( GL20 . GL_FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT ) ) throw new IllegalStateException ( "frame<seq2seq4repair_space>buffer<seq2seq4repair_space>couldn't<seq2seq4repair_space>be<seq2seq4repair_space>constructed:<seq2seq4repair_space>missing<seq2seq4repair_space>attachment" ) ; } } public void dispose ( ) { } public void begin ( ) { } public void end ( ) { } private void addManagedFrameBuffer ( Application app , FrameBuffer frameBuffer ) { } public static void invalidateAllFrameBuffers ( Application app ) { } public static void clearAllFrameBuffers ( Application app ) { } public static String getManagedStatus ( ) { } public Texture getColorBufferTexture ( ) { } public int getHeight ( ) { } public int getWidth ( ) { } }<BUG2FIX>FrameBuffer . defaultFramebufferHandle = intbuf . get ( ) ;
public class Pixmap implements Disposable { public enum Format { Alpha , LuminanceAlpha , RGB565 , RGBA4444 , RGB888 , RGBA8888 ; static int toGdx2DPixmapFormat ( Pixmap . Format format ) { } static Pixmap . Format fromGdx2DPixmapFormat ( int format ) { } } public enum Blending { None , SourceOver ; } public enum Filter { NearestNeighbour , BiLinear ; } final Gdx2DPixmap pixmap ; int color = 0 ; public static void setBlending ( Pixmap . Blending blending ) { } public static void setFilter ( Pixmap . Filter filter ) { } public Pixmap ( int width , int height , Pixmap . Format format ) { } public Pixmap ( FileHandle file ) { } public void setColor ( float r , float g , float b , float a ) { } public void fill ( ) { } public void drawLine ( int x , int y , int x2 , int y2 ) { } public void drawRectangle ( int x , int y , int width , int height ) { } public void drawPixmap ( Pixmap pixmap , int x , int y , int srcx , int srcy , int srcWidth , int srcHeight ) { } public void drawPixmap ( Pixmap pixmap , int srcx , int srcy , int srcWidth , int srcHeight , int dstx , int dsty , int dstWidth , int dstHeight ) { } public void fillRectangle ( int x , int y , int width , int height ) { } public void drawCircle ( int x , int y , int radius ) { } public void fillCircle ( int x , int y , int radius ) { <START_BUG> pixmap . drawCircle ( x , y , radius , color ) ; <END_BUG> } public int getPixel ( int x , int y ) { } public int getWidth ( ) { } public int getHeight ( ) { } public void dispose ( ) { } public void drawPixel ( int x , int y ) { } public int getGLFormat ( ) { } public int getGLInternalFormat ( ) { } public int getGLType ( ) { } public ByteBuffer getPixels ( ) { } public Pixmap . Format getFormat ( ) { } }<BUG2FIX>pixmap . fillCircle ( x , y , radius , color ) ;
public class TransportBroadcastPingAction extends TransportBroadcastOperationAction < BroadcastPingRequest , BroadcastPingResponse , BroadcastShardPingRequest , BroadcastShardPingResponse > { @ Inject public TransportBroadcastPingAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportService transportService ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected String transportShardAction ( ) { } @ Override protected BroadcastPingRequest newRequest ( ) { } @ Override protected GroupShardsIterator shards ( BroadcastPingRequest request , ClusterState clusterState ) { <START_BUG> return clusterService . operationRouting ( ) . searchShards ( clusterState , request . indices ( ) , request . queryHint ( ) , null ) ; <END_BUG> } @ Override protected BroadcastPingResponse newResponse ( BroadcastPingRequest request , AtomicReferenceArray shardsResponses , ClusterState clusterState ) { } @ Override protected BroadcastShardPingRequest newShardRequest ( ) { } @ Override protected BroadcastShardPingRequest newShardRequest ( ShardRouting shard , BroadcastPingRequest request ) { } @ Override protected BroadcastShardPingResponse newShardResponse ( ) { } @ Override protected BroadcastShardPingResponse shardOperation ( BroadcastShardPingRequest broadcastShardPingRequest ) throws ElasticSearchException { } }<BUG2FIX>return clusterService . operationRouting ( ) . searchShards ( clusterState , request . indices ( ) , request . queryHint ( ) , null , null ) ;
public abstract class FollowingFragment extends PagedUserFragment { @ Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; <START_BUG> setEmptyText ( getString ( no_people ) ) ; <END_BUG> } @ Override protected int getLoadingMessage ( ) { } @ Override public void onLoadFinished ( Loader < List < User > > loader , List < User > items ) { } }<BUG2FIX>setEmptyText ( no_people ) ;
public final class BytesRefValComparator extends NestedWrappableComparator < BytesRef > { private final IndexFieldData < ? > indexFieldData ; private final MultiValueMode sortMode ; private final BytesRef missingValue ; private final BytesRef [ ] values ; private BytesRef bottom ; private BytesRef top ; private BytesValues docTerms ; BytesRefValComparator ( IndexFieldData < ? > indexFieldData , int numHits , MultiValueMode sortMode , BytesRef missingValue ) { } @ Override public int compare ( int slot1 , int slot2 ) { } @ Override public int compareBottom ( int doc ) throws IOException { } @ Override public int compareTop ( int doc ) throws IOException { } @ Override public void copy ( int slot , int doc ) throws IOException { } @ Override public FieldComparator < BytesRef > setNextReader ( AtomicReaderContext context ) throws IOException { <START_BUG> docTerms = indexFieldData . load ( context ) . getBytesValues ( false ) ; <END_BUG> return this ; } @ Override public void setBottom ( final int bottom ) { } @ Override public void setTopValue ( BytesRef top ) { } @ Override public BytesRef value ( int slot ) { } @ Override public int compareValues ( BytesRef val1 , BytesRef val2 ) { } @ Override public void missing ( int slot ) { } @ Override public int compareBottomMissing ( ) { } @ Override public int compareTopMissing ( ) { } }<BUG2FIX>docTerms = indexFieldData . load ( context ) . getBytesValues ( ) ;
public final class EarClippingTriangulator { private static final int CONCAVE = 1 ; private static final int CONVEX = - 1 ; private int concaveVertexCount ; public List < Vector2 > computeTriangles ( final List < Vector2 > polygon ) { final ArrayList < Vector2 > triangles = new ArrayList < Vector2 > ( ) ; final ArrayList < Vector2 > vertices = new ArrayList < Vector2 > ( polygon . size ( ) ) ; vertices . addAll ( polygon ) ; <START_BUG> while ( ( vertices . size ( ) ) >= 3 ) { <END_BUG> final int [ ] vertexTypes = this . classifyVertices ( vertices ) ; final int vertexCount = vertices . size ( ) ; for ( int index = 0 ; index < vertexCount ; index ++ ) { if ( this . isEarTip ( vertices , index , vertexTypes ) ) { this . cutEarTip ( vertices , index , triangles ) ; break ; } } } if ( ( vertices . size ( ) ) == 3 ) { triangles . addAll ( vertices ) ; } return triangles ; } private static boolean areVerticesClockwise ( final ArrayList < Vector2 > pVertices ) { } private int [ ] classifyVertices ( final ArrayList < Vector2 > pVertices ) { } private static boolean isTriangleConvex ( final float pX1 , final float pY1 , final float pX2 , final float pY2 , final float pX3 , final float pY3 ) { } private static int computeSpannedAreaSign ( final float pX1 , final float pY1 , final float pX2 , final float pY2 , final float pX3 , final float pY3 ) { } private static boolean isAnyVertexInTriangle ( final ArrayList < Vector2 > pVertices , final int [ ] pVertexTypes , final float pX1 , final float pY1 , final float pX2 , final float pY2 , final float pX3 , final float pY3 ) { } private boolean isEarTip ( final ArrayList < Vector2 > pVertices , final int pEarTipIndex , final int [ ] pVertexTypes ) { } private void cutEarTip ( final ArrayList < Vector2 > pVertices , final int pEarTipIndex , final ArrayList < Vector2 > pTriangles ) { } private static void removeCollinearNeighborEarsAfterRemovingEarTip ( final ArrayList < Vector2 > pVertices , final int pEarTipCutIndex ) { } private static boolean isCollinear ( final ArrayList < Vector2 > pVertices , final int pIndex ) { } private static boolean isCollinear ( final ArrayList < Vector2 > pVertices , final int pPreviousIndex , final int pIndex , final int pNextIndex ) { } private static int computePreviousIndex ( final List < Vector2 > pVertices , final int pIndex ) { } private static int computeNextIndex ( final List < Vector2 > pVertices , final int pIndex ) { } }<BUG2FIX>while ( ( vertices . size ( ) ) > 3 ) {
public abstract class EventPager extends ResourcePager < Event > { @ Override <START_BUG> protected String getId ( Event resource ) { <END_BUG> return resource . getId ( ) ; } }<BUG2FIX>protected Object getId ( Event resource ) {
public class SpanTermQueryParser extends AbstractIndexComponent implements XContentQueryParser { public static final String NAME = "span_term" ; @ Inject public SpanTermQueryParser ( Index index , @ IndexSettings Settings settings ) { } @ Override public String [ ] names ( ) { } @ Override public Query parse ( QueryParseContext parseContext ) throws IOException , QueryParsingException { XContentParser parser = parseContext . parser ( ) ; XContentParser . Token token = parser . currentToken ( ) ; if ( token == ( Token . START_OBJECT ) ) { token = parser . nextToken ( ) ; } assert token == ( Token . FIELD_NAME ) ; String fieldName = parser . currentName ( ) ; String value = null ; float boost = 1.0F ; token = parser . nextToken ( ) ; if ( token == ( Token . START_OBJECT ) ) { String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) != ( Token . END_OBJECT ) ) { if ( token == ( Token . FIELD_NAME ) ) { currentFieldName = parser . currentName ( ) ; } else { if ( "value" . equals ( currentFieldName ) ) { value = parser . text ( ) ; } else if ( "boost" . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } } } } else { value = parser . text ( ) ; parser . nextToken ( ) ; } if ( value == null ) { throw new QueryParsingException ( index , "No<seq2seq4repair_space>value<seq2seq4repair_space>specified<seq2seq4repair_space>for<seq2seq4repair_space>term<seq2seq4repair_space>query" ) ; } MapperService . SmartNameFieldMappers smartNameFieldMappers = parseContext . smartFieldMappers ( fieldName ) ; if ( smartNameFieldMappers != null ) { if ( smartNameFieldMappers . hasMapper ( ) ) { fieldName = smartNameFieldMappers . mapper ( ) . names ( ) . indexName ( ) ; value = smartNameFieldMappers . mapper ( ) . indexedValue ( value ) ; } } SpanTermQuery query = new SpanTermQuery ( new Term ( fieldName , value ) ) ; query . setBoost ( boost ) ; <START_BUG> return wrapSmartNameQuery ( query , smartNameFieldMappers , parseContext . indexCache ( ) ) ; <END_BUG> } }<BUG2FIX>return wrapSmartNameQuery ( query , smartNameFieldMappers , parseContext ) ;
public class LwjglDebugStarter { public static void main ( String [ ] argv ) { LwjglApplicationConfiguration config = new LwjglApplicationConfiguration ( ) ; <START_BUG> config . useGL20 = false ; <END_BUG> config . vSyncEnabled = true ; new com . badlogic . gdx . backends . lwjgl . LwjglApplication ( new ShapeRendererTest ( ) , config ) ; } }<BUG2FIX>config . useGL20 = true ;
public class FastImage extends Actor { public final TextureRegion region ; private float sX ; private float sY ; private float sOriginX ; private float sOriginY ; private float sRotation ; private float sScaleX ; private float sScaleY ; private float sWidth ; private float sHeight ; private Sprite sprite = new Sprite ( ) ; boolean updated = false ; public FastImage ( String name ) { } public FastImage ( String name , Texture texture ) { } public FastImage ( String name , TextureRegion region ) { } @ Override protected void draw ( SpriteBatch batch , float parentAlpha ) { updateSprite ( ) ; if ( ( region . getTexture ( ) ) != null ) { <START_BUG> sprite . draw ( batch ) ; <END_BUG> } } private void updateSprite ( ) { } @ Override protected boolean touchDown ( float x , float y , int pointer ) { } @ Override protected boolean touchUp ( float x , float y , int pointer ) { } @ Override protected boolean touchDragged ( float x , float y , int pointer ) { } public Actor hit ( float x , float y ) { } }<BUG2FIX>sprite . draw ( batch , parentAlpha ) ;
public final class NoisyChannelSpellChecker { public static final double REAL_WORD_LIKELYHOOD = 0.95 ; public static final int DEFAULT_TOKEN_LIMIT = 10 ; private final double realWordLikelihood ; private final boolean requireUnigram ; private final int tokenLimit ; public NoisyChannelSpellChecker ( ) { } public NoisyChannelSpellChecker ( double nonErrorLikelihood ) { } public NoisyChannelSpellChecker ( double nonErrorLikelihood , boolean requireUnigram , int tokenLimit ) { } public Correction [ ] getCorrections ( TokenStream stream , final CandidateGenerator generator , float maxErrors , int numCorrections , IndexReader reader , WordScorer wordScorer , BytesRef separator , float confidence , int gramSize ) throws IOException { final List < CandidateSet > candidateSetsList = new ArrayList < DirectCandidateGenerator . CandidateSet > ( ) ; SuggestUtils . analyze ( stream , new SuggestUtils . TokenConsumer ( ) { CandidateSet currentSet = null ; private TypeAttribute typeAttribute ; private final BytesRef termsRef = new BytesRef ( ) ; private boolean anyUnigram = false ; private boolean anyTokens = false ; @ Override public void reset ( TokenStream stream ) { super . reset ( stream ) ; typeAttribute = stream . addAttribute ( TypeAttribute . class ) ; } @ Override public void nextToken ( ) throws IOException { anyTokens = true ; BytesRef term = fillBytesRef ( termsRef ) ; if ( ( requireUnigram ) && ( ( typeAttribute . type ( ) ) == ( ShingleFilter . DEFAULT_TOKEN_TYPE ) ) ) { return ; } anyUnigram = true ; if ( ( ( posIncAttr . getPositionIncrement ( ) ) == 0 ) && ( ( typeAttribute . type ( ) ) == ( SynonymFilter . TYPE_SYNONYM ) ) ) { assert ( currentSet ) != null ; long freq = 0 ; if ( ( freq = generator . frequency ( term ) ) > 0 ) { currentSet . addOneCandidate ( generator . createCandidate ( BytesRef . deepCopyOf ( term ) , freq , realWordLikelihood ) ) ; } } else { if ( ( currentSet ) != null ) { candidateSetsList . add ( currentSet ) ; } <START_BUG> currentSet = new CandidateSet ( Candidate . EMPTY , generator . createCandidate ( BytesRef . deepCopyOf ( term ) ) ) ; <END_BUG> } } @ Override public void end ( ) { if ( ( currentSet ) != null ) { candidateSetsList . add ( currentSet ) ; } if ( ( ( requireUnigram ) && ( ! ( anyUnigram ) ) ) && ( anyTokens ) ) { throw new IllegalStateException ( "At<seq2seq4repair_space>least<seq2seq4repair_space>one<seq2seq4repair_space>unigram<seq2seq4repair_space>is<seq2seq4repair_space>required<seq2seq4repair_space>but<seq2seq4repair_space>all<seq2seq4repair_space>tokens<seq2seq4repair_space>were<seq2seq4repair_space>ngrams" ) ; } } } ) ; if ( ( candidateSetsList . isEmpty ( ) ) || ( ( candidateSetsList . size ( ) ) >= ( tokenLimit ) ) ) { return Correction . EMPTY ; } for ( CandidateSet candidateSet : candidateSetsList ) { generator . drawCandidates ( candidateSet ) ; } double cutoffScore = Double . MIN_VALUE ; CandidateScorer scorer = new CandidateScorer ( wordScorer , numCorrections , gramSize ) ; CandidateSet [ ] candidateSets = candidateSetsList . toArray ( new CandidateSet [ candidateSetsList . size ( ) ] ) ; if ( confidence > 0.0 ) { Candidate [ ] candidates = new Candidate [ candidateSets . length ] ; for ( int i = 0 ; i < ( candidates . length ) ; i ++ ) { candidates [ i ] = candidateSets [ i ] . originalTerm ; } cutoffScore = scorer . score ( candidates , candidateSets ) ; } Correction [ ] findBestCandiates = scorer . findBestCandiates ( candidateSets , maxErrors , ( cutoffScore * confidence ) ) ; return findBestCandiates ; } public Correction [ ] getCorrections ( Analyzer analyzer , BytesRef query , CandidateGenerator generator , float maxErrors , int numCorrections , IndexReader reader , String analysisField , WordScorer scorer , float confidence , int gramSize ) throws IOException { } public TokenStream tokenStream ( Analyzer analyzer , BytesRef query , CharsRef spare , String field ) throws IOException { } }<BUG2FIX>currentSet = new CandidateSet ( Candidate . EMPTY , generator . createCandidate ( BytesRef . deepCopyOf ( term ) , true ) ) ;
public abstract class TransportIndicesReplicationOperationAction < Request extends IndicesReplicationOperationRequest , Response extends ActionResponse , IndexRequest extends IndexReplicationOperationRequest , IndexResponse extends ActionResponse , ShardRequest extends ShardReplicationOperationRequest , ShardReplicaRequest extends ShardReplicationOperationRequest , ShardResponse extends ActionResponse > extends TransportAction < Request , Response > { protected final ClusterService clusterService ; protected final TransportIndexReplicationOperationAction < IndexRequest , IndexResponse , ShardRequest , ShardReplicaRequest , ShardResponse > indexAction ; final String transportAction ; @ Inject public TransportIndicesReplicationOperationAction ( Settings settings , TransportService transportService , ClusterService clusterService , ThreadPool threadPool , TransportIndexReplicationOperationAction < IndexRequest , IndexResponse , ShardRequest , ShardReplicaRequest , ShardResponse > indexAction ) { } protected abstract Map < String , Set < String > > resolveRouting ( ClusterState clusterState , Request request ) throws ElasticsearchException { } @ Override protected void doExecute ( final Request request , final ActionListener < Response > listener ) { ClusterState clusterState = clusterService . state ( ) ; ClusterBlockException blockException = checkGlobalBlock ( clusterState , request ) ; if ( blockException != null ) { throw blockException ; } <START_BUG> String [ ] concreteIndices = clusterState . metaData ( ) . concreteIndices ( request . indices ( ) , request . indicesOptions ( ) ) ; <END_BUG> blockException = checkRequestBlock ( clusterState , request , concreteIndices ) ; if ( blockException != null ) { throw blockException ; } final AtomicInteger indexCounter = new AtomicInteger ( ) ; final AtomicInteger completionCounter = new AtomicInteger ( concreteIndices . length ) ; final AtomicReferenceArray < Object > indexResponses = new AtomicReferenceArray < > ( concreteIndices . length ) ; final long startTimeInMillis = System . currentTimeMillis ( ) ; Map < String , Set < String > > routingMap = resolveRouting ( clusterState , request ) ; if ( ( concreteIndices == null ) || ( ( concreteIndices . length ) == 0 ) ) { listener . onResponse ( newResponseInstance ( request , indexResponses ) ) ; } else { for ( final String index : concreteIndices ) { Set < String > routing = null ; if ( routingMap != null ) { routing = routingMap . get ( index ) ; } IndexRequest indexRequest = newIndexRequestInstance ( request , index , routing , startTimeInMillis ) ; indexRequest . listenerThreaded ( false ) ; indexAction . execute ( indexRequest , new ActionListener < IndexResponse > ( ) { @ Override public void onResponse ( IndexResponse result ) { indexResponses . set ( indexCounter . getAndIncrement ( ) , result ) ; if ( ( completionCounter . decrementAndGet ( ) ) == 0 ) { listener . onResponse ( newResponseInstance ( request , indexResponses ) ) ; } } @ Override public void onFailure ( Throwable e ) { int index = indexCounter . getAndIncrement ( ) ; if ( accumulateExceptions ( ) ) { indexResponses . set ( index , e ) ; } if ( ( completionCounter . decrementAndGet ( ) ) == 0 ) { listener . onResponse ( newResponseInstance ( request , indexResponses ) ) ; } } } ) ; } } } protected abstract Request newRequestInstance ( ) { } protected abstract Response newResponseInstance ( Request request , AtomicReferenceArray indexResponses ) { } protected abstract String transportAction ( ) { } protected abstract IndexRequest newIndexRequestInstance ( Request request , String index , Set < String > routing , long startTimeInMillis ) { } protected abstract boolean accumulateExceptions ( ) { } protected abstract ClusterBlockException checkGlobalBlock ( ClusterState state , Request request ) { } protected abstract ClusterBlockException checkRequestBlock ( ClusterState state , Request request , String [ ] concreteIndices ) { } private class TransportHandler extends BaseTransportRequestHandler < Request > { @ Override public Request newInstance ( ) { } @ Override public String executor ( ) { } @ Override public void messageReceived ( final Request request , final TransportChannel channel ) throws Exception { } } }<BUG2FIX>String [ ] concreteIndices = clusterState . metaData ( ) . concreteIndices ( request . indicesOptions ( ) , request . indices ( ) ) ;
public abstract class TransportBroadcastOperationAction < Request extends BroadcastOperationRequest , Response extends BroadcastOperationResponse , ShardRequest extends BroadcastShardOperationRequest , ShardResponse extends BroadcastShardOperationResponse > extends TransportAction < Request , Response > { protected final ClusterService clusterService ; protected final TransportService transportService ; protected final ThreadPool threadPool ; final String transportAction ; final String transportShardAction ; final String executor ; protected TransportBroadcastOperationAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportService transportService ) { } @ Override protected void doExecute ( Request request , ActionListener < Response > listener ) { } protected abstract String transportAction ( ) { } protected abstract String executor ( ) { } protected abstract Request newRequest ( ) { } protected abstract Response newResponse ( Request request , AtomicReferenceArray shardsResponses , ClusterState clusterState ) { } protected abstract ShardRequest newShardRequest ( ) { } protected abstract ShardRequest newShardRequest ( ShardRouting shard , Request request ) { } protected abstract ShardResponse newShardResponse ( ) { } protected abstract ShardResponse shardOperation ( ShardRequest request ) throws ElasticSearchException { } protected abstract GroupShardsIterator shards ( ClusterState clusterState , Request request , String [ ] concreteIndices ) { } protected boolean accumulateExceptions ( ) { } protected boolean ignoreException ( Throwable t ) { } protected boolean ignoreNonActiveExceptions ( ) { } protected boolean ignoreIllegalShardState ( ) { } protected abstract ClusterBlockException checkGlobalBlock ( ClusterState state , Request request ) { } protected abstract ClusterBlockException checkRequestBlock ( ClusterState state , Request request , String [ ] concreteIndices ) { } class AsyncBroadcastAction { private final Request request ; private final ActionListener < Response > listener ; private final ClusterState clusterState ; private final DiscoveryNodes nodes ; private final GroupShardsIterator shardsIts ; private final int expectedOps ; private final AtomicInteger counterOps = new AtomicInteger ( ) ; private final AtomicInteger indexCounter = new AtomicInteger ( ) ; private final AtomicReferenceArray shardsResponses ; AsyncBroadcastAction ( Request request , ActionListener < Response > listener ) { } public void start ( ) { } void performOperation ( final ShardIterator shardIt , boolean localAsync ) { } void performOperation ( final ShardIterator shardIt , final ShardRouting shard , boolean localAsync ) { } @ SuppressWarnings ( { "unchecked" } ) void onOperation ( ShardRouting shard , ShardResponse response ) { } @ SuppressWarnings ( { "unchecked" } ) void onOperation ( @ Nullable ShardRouting shard , final ShardIterator shardIt , Throwable t ) { } void finishHim ( ) { } } class TransportHandler extends BaseTransportRequestHandler < Request > { @ Override public Request newInstance ( ) { } @ Override public String executor ( ) { } @ Override public void messageReceived ( Request request , final TransportChannel channel ) throws Exception { request . listenerThreaded ( false ) ; if ( ( request . operationThreading ( ) ) == ( BroadcastOperationThreading . NO_THREADS ) ) { request . operationThreading ( SINGLE_THREAD ) ; } TransportBroadcastOperationAction . TransportHandler . execute ( request , new ActionListener < Response > ( ) { @ Override public void onResponse ( Response response ) { try { channel . sendResponse ( response ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( e ) ; } catch ( Exception e1 ) { logger . warn ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } } class ShardTransportHandler extends BaseTransportRequestHandler < ShardRequest > { @ Override public ShardRequest newInstance ( ) { } @ Override public String executor ( ) { } @ Override public void messageReceived ( final ShardRequest request , final TransportChannel channel ) throws Exception { } } }<BUG2FIX>} catch ( Throwable e ) {
public class IOSFileHandle extends FileHandle { public IOSFileHandle ( String fileName , FileType type ) { } public IOSFileHandle ( File file , FileType type ) { } public FileHandle child ( String name ) { } public FileHandle parent ( ) { } @ Override public boolean exists ( ) { <START_BUG> return file ( ) . exists ( ) ; <END_BUG> } public File file ( ) { } }<BUG2FIX>return file . exists ( ) ;
public class MembershipAction extends AbstractComponent { public static interface MembershipListener { ClusterState onJoin ( DiscoveryNode node ) { } void onLeave ( DiscoveryNode node ) { } } private final TransportService transportService ; private final DiscoveryNodesProvider nodesProvider ; private final MembershipAction . MembershipListener listener ; public MembershipAction ( Settings settings , TransportService transportService , DiscoveryNodesProvider nodesProvider , MembershipAction . MembershipListener listener ) { } public void close ( ) { } public void sendLeaveRequest ( DiscoveryNode masterNode , DiscoveryNode node ) { } public void sendLeaveRequestBlocking ( DiscoveryNode masterNode , DiscoveryNode node , TimeValue timeout ) throws ElasticSearchException { } public void sendJoinRequest ( DiscoveryNode masterNode , DiscoveryNode node ) { } public ClusterState sendJoinRequestBlocking ( DiscoveryNode masterNode , DiscoveryNode node , TimeValue timeout ) throws ElasticSearchException { } static class JoinRequest implements Streamable { DiscoveryNode node ; boolean withClusterState ; private JoinRequest ( ) { } private JoinRequest ( DiscoveryNode node , boolean withClusterState ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { node = DiscoveryNode . readNode ( in ) ; withClusterState = in . readBoolean ( ) ; } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } class JoinResponse implements Streamable { ClusterState clusterState ; JoinResponse ( ) { } JoinResponse ( ClusterState clusterState ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { <START_BUG> clusterState = Builder . readFrom ( in , settings , nodesProvider . nodes ( ) . localNode ( ) ) ; <END_BUG> } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } private class JoinRequestRequestHandler extends BaseTransportRequestHandler < MembershipAction . JoinRequest > { static final String ACTION = "discovery/zen/join" ; @ Override public MembershipAction . JoinRequest newInstance ( ) { } @ Override public void messageReceived ( MembershipAction . JoinRequest request , TransportChannel channel ) throws Exception { } } private static class LeaveRequest implements Streamable { private DiscoveryNode node ; private LeaveRequest ( ) { } private LeaveRequest ( DiscoveryNode node ) { } @ Override public void readFrom ( StreamInput in ) throws IOException { node = DiscoveryNode . readNode ( in ) ; } @ Override public void writeTo ( StreamOutput out ) throws IOException { } } private class LeaveRequestRequestHandler extends BaseTransportRequestHandler < MembershipAction . LeaveRequest > { static final String ACTION = "discovery/zen/leave" ; @ Override public MembershipAction . LeaveRequest newInstance ( ) { } @ Override public void messageReceived ( MembershipAction . LeaveRequest request , TransportChannel channel ) throws Exception { } } }<BUG2FIX>clusterState = Builder . readFrom ( in , nodesProvider . nodes ( ) . localNode ( ) ) ;
public class TransportSuggestAction extends TransportBroadcastOperationAction < SuggestRequest , SuggestResponse , ShardSuggestRequest , ShardSuggestResponse > { private final IndicesService indicesService ; private final SuggestPhase suggestPhase ; @ Inject public TransportSuggestAction ( Settings settings , ThreadPool threadPool , ClusterService clusterService , TransportService transportService , IndicesService indicesService , SuggestPhase suggestPhase ) { } @ Override protected String executor ( ) { } @ Override protected String transportAction ( ) { } @ Override protected SuggestRequest newRequest ( ) { } @ Override protected ShardSuggestRequest newShardRequest ( ) { } @ Override protected ShardSuggestRequest newShardRequest ( ShardRouting shard , SuggestRequest request ) { } @ Override protected ShardSuggestResponse newShardResponse ( ) { } @ Override protected GroupShardsIterator shards ( ClusterState clusterState , SuggestRequest request , String [ ] concreteIndices ) { } @ Override protected ClusterBlockException checkGlobalBlock ( ClusterState state , SuggestRequest request ) { } @ Override protected ClusterBlockException checkRequestBlock ( ClusterState state , SuggestRequest countRequest , String [ ] concreteIndices ) { } @ Override protected SuggestResponse newResponse ( SuggestRequest request , AtomicReferenceArray shardsResponses , ClusterState clusterState ) { } @ Override protected ShardSuggestResponse shardOperation ( ShardSuggestRequest request ) throws ElasticsearchException { IndexService indexService = indicesService . indexServiceSafe ( request . index ( ) ) ; IndexShard indexShard = indexService . shardSafe ( request . shardId ( ) ) ; final Engine . Searcher searcher = indexShard . acquireSearcher ( "suggest" ) ; ShardSuggestService shardSuggestService = indexShard . shardSuggestService ( ) ; shardSuggestService . preSuggest ( ) ; long startTime = System . nanoTime ( ) ; XContentParser parser = null ; try { BytesReference suggest = request . suggest ( ) ; if ( ( suggest != null ) && ( ( suggest . length ( ) ) > 0 ) ) { parser = XContentFactory . xContent ( suggest ) . createParser ( suggest ) ; if ( ( parser . nextToken ( ) ) != ( Token . START_OBJECT ) ) { throw new ElasticsearchIllegalArgumentException ( "suggest<seq2seq4repair_space>content<seq2seq4repair_space>missing" ) ; } final SuggestionSearchContext context = suggestPhase . parseElement ( ) . parseInternal ( parser , indexService . mapperService ( ) , request . index ( ) , request . shardId ( ) ) ; final Suggest result = suggestPhase . execute ( context , searcher . reader ( ) ) ; return new ShardSuggestResponse ( request . index ( ) , request . shardId ( ) , result ) ; } return new ShardSuggestResponse ( request . index ( ) , request . shardId ( ) , new Suggest ( ) ) ; } catch ( Throwable ex ) { throw new ElasticsearchException ( "failed<seq2seq4repair_space>to<seq2seq4repair_space>execute<seq2seq4repair_space>suggest" , ex ) ; } finally { <START_BUG> searcher . release ( ) ; <END_BUG> if ( parser != null ) { parser . close ( ) ; } shardSuggestService . postSuggest ( ( ( System . nanoTime ( ) ) - startTime ) ) ; } } }<BUG2FIX>searcher . close ( ) ;
public class SimpleTestApplet extends Applet implements InputListener , RenderListener { private static final long serialVersionUID = 2795113572615488100L ; public void init ( ) { } PerspectiveCamera cam ; Mesh mesh ; Texture texture ; float angleY = 0 ; float angleX = 0 ; float [ ] lightColor = new float [ ] { 1 , 1 , 1 , 0 } ; float [ ] lightPosition = new float [ ] { 2 , 5 , 10 , 0 } ; float touchStartX = 0 ; float touchStartY = 0 ; long frameStart ; int frames = 0 ; @ Override public void surfaceCreated ( ) { if ( ( mesh ) == null ) { input . addInputListener ( this ) ; <START_BUG> mesh = ModelLoader . loadObj ( files . readFile ( "data/cube.obj" , Internal ) , true ) ; <END_BUG> texture = graphics . newTexture ( files . getFileHandle ( "data/badlogic.jpd" , Internal ) , MipMap , Linear , ClampToEdge , ClampToEdge ) ; cam = new PerspectiveCamera ( ) ; cam . getPosition ( ) . set ( 2 , 2 , 2 ) ; cam . getDirection ( ) . set ( ( - 1 ) , ( - 1 ) , ( - 1 ) ) ; } frameStart = System . nanoTime ( ) ; } @ Override public void surfaceChanged ( int width , int height ) { } @ Override public void render ( ) { } @ Override public void dispose ( ) { } @ Override public boolean keyDown ( int keycode ) { } @ Override public boolean keyTyped ( char character ) { } @ Override public boolean keyUp ( int keycode ) { } @ Override public boolean touchDown ( int x , int y , int pointer ) { } @ Override public boolean touchDragged ( int x , int y , int pointer ) { } @ Override public boolean touchUp ( int x , int y , int pointer ) { } }<BUG2FIX>mesh = ModelLoader . loadObj ( files . readFile ( "data/cube.obj" , Internal ) ) ;
public class JsonBoostFieldMapper extends JsonNumberFieldMapper < Float > implements BoostFieldMapper { public static final String JSON_TYPE = "boostField" ; public static class Defaults extends JsonNumberFieldMapper . Defaults { public static final String NAME = "_boost" ; public static final Float NULL_VALUE = null ; public static final Index INDEX = Index . NO ; public static final Store STORE = Store . NO ; } public static class Builder extends JsonNumberFieldMapper . Builder < JsonBoostFieldMapper . Builder , JsonBoostFieldMapper > { protected Float nullValue = JsonBoostFieldMapper . Defaults . NULL_VALUE ; public Builder ( String name ) { } public JsonBoostFieldMapper . Builder nullValue ( float nullValue ) { } @ Override public JsonBoostFieldMapper build ( BuilderContext context ) { } } private final Float nullValue ; protected JsonBoostFieldMapper ( ) { } protected JsonBoostFieldMapper ( String name , String indexName ) { } protected JsonBoostFieldMapper ( String name , String indexName , int precisionStep , Field . Index index , Field . Store store , float boost , boolean omitNorms , boolean omitTermFreqAndPositions , Float nullValue ) { } @ Override protected int maxPrecisionStep ( ) { } @ Override public Float value ( Fieldable field ) { byte [ ] value = field . getBinaryValue ( ) ; if ( value == null ) { <START_BUG> return Float . NaN ; <END_BUG> } return Numbers . bytesToFloat ( value ) ; } @ Override public String indexedValue ( String value ) { } @ Override public String indexedValue ( Float value ) { } @ Override public Object valueFromTerm ( String term ) { } @ Override public Object valueFromString ( String text ) { } @ Override public Query rangeQuery ( String lowerTerm , String upperTerm , boolean includeLower , boolean includeUpper ) { } @ Override public Filter rangeFilter ( String lowerTerm , String upperTerm , boolean includeLower , boolean includeUpper ) { } @ Override public void parse ( JsonParseContext jsonContext ) throws IOException { } @ Override protected Field parseCreateField ( JsonParseContext jsonContext ) throws IOException { } private float parseFloatValue ( JsonParseContext jsonContext ) throws IOException { } @ Override public int sortType ( ) { } @ Override protected String jsonType ( ) { } @ Override public void toJson ( JsonBuilder builder , Params params ) throws IOException { } @ Override public void merge ( JsonMapper mergeWith , JsonMergeContext mergeContext ) throws MergeMappingException { } }<BUG2FIX>return null ;
public class CommitUtils { public static final int LENGTH = 10 ; private static final NumberFormat FORMAT = NumberFormat . getIntegerInstance ( ) ; public static String abbreviate ( final RepositoryCommit commit ) { } public static String abbreviate ( final Commit commit ) { } public static String abbreviate ( final String sha ) { } public static boolean isValidCommit ( final String sha ) { } public static String getAuthor ( final RepositoryCommit commit ) { } public static String getCommitter ( final RepositoryCommit commit ) { } public static Date getAuthorDate ( final RepositoryCommit commit ) { } public static Date getCommiterDate ( final RepositoryCommit commit ) { } public static ImageView bindAuthor ( final RepositoryCommit commit , final AvatarLoader avatars , final ImageView view ) { } public static ImageView bindCommitter ( final RepositoryCommit commit , final AvatarLoader avatars , final ImageView view ) { } public static String getCommentCount ( final RepositoryCommit commit ) { } public static StyledText formatStats ( final Collection < CommitFile > files ) { StyledText fileDetails = new StyledText ( ) ; int added = 0 ; int deleted = 0 ; int changed = 0 ; if ( files != null ) for ( CommitFile file : files ) { added += file . getAdditions ( ) ; deleted += file . getDeletions ( ) ; changed ++ ; } <START_BUG> if ( changed > 1 ) <END_BUG> fileDetails . append ( CommitUtils . FORMAT . format ( changed ) ) . append ( "<seq2seq4repair_space>changed<seq2seq4repair_space>files" ) ; else fileDetails . append ( "1<seq2seq4repair_space>changed<seq2seq4repair_space>file" ) ; fileDetails . append ( "<seq2seq4repair_space>with<seq2seq4repair_space>" ) ; if ( added != 1 ) fileDetails . append ( CommitUtils . FORMAT . format ( added ) ) . append ( "<seq2seq4repair_space>additions" ) ; else fileDetails . append ( "1<seq2seq4repair_space>addition<seq2seq4repair_space>" ) ; fileDetails . append ( "<seq2seq4repair_space>and<seq2seq4repair_space>" ) ; if ( deleted != 1 ) fileDetails . append ( CommitUtils . FORMAT . format ( deleted ) ) . append ( "<seq2seq4repair_space>deletions" ) ; else fileDetails . append ( "1<seq2seq4repair_space>deletion" ) ; return fileDetails ; } public static String getName ( final CommitFile file ) { } public static String getName ( final String path ) { } }<BUG2FIX>if ( changed != 1 )
public class IntFloatMap { private static final int PRIME1 = - 1105259343 ; private static final int PRIME2 = - 1262997959 ; private static final int PRIME3 = - 825114047 ; private static final int EMPTY = 0 ; public int size ; int [ ] keyTable ; float [ ] valueTable ; int capacity ; int stashSize ; float zeroValue ; boolean hasZeroValue ; private float loadFactor ; private int hashShift ; private int mask ; private int threshold ; private int stashCapacity ; private int pushIterations ; private IntFloatMap . Entries entries1 ; private IntFloatMap . Entries entries2 ; private IntFloatMap . Values values1 ; private IntFloatMap . Values values2 ; private IntFloatMap . Keys keys1 ; private IntFloatMap . Keys keys2 ; public IntFloatMap ( ) { } public IntFloatMap ( int initialCapacity ) { } public IntFloatMap ( int initialCapacity , float loadFactor ) { } public IntFloatMap ( IntFloatMap map ) { } public void put ( int key , float value ) { } public void putAll ( IntFloatMap map ) { } private void putResize ( int key , float value ) { } private void push ( int insertKey , float insertValue , int index1 , int key1 , int index2 , int key2 , int index3 , int key3 ) { } private void putStash ( int key , float value ) { } public float get ( int key , float defaultValue ) { } private float getStash ( int key , float defaultValue ) { } public float getAndIncrement ( int key , float defaultValue , float increment ) { } private float getAndIncrementStash ( int key , float defaultValue , float increment ) { } public float remove ( int key , float defaultValue ) { } float removeStash ( int key , float defaultValue ) { } void removeStashIndex ( int index ) { } public void shrink ( int maximumCapacity ) { } public void clear ( int maximumCapacity ) { } public void clear ( ) { } public boolean containsValue ( float value ) { } public boolean containsValue ( float value , float epsilon ) { } public boolean containsKey ( int key ) { } private boolean containsKeyStash ( int key ) { } public int findKey ( float value , int notFound ) { } public void ensureCapacity ( int additionalCapacity ) { } private void resize ( int newSize ) { } private int hash2 ( int h ) { } private int hash3 ( int h ) { } public String toString ( ) { } public IntFloatMap . Entries entries ( ) { } public IntFloatMap . Values values ( ) { } public IntFloatMap . Keys keys ( ) { } public static class Entry < K > { public int key ; public float value ; public String toString ( ) { } } private static class MapIterator < K > { static final int INDEX_ILLEGAL = - 2 ; static final int INDEX_ZERO = - 1 ; public boolean hasNext ; final IntFloatMap map ; int nextIndex ; int currentIndex ; boolean valid = true ; public MapIterator ( IntFloatMap map ) { } public void reset ( ) { } void findNextIndex ( ) { } public void remove ( ) { if ( ( ( currentIndex ) == ( IntFloatMap . MapIterator . INDEX_ZERO ) ) && ( map . hasZeroValue ) ) { map . hasZeroValue = false ; } else if ( ( currentIndex ) < 0 ) { throw new IllegalStateException ( "next<seq2seq4repair_space>must<seq2seq4repair_space>be<seq2seq4repair_space>called<seq2seq4repair_space>before<seq2seq4repair_space>remove." ) ; } else if ( ( currentIndex ) >= ( map . capacity ) ) { map . removeStashIndex ( currentIndex ) ; <START_BUG> nextIndex = currentIndex ; <END_BUG> findNextIndex ( ) ; } else { map . keyTable [ currentIndex ] = IntFloatMap . EMPTY ; } currentIndex = IntFloatMap . MapIterator . INDEX_ILLEGAL ; ( map . size ) -- ; } } public static class Entries extends IntFloatMap . MapIterator implements Iterable < IntFloatMap . Entry > , Iterator < IntFloatMap . Entry > { private IntFloatMap . Entry entry = new IntFloatMap . Entry ( ) ; public Entries ( IntFloatMap map ) { } public IntFloatMap . Entry next ( ) { } public boolean hasNext ( ) { } public Iterator < IntFloatMap . Entry > iterator ( ) { } } public static class Values extends IntFloatMap . MapIterator < Object > { public Values ( IntFloatMap map ) { } public boolean hasNext ( ) { } public float next ( ) { } public FloatArray toArray ( ) { } } public static class Keys extends IntFloatMap . MapIterator { public Keys ( IntFloatMap map ) { } public boolean hasNext ( ) { } public int next ( ) { } public IntArray toArray ( ) { } } }<BUG2FIX>nextIndex = ( currentIndex ) - 1 ;
public class WidgetGroup extends Group implements Layout { private boolean needsLayout = true ; private boolean fillParent ; private boolean layoutEnabled = true ; public float getMinWidth ( ) { } public float getMinHeight ( ) { } public float getPrefWidth ( ) { } public float getPrefHeight ( ) { } public float getMaxWidth ( ) { } public float getMaxHeight ( ) { } public void setLayoutEnabled ( boolean enabled ) { } private void setLayoutEnabled ( Group parent , boolean enabled ) { <START_BUG> SnapshotArray < Actor > children = getChildren ( ) ; <END_BUG> for ( int i = 0 , n = children . size ; i < n ; i ++ ) { Actor actor = children . get ( i ) ; if ( actor instanceof Layout ) ( ( Layout ) ( actor ) ) . setLayoutEnabled ( enabled ) ; else if ( actor instanceof Group ) setLayoutEnabled ( ( ( Group ) ( actor ) ) , enabled ) ; } } public void validate ( ) { } public boolean needsLayout ( ) { } public void invalidate ( ) { } public void invalidateHierarchy ( ) { } protected void childrenChanged ( ) { } protected void sizeChanged ( ) { } public void pack ( ) { } public void setFillParent ( boolean fillParent ) { } public void layout ( ) { } public void draw ( Batch batch , float parentAlpha ) { } }<BUG2FIX>SnapshotArray < Actor > children = parent . getChildren ( ) ;
public class EmptyOrdinals implements Ordinals { private final int numDocs ; public EmptyOrdinals ( int numDocs ) { } @ Override public long getMemorySizeInBytes ( ) { } @ Override public Object getBackingStorage ( ) { } @ Override public boolean isMultiValued ( ) { } @ Override public int getNumDocs ( ) { } @ Override public int getNumOrds ( ) { <START_BUG> return ( numDocs ) + 1 ; <END_BUG> } @ Override public EmptyOrdinals . Docs ordinals ( ) { } public static class Docs implements Ordinals . Docs { private final EmptyOrdinals parent ; public Docs ( EmptyOrdinals parent ) { } @ Override public Ordinals ordinals ( ) { } @ Override public int getNumDocs ( ) { } @ Override public int getNumOrds ( ) { return parent . getNumOrds ( ) ; } @ Override public boolean isMultiValued ( ) { } @ Override public int getOrd ( int docId ) { } @ Override public IntArrayRef getOrds ( int docId ) { } @ Override public Iter getIter ( int docId ) { } @ Override public void forEachOrdinalInDoc ( int docId , OrdinalInDocProc proc ) { } } }<BUG2FIX>return 1 ;
public class FieldLookup { private final FieldMapper mapper ; private Document doc ; private Object value ; private boolean valueLoaded = false ; private List < Object > values = new ArrayList < Object > ( ) ; private boolean valuesLoaded = false ; FieldLookup ( FieldMapper mapper ) { } public FieldMapper mapper ( ) { } public Document doc ( ) { } public void doc ( Document doc ) { } public void clear ( ) { value = null ; valueLoaded = false ; values . clear ( ) ; <START_BUG> valuesLoaded = true ; <END_BUG> doc = null ; } public boolean isEmpty ( ) { } public Object getValue ( ) { } public List < Object > getValues ( ) { } }<BUG2FIX>valuesLoaded = false ;
public class StageTest extends GdxTest implements InputProcessor { private static final int NUM_GROUPS = 5 ; private static final int NUM_SPRITES = ( ( int ) ( Math . sqrt ( ( 400 / ( StageTest . NUM_GROUPS ) ) ) ) ) ; private static final float SPACING = 5 ; ShapeRenderer renderer ; Stage stage ; Stage ui ; Texture texture ; Texture uiTexture ; BitmapFont font ; boolean rotateSprites = false ; boolean scaleSprites = false ; float angle ; List < Image > images = new ArrayList < Image > ( ) ; float scale = 1 ; float vScale = 1 ; Label fps ; @ Override public void create ( ) { } private void fillGroup ( Group group , Texture texture ) { } @ Override public void render ( ) { gl . glViewport ( 0 , 0 , graphics . getWidth ( ) , graphics . getHeight ( ) ) ; gl . glClearColor ( 0.2F , 0.2F , 0.2F , 1 ) ; gl . glClear ( GL_COLOR_BUFFER_BIT ) ; if ( input . isTouched ( ) ) { Vector2 stageCoords = Vector2 . tmp ; stage . screenToStageCoordinates ( stageCoords . set ( input . getX ( ) , input . getY ( ) ) ) ; <START_BUG> Actor actor = stage . hit ( stageCoords . x , stageCoords . y , true ) ; <END_BUG> if ( actor instanceof Image ) ( ( Image ) ( actor ) ) . setColor ( ( ( float ) ( Math . random ( ) ) ) , ( ( float ) ( Math . random ( ) ) ) , ( ( float ) ( Math . random ( ) ) ) , ( 0.5F + ( 0.5F * ( ( float ) ( Math . random ( ) ) ) ) ) ) ; } Array < Actor > actors = stage . getActors ( ) ; int len = actors . size ; if ( rotateSprites ) { for ( int i = 0 ; i < len ; i ++ ) actors . get ( i ) . rotate ( ( ( graphics . getDeltaTime ( ) ) * 10 ) ) ; } scale += ( vScale ) * ( graphics . getDeltaTime ( ) ) ; if ( ( scale ) > 1 ) { scale = 1 ; vScale = - ( vScale ) ; } if ( ( scale ) < 0.5F ) { scale = 0.5F ; vScale = - ( vScale ) ; } len = images . size ( ) ; for ( int i = 0 ; i < len ; i ++ ) { Image img = images . get ( i ) ; if ( rotateSprites ) img . rotate ( ( ( - 40 ) * ( graphics . getDeltaTime ( ) ) ) ) ; else img . setRotation ( 0 ) ; if ( scaleSprites ) { img . setScale ( scale ) ; } else { img . setScale ( 1 ) ; } img . invalidate ( ) ; } stage . draw ( ) ; renderer . begin ( Point ) ; renderer . setColor ( 1 , 0 , 0 , 1 ) ; len = actors . size ; for ( int i = 0 ; i < len ; i ++ ) { Group group = ( ( Group ) ( actors . get ( i ) ) ) ; renderer . point ( ( ( group . getX ( ) ) + ( group . getOriginX ( ) ) ) , ( ( group . getY ( ) ) + ( group . getOriginY ( ) ) ) , 0 ) ; } renderer . end ( ) ; fps . setText ( ( ( ( ( ( "fps:<seq2seq4repair_space>" + ( graphics . getFramesPerSecond ( ) ) ) + ",<seq2seq4repair_space>actors<seq2seq4repair_space>" ) + ( images . size ( ) ) ) + ",<seq2seq4repair_space>groups<seq2seq4repair_space>" ) + ( actors . size ) ) ) ; ui . draw ( ) ; } @ Override public boolean touchDown ( int x , int y , int pointer , int button ) { } @ Override public void dispose ( ) { } }<BUG2FIX>Actor actor = stage . hit ( stageCoords . x , stageCoords . y ) ;
public class RestGetMappingAction extends BaseRestHandler { @ Inject public RestGetMappingAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { final String [ ] indices = splitIndices ( request . param ( "index" ) ) ; final Set < String > types = ImmutableSet . copyOf ( splitTypes ( request . param ( "type" ) ) ) ; ClusterStateRequest clusterStateRequest = Requests . clusterStateRequest ( ) . filterRoutingTable ( true ) . filterNodes ( true ) . filteredIndices ( indices ) ; clusterStateRequest . listenerThreaded ( false ) ; client . admin ( ) . cluster ( ) . state ( clusterStateRequest , new org . elasticsearch . action . ActionListener < ClusterStateResponse > ( ) { @ Override public void onResponse ( ClusterStateResponse response ) { try { boolean foundAny = false ; MetaData metaData = response . getState ( ) . metaData ( ) ; XContentBuilder builder = RestXContentBuilder . restContentBuilder ( request ) ; builder . startObject ( ) ; if ( ( ( indices . length ) == 1 ) && ( metaData . indices ( ) . isEmpty ( ) ) ) { channel . sendResponse ( new XContentThrowableRestResponse ( request , new org . elasticsearch . indices . IndexMissingException ( new Index ( indices [ 0 ] ) ) ) ) ; return ; } if ( ( ( indices . length ) == 1 ) && ( ( types . size ( ) ) == 1 ) ) { boolean foundType = false ; IndexMetaData indexMetaData = metaData . iterator ( ) . next ( ) ; for ( MappingMetaData mappingMd : indexMetaData . mappings ( ) . values ( ) ) { if ( ( ! ( types . isEmpty ( ) ) ) && ( ! ( types . contains ( mappingMd . type ( ) ) ) ) ) { continue ; } foundAny = true ; foundType = true ; builder . field ( mappingMd . type ( ) ) ; builder . map ( mappingMd . sourceAsMap ( ) ) ; } if ( ! foundType ) { channel . sendResponse ( new XContentThrowableRestResponse ( request , new org . elasticsearch . indices . TypeMissingException ( new Index ( indices [ 0 ] ) , types . iterator ( ) . next ( ) ) ) ) ; return ; } } else { for ( IndexMetaData indexMetaData : metaData ) { builder . startObject ( indexMetaData . index ( ) , NONE ) ; for ( MappingMetaData mappingMd : indexMetaData . mappings ( ) . values ( ) ) { if ( ( ! ( types . isEmpty ( ) ) ) && ( ! ( types . contains ( mappingMd . type ( ) ) ) ) ) { continue ; } foundAny = true ; builder . field ( mappingMd . type ( ) ) ; builder . map ( mappingMd . sourceAsMap ( ) ) ; } if ( ( indexMetaData . mappings ( ) . values ( ) . isEmpty ( ) ) && ( types . isEmpty ( ) ) ) { foundAny = true ; } builder . endObject ( ) ; } } builder . endObject ( ) ; channel . sendResponse ( new XContentRestResponse ( request , ( foundAny || ( ( indices . length ) == 0 ) ? RestStatus . OK : RestStatus . NOT_FOUND ) , builder ) ) ; <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class InternalClusterService extends AbstractLifecycleComponent < ClusterService > implements ClusterService { private final TimeValue timeoutInterval ; private final ThreadPool threadPool ; private final DiscoveryService discoveryService ; private final TransportService transportService ; private volatile ExecutorService updateTasksExecutor ; private final List < ClusterStateListener > clusterStateListeners = new CopyOnWriteArrayList < ClusterStateListener > ( ) ; private final List < InternalClusterService . TimeoutHolder > clusterStateTimeoutListeners = new CopyOnWriteArrayList < InternalClusterService . TimeoutHolder > ( ) ; private volatile ScheduledFuture scheduledFuture ; private volatile ClusterState . ClusterState clusterState = newClusterStateBuilder ( ) . build ( ) ; @ Inject public InternalClusterService ( Settings settings , DiscoveryService discoveryService , TransportService transportService , ThreadPool threadPool ) { } @ Override protected void doStart ( ) throws ElasticSearchException { } @ Override protected void doStop ( ) throws ElasticSearchException { } @ Override protected void doClose ( ) throws ElasticSearchException { } public ClusterState . ClusterState state ( ) { } public void add ( ClusterStateListener listener ) { } public void remove ( ClusterStateListener listener ) { } public void add ( TimeValue timeout , TimeoutClusterStateListener listener ) { } public void remove ( TimeoutClusterStateListener listener ) { } public void submitStateUpdateTask ( final String source , final ClusterStateUpdateTask updateTask ) { if ( ! ( lifecycle . started ( ) ) ) { return ; } updateTasksExecutor . execute ( new Runnable ( ) { @ Override public void run ( ) { if ( ! ( lifecycle . started ( ) ) ) { return ; } ClusterState . ClusterState previousClusterState = clusterState ; try { clusterState = updateTask . execute ( previousClusterState ) ; } catch ( Exception e ) { StringBuilder sb = new StringBuilder ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>execute<seq2seq4repair_space>cluster<seq2seq4repair_space>state<seq2seq4repair_space>update,<seq2seq4repair_space>state:\nVersion<seq2seq4repair_space>[" ) . append ( clusterState . version ( ) ) . append ( "],<seq2seq4repair_space>source<seq2seq4repair_space>[" ) . append ( source ) . append ( "]\n" ) ; sb . append ( clusterState . nodes ( ) . prettyPrint ( ) ) ; sb . append ( clusterState . routingTable ( ) . prettyPrint ( ) ) ; sb . append ( clusterState . readOnlyRoutingNodes ( ) . prettyPrint ( ) ) ; logger . warn ( sb . toString ( ) , e ) ; return ; } if ( previousClusterState != ( clusterState ) ) { if ( clusterState . nodes ( ) . localNodeMaster ( ) ) { clusterState = new ClusterState . ClusterState ( ( ( clusterState . version ( ) ) + 1 ) , clusterState . metaData ( ) , clusterState . routingTable ( ) , clusterState . nodes ( ) ) ; } else { if ( ( clusterState . version ( ) ) < ( previousClusterState . version ( ) ) ) { logger . info ( ( ( ( ( ( ( "Got<seq2seq4repair_space>old<seq2seq4repair_space>cluster<seq2seq4repair_space>state<seq2seq4repair_space>[" + ( clusterState . version ( ) ) ) + "<" ) + ( previousClusterState . version ( ) ) ) + "]<seq2seq4repair_space>from<seq2seq4repair_space>source<seq2seq4repair_space>[" ) + source ) + "],<seq2seq4repair_space>ignoring" ) ) ; return ; } } if ( logger . isTraceEnabled ( ) ) { StringBuilder sb = new StringBuilder ( "Cluster<seq2seq4repair_space>State<seq2seq4repair_space>updated:\nVersion<seq2seq4repair_space>[" ) . append ( clusterState . version ( ) ) . append ( "],<seq2seq4repair_space>source<seq2seq4repair_space>[" ) . append ( source ) . append ( "]\n" ) ; sb . append ( clusterState . nodes ( ) . prettyPrint ( ) ) ; sb . append ( clusterState . routingTable ( ) . prettyPrint ( ) ) ; sb . append ( clusterState . readOnlyRoutingNodes ( ) . prettyPrint ( ) ) ; logger . trace ( sb . toString ( ) ) ; } else if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Cluster<seq2seq4repair_space>state<seq2seq4repair_space>updated,<seq2seq4repair_space>version<seq2seq4repair_space>[{}],<seq2seq4repair_space>source<seq2seq4repair_space>[{}]" , clusterState . version ( ) , source ) ; } <START_BUG> ClusterChangedEvent clusterChangedEvent = new ClusterChangedEvent ( source , clusterState , previousClusterState , discoveryService . firstMaster ( ) ) ; <END_BUG> final DiscoveryNodes . Delta nodesDelta = clusterChangedEvent . nodesDelta ( ) ; if ( ( nodesDelta . hasChanges ( ) ) && ( logger . isInfoEnabled ( ) ) ) { String summary = nodesDelta . shortSummary ( ) ; if ( ( summary . length ( ) ) > 0 ) { logger . info ( "{},<seq2seq4repair_space>Reason:<seq2seq4repair_space>{}" , summary , source ) ; } } for ( DiscoveryNode node : nodesDelta . addedNodes ( ) ) { try { transportService . connectToNode ( node ) ; } catch ( Exception e ) { logger . warn ( ( ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>connect<seq2seq4repair_space>to<seq2seq4repair_space>node<seq2seq4repair_space>[" + node ) + "]" ) , e ) ; } } for ( InternalClusterService . TimeoutHolder timeoutHolder : clusterStateTimeoutListeners ) { timeoutHolder . listener . clusterChanged ( clusterChangedEvent ) ; } for ( ClusterStateListener listener : clusterStateListeners ) { listener . clusterChanged ( clusterChangedEvent ) ; } threadPool . execute ( new Runnable ( ) { @ Override public void run ( ) { for ( DiscoveryNode node : nodesDelta . removedNodes ( ) ) { transportService . disconnectFromNode ( node ) ; } } } ) ; if ( clusterState . nodes ( ) . localNodeMaster ( ) ) { discoveryService . publish ( clusterState ) ; } if ( updateTask instanceof ProcessedClusterStateUpdateTask ) { ( ( ProcessedClusterStateUpdateTask ) ( updateTask ) ) . clusterStateProcessed ( clusterState ) ; } } } } ) ; } private static class TimeoutHolder { final TimeoutClusterStateListener listener ; final long timestamp ; final TimeValue timeout ; private TimeoutHolder ( TimeoutClusterStateListener listener , long timestamp , TimeValue timeout ) { } @ Override public int hashCode ( ) { } @ Override public boolean equals ( Object obj ) { } } }<BUG2FIX>ClusterChangedEvent clusterChangedEvent = new ClusterChangedEvent ( source , clusterState , previousClusterState ) ;
public class RestGetAction extends BaseRestHandler { @ Inject public RestGetAction ( Settings settings , Client client , RestController controller ) { } @ Override public void handleRequest ( final RestRequest request , final RestChannel channel ) { final GetRequest getRequest = new GetRequest ( request . param ( "index" ) , request . param ( "type" ) , request . param ( "id" ) ) ; getRequest . listenerThreaded ( false ) ; getRequest . operationThreaded ( true ) ; getRequest . refresh ( request . paramAsBoolean ( "refresh" , getRequest . refresh ( ) ) ) ; getRequest . routing ( request . param ( "routing" ) ) ; getRequest . parent ( request . param ( "parent" ) ) ; getRequest . preference ( request . param ( "preference" ) ) ; getRequest . realtime ( request . paramAsBooleanOptional ( "realtime" , null ) ) ; String sField = request . param ( "fields" ) ; if ( sField != null ) { String [ ] sFields = Strings . splitStringByCommaToArray ( sField ) ; if ( sFields != null ) { getRequest . fields ( sFields ) ; } } client . get ( getRequest , new org . elasticsearch . action . ActionListener < GetResponse > ( ) { @ Override public void onResponse ( GetResponse response ) { try { XContentBuilder builder = restContentBuilder ( request ) ; response . toXContent ( builder , request ) ; if ( ! ( response . isExists ( ) ) ) { channel . sendResponse ( new XContentRestResponse ( request , RestStatus . NOT_FOUND , builder ) ) ; } else { channel . sendResponse ( new XContentRestResponse ( request , RestStatus . OK , builder ) ) ; } <START_BUG> } catch ( Exception e ) { <END_BUG> onFailure ( e ) ; } } @ Override public void onFailure ( Throwable e ) { try { channel . sendResponse ( new XContentThrowableRestResponse ( request , e ) ) ; } catch ( IOException e1 ) { logger . error ( "Failed<seq2seq4repair_space>to<seq2seq4repair_space>send<seq2seq4repair_space>failure<seq2seq4repair_space>response" , e1 ) ; } } } ) ; } }<BUG2FIX>} catch ( Throwable e ) {
public class SearchSourceBuilder { public static SearchSourceBuilder searchSource ( ) { } public static SearchSourceFacetsBuilder facets ( ) { } public static SearchSourceHighlightBuilder highlight ( ) { } private JsonQueryBuilder queryBuilder ; private int from = - 1 ; private int size = - 1 ; private String queryParserName ; private Boolean explain ; private List < SearchSourceBuilder . SortTuple > sortFields ; private List < String > fieldNames ; private SearchSourceFacetsBuilder facetsBuilder ; private SearchSourceHighlightBuilder highlightBuilder ; private TObjectFloatHashMap < String > indexBoost = null ; public SearchSourceBuilder ( ) { } public SearchSourceBuilder query ( JsonQueryBuilder query ) { } public SearchSourceBuilder from ( int from ) { } public SearchSourceBuilder size ( int size ) { } public SearchSourceBuilder queryParserName ( String queryParserName ) { } <START_BUG> public SearchSourceBuilder explain ( boolean explain ) { <END_BUG> this . explain = explain ; return this ; } public SearchSourceBuilder sort ( String name , boolean reverse ) { } public SearchSourceBuilder sort ( String name ) { } public SearchSourceBuilder sort ( String name , String type ) { } public SearchSourceBuilder sort ( String name , String type , boolean reverse ) { } public SearchSourceBuilder facets ( SearchSourceFacetsBuilder facetsBuilder ) { } public SearchSourceBuilder highlight ( SearchSourceHighlightBuilder highlightBuilder ) { } public SearchSourceBuilder fields ( List < String > fields ) { } public SearchSourceBuilder field ( String name ) { } public SearchSourceBuilder indexBoost ( String index , float indexBoost ) { } public byte [ ] build ( ) throws SearchException { } private static class SortTuple { private final String fieldName ; private final boolean reverse ; private final String type ; private SortTuple ( String fieldName , boolean reverse , String type ) { } public String fieldName ( ) { } public boolean reverse ( ) { } public String type ( ) { } } }<BUG2FIX>public SearchSourceBuilder explain ( Boolean explain ) {
